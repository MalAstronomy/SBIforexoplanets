{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to count the number of parameters\n",
    "def get_n_params(model): \n",
    "    np = 0\n",
    "    for p in list(model.parameters()):\n",
    "        np+= p.nelement()\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malavika/anaconda3/envs/petitRT/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729138878/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/malavika/Documents/Research/assessment/training'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"/home/malavika/Documents/Research/assessment/datasets/6params_train_bce_1M2.h5\"\n",
    "#path_to_file = \"/home/malavika/Documents/Research/assessment/datasets/10params_train_bce_1M2.h5\"\n",
    "\n",
    "params = '6'\n",
    "\n",
    "with h5py.File(path_to_file, 'r') as hdf:\n",
    "    data = np.array(hdf.get('data')).astype(np.float32)\n",
    "    label = np.array(hdf.get('labels')).astype(np.float32)\n",
    "\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221852, 377)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "a_min = np.min(data)\n",
    "a_max = np.max(data)\n",
    "data_norm = (data-a_min)/(a_max-a_min)\n",
    "\n",
    "#Tensor\n",
    "target = torch.from_numpy(label)\n",
    "inpt = torch.from_numpy(data_norm)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = inpt\n",
    "        self.target = target\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index] \n",
    "        x = x[np.newaxis, ...] # To specify the number of channels c (here c=1)\n",
    "        y = self.target[index]\n",
    "        \n",
    "        return {'input': x, 'target': y}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "dataset = MyDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = [0.9, 0.1]\n",
    "split_train = '0.9'\n",
    "batch_size = 128 \n",
    "indices = list(range(len(dataset)))\n",
    "s = int(np.floor(split[1] * len(dataset)))\n",
    "\n",
    "#shuffling\n",
    "np.random.seed(111)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[s:], indices[:s]\n",
    "\n",
    "train_sampler, val_sampler = SubsetRandomSampler(train_indices), SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, sampler=train_sampler)\n",
    "val_dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1560"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([221852, 377])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_dataloader.dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(train_dataloader.dataset.data)[1]\n",
    "f = np.shape(train_dataloader.dataset.data)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "dataloaders['train'], dataloaders['val'] = train_dataloader, val_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1560"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221852"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['train'].dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, sample in enumerate(dataloaders['train']):\n",
    "#     print(len(dataloaders['train'].dataset))\n",
    "#     print(len(dataloaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, n_feature, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(n_feature , n_feature, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(128*42, 128)\n",
    "        self.fc2 = nn.Linear(128,1)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = max_pool1d(x,kernel_size=2)\n",
    "        x = self.conv2(x)\n",
    "        x = max_pool1d(x,kernel_size=2)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(-1, self.n_feature*4*4)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(f, 100) \n",
    "        self.layer_2 = nn.Linear(100, 32)\n",
    "        self.layer_out = nn.Linear(32, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(1)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(32)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.layer_out(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    #layer, relu, bn, dp\n",
    "    \n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "                           \n",
    "    def get_weights(self):\n",
    "        return self.weight\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = F.sigmoid(self.fc2(out)) #sigmoid as we use BCELoss\n",
    "        return out\n",
    "    \n",
    "##############################################################################################################\n",
    "# looping networks\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        current_dim = input_dim\n",
    "        self.layers = nn.ModuleList()\n",
    "        for hdim in hidden_dim:\n",
    "            self.layers.append(nn.Linear(current_dim, hdim))\n",
    "            current_dim = hdim\n",
    "        self.layers.append(nn.Linear(current_dim, output_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        out = F.sigmoid(self.layers[-1](x))\n",
    "        return out\n",
    "\n",
    "class CNNet(nn.Module):\n",
    "\n",
    "    def op_size_formula(self, f, ks , ksp, s=1, p=0 , d=1):\n",
    "        return round((((f + (2*p) - (d * (ks-1)) -1)/s) +1)/ksp)\n",
    "\n",
    "    def __init__(self, cnn_params, linear_params):\n",
    "        super(CNNet, self).__init__()\n",
    "        self.cnn_params = cnn_params\n",
    "        self.cnn_layers = nn.ModuleList()\n",
    "        \n",
    "        self.opsize = 371 + int(params)\n",
    "        for l in range(len(self.cnn_params['ip_ch'])):\n",
    "            self.cnn_layers.append(self.layer_method(l))\n",
    "            if l>0: \n",
    "                self.opsize = self.op_size_formula(self.opsize, self.cnn_params['kernel_size'][l-1], \\\n",
    "                                               self.cnn_params['kernel_size_pool'][l-1])\n",
    "            \n",
    "        self.linear_params = linear_params\n",
    "        current_dim = self.opsize * self.cnn_params['op_ch'][-2]                      #linear_params['input_dim']\n",
    "        self.linear_layers = nn.ModuleList()\n",
    "        for hdim in linear_params['hidden_dim']:\n",
    "            self.linear_layers.append(nn.Linear(current_dim, hdim))\n",
    "            current_dim = hdim\n",
    "        self.linear_layers.append(nn.Linear(current_dim, linear_params['output_dim']))\n",
    "\n",
    "    def layer_method(self,l): \n",
    "        \n",
    "        cnn_layer = nn.Sequential(nn.Conv1d(self.cnn_params['ip_ch'][l],\n",
    "                                            self.cnn_params['op_ch'][l], \n",
    "                                            self.cnn_params['kernel_size'][l]),\n",
    "                              nn.ReLU(),\n",
    "                              nn.MaxPool1d(self.cnn_params['kernel_size_pool'][l])\n",
    "                             )\n",
    "        return cnn_layer\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.cnn_layers[:-1]:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = F.relu(layer(x))                         #add a droupout if necessary\n",
    "        out = F.sigmoid(self.linear_layers[-1](x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_size_formula(f, ks , ksp, s=1, p=0 , d=1):\n",
    "        return round((((f + (2*p) - (d * (ks-1)) -1)/s) +1)/ksp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0 377\n",
      "layer 1 126\n",
      "layer 2 42\n",
      "layer 3 14\n",
      "layer 4 5\n",
      "layer 5 2\n",
      "layer 6 1\n"
     ]
    }
   ],
   "source": [
    "x=f\n",
    "for i in range(7):\n",
    "    print('layer '+ str(i), round(x))\n",
    "    x = op_size_formula(x, 3, 1, 3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "\n",
    "def train(n_epochs, model):\n",
    "    \n",
    "    best_loss = 0.0\n",
    "    for epoch in range(n_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            \n",
    "            \n",
    "            #both    \n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for batch_idx, sample in enumerate(dataloaders[phase]):\n",
    "                inputs = sample['input'].to(device)\n",
    "                target = sample['target'].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(torch.squeeze(output), torch.squeeze(target))\n",
    "                    acc = binary_acc(torch.squeeze(output), torch.squeeze(target))\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()   \n",
    "                \n",
    "                    running_loss += 1 * loss.item() * inputs.size(0) #loss for the phase/whole dataset\n",
    "\n",
    "                if batch_idx % 100 == 0: \n",
    "                    print('{} epoch: {} [{}/{} ({:0.0f}%)]\\tLoss: {:.6f}\\tAcc: {:.2f}'.format(\\\n",
    "                    phase,epoch,(batch_idx+1)*len(sample['input']),len(dataloaders[phase].dataset),\\\n",
    "                    100.* ((batch_idx+1)*len(sample['input']))/len(dataloaders[phase].dataset),loss.item(), acc))\n",
    "    \n",
    "            if phase == 'train':\n",
    "                metrics[phase+'_loss'].append(running_loss/int(dataset_size*split[0]))\n",
    "            else:\n",
    "                metrics[phase+'_loss'].append(running_loss/int(dataset_size*split[1]))\n",
    "\n",
    "            if phase == 'val': \n",
    "                if epoch ==  (n_epochs-1) or running_loss < best_loss:\n",
    "                    print('saving')\n",
    "                    best_loss = running_loss\n",
    "                    model_path = os.path.join(model_dir, 'model.pth')\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "                    \n",
    "        with open(metrics_path, 'w') as f:\n",
    "            json.dump(metrics, f, indent=4)\n",
    "                    \n",
    "#         print('--------------------------------------------------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "nb_epoch = 200\n",
    "optimizer_name = 'Adam'\n",
    "dl_arch = 'CNN'\n",
    "metric = 'bce'\n",
    "LEARNING_RATE = 0.001\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model_path = '/home/malavika/Documents/Research/assessment/models/model1/'\n",
    "model_name = 'model_'+params+'_spectra'+str(dataset_size)+'_split'+split_train+'_bs'+str(batch_size)+'_Loss'+\\\n",
    "            metric+'_opt'+str(optimizer_name)+'_lr'+str(LEARNING_RATE)+'_ep'+str(nb_epoch)+'_'+dl_arch\n",
    "\n",
    "#hidden layers\n",
    "\n",
    "hl2 = [128,32]\n",
    "hl3 = [128,32,8]\n",
    "hl4 = [128,64,32,8]\n",
    "hl5 = [128,64,32,16,8]\n",
    "hl6 = [128,64,32,16,8,4]\n",
    "\n",
    "HL = [hl2, hl3, hl4, hl5, hl6] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary 2hl\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 128]          48,384\n",
      "            Linear-2                [-1, 1, 32]           4,128\n",
      "            Linear-3                 [-1, 1, 1]              33\n",
      "================================================================\n",
      "Total params: 52,545\n",
      "Trainable params: 52,545\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.20\n",
      "Estimated Total Size (MB): 0.20\n",
      "----------------------------------------------------------------\n",
      "summary 3hl\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 128]          48,384\n",
      "            Linear-2                [-1, 1, 32]           4,128\n",
      "            Linear-3                 [-1, 1, 8]             264\n",
      "            Linear-4                 [-1, 1, 1]               9\n",
      "================================================================\n",
      "Total params: 52,785\n",
      "Trainable params: 52,785\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.20\n",
      "Estimated Total Size (MB): 0.20\n",
      "----------------------------------------------------------------\n",
      "summary 4hl\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 128]          48,384\n",
      "            Linear-2                [-1, 1, 64]           8,256\n",
      "            Linear-3                [-1, 1, 32]           2,080\n",
      "            Linear-4                 [-1, 1, 8]             264\n",
      "            Linear-5                 [-1, 1, 1]               9\n",
      "================================================================\n",
      "Total params: 58,993\n",
      "Trainable params: 58,993\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.23\n",
      "Estimated Total Size (MB): 0.23\n",
      "----------------------------------------------------------------\n",
      "summary 5hl\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 128]          48,384\n",
      "            Linear-2                [-1, 1, 64]           8,256\n",
      "            Linear-3                [-1, 1, 32]           2,080\n",
      "            Linear-4                [-1, 1, 16]             528\n",
      "            Linear-5                 [-1, 1, 8]             136\n",
      "            Linear-6                 [-1, 1, 1]               9\n",
      "================================================================\n",
      "Total params: 59,393\n",
      "Trainable params: 59,393\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.23\n",
      "Estimated Total Size (MB): 0.23\n",
      "----------------------------------------------------------------\n",
      "summary 6hl\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 128]          48,384\n",
      "            Linear-2                [-1, 1, 64]           8,256\n",
      "            Linear-3                [-1, 1, 32]           2,080\n",
      "            Linear-4                [-1, 1, 16]             528\n",
      "            Linear-5                 [-1, 1, 8]             136\n",
      "            Linear-6                 [-1, 1, 4]              36\n",
      "            Linear-7                 [-1, 1, 1]               5\n",
      "================================================================\n",
      "Total params: 59,425\n",
      "Trainable params: 59,425\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.23\n",
      "Estimated Total Size (MB): 0.23\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#for MLP only\n",
    "\n",
    "for hl in HL:\n",
    "    model_loop = Net(f, 1, hl)\n",
    "#     model_loop.to(device)\n",
    "    print('summary '+ str(len(hl))+'hl')\n",
    "    summary(model_loop, (1, f))\n",
    "#     optimizer = optim.Adam(model_loop.parameters(), lr=float(LEARNING_RATE))\n",
    "    \n",
    "#     layers= str(len(hl))+'hl'\n",
    "#     model_dir = model_path + model_name+'_'+layers\n",
    "    \n",
    "#     if not os.path.exists(model_dir):\n",
    "#             os.makedirs(model_dir)    \n",
    "#     metrics_path = os.path.join(model_dir, 'metrics.json')\n",
    "    \n",
    "#     metrics = {\n",
    "#         'model': model_dir,\n",
    "#         'optimizer': optimizer.__class__.__name__,\n",
    "#         'criterion': criterion.__class__.__name__,\n",
    "#     #     'scheduler': scheduler.__class__.__name__,\n",
    "#         'dataset_size': int(len(dataset)),\n",
    "#         'train_size': int(split[0]*len(dataset)),\n",
    "#         'test_size': int(split[1]*len(dataset)),\n",
    "#         'n_epoch': nb_epoch,\n",
    "#         'batch_size': batch_size,\n",
    "#     #     'learning_rate': [],\n",
    "#         'train_loss': [],\n",
    "#         'val_loss': []\n",
    "#     }\n",
    "    \n",
    "#     train(nb_epoch, model_loop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary 2cnnl_4hl\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 5, 375]              20\n",
      "              ReLU-2               [-1, 5, 375]               0\n",
      "         MaxPool1d-3               [-1, 5, 125]               0\n",
      "            Linear-4                  [-1, 128]          80,128\n",
      "            Linear-5                   [-1, 64]           8,256\n",
      "            Linear-6                   [-1, 32]           2,080\n",
      "            Linear-7                    [-1, 8]             264\n",
      "            Linear-8                    [-1, 1]               9\n",
      "================================================================\n",
      "Total params: 90,757\n",
      "Trainable params: 90,757\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.35\n",
      "Estimated Total Size (MB): 0.38\n",
      "----------------------------------------------------------------\n",
      "summary 3cnnl_4hl\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 5, 375]              20\n",
      "              ReLU-2               [-1, 5, 375]               0\n",
      "         MaxPool1d-3               [-1, 5, 125]               0\n",
      "            Conv1d-4              [-1, 10, 123]             160\n",
      "              ReLU-5              [-1, 10, 123]               0\n",
      "         MaxPool1d-6               [-1, 10, 41]               0\n",
      "            Linear-7                  [-1, 128]          52,608\n",
      "            Linear-8                   [-1, 64]           8,256\n",
      "            Linear-9                   [-1, 32]           2,080\n",
      "           Linear-10                    [-1, 8]             264\n",
      "           Linear-11                    [-1, 1]               9\n",
      "================================================================\n",
      "Total params: 63,397\n",
      "Trainable params: 63,397\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.30\n",
      "----------------------------------------------------------------\n",
      "summary 4cnnl_4hl\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 5, 375]              20\n",
      "              ReLU-2               [-1, 5, 375]               0\n",
      "         MaxPool1d-3               [-1, 5, 125]               0\n",
      "            Conv1d-4              [-1, 10, 123]             160\n",
      "              ReLU-5              [-1, 10, 123]               0\n",
      "         MaxPool1d-6               [-1, 10, 41]               0\n",
      "            Conv1d-7               [-1, 15, 39]             465\n",
      "              ReLU-8               [-1, 15, 39]               0\n",
      "         MaxPool1d-9               [-1, 15, 13]               0\n",
      "           Linear-10                  [-1, 128]          25,088\n",
      "           Linear-11                   [-1, 64]           8,256\n",
      "           Linear-12                   [-1, 32]           2,080\n",
      "           Linear-13                    [-1, 8]             264\n",
      "           Linear-14                    [-1, 1]               9\n",
      "================================================================\n",
      "Total params: 36,342\n",
      "Trainable params: 36,342\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.07\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 0.21\n",
      "----------------------------------------------------------------\n",
      "summary 5cnnl_4hl\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x60 and 80x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6deccc8ea055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                               linear_params = {'output_dim': 1, 'hidden_dim': hl})\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'summary '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ip_ch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'cnnl_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'hl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_CNNloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#         model_CNNloop.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/petitRT/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/petitRT/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-3bcc1d690a2a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;31m#add a droupout if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/petitRT/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/petitRT/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/petitRT/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x60 and 80x128)"
     ]
    }
   ],
   "source": [
    "# for CNN only\n",
    "CNN2 = {'ip_ch':[1,5], 'op_ch': [5,10], 'kernel_size': [3,3], 'kernel_size_pool': [3,3]}\n",
    "CNN3 = {'ip_ch':[1,5,10], 'op_ch': [5,10, 15], 'kernel_size': [3,3,3], 'kernel_size_pool': [3,3,3]}\n",
    "CNN4 = {'ip_ch':[1,5,10,15], 'op_ch': [5,10, 15,20], 'kernel_size': [3,3,3,3], 'kernel_size_pool': [3,3,3,3]}\n",
    "CNN5 = {'ip_ch':[1,5,10,15,20], 'op_ch': [5,10,15,20,25], 'kernel_size': [3,3,3,3,3], 'kernel_size_pool': [3,3,3,3,3]}\n",
    "CNN6 = {'ip_ch':[1,5,10,15,20,25], 'op_ch': [5,10,15,20,25,30], 'kernel_size': [3,3,3,3,3,3], 'kernel_size_pool': [3,3,3,3,3,3]}\n",
    "\n",
    "CNN = [CNN2, CNN3, CNN4, CNN5, CNN6]\n",
    "\n",
    "for cnn in CNN:\n",
    "    for hl in HL:\n",
    "        hl = [128,64,32,8]\n",
    "        model_CNNloop = CNNet(cnn_params=cnn,\\\n",
    "                              linear_params = {'output_dim': 1, 'hidden_dim': hl})\n",
    "#         print('summary ',str(len(cnn['ip_ch']))+'cnnl_' + str(len(hl))+'hl')\n",
    "#         summary(model_CNNloop, (1, f))\n",
    "        model_CNNloop.to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model_CNNloop.parameters(), lr=float(LEARNING_RATE))\n",
    "\n",
    "        layers= str(len(cnn['ip_ch']))+'cnnl_' + str(len(hl))+'hl'\n",
    "        model_dir = model_path + model_name+'_'+layers\n",
    "\n",
    "        if not os.path.exists(model_dir):\n",
    "                os.makedirs(model_dir)    \n",
    "        metrics_path = os.path.join(model_dir, 'metrics.json')\n",
    "\n",
    "        metrics = {\n",
    "            'model': model_dir,\n",
    "            'optimizer': optimizer.__class__.__name__,\n",
    "            'criterion': criterion.__class__.__name__,\n",
    "        #     'scheduler': scheduler.__class__.__name__,\n",
    "            'dataset_size': int(len(dataset)),\n",
    "            'train_size': int(split[0]*len(dataset)),\n",
    "            'test_size': int(split[1]*len(dataset)),\n",
    "            'n_epoch': nb_epoch,\n",
    "            'batch_size': batch_size,\n",
    "        #     'learning_rate': [],\n",
    "            'train_loss': [],\n",
    "            'val_loss': []\n",
    "        }\n",
    "\n",
    "        train(nb_epoch, model_CNNloop)\n",
    "        \n",
    "        break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "petitRT",
   "language": "python",
   "name": "petitrt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
