{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to count the number of parameters\n",
    "def get_n_params(model): \n",
    "    np = 0\n",
    "    for p in list(model.parameters()):\n",
    "        np+= p.nelement()\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malavika/anaconda3/envs/petitRT/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729138878/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/malavika/Documents/Research/assessment/training'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"/home/malavika/Documents/Research/assessment/datasets/6params_train_bce_1M2.h5\"\n",
    "#path_to_file = \"/home/malavika/Documents/Research/assessment/datasets/10params_train_bce_1M2.h5\"\n",
    "\n",
    "params = '6'\n",
    "\n",
    "with h5py.File(path_to_file, 'r') as hdf:\n",
    "    data = np.array(hdf.get('data')).astype(np.float32)\n",
    "    label = np.array(hdf.get('labels')).astype(np.float32)\n",
    "\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221852, 377)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "a_min = np.min(data)\n",
    "a_max = np.max(data)\n",
    "data_norm = (data-a_min)/(a_max-a_min)\n",
    "\n",
    "#Tensor\n",
    "target = torch.from_numpy(label)\n",
    "inpt = torch.from_numpy(data_norm)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = inpt\n",
    "        self.target = target\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index] \n",
    "        x = x[np.newaxis, ...] # To specify the number of channels c (here c=1)\n",
    "        y = self.target[index]\n",
    "        \n",
    "        return {'input': x, 'target': y}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "dataset = MyDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = [0.9, 0.1]\n",
    "split_train = '0.9'\n",
    "batch_size = 128 \n",
    "indices = list(range(len(dataset)))\n",
    "s = int(np.floor(split[1] * len(dataset)))\n",
    "\n",
    "#shuffling\n",
    "np.random.seed(111)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[s:], indices[:s]\n",
    "\n",
    "train_sampler, val_sampler = SubsetRandomSampler(train_indices), SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, sampler=train_sampler)\n",
    "val_dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1560"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([221852, 377])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_dataloader.dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(train_dataloader.dataset.data)[1]\n",
    "f = np.shape(train_dataloader.dataset.data)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "dataloaders['train'], dataloaders['val'] = train_dataloader, val_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1560"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221852"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['train'].dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, sample in enumerate(dataloaders['train']):\n",
    "#     print(len(dataloaders['train'].dataset))\n",
    "#     print(len(dataloaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, n_feature, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(n_feature , n_feature, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(128*42, 128)\n",
    "        self.fc2 = nn.Linear(128,1)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = max_pool1d(x,kernel_size=2)\n",
    "        x = self.conv2(x)\n",
    "        x = max_pool1d(x,kernel_size=2)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(-1, self.n_feature*4*4)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(f, 100) \n",
    "        self.layer_2 = nn.Linear(100, 32)\n",
    "        self.layer_out = nn.Linear(32, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(1)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(32)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.layer_out(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    #layer, relu, bn, dp\n",
    "    \n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "                           \n",
    "    def get_weights(self):\n",
    "        return self.weight\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = F.sigmoid(self.fc2(out)) #sigmoid as we use BCELoss\n",
    "        return out\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        current_dim = input_dim\n",
    "        self.layers = nn.ModuleList()\n",
    "        for hdim in hidden_dim:\n",
    "            self.layers.append(nn.Linear(current_dim, hdim))\n",
    "            current_dim = hdim\n",
    "        self.layers.append(nn.Linear(current_dim, output_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        out = F.sigmoid(self.layers[-1](x))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "\n",
    "def train(n_epochs, model):\n",
    "    \n",
    "    best_loss = 0.0\n",
    "    for epoch in range(n_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            \n",
    "            \n",
    "            #both    \n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for batch_idx, sample in enumerate(dataloaders[phase]):\n",
    "                inputs = sample['input'].to(device)\n",
    "                target = sample['target'].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(torch.squeeze(output), torch.squeeze(target))\n",
    "                    acc = binary_acc(torch.squeeze(output), torch.squeeze(target))\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()   \n",
    "                \n",
    "                    running_loss += 1 * loss.item() * inputs.size(0) #loss for the phase/whole dataset\n",
    "\n",
    "                if batch_idx % 100 == 0: \n",
    "                    print('{} epoch: {} [{}/{} ({:0.0f}%)]\\tLoss: {:.6f}\\tAcc: {:.2f}'.format(\\\n",
    "                    phase,epoch,(batch_idx+1)*len(sample['input']),len(dataloaders[phase].dataset),\\\n",
    "                    100.* ((batch_idx+1)*len(sample['input']))/len(dataloaders[phase].dataset),loss.item(), acc))\n",
    "    \n",
    "            if phase == 'train':\n",
    "                metrics[phase+'_loss'].append(running_loss/int(dataset_size*split[0]))\n",
    "            else:\n",
    "                metrics[phase+'_loss'].append(running_loss/int(dataset_size*split[1]))\n",
    "\n",
    "            if phase == 'val': \n",
    "                if epoch ==  (n_epochs-1) or running_loss < best_loss:\n",
    "                    print('saving')\n",
    "                    best_loss = running_loss\n",
    "                    model_path = os.path.join(model_dir, 'model.pth')\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "                    \n",
    "        with open(metrics_path, 'w') as f:\n",
    "            json.dump(metrics, f, indent=4)\n",
    "                    \n",
    "#         print('--------------------------------------------------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "nb_epoch = 200\n",
    "optimizer_name = 'Adam'\n",
    "dl_arch = 'mlp'\n",
    "metric = 'bce'\n",
    "LEARNING_RATE = 0.001\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model_path = '/home/malavika/Documents/Research/assessment/models/model1/'\n",
    "model_name = 'model_'+params+'_spectra'+str(dataset_size)+'_split'+split_train+'_bs'+str(batch_size)+'_Loss'+\\\n",
    "            metric+'_opt'+str(optimizer_name)+'_lr'+str(LEARNING_RATE)+'_ep'+str(nb_epoch)+'_'+dl_arch\n",
    "\n",
    "#hidden layers\n",
    "\n",
    "hl2 = [128,32]\n",
    "hl3 = [128,32,8]\n",
    "hl4 = [128,64,32,8]\n",
    "hl5 = [128,64,32,16,8]\n",
    "hl6 = [128,64,32,16,8,4]\n",
    "\n",
    "HL = [hl2, hl3, hl4, hl5, hl6] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malavika/anaconda3/envs/petitRT/lib/python3.7/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 0 [128/221852 (0%)]\tLoss: 0.688611\tAcc: 44.00\n",
      "train epoch: 0 [12928/221852 (6%)]\tLoss: 0.695077\tAcc: 48.00\n",
      "train epoch: 0 [25728/221852 (12%)]\tLoss: 0.698434\tAcc: 53.00\n",
      "train epoch: 0 [38528/221852 (17%)]\tLoss: 0.687644\tAcc: 46.00\n",
      "train epoch: 0 [51328/221852 (23%)]\tLoss: 0.684887\tAcc: 55.00\n",
      "train epoch: 0 [64128/221852 (29%)]\tLoss: 0.674369\tAcc: 51.00\n",
      "train epoch: 0 [76928/221852 (35%)]\tLoss: 0.669688\tAcc: 50.00\n",
      "train epoch: 0 [89728/221852 (40%)]\tLoss: 0.610727\tAcc: 48.00\n",
      "train epoch: 0 [102528/221852 (46%)]\tLoss: 0.603302\tAcc: 53.00\n",
      "train epoch: 0 [115328/221852 (52%)]\tLoss: 0.566783\tAcc: 44.00\n",
      "train epoch: 0 [128128/221852 (58%)]\tLoss: 0.604892\tAcc: 51.00\n",
      "train epoch: 0 [140928/221852 (64%)]\tLoss: 0.660942\tAcc: 53.00\n",
      "train epoch: 0 [153728/221852 (69%)]\tLoss: 0.616082\tAcc: 61.00\n",
      "train epoch: 0 [166528/221852 (75%)]\tLoss: 0.589299\tAcc: 59.00\n",
      "train epoch: 0 [179328/221852 (81%)]\tLoss: 0.532808\tAcc: 48.00\n",
      "train epoch: 0 [192128/221852 (87%)]\tLoss: 0.541599\tAcc: 54.00\n",
      "val epoch: 0 [128/221852 (0%)]\tLoss: 0.538419\tAcc: 48.00\n",
      "val epoch: 0 [12928/221852 (6%)]\tLoss: 0.573439\tAcc: 49.00\n",
      "train epoch: 1 [128/221852 (0%)]\tLoss: 0.513367\tAcc: 52.00\n",
      "train epoch: 1 [12928/221852 (6%)]\tLoss: 0.495391\tAcc: 55.00\n",
      "train epoch: 1 [25728/221852 (12%)]\tLoss: 0.458908\tAcc: 49.00\n",
      "train epoch: 1 [38528/221852 (17%)]\tLoss: 0.486638\tAcc: 50.00\n",
      "train epoch: 1 [51328/221852 (23%)]\tLoss: 0.471711\tAcc: 48.00\n",
      "train epoch: 1 [64128/221852 (29%)]\tLoss: 0.492615\tAcc: 55.00\n",
      "train epoch: 1 [76928/221852 (35%)]\tLoss: 0.481537\tAcc: 52.00\n",
      "train epoch: 1 [89728/221852 (40%)]\tLoss: 0.442424\tAcc: 52.00\n",
      "train epoch: 1 [102528/221852 (46%)]\tLoss: 0.411655\tAcc: 45.00\n",
      "train epoch: 1 [115328/221852 (52%)]\tLoss: 0.425271\tAcc: 48.00\n",
      "train epoch: 1 [128128/221852 (58%)]\tLoss: 0.490719\tAcc: 50.00\n",
      "train epoch: 1 [140928/221852 (64%)]\tLoss: 0.448089\tAcc: 52.00\n",
      "train epoch: 1 [153728/221852 (69%)]\tLoss: 0.458980\tAcc: 55.00\n",
      "train epoch: 1 [166528/221852 (75%)]\tLoss: 0.450271\tAcc: 49.00\n",
      "train epoch: 1 [179328/221852 (81%)]\tLoss: 0.439300\tAcc: 52.00\n",
      "train epoch: 1 [192128/221852 (87%)]\tLoss: 0.430587\tAcc: 54.00\n",
      "val epoch: 1 [128/221852 (0%)]\tLoss: 0.440519\tAcc: 52.00\n",
      "val epoch: 1 [12928/221852 (6%)]\tLoss: 0.418745\tAcc: 50.00\n",
      "train epoch: 2 [128/221852 (0%)]\tLoss: 0.413394\tAcc: 42.00\n",
      "train epoch: 2 [12928/221852 (6%)]\tLoss: 0.428578\tAcc: 42.00\n",
      "train epoch: 2 [25728/221852 (12%)]\tLoss: 0.461902\tAcc: 45.00\n",
      "train epoch: 2 [38528/221852 (17%)]\tLoss: 0.435105\tAcc: 52.00\n",
      "train epoch: 2 [51328/221852 (23%)]\tLoss: 0.384110\tAcc: 57.00\n",
      "train epoch: 2 [64128/221852 (29%)]\tLoss: 0.387422\tAcc: 62.00\n",
      "train epoch: 2 [76928/221852 (35%)]\tLoss: 0.526902\tAcc: 48.00\n",
      "train epoch: 2 [89728/221852 (40%)]\tLoss: 0.380896\tAcc: 47.00\n",
      "train epoch: 2 [102528/221852 (46%)]\tLoss: 0.387631\tAcc: 54.00\n",
      "train epoch: 2 [115328/221852 (52%)]\tLoss: 0.348115\tAcc: 56.00\n",
      "train epoch: 2 [128128/221852 (58%)]\tLoss: 0.390656\tAcc: 55.00\n",
      "train epoch: 2 [140928/221852 (64%)]\tLoss: 0.486387\tAcc: 53.00\n",
      "train epoch: 2 [153728/221852 (69%)]\tLoss: 0.371415\tAcc: 55.00\n",
      "train epoch: 2 [166528/221852 (75%)]\tLoss: 0.377970\tAcc: 52.00\n",
      "train epoch: 2 [179328/221852 (81%)]\tLoss: 0.383286\tAcc: 48.00\n",
      "train epoch: 2 [192128/221852 (87%)]\tLoss: 0.404209\tAcc: 55.00\n",
      "val epoch: 2 [128/221852 (0%)]\tLoss: 0.371736\tAcc: 58.00\n",
      "val epoch: 2 [12928/221852 (6%)]\tLoss: 0.416522\tAcc: 52.00\n",
      "train epoch: 3 [128/221852 (0%)]\tLoss: 0.319280\tAcc: 55.00\n",
      "train epoch: 3 [12928/221852 (6%)]\tLoss: 0.472310\tAcc: 52.00\n",
      "train epoch: 3 [25728/221852 (12%)]\tLoss: 0.419221\tAcc: 48.00\n",
      "train epoch: 3 [38528/221852 (17%)]\tLoss: 0.499616\tAcc: 53.00\n",
      "train epoch: 3 [51328/221852 (23%)]\tLoss: 0.358831\tAcc: 59.00\n",
      "train epoch: 3 [64128/221852 (29%)]\tLoss: 0.385006\tAcc: 48.00\n",
      "train epoch: 3 [76928/221852 (35%)]\tLoss: 0.380663\tAcc: 61.00\n",
      "train epoch: 3 [89728/221852 (40%)]\tLoss: 0.397177\tAcc: 59.00\n",
      "train epoch: 3 [102528/221852 (46%)]\tLoss: 0.445411\tAcc: 55.00\n",
      "train epoch: 3 [115328/221852 (52%)]\tLoss: 0.423099\tAcc: 48.00\n",
      "train epoch: 3 [128128/221852 (58%)]\tLoss: 0.368918\tAcc: 53.00\n",
      "train epoch: 3 [140928/221852 (64%)]\tLoss: 0.358627\tAcc: 59.00\n",
      "train epoch: 3 [153728/221852 (69%)]\tLoss: 0.359899\tAcc: 62.00\n",
      "train epoch: 3 [166528/221852 (75%)]\tLoss: 0.371765\tAcc: 50.00\n",
      "train epoch: 3 [179328/221852 (81%)]\tLoss: 0.301440\tAcc: 57.00\n",
      "train epoch: 3 [192128/221852 (87%)]\tLoss: 0.360399\tAcc: 52.00\n",
      "val epoch: 3 [128/221852 (0%)]\tLoss: 0.272585\tAcc: 56.00\n",
      "val epoch: 3 [12928/221852 (6%)]\tLoss: 0.326870\tAcc: 52.00\n",
      "train epoch: 4 [128/221852 (0%)]\tLoss: 0.383219\tAcc: 55.00\n",
      "train epoch: 4 [12928/221852 (6%)]\tLoss: 0.372289\tAcc: 70.00\n",
      "train epoch: 4 [25728/221852 (12%)]\tLoss: 0.312941\tAcc: 55.00\n",
      "train epoch: 4 [38528/221852 (17%)]\tLoss: 0.419144\tAcc: 54.00\n",
      "train epoch: 4 [51328/221852 (23%)]\tLoss: 0.476763\tAcc: 47.00\n",
      "train epoch: 4 [64128/221852 (29%)]\tLoss: 0.409217\tAcc: 52.00\n",
      "train epoch: 4 [76928/221852 (35%)]\tLoss: 0.294901\tAcc: 58.00\n",
      "train epoch: 4 [89728/221852 (40%)]\tLoss: 0.394005\tAcc: 59.00\n",
      "train epoch: 4 [102528/221852 (46%)]\tLoss: 0.384367\tAcc: 53.00\n",
      "train epoch: 4 [115328/221852 (52%)]\tLoss: 0.331420\tAcc: 58.00\n",
      "train epoch: 4 [128128/221852 (58%)]\tLoss: 0.357867\tAcc: 59.00\n",
      "train epoch: 4 [140928/221852 (64%)]\tLoss: 0.312205\tAcc: 61.00\n",
      "train epoch: 4 [153728/221852 (69%)]\tLoss: 0.400398\tAcc: 52.00\n",
      "train epoch: 4 [166528/221852 (75%)]\tLoss: 0.424573\tAcc: 54.00\n",
      "train epoch: 4 [179328/221852 (81%)]\tLoss: 0.409672\tAcc: 60.00\n",
      "train epoch: 4 [192128/221852 (87%)]\tLoss: 0.432478\tAcc: 62.00\n",
      "val epoch: 4 [128/221852 (0%)]\tLoss: 0.299690\tAcc: 49.00\n",
      "val epoch: 4 [12928/221852 (6%)]\tLoss: 0.292945\tAcc: 59.00\n",
      "train epoch: 5 [128/221852 (0%)]\tLoss: 0.403357\tAcc: 59.00\n",
      "train epoch: 5 [12928/221852 (6%)]\tLoss: 0.452942\tAcc: 48.00\n",
      "train epoch: 5 [25728/221852 (12%)]\tLoss: 0.344371\tAcc: 60.00\n",
      "train epoch: 5 [38528/221852 (17%)]\tLoss: 0.409771\tAcc: 56.00\n",
      "train epoch: 5 [51328/221852 (23%)]\tLoss: 0.380873\tAcc: 58.00\n",
      "train epoch: 5 [64128/221852 (29%)]\tLoss: 0.336469\tAcc: 57.00\n",
      "train epoch: 5 [76928/221852 (35%)]\tLoss: 0.366770\tAcc: 54.00\n",
      "train epoch: 5 [89728/221852 (40%)]\tLoss: 0.435224\tAcc: 62.00\n",
      "train epoch: 5 [102528/221852 (46%)]\tLoss: 0.372890\tAcc: 61.00\n",
      "train epoch: 5 [115328/221852 (52%)]\tLoss: 0.483436\tAcc: 53.00\n",
      "train epoch: 5 [128128/221852 (58%)]\tLoss: 0.357417\tAcc: 64.00\n",
      "train epoch: 5 [140928/221852 (64%)]\tLoss: 0.323362\tAcc: 67.00\n",
      "train epoch: 5 [153728/221852 (69%)]\tLoss: 0.304896\tAcc: 61.00\n",
      "train epoch: 5 [166528/221852 (75%)]\tLoss: 0.441447\tAcc: 58.00\n",
      "train epoch: 5 [179328/221852 (81%)]\tLoss: 0.449457\tAcc: 52.00\n",
      "train epoch: 5 [192128/221852 (87%)]\tLoss: 0.495911\tAcc: 58.00\n",
      "val epoch: 5 [128/221852 (0%)]\tLoss: 0.319469\tAcc: 62.00\n",
      "val epoch: 5 [12928/221852 (6%)]\tLoss: 0.363561\tAcc: 57.00\n",
      "train epoch: 6 [128/221852 (0%)]\tLoss: 0.358551\tAcc: 55.00\n",
      "train epoch: 6 [12928/221852 (6%)]\tLoss: 0.349378\tAcc: 54.00\n",
      "train epoch: 6 [25728/221852 (12%)]\tLoss: 0.356595\tAcc: 65.00\n",
      "train epoch: 6 [38528/221852 (17%)]\tLoss: 0.400760\tAcc: 62.00\n",
      "train epoch: 6 [51328/221852 (23%)]\tLoss: 0.362839\tAcc: 59.00\n",
      "train epoch: 6 [64128/221852 (29%)]\tLoss: 0.372744\tAcc: 60.00\n",
      "train epoch: 6 [76928/221852 (35%)]\tLoss: 0.497251\tAcc: 59.00\n",
      "train epoch: 6 [89728/221852 (40%)]\tLoss: 0.441425\tAcc: 59.00\n",
      "train epoch: 6 [102528/221852 (46%)]\tLoss: 0.592779\tAcc: 53.00\n",
      "train epoch: 6 [115328/221852 (52%)]\tLoss: 0.371833\tAcc: 48.00\n",
      "train epoch: 6 [128128/221852 (58%)]\tLoss: 0.354474\tAcc: 58.00\n",
      "train epoch: 6 [140928/221852 (64%)]\tLoss: 0.346259\tAcc: 62.00\n",
      "train epoch: 6 [153728/221852 (69%)]\tLoss: 0.369202\tAcc: 59.00\n",
      "train epoch: 6 [166528/221852 (75%)]\tLoss: 0.327814\tAcc: 60.00\n",
      "train epoch: 6 [179328/221852 (81%)]\tLoss: 0.437348\tAcc: 59.00\n",
      "train epoch: 6 [192128/221852 (87%)]\tLoss: 0.354325\tAcc: 56.00\n",
      "val epoch: 6 [128/221852 (0%)]\tLoss: 0.334466\tAcc: 63.00\n",
      "val epoch: 6 [12928/221852 (6%)]\tLoss: 0.300395\tAcc: 56.00\n",
      "train epoch: 7 [128/221852 (0%)]\tLoss: 0.448115\tAcc: 59.00\n",
      "train epoch: 7 [12928/221852 (6%)]\tLoss: 0.319977\tAcc: 63.00\n",
      "train epoch: 7 [25728/221852 (12%)]\tLoss: 0.373345\tAcc: 52.00\n",
      "train epoch: 7 [38528/221852 (17%)]\tLoss: 0.359472\tAcc: 65.00\n",
      "train epoch: 7 [51328/221852 (23%)]\tLoss: 0.390551\tAcc: 52.00\n",
      "train epoch: 7 [64128/221852 (29%)]\tLoss: 0.398913\tAcc: 59.00\n",
      "train epoch: 7 [76928/221852 (35%)]\tLoss: 0.412546\tAcc: 59.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 7 [89728/221852 (40%)]\tLoss: 0.333846\tAcc: 69.00\n",
      "train epoch: 7 [102528/221852 (46%)]\tLoss: 0.350516\tAcc: 53.00\n",
      "train epoch: 7 [115328/221852 (52%)]\tLoss: 0.293223\tAcc: 59.00\n",
      "train epoch: 7 [128128/221852 (58%)]\tLoss: 0.313373\tAcc: 55.00\n",
      "train epoch: 7 [140928/221852 (64%)]\tLoss: 0.366859\tAcc: 62.00\n",
      "train epoch: 7 [153728/221852 (69%)]\tLoss: 0.433287\tAcc: 56.00\n",
      "train epoch: 7 [166528/221852 (75%)]\tLoss: 0.395606\tAcc: 53.00\n",
      "train epoch: 7 [179328/221852 (81%)]\tLoss: 0.324338\tAcc: 64.00\n",
      "train epoch: 7 [192128/221852 (87%)]\tLoss: 0.424914\tAcc: 62.00\n",
      "val epoch: 7 [128/221852 (0%)]\tLoss: 0.309230\tAcc: 67.00\n",
      "val epoch: 7 [12928/221852 (6%)]\tLoss: 0.379163\tAcc: 54.00\n",
      "train epoch: 8 [128/221852 (0%)]\tLoss: 0.343545\tAcc: 54.00\n",
      "train epoch: 8 [12928/221852 (6%)]\tLoss: 0.347091\tAcc: 56.00\n",
      "train epoch: 8 [25728/221852 (12%)]\tLoss: 0.301719\tAcc: 62.00\n",
      "train epoch: 8 [38528/221852 (17%)]\tLoss: 0.437807\tAcc: 55.00\n",
      "train epoch: 8 [51328/221852 (23%)]\tLoss: 0.354774\tAcc: 55.00\n",
      "train epoch: 8 [64128/221852 (29%)]\tLoss: 0.362645\tAcc: 60.00\n",
      "train epoch: 8 [76928/221852 (35%)]\tLoss: 0.356312\tAcc: 66.00\n",
      "train epoch: 8 [89728/221852 (40%)]\tLoss: 0.239062\tAcc: 66.00\n",
      "train epoch: 8 [102528/221852 (46%)]\tLoss: 0.359801\tAcc: 59.00\n",
      "train epoch: 8 [115328/221852 (52%)]\tLoss: 0.392768\tAcc: 62.00\n",
      "train epoch: 8 [128128/221852 (58%)]\tLoss: 0.386834\tAcc: 56.00\n",
      "train epoch: 8 [140928/221852 (64%)]\tLoss: 0.315831\tAcc: 64.00\n",
      "train epoch: 8 [153728/221852 (69%)]\tLoss: 0.273517\tAcc: 67.00\n",
      "train epoch: 8 [166528/221852 (75%)]\tLoss: 0.364366\tAcc: 60.00\n",
      "train epoch: 8 [179328/221852 (81%)]\tLoss: 0.300497\tAcc: 58.00\n",
      "train epoch: 8 [192128/221852 (87%)]\tLoss: 0.409563\tAcc: 62.00\n",
      "val epoch: 8 [128/221852 (0%)]\tLoss: 0.241418\tAcc: 60.00\n",
      "val epoch: 8 [12928/221852 (6%)]\tLoss: 0.301467\tAcc: 62.00\n",
      "train epoch: 9 [128/221852 (0%)]\tLoss: 0.336042\tAcc: 65.00\n",
      "train epoch: 9 [12928/221852 (6%)]\tLoss: 0.352401\tAcc: 62.00\n",
      "train epoch: 9 [25728/221852 (12%)]\tLoss: 0.398665\tAcc: 60.00\n",
      "train epoch: 9 [38528/221852 (17%)]\tLoss: 0.360582\tAcc: 61.00\n",
      "train epoch: 9 [51328/221852 (23%)]\tLoss: 0.323122\tAcc: 67.00\n",
      "train epoch: 9 [64128/221852 (29%)]\tLoss: 0.267119\tAcc: 63.00\n",
      "train epoch: 9 [76928/221852 (35%)]\tLoss: 0.370961\tAcc: 61.00\n",
      "train epoch: 9 [89728/221852 (40%)]\tLoss: 0.349328\tAcc: 55.00\n",
      "train epoch: 9 [102528/221852 (46%)]\tLoss: 0.305525\tAcc: 59.00\n",
      "train epoch: 9 [115328/221852 (52%)]\tLoss: 0.316158\tAcc: 63.00\n",
      "train epoch: 9 [128128/221852 (58%)]\tLoss: 0.304646\tAcc: 63.00\n",
      "train epoch: 9 [140928/221852 (64%)]\tLoss: 0.301674\tAcc: 59.00\n",
      "train epoch: 9 [153728/221852 (69%)]\tLoss: 0.359654\tAcc: 59.00\n",
      "train epoch: 9 [166528/221852 (75%)]\tLoss: 0.390986\tAcc: 59.00\n",
      "train epoch: 9 [179328/221852 (81%)]\tLoss: 0.306858\tAcc: 66.00\n",
      "train epoch: 9 [192128/221852 (87%)]\tLoss: 0.342970\tAcc: 67.00\n",
      "val epoch: 9 [128/221852 (0%)]\tLoss: 0.368997\tAcc: 62.00\n",
      "val epoch: 9 [12928/221852 (6%)]\tLoss: 0.350822\tAcc: 66.00\n",
      "train epoch: 10 [128/221852 (0%)]\tLoss: 0.377418\tAcc: 62.00\n",
      "train epoch: 10 [12928/221852 (6%)]\tLoss: 0.338347\tAcc: 61.00\n",
      "train epoch: 10 [25728/221852 (12%)]\tLoss: 0.347457\tAcc: 56.00\n",
      "train epoch: 10 [38528/221852 (17%)]\tLoss: 0.333881\tAcc: 64.00\n",
      "train epoch: 10 [51328/221852 (23%)]\tLoss: 0.339995\tAcc: 64.00\n",
      "train epoch: 10 [64128/221852 (29%)]\tLoss: 0.423632\tAcc: 63.00\n",
      "train epoch: 10 [76928/221852 (35%)]\tLoss: 0.373740\tAcc: 66.00\n",
      "train epoch: 10 [89728/221852 (40%)]\tLoss: 0.404346\tAcc: 56.00\n",
      "train epoch: 10 [102528/221852 (46%)]\tLoss: 0.311403\tAcc: 65.00\n",
      "train epoch: 10 [115328/221852 (52%)]\tLoss: 0.272840\tAcc: 58.00\n",
      "train epoch: 10 [128128/221852 (58%)]\tLoss: 0.373183\tAcc: 56.00\n",
      "train epoch: 10 [140928/221852 (64%)]\tLoss: 0.304418\tAcc: 59.00\n",
      "train epoch: 10 [153728/221852 (69%)]\tLoss: 0.256016\tAcc: 62.00\n",
      "train epoch: 10 [166528/221852 (75%)]\tLoss: 0.400646\tAcc: 54.00\n",
      "train epoch: 10 [179328/221852 (81%)]\tLoss: 0.400878\tAcc: 66.00\n",
      "train epoch: 10 [192128/221852 (87%)]\tLoss: 0.323043\tAcc: 63.00\n",
      "val epoch: 10 [128/221852 (0%)]\tLoss: 0.341325\tAcc: 61.00\n",
      "val epoch: 10 [12928/221852 (6%)]\tLoss: 0.311728\tAcc: 59.00\n",
      "train epoch: 11 [128/221852 (0%)]\tLoss: 0.337286\tAcc: 60.00\n",
      "train epoch: 11 [12928/221852 (6%)]\tLoss: 0.345909\tAcc: 65.00\n",
      "train epoch: 11 [25728/221852 (12%)]\tLoss: 0.240770\tAcc: 74.00\n",
      "train epoch: 11 [38528/221852 (17%)]\tLoss: 0.318038\tAcc: 57.00\n",
      "train epoch: 11 [51328/221852 (23%)]\tLoss: 0.330859\tAcc: 61.00\n",
      "train epoch: 11 [64128/221852 (29%)]\tLoss: 0.346127\tAcc: 64.00\n",
      "train epoch: 11 [76928/221852 (35%)]\tLoss: 0.314906\tAcc: 62.00\n",
      "train epoch: 11 [89728/221852 (40%)]\tLoss: 0.363622\tAcc: 55.00\n",
      "train epoch: 11 [102528/221852 (46%)]\tLoss: 0.304254\tAcc: 64.00\n",
      "train epoch: 11 [115328/221852 (52%)]\tLoss: 0.287785\tAcc: 62.00\n",
      "train epoch: 11 [128128/221852 (58%)]\tLoss: 0.351176\tAcc: 62.00\n",
      "train epoch: 11 [140928/221852 (64%)]\tLoss: 0.306654\tAcc: 63.00\n",
      "train epoch: 11 [153728/221852 (69%)]\tLoss: 0.333545\tAcc: 62.00\n",
      "train epoch: 11 [166528/221852 (75%)]\tLoss: 0.277738\tAcc: 64.00\n",
      "train epoch: 11 [179328/221852 (81%)]\tLoss: 0.325313\tAcc: 56.00\n",
      "train epoch: 11 [192128/221852 (87%)]\tLoss: 0.331664\tAcc: 67.00\n",
      "val epoch: 11 [128/221852 (0%)]\tLoss: 0.299436\tAcc: 55.00\n",
      "val epoch: 11 [12928/221852 (6%)]\tLoss: 0.375142\tAcc: 57.00\n",
      "train epoch: 12 [128/221852 (0%)]\tLoss: 0.374400\tAcc: 63.00\n",
      "train epoch: 12 [12928/221852 (6%)]\tLoss: 0.447926\tAcc: 55.00\n",
      "train epoch: 12 [25728/221852 (12%)]\tLoss: 0.298039\tAcc: 57.00\n",
      "train epoch: 12 [38528/221852 (17%)]\tLoss: 0.317986\tAcc: 63.00\n",
      "train epoch: 12 [51328/221852 (23%)]\tLoss: 0.295961\tAcc: 60.00\n",
      "train epoch: 12 [64128/221852 (29%)]\tLoss: 0.253857\tAcc: 66.00\n",
      "train epoch: 12 [76928/221852 (35%)]\tLoss: 0.413427\tAcc: 62.00\n",
      "train epoch: 12 [89728/221852 (40%)]\tLoss: 0.293875\tAcc: 66.00\n",
      "train epoch: 12 [102528/221852 (46%)]\tLoss: 0.371443\tAcc: 53.00\n",
      "train epoch: 12 [115328/221852 (52%)]\tLoss: 0.354421\tAcc: 65.00\n",
      "train epoch: 12 [128128/221852 (58%)]\tLoss: 0.286552\tAcc: 60.00\n",
      "train epoch: 12 [140928/221852 (64%)]\tLoss: 0.369110\tAcc: 62.00\n",
      "train epoch: 12 [153728/221852 (69%)]\tLoss: 0.338261\tAcc: 66.00\n",
      "train epoch: 12 [166528/221852 (75%)]\tLoss: 0.356250\tAcc: 60.00\n",
      "train epoch: 12 [179328/221852 (81%)]\tLoss: 0.343923\tAcc: 63.00\n",
      "train epoch: 12 [192128/221852 (87%)]\tLoss: 0.317124\tAcc: 63.00\n",
      "val epoch: 12 [128/221852 (0%)]\tLoss: 0.308455\tAcc: 68.00\n",
      "val epoch: 12 [12928/221852 (6%)]\tLoss: 0.299331\tAcc: 62.00\n",
      "train epoch: 13 [128/221852 (0%)]\tLoss: 0.265329\tAcc: 70.00\n",
      "train epoch: 13 [12928/221852 (6%)]\tLoss: 0.428607\tAcc: 59.00\n",
      "train epoch: 13 [25728/221852 (12%)]\tLoss: 0.259321\tAcc: 69.00\n",
      "train epoch: 13 [38528/221852 (17%)]\tLoss: 0.382961\tAcc: 62.00\n",
      "train epoch: 13 [51328/221852 (23%)]\tLoss: 0.217008\tAcc: 62.00\n",
      "train epoch: 13 [64128/221852 (29%)]\tLoss: 0.383032\tAcc: 63.00\n",
      "train epoch: 13 [76928/221852 (35%)]\tLoss: 0.298471\tAcc: 52.00\n",
      "train epoch: 13 [89728/221852 (40%)]\tLoss: 0.397137\tAcc: 61.00\n",
      "train epoch: 13 [102528/221852 (46%)]\tLoss: 0.250251\tAcc: 61.00\n",
      "train epoch: 13 [115328/221852 (52%)]\tLoss: 0.250737\tAcc: 60.00\n",
      "train epoch: 13 [128128/221852 (58%)]\tLoss: 0.360636\tAcc: 59.00\n",
      "train epoch: 13 [140928/221852 (64%)]\tLoss: 0.316554\tAcc: 66.00\n",
      "train epoch: 13 [153728/221852 (69%)]\tLoss: 0.215433\tAcc: 59.00\n",
      "train epoch: 13 [166528/221852 (75%)]\tLoss: 0.326813\tAcc: 63.00\n",
      "train epoch: 13 [179328/221852 (81%)]\tLoss: 0.348130\tAcc: 64.00\n",
      "train epoch: 13 [192128/221852 (87%)]\tLoss: 0.356867\tAcc: 64.00\n",
      "val epoch: 13 [128/221852 (0%)]\tLoss: 0.310004\tAcc: 66.00\n",
      "val epoch: 13 [12928/221852 (6%)]\tLoss: 0.358637\tAcc: 63.00\n",
      "train epoch: 14 [128/221852 (0%)]\tLoss: 0.288946\tAcc: 66.00\n",
      "train epoch: 14 [12928/221852 (6%)]\tLoss: 0.254090\tAcc: 60.00\n",
      "train epoch: 14 [25728/221852 (12%)]\tLoss: 0.394851\tAcc: 60.00\n",
      "train epoch: 14 [38528/221852 (17%)]\tLoss: 0.306183\tAcc: 61.00\n",
      "train epoch: 14 [51328/221852 (23%)]\tLoss: 0.329735\tAcc: 61.00\n",
      "train epoch: 14 [64128/221852 (29%)]\tLoss: 0.350949\tAcc: 58.00\n",
      "train epoch: 14 [76928/221852 (35%)]\tLoss: 0.284216\tAcc: 66.00\n",
      "train epoch: 14 [89728/221852 (40%)]\tLoss: 0.383486\tAcc: 67.00\n",
      "train epoch: 14 [102528/221852 (46%)]\tLoss: 0.332811\tAcc: 66.00\n",
      "train epoch: 14 [115328/221852 (52%)]\tLoss: 0.298469\tAcc: 63.00\n",
      "train epoch: 14 [128128/221852 (58%)]\tLoss: 0.266961\tAcc: 62.00\n",
      "train epoch: 14 [140928/221852 (64%)]\tLoss: 0.247899\tAcc: 60.00\n",
      "train epoch: 14 [153728/221852 (69%)]\tLoss: 0.339550\tAcc: 64.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 14 [166528/221852 (75%)]\tLoss: 0.354146\tAcc: 61.00\n",
      "train epoch: 14 [179328/221852 (81%)]\tLoss: 0.425776\tAcc: 68.00\n",
      "train epoch: 14 [192128/221852 (87%)]\tLoss: 0.352909\tAcc: 72.00\n",
      "val epoch: 14 [128/221852 (0%)]\tLoss: 0.252507\tAcc: 67.00\n",
      "val epoch: 14 [12928/221852 (6%)]\tLoss: 0.291830\tAcc: 65.00\n",
      "train epoch: 15 [128/221852 (0%)]\tLoss: 0.351848\tAcc: 62.00\n",
      "train epoch: 15 [12928/221852 (6%)]\tLoss: 0.373552\tAcc: 55.00\n",
      "train epoch: 15 [25728/221852 (12%)]\tLoss: 0.257229\tAcc: 62.00\n",
      "train epoch: 15 [38528/221852 (17%)]\tLoss: 0.366454\tAcc: 64.00\n",
      "train epoch: 15 [51328/221852 (23%)]\tLoss: 0.326472\tAcc: 73.00\n",
      "train epoch: 15 [64128/221852 (29%)]\tLoss: 0.251894\tAcc: 71.00\n",
      "train epoch: 15 [76928/221852 (35%)]\tLoss: 0.362414\tAcc: 66.00\n",
      "train epoch: 15 [89728/221852 (40%)]\tLoss: 0.370608\tAcc: 65.00\n",
      "train epoch: 15 [102528/221852 (46%)]\tLoss: 0.342376\tAcc: 62.00\n",
      "train epoch: 15 [115328/221852 (52%)]\tLoss: 0.268524\tAcc: 72.00\n",
      "train epoch: 15 [128128/221852 (58%)]\tLoss: 0.281660\tAcc: 64.00\n",
      "train epoch: 15 [140928/221852 (64%)]\tLoss: 0.265123\tAcc: 63.00\n",
      "train epoch: 15 [153728/221852 (69%)]\tLoss: 0.266318\tAcc: 62.00\n",
      "train epoch: 15 [166528/221852 (75%)]\tLoss: 0.390356\tAcc: 55.00\n",
      "train epoch: 15 [179328/221852 (81%)]\tLoss: 0.305336\tAcc: 59.00\n",
      "train epoch: 15 [192128/221852 (87%)]\tLoss: 0.388153\tAcc: 59.00\n",
      "val epoch: 15 [128/221852 (0%)]\tLoss: 0.356804\tAcc: 66.00\n",
      "val epoch: 15 [12928/221852 (6%)]\tLoss: 0.276972\tAcc: 73.00\n",
      "train epoch: 16 [128/221852 (0%)]\tLoss: 0.305839\tAcc: 62.00\n",
      "train epoch: 16 [12928/221852 (6%)]\tLoss: 0.344078\tAcc: 62.00\n",
      "train epoch: 16 [25728/221852 (12%)]\tLoss: 0.313324\tAcc: 59.00\n",
      "train epoch: 16 [38528/221852 (17%)]\tLoss: 0.255172\tAcc: 66.00\n",
      "train epoch: 16 [51328/221852 (23%)]\tLoss: 0.366907\tAcc: 66.00\n",
      "train epoch: 16 [64128/221852 (29%)]\tLoss: 0.278342\tAcc: 61.00\n",
      "train epoch: 16 [76928/221852 (35%)]\tLoss: 0.291808\tAcc: 56.00\n",
      "train epoch: 16 [89728/221852 (40%)]\tLoss: 0.321035\tAcc: 62.00\n",
      "train epoch: 16 [102528/221852 (46%)]\tLoss: 0.336165\tAcc: 70.00\n",
      "train epoch: 16 [115328/221852 (52%)]\tLoss: 0.257994\tAcc: 63.00\n",
      "train epoch: 16 [128128/221852 (58%)]\tLoss: 0.298496\tAcc: 68.00\n",
      "train epoch: 16 [140928/221852 (64%)]\tLoss: 0.313715\tAcc: 65.00\n",
      "train epoch: 16 [153728/221852 (69%)]\tLoss: 0.346921\tAcc: 66.00\n",
      "train epoch: 16 [166528/221852 (75%)]\tLoss: 0.319302\tAcc: 56.00\n",
      "train epoch: 16 [179328/221852 (81%)]\tLoss: 0.309087\tAcc: 62.00\n",
      "train epoch: 16 [192128/221852 (87%)]\tLoss: 0.195468\tAcc: 59.00\n",
      "val epoch: 16 [128/221852 (0%)]\tLoss: 0.241579\tAcc: 70.00\n",
      "val epoch: 16 [12928/221852 (6%)]\tLoss: 0.278050\tAcc: 68.00\n",
      "train epoch: 17 [128/221852 (0%)]\tLoss: 0.261502\tAcc: 73.00\n",
      "train epoch: 17 [12928/221852 (6%)]\tLoss: 0.542785\tAcc: 58.00\n",
      "train epoch: 17 [25728/221852 (12%)]\tLoss: 0.295970\tAcc: 64.00\n",
      "train epoch: 17 [38528/221852 (17%)]\tLoss: 0.269635\tAcc: 73.00\n",
      "train epoch: 17 [51328/221852 (23%)]\tLoss: 0.270347\tAcc: 65.00\n",
      "train epoch: 17 [64128/221852 (29%)]\tLoss: 0.327824\tAcc: 61.00\n",
      "train epoch: 17 [76928/221852 (35%)]\tLoss: 0.284336\tAcc: 63.00\n",
      "train epoch: 17 [89728/221852 (40%)]\tLoss: 0.305573\tAcc: 67.00\n",
      "train epoch: 17 [102528/221852 (46%)]\tLoss: 0.280775\tAcc: 66.00\n",
      "train epoch: 17 [115328/221852 (52%)]\tLoss: 0.284030\tAcc: 65.00\n",
      "train epoch: 17 [128128/221852 (58%)]\tLoss: 0.270801\tAcc: 67.00\n",
      "train epoch: 17 [140928/221852 (64%)]\tLoss: 0.288752\tAcc: 68.00\n",
      "train epoch: 17 [153728/221852 (69%)]\tLoss: 0.298799\tAcc: 56.00\n",
      "train epoch: 17 [166528/221852 (75%)]\tLoss: 0.303546\tAcc: 70.00\n",
      "train epoch: 17 [179328/221852 (81%)]\tLoss: 0.303193\tAcc: 66.00\n",
      "train epoch: 17 [192128/221852 (87%)]\tLoss: 0.383643\tAcc: 60.00\n",
      "val epoch: 17 [128/221852 (0%)]\tLoss: 0.287257\tAcc: 66.00\n",
      "val epoch: 17 [12928/221852 (6%)]\tLoss: 0.280833\tAcc: 62.00\n",
      "train epoch: 18 [128/221852 (0%)]\tLoss: 0.280971\tAcc: 64.00\n",
      "train epoch: 18 [12928/221852 (6%)]\tLoss: 0.379121\tAcc: 66.00\n",
      "train epoch: 18 [25728/221852 (12%)]\tLoss: 0.274838\tAcc: 68.00\n",
      "train epoch: 18 [38528/221852 (17%)]\tLoss: 0.345464\tAcc: 58.00\n",
      "train epoch: 18 [51328/221852 (23%)]\tLoss: 0.321291\tAcc: 59.00\n",
      "train epoch: 18 [64128/221852 (29%)]\tLoss: 0.250971\tAcc: 75.00\n",
      "train epoch: 18 [76928/221852 (35%)]\tLoss: 0.340304\tAcc: 63.00\n",
      "train epoch: 18 [89728/221852 (40%)]\tLoss: 0.256167\tAcc: 70.00\n",
      "train epoch: 18 [102528/221852 (46%)]\tLoss: 0.220963\tAcc: 62.00\n",
      "train epoch: 18 [115328/221852 (52%)]\tLoss: 0.306408\tAcc: 68.00\n",
      "train epoch: 18 [128128/221852 (58%)]\tLoss: 0.306397\tAcc: 62.00\n",
      "train epoch: 18 [140928/221852 (64%)]\tLoss: 0.260130\tAcc: 63.00\n",
      "train epoch: 18 [153728/221852 (69%)]\tLoss: 0.271664\tAcc: 62.00\n",
      "train epoch: 18 [166528/221852 (75%)]\tLoss: 0.218418\tAcc: 68.00\n",
      "train epoch: 18 [179328/221852 (81%)]\tLoss: 0.393893\tAcc: 52.00\n",
      "train epoch: 18 [192128/221852 (87%)]\tLoss: 0.313813\tAcc: 60.00\n",
      "val epoch: 18 [128/221852 (0%)]\tLoss: 0.292959\tAcc: 59.00\n",
      "val epoch: 18 [12928/221852 (6%)]\tLoss: 0.257926\tAcc: 61.00\n",
      "train epoch: 19 [128/221852 (0%)]\tLoss: 0.288943\tAcc: 55.00\n",
      "train epoch: 19 [12928/221852 (6%)]\tLoss: 0.312633\tAcc: 67.00\n",
      "train epoch: 19 [25728/221852 (12%)]\tLoss: 0.282325\tAcc: 66.00\n",
      "train epoch: 19 [38528/221852 (17%)]\tLoss: 0.357712\tAcc: 60.00\n",
      "train epoch: 19 [51328/221852 (23%)]\tLoss: 0.278322\tAcc: 66.00\n",
      "train epoch: 19 [64128/221852 (29%)]\tLoss: 0.306016\tAcc: 64.00\n",
      "train epoch: 19 [76928/221852 (35%)]\tLoss: 0.286919\tAcc: 64.00\n",
      "train epoch: 19 [89728/221852 (40%)]\tLoss: 0.328287\tAcc: 61.00\n",
      "train epoch: 19 [102528/221852 (46%)]\tLoss: 0.317849\tAcc: 65.00\n",
      "train epoch: 19 [115328/221852 (52%)]\tLoss: 0.487162\tAcc: 59.00\n",
      "train epoch: 19 [128128/221852 (58%)]\tLoss: 0.283046\tAcc: 70.00\n",
      "train epoch: 19 [140928/221852 (64%)]\tLoss: 0.310053\tAcc: 70.00\n",
      "train epoch: 19 [153728/221852 (69%)]\tLoss: 0.287915\tAcc: 67.00\n",
      "train epoch: 19 [166528/221852 (75%)]\tLoss: 0.231185\tAcc: 69.00\n",
      "train epoch: 19 [179328/221852 (81%)]\tLoss: 0.351927\tAcc: 59.00\n",
      "train epoch: 19 [192128/221852 (87%)]\tLoss: 0.290000\tAcc: 62.00\n",
      "val epoch: 19 [128/221852 (0%)]\tLoss: 0.272621\tAcc: 59.00\n",
      "val epoch: 19 [12928/221852 (6%)]\tLoss: 0.350039\tAcc: 62.00\n",
      "train epoch: 20 [128/221852 (0%)]\tLoss: 0.336040\tAcc: 65.00\n",
      "train epoch: 20 [12928/221852 (6%)]\tLoss: 0.370825\tAcc: 61.00\n",
      "train epoch: 20 [25728/221852 (12%)]\tLoss: 0.403694\tAcc: 63.00\n",
      "train epoch: 20 [38528/221852 (17%)]\tLoss: 0.312930\tAcc: 66.00\n",
      "train epoch: 20 [51328/221852 (23%)]\tLoss: 0.310124\tAcc: 60.00\n",
      "train epoch: 20 [64128/221852 (29%)]\tLoss: 0.278338\tAcc: 65.00\n",
      "train epoch: 20 [76928/221852 (35%)]\tLoss: 0.249854\tAcc: 66.00\n",
      "train epoch: 20 [89728/221852 (40%)]\tLoss: 0.205401\tAcc: 73.00\n",
      "train epoch: 20 [102528/221852 (46%)]\tLoss: 0.274160\tAcc: 60.00\n",
      "train epoch: 20 [115328/221852 (52%)]\tLoss: 0.246157\tAcc: 74.00\n",
      "train epoch: 20 [128128/221852 (58%)]\tLoss: 0.325010\tAcc: 64.00\n",
      "train epoch: 20 [140928/221852 (64%)]\tLoss: 0.249260\tAcc: 63.00\n",
      "train epoch: 20 [153728/221852 (69%)]\tLoss: 0.304802\tAcc: 72.00\n",
      "train epoch: 20 [166528/221852 (75%)]\tLoss: 0.367640\tAcc: 66.00\n",
      "train epoch: 20 [179328/221852 (81%)]\tLoss: 0.222912\tAcc: 68.00\n",
      "train epoch: 20 [192128/221852 (87%)]\tLoss: 0.391847\tAcc: 63.00\n",
      "val epoch: 20 [128/221852 (0%)]\tLoss: 0.254144\tAcc: 59.00\n",
      "val epoch: 20 [12928/221852 (6%)]\tLoss: 0.221810\tAcc: 67.00\n",
      "train epoch: 21 [128/221852 (0%)]\tLoss: 0.282704\tAcc: 67.00\n",
      "train epoch: 21 [12928/221852 (6%)]\tLoss: 0.269995\tAcc: 62.00\n",
      "train epoch: 21 [25728/221852 (12%)]\tLoss: 0.242310\tAcc: 70.00\n",
      "train epoch: 21 [38528/221852 (17%)]\tLoss: 0.223783\tAcc: 71.00\n",
      "train epoch: 21 [51328/221852 (23%)]\tLoss: 0.201171\tAcc: 66.00\n",
      "train epoch: 21 [64128/221852 (29%)]\tLoss: 0.257107\tAcc: 68.00\n",
      "train epoch: 21 [76928/221852 (35%)]\tLoss: 0.275880\tAcc: 70.00\n",
      "train epoch: 21 [89728/221852 (40%)]\tLoss: 0.427325\tAcc: 68.00\n",
      "train epoch: 21 [102528/221852 (46%)]\tLoss: 0.277893\tAcc: 61.00\n",
      "train epoch: 21 [115328/221852 (52%)]\tLoss: 0.282005\tAcc: 58.00\n",
      "train epoch: 21 [128128/221852 (58%)]\tLoss: 0.291064\tAcc: 66.00\n",
      "train epoch: 21 [140928/221852 (64%)]\tLoss: 0.350449\tAcc: 65.00\n",
      "train epoch: 21 [153728/221852 (69%)]\tLoss: 0.315848\tAcc: 66.00\n",
      "train epoch: 21 [166528/221852 (75%)]\tLoss: 0.320881\tAcc: 66.00\n",
      "train epoch: 21 [179328/221852 (81%)]\tLoss: 0.235114\tAcc: 63.00\n",
      "train epoch: 21 [192128/221852 (87%)]\tLoss: 0.252599\tAcc: 64.00\n",
      "val epoch: 21 [128/221852 (0%)]\tLoss: 0.238341\tAcc: 62.00\n",
      "val epoch: 21 [12928/221852 (6%)]\tLoss: 0.326255\tAcc: 64.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 22 [128/221852 (0%)]\tLoss: 0.286997\tAcc: 59.00\n",
      "train epoch: 22 [12928/221852 (6%)]\tLoss: 0.275799\tAcc: 70.00\n",
      "train epoch: 22 [25728/221852 (12%)]\tLoss: 0.281840\tAcc: 69.00\n",
      "train epoch: 22 [38528/221852 (17%)]\tLoss: 0.312668\tAcc: 66.00\n",
      "train epoch: 22 [51328/221852 (23%)]\tLoss: 0.392489\tAcc: 56.00\n",
      "train epoch: 22 [64128/221852 (29%)]\tLoss: 0.278413\tAcc: 66.00\n",
      "train epoch: 22 [76928/221852 (35%)]\tLoss: 0.319114\tAcc: 67.00\n",
      "train epoch: 22 [89728/221852 (40%)]\tLoss: 0.322312\tAcc: 72.00\n",
      "train epoch: 22 [102528/221852 (46%)]\tLoss: 0.262178\tAcc: 68.00\n",
      "train epoch: 22 [115328/221852 (52%)]\tLoss: 0.355386\tAcc: 61.00\n",
      "train epoch: 22 [128128/221852 (58%)]\tLoss: 0.278586\tAcc: 66.00\n",
      "train epoch: 22 [140928/221852 (64%)]\tLoss: 0.335917\tAcc: 67.00\n",
      "train epoch: 22 [153728/221852 (69%)]\tLoss: 0.361243\tAcc: 62.00\n",
      "train epoch: 22 [166528/221852 (75%)]\tLoss: 0.311283\tAcc: 71.00\n",
      "train epoch: 22 [179328/221852 (81%)]\tLoss: 0.240839\tAcc: 68.00\n",
      "train epoch: 22 [192128/221852 (87%)]\tLoss: 0.358391\tAcc: 62.00\n",
      "val epoch: 22 [128/221852 (0%)]\tLoss: 0.355452\tAcc: 62.00\n",
      "val epoch: 22 [12928/221852 (6%)]\tLoss: 0.352813\tAcc: 63.00\n",
      "train epoch: 23 [128/221852 (0%)]\tLoss: 0.226425\tAcc: 72.00\n",
      "train epoch: 23 [12928/221852 (6%)]\tLoss: 0.369023\tAcc: 63.00\n",
      "train epoch: 23 [25728/221852 (12%)]\tLoss: 0.166330\tAcc: 61.00\n",
      "train epoch: 23 [38528/221852 (17%)]\tLoss: 0.294017\tAcc: 68.00\n",
      "train epoch: 23 [51328/221852 (23%)]\tLoss: 0.305541\tAcc: 61.00\n",
      "train epoch: 23 [64128/221852 (29%)]\tLoss: 0.260383\tAcc: 69.00\n",
      "train epoch: 23 [76928/221852 (35%)]\tLoss: 0.359273\tAcc: 66.00\n",
      "train epoch: 23 [89728/221852 (40%)]\tLoss: 0.310720\tAcc: 70.00\n",
      "train epoch: 23 [102528/221852 (46%)]\tLoss: 0.316259\tAcc: 65.00\n",
      "train epoch: 23 [115328/221852 (52%)]\tLoss: 0.217046\tAcc: 66.00\n",
      "train epoch: 23 [128128/221852 (58%)]\tLoss: 0.178168\tAcc: 67.00\n",
      "train epoch: 23 [140928/221852 (64%)]\tLoss: 0.301247\tAcc: 62.00\n",
      "train epoch: 23 [153728/221852 (69%)]\tLoss: 0.229504\tAcc: 60.00\n",
      "train epoch: 23 [166528/221852 (75%)]\tLoss: 0.316452\tAcc: 61.00\n",
      "train epoch: 23 [179328/221852 (81%)]\tLoss: 0.213939\tAcc: 68.00\n",
      "train epoch: 23 [192128/221852 (87%)]\tLoss: 0.306820\tAcc: 66.00\n",
      "val epoch: 23 [128/221852 (0%)]\tLoss: 0.271076\tAcc: 63.00\n",
      "val epoch: 23 [12928/221852 (6%)]\tLoss: 0.247091\tAcc: 73.00\n",
      "train epoch: 24 [128/221852 (0%)]\tLoss: 0.260446\tAcc: 67.00\n",
      "train epoch: 24 [12928/221852 (6%)]\tLoss: 0.398524\tAcc: 59.00\n",
      "train epoch: 24 [25728/221852 (12%)]\tLoss: 0.271592\tAcc: 72.00\n",
      "train epoch: 24 [38528/221852 (17%)]\tLoss: 0.341653\tAcc: 62.00\n",
      "train epoch: 24 [51328/221852 (23%)]\tLoss: 0.320089\tAcc: 66.00\n",
      "train epoch: 24 [64128/221852 (29%)]\tLoss: 0.277183\tAcc: 73.00\n",
      "train epoch: 24 [76928/221852 (35%)]\tLoss: 0.258985\tAcc: 66.00\n",
      "train epoch: 24 [89728/221852 (40%)]\tLoss: 0.225581\tAcc: 61.00\n",
      "train epoch: 24 [102528/221852 (46%)]\tLoss: 0.381348\tAcc: 60.00\n",
      "train epoch: 24 [115328/221852 (52%)]\tLoss: 0.279011\tAcc: 67.00\n",
      "train epoch: 24 [128128/221852 (58%)]\tLoss: 0.329022\tAcc: 64.00\n",
      "train epoch: 24 [140928/221852 (64%)]\tLoss: 0.265024\tAcc: 62.00\n",
      "train epoch: 24 [153728/221852 (69%)]\tLoss: 0.229492\tAcc: 69.00\n",
      "train epoch: 24 [166528/221852 (75%)]\tLoss: 0.393724\tAcc: 63.00\n",
      "train epoch: 24 [179328/221852 (81%)]\tLoss: 0.352549\tAcc: 67.00\n",
      "train epoch: 24 [192128/221852 (87%)]\tLoss: 0.253567\tAcc: 78.00\n",
      "val epoch: 24 [128/221852 (0%)]\tLoss: 0.248666\tAcc: 64.00\n",
      "val epoch: 24 [12928/221852 (6%)]\tLoss: 0.264144\tAcc: 67.00\n",
      "train epoch: 25 [128/221852 (0%)]\tLoss: 0.236695\tAcc: 69.00\n",
      "train epoch: 25 [12928/221852 (6%)]\tLoss: 0.215602\tAcc: 67.00\n",
      "train epoch: 25 [25728/221852 (12%)]\tLoss: 0.331531\tAcc: 70.00\n",
      "train epoch: 25 [38528/221852 (17%)]\tLoss: 0.414047\tAcc: 62.00\n",
      "train epoch: 25 [51328/221852 (23%)]\tLoss: 0.265531\tAcc: 60.00\n",
      "train epoch: 25 [64128/221852 (29%)]\tLoss: 0.337221\tAcc: 66.00\n",
      "train epoch: 25 [76928/221852 (35%)]\tLoss: 0.294006\tAcc: 62.00\n",
      "train epoch: 25 [89728/221852 (40%)]\tLoss: 0.267274\tAcc: 66.00\n",
      "train epoch: 25 [102528/221852 (46%)]\tLoss: 0.361712\tAcc: 67.00\n",
      "train epoch: 25 [115328/221852 (52%)]\tLoss: 0.323050\tAcc: 63.00\n",
      "train epoch: 25 [128128/221852 (58%)]\tLoss: 0.192449\tAcc: 73.00\n",
      "train epoch: 25 [140928/221852 (64%)]\tLoss: 0.287649\tAcc: 73.00\n",
      "train epoch: 25 [153728/221852 (69%)]\tLoss: 0.315369\tAcc: 64.00\n",
      "train epoch: 25 [166528/221852 (75%)]\tLoss: 0.307190\tAcc: 62.00\n",
      "train epoch: 25 [179328/221852 (81%)]\tLoss: 0.284183\tAcc: 59.00\n",
      "train epoch: 25 [192128/221852 (87%)]\tLoss: 0.299995\tAcc: 66.00\n",
      "val epoch: 25 [128/221852 (0%)]\tLoss: 0.196292\tAcc: 70.00\n",
      "val epoch: 25 [12928/221852 (6%)]\tLoss: 0.292568\tAcc: 67.00\n",
      "train epoch: 26 [128/221852 (0%)]\tLoss: 0.297718\tAcc: 70.00\n",
      "train epoch: 26 [12928/221852 (6%)]\tLoss: 0.282312\tAcc: 66.00\n",
      "train epoch: 26 [25728/221852 (12%)]\tLoss: 0.378430\tAcc: 66.00\n",
      "train epoch: 26 [38528/221852 (17%)]\tLoss: 0.291037\tAcc: 70.00\n",
      "train epoch: 26 [51328/221852 (23%)]\tLoss: 0.233944\tAcc: 70.00\n",
      "train epoch: 26 [64128/221852 (29%)]\tLoss: 0.220197\tAcc: 67.00\n",
      "train epoch: 26 [76928/221852 (35%)]\tLoss: 0.385641\tAcc: 67.00\n",
      "train epoch: 26 [89728/221852 (40%)]\tLoss: 0.259021\tAcc: 68.00\n",
      "train epoch: 26 [102528/221852 (46%)]\tLoss: 0.294095\tAcc: 62.00\n",
      "train epoch: 26 [115328/221852 (52%)]\tLoss: 0.311771\tAcc: 73.00\n",
      "train epoch: 26 [128128/221852 (58%)]\tLoss: 0.202012\tAcc: 63.00\n",
      "train epoch: 26 [140928/221852 (64%)]\tLoss: 0.296068\tAcc: 66.00\n",
      "train epoch: 26 [153728/221852 (69%)]\tLoss: 0.361469\tAcc: 62.00\n",
      "train epoch: 26 [166528/221852 (75%)]\tLoss: 0.225928\tAcc: 68.00\n",
      "train epoch: 26 [179328/221852 (81%)]\tLoss: 0.269547\tAcc: 73.00\n",
      "train epoch: 26 [192128/221852 (87%)]\tLoss: 0.279447\tAcc: 60.00\n",
      "val epoch: 26 [128/221852 (0%)]\tLoss: 0.281173\tAcc: 69.00\n",
      "val epoch: 26 [12928/221852 (6%)]\tLoss: 0.401734\tAcc: 60.00\n",
      "train epoch: 27 [128/221852 (0%)]\tLoss: 0.320122\tAcc: 73.00\n",
      "train epoch: 27 [12928/221852 (6%)]\tLoss: 0.294467\tAcc: 59.00\n",
      "train epoch: 27 [25728/221852 (12%)]\tLoss: 0.226577\tAcc: 71.00\n",
      "train epoch: 27 [38528/221852 (17%)]\tLoss: 0.413602\tAcc: 68.00\n",
      "train epoch: 27 [51328/221852 (23%)]\tLoss: 0.304233\tAcc: 58.00\n",
      "train epoch: 27 [64128/221852 (29%)]\tLoss: 0.316761\tAcc: 70.00\n",
      "train epoch: 27 [76928/221852 (35%)]\tLoss: 0.242743\tAcc: 66.00\n",
      "train epoch: 27 [89728/221852 (40%)]\tLoss: 0.230997\tAcc: 70.00\n",
      "train epoch: 27 [102528/221852 (46%)]\tLoss: 0.309454\tAcc: 59.00\n",
      "train epoch: 27 [115328/221852 (52%)]\tLoss: 0.244728\tAcc: 64.00\n",
      "train epoch: 27 [128128/221852 (58%)]\tLoss: 0.245177\tAcc: 70.00\n",
      "train epoch: 27 [140928/221852 (64%)]\tLoss: 0.276611\tAcc: 66.00\n",
      "train epoch: 27 [153728/221852 (69%)]\tLoss: 0.351646\tAcc: 69.00\n",
      "train epoch: 27 [166528/221852 (75%)]\tLoss: 0.245728\tAcc: 67.00\n",
      "train epoch: 27 [179328/221852 (81%)]\tLoss: 0.291109\tAcc: 60.00\n",
      "train epoch: 27 [192128/221852 (87%)]\tLoss: 0.281036\tAcc: 66.00\n",
      "val epoch: 27 [128/221852 (0%)]\tLoss: 0.361775\tAcc: 68.00\n",
      "val epoch: 27 [12928/221852 (6%)]\tLoss: 0.417727\tAcc: 61.00\n",
      "train epoch: 28 [128/221852 (0%)]\tLoss: 0.316678\tAcc: 62.00\n",
      "train epoch: 28 [12928/221852 (6%)]\tLoss: 0.227317\tAcc: 74.00\n",
      "train epoch: 28 [25728/221852 (12%)]\tLoss: 0.299598\tAcc: 62.00\n",
      "train epoch: 28 [38528/221852 (17%)]\tLoss: 0.361959\tAcc: 63.00\n",
      "train epoch: 28 [51328/221852 (23%)]\tLoss: 0.329969\tAcc: 61.00\n",
      "train epoch: 28 [64128/221852 (29%)]\tLoss: 0.254811\tAcc: 63.00\n",
      "train epoch: 28 [76928/221852 (35%)]\tLoss: 0.260923\tAcc: 64.00\n",
      "train epoch: 28 [89728/221852 (40%)]\tLoss: 0.228755\tAcc: 64.00\n",
      "train epoch: 28 [102528/221852 (46%)]\tLoss: 0.298443\tAcc: 69.00\n",
      "train epoch: 28 [115328/221852 (52%)]\tLoss: 0.274318\tAcc: 67.00\n",
      "train epoch: 28 [128128/221852 (58%)]\tLoss: 0.223761\tAcc: 59.00\n",
      "train epoch: 28 [140928/221852 (64%)]\tLoss: 0.227350\tAcc: 71.00\n",
      "train epoch: 28 [153728/221852 (69%)]\tLoss: 0.284712\tAcc: 62.00\n",
      "train epoch: 28 [166528/221852 (75%)]\tLoss: 0.252365\tAcc: 67.00\n",
      "train epoch: 28 [179328/221852 (81%)]\tLoss: 0.248117\tAcc: 63.00\n",
      "train epoch: 28 [192128/221852 (87%)]\tLoss: 0.356459\tAcc: 61.00\n",
      "val epoch: 28 [128/221852 (0%)]\tLoss: 0.184006\tAcc: 68.00\n",
      "val epoch: 28 [12928/221852 (6%)]\tLoss: 0.236940\tAcc: 68.00\n",
      "train epoch: 29 [128/221852 (0%)]\tLoss: 0.267222\tAcc: 62.00\n",
      "train epoch: 29 [12928/221852 (6%)]\tLoss: 0.227773\tAcc: 66.00\n",
      "train epoch: 29 [25728/221852 (12%)]\tLoss: 0.309340\tAcc: 69.00\n",
      "train epoch: 29 [38528/221852 (17%)]\tLoss: 0.238696\tAcc: 66.00\n",
      "train epoch: 29 [51328/221852 (23%)]\tLoss: 0.266363\tAcc: 75.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 29 [64128/221852 (29%)]\tLoss: 0.273591\tAcc: 64.00\n",
      "train epoch: 29 [76928/221852 (35%)]\tLoss: 0.301334\tAcc: 70.00\n",
      "train epoch: 29 [89728/221852 (40%)]\tLoss: 0.291936\tAcc: 62.00\n",
      "train epoch: 29 [102528/221852 (46%)]\tLoss: 0.257726\tAcc: 66.00\n",
      "train epoch: 29 [115328/221852 (52%)]\tLoss: 0.285952\tAcc: 64.00\n",
      "train epoch: 29 [128128/221852 (58%)]\tLoss: 0.266442\tAcc: 71.00\n",
      "train epoch: 29 [140928/221852 (64%)]\tLoss: 0.250121\tAcc: 72.00\n",
      "train epoch: 29 [153728/221852 (69%)]\tLoss: 0.349778\tAcc: 59.00\n",
      "train epoch: 29 [166528/221852 (75%)]\tLoss: 0.306167\tAcc: 59.00\n",
      "train epoch: 29 [179328/221852 (81%)]\tLoss: 0.223326\tAcc: 69.00\n",
      "train epoch: 29 [192128/221852 (87%)]\tLoss: 0.278118\tAcc: 69.00\n",
      "val epoch: 29 [128/221852 (0%)]\tLoss: 0.344184\tAcc: 60.00\n",
      "val epoch: 29 [12928/221852 (6%)]\tLoss: 0.292732\tAcc: 68.00\n",
      "train epoch: 30 [128/221852 (0%)]\tLoss: 0.347521\tAcc: 69.00\n",
      "train epoch: 30 [12928/221852 (6%)]\tLoss: 0.240020\tAcc: 66.00\n",
      "train epoch: 30 [25728/221852 (12%)]\tLoss: 0.193811\tAcc: 64.00\n",
      "train epoch: 30 [38528/221852 (17%)]\tLoss: 0.312402\tAcc: 65.00\n",
      "train epoch: 30 [51328/221852 (23%)]\tLoss: 0.250922\tAcc: 66.00\n",
      "train epoch: 30 [64128/221852 (29%)]\tLoss: 0.208208\tAcc: 65.00\n",
      "train epoch: 30 [76928/221852 (35%)]\tLoss: 0.282202\tAcc: 70.00\n",
      "train epoch: 30 [89728/221852 (40%)]\tLoss: 0.257180\tAcc: 67.00\n",
      "train epoch: 30 [102528/221852 (46%)]\tLoss: 0.334907\tAcc: 66.00\n",
      "train epoch: 30 [115328/221852 (52%)]\tLoss: 0.407922\tAcc: 62.00\n",
      "train epoch: 30 [128128/221852 (58%)]\tLoss: 0.332290\tAcc: 67.00\n",
      "train epoch: 30 [140928/221852 (64%)]\tLoss: 0.215448\tAcc: 68.00\n",
      "train epoch: 30 [153728/221852 (69%)]\tLoss: 0.263763\tAcc: 72.00\n",
      "train epoch: 30 [166528/221852 (75%)]\tLoss: 0.222596\tAcc: 76.00\n",
      "train epoch: 30 [179328/221852 (81%)]\tLoss: 0.352075\tAcc: 67.00\n",
      "train epoch: 30 [192128/221852 (87%)]\tLoss: 0.326735\tAcc: 65.00\n",
      "val epoch: 30 [128/221852 (0%)]\tLoss: 0.233117\tAcc: 67.00\n",
      "val epoch: 30 [12928/221852 (6%)]\tLoss: 0.254279\tAcc: 65.00\n",
      "train epoch: 31 [128/221852 (0%)]\tLoss: 0.277025\tAcc: 69.00\n",
      "train epoch: 31 [12928/221852 (6%)]\tLoss: 0.332158\tAcc: 55.00\n",
      "train epoch: 31 [25728/221852 (12%)]\tLoss: 0.230226\tAcc: 69.00\n",
      "train epoch: 31 [38528/221852 (17%)]\tLoss: 0.297357\tAcc: 66.00\n",
      "train epoch: 31 [51328/221852 (23%)]\tLoss: 0.282461\tAcc: 67.00\n",
      "train epoch: 31 [64128/221852 (29%)]\tLoss: 0.301030\tAcc: 72.00\n",
      "train epoch: 31 [76928/221852 (35%)]\tLoss: 0.298628\tAcc: 67.00\n",
      "train epoch: 31 [89728/221852 (40%)]\tLoss: 0.290839\tAcc: 65.00\n",
      "train epoch: 31 [102528/221852 (46%)]\tLoss: 0.319987\tAcc: 68.00\n",
      "train epoch: 31 [115328/221852 (52%)]\tLoss: 0.165256\tAcc: 70.00\n",
      "train epoch: 31 [128128/221852 (58%)]\tLoss: 0.344620\tAcc: 50.00\n",
      "train epoch: 31 [140928/221852 (64%)]\tLoss: 0.192889\tAcc: 73.00\n",
      "train epoch: 31 [153728/221852 (69%)]\tLoss: 0.277667\tAcc: 63.00\n",
      "train epoch: 31 [166528/221852 (75%)]\tLoss: 0.302898\tAcc: 60.00\n",
      "train epoch: 31 [179328/221852 (81%)]\tLoss: 0.365425\tAcc: 67.00\n",
      "train epoch: 31 [192128/221852 (87%)]\tLoss: 0.244372\tAcc: 68.00\n",
      "val epoch: 31 [128/221852 (0%)]\tLoss: 0.241434\tAcc: 66.00\n",
      "val epoch: 31 [12928/221852 (6%)]\tLoss: 0.274270\tAcc: 67.00\n",
      "train epoch: 32 [128/221852 (0%)]\tLoss: 0.193066\tAcc: 70.00\n",
      "train epoch: 32 [12928/221852 (6%)]\tLoss: 0.265909\tAcc: 62.00\n",
      "train epoch: 32 [25728/221852 (12%)]\tLoss: 0.270529\tAcc: 72.00\n",
      "train epoch: 32 [38528/221852 (17%)]\tLoss: 0.262717\tAcc: 70.00\n",
      "train epoch: 32 [51328/221852 (23%)]\tLoss: 0.199905\tAcc: 68.00\n",
      "train epoch: 32 [64128/221852 (29%)]\tLoss: 0.313356\tAcc: 66.00\n",
      "train epoch: 32 [76928/221852 (35%)]\tLoss: 0.313798\tAcc: 67.00\n",
      "train epoch: 32 [89728/221852 (40%)]\tLoss: 0.214326\tAcc: 76.00\n",
      "train epoch: 32 [102528/221852 (46%)]\tLoss: 0.304816\tAcc: 72.00\n",
      "train epoch: 32 [115328/221852 (52%)]\tLoss: 0.245620\tAcc: 67.00\n",
      "train epoch: 32 [128128/221852 (58%)]\tLoss: 0.238197\tAcc: 76.00\n",
      "train epoch: 32 [140928/221852 (64%)]\tLoss: 0.210893\tAcc: 59.00\n",
      "train epoch: 32 [153728/221852 (69%)]\tLoss: 0.202834\tAcc: 67.00\n",
      "train epoch: 32 [166528/221852 (75%)]\tLoss: 0.275202\tAcc: 71.00\n",
      "train epoch: 32 [179328/221852 (81%)]\tLoss: 0.320478\tAcc: 62.00\n",
      "train epoch: 32 [192128/221852 (87%)]\tLoss: 0.302744\tAcc: 63.00\n",
      "val epoch: 32 [128/221852 (0%)]\tLoss: 0.282458\tAcc: 68.00\n",
      "val epoch: 32 [12928/221852 (6%)]\tLoss: 0.274506\tAcc: 57.00\n",
      "train epoch: 33 [128/221852 (0%)]\tLoss: 0.193931\tAcc: 64.00\n",
      "train epoch: 33 [12928/221852 (6%)]\tLoss: 0.239424\tAcc: 70.00\n",
      "train epoch: 33 [25728/221852 (12%)]\tLoss: 0.260406\tAcc: 64.00\n",
      "train epoch: 33 [38528/221852 (17%)]\tLoss: 0.313651\tAcc: 67.00\n",
      "train epoch: 33 [51328/221852 (23%)]\tLoss: 0.313577\tAcc: 68.00\n",
      "train epoch: 33 [64128/221852 (29%)]\tLoss: 0.302960\tAcc: 67.00\n",
      "train epoch: 33 [76928/221852 (35%)]\tLoss: 0.237454\tAcc: 60.00\n",
      "train epoch: 33 [89728/221852 (40%)]\tLoss: 0.233165\tAcc: 66.00\n",
      "train epoch: 33 [102528/221852 (46%)]\tLoss: 0.289214\tAcc: 70.00\n",
      "train epoch: 33 [115328/221852 (52%)]\tLoss: 0.300030\tAcc: 66.00\n",
      "train epoch: 33 [128128/221852 (58%)]\tLoss: 0.407990\tAcc: 69.00\n",
      "train epoch: 33 [140928/221852 (64%)]\tLoss: 0.372747\tAcc: 66.00\n",
      "train epoch: 33 [153728/221852 (69%)]\tLoss: 0.188611\tAcc: 68.00\n",
      "train epoch: 33 [166528/221852 (75%)]\tLoss: 0.220749\tAcc: 67.00\n",
      "train epoch: 33 [179328/221852 (81%)]\tLoss: 0.313370\tAcc: 66.00\n",
      "train epoch: 33 [192128/221852 (87%)]\tLoss: 0.242499\tAcc: 62.00\n",
      "val epoch: 33 [128/221852 (0%)]\tLoss: 0.258683\tAcc: 66.00\n",
      "val epoch: 33 [12928/221852 (6%)]\tLoss: 0.239527\tAcc: 71.00\n",
      "train epoch: 34 [128/221852 (0%)]\tLoss: 0.239643\tAcc: 70.00\n",
      "train epoch: 34 [12928/221852 (6%)]\tLoss: 0.194247\tAcc: 74.00\n",
      "train epoch: 34 [25728/221852 (12%)]\tLoss: 0.350391\tAcc: 55.00\n",
      "train epoch: 34 [38528/221852 (17%)]\tLoss: 0.265606\tAcc: 70.00\n",
      "train epoch: 34 [51328/221852 (23%)]\tLoss: 0.197073\tAcc: 72.00\n",
      "train epoch: 34 [64128/221852 (29%)]\tLoss: 0.347956\tAcc: 74.00\n",
      "train epoch: 34 [76928/221852 (35%)]\tLoss: 0.178873\tAcc: 70.00\n",
      "train epoch: 34 [89728/221852 (40%)]\tLoss: 0.252336\tAcc: 65.00\n",
      "train epoch: 34 [102528/221852 (46%)]\tLoss: 0.282515\tAcc: 62.00\n",
      "train epoch: 34 [115328/221852 (52%)]\tLoss: 0.232384\tAcc: 77.00\n",
      "train epoch: 34 [128128/221852 (58%)]\tLoss: 0.322906\tAcc: 66.00\n",
      "train epoch: 34 [140928/221852 (64%)]\tLoss: 0.284290\tAcc: 69.00\n",
      "train epoch: 34 [153728/221852 (69%)]\tLoss: 0.292604\tAcc: 66.00\n",
      "train epoch: 34 [166528/221852 (75%)]\tLoss: 0.269428\tAcc: 64.00\n",
      "train epoch: 34 [179328/221852 (81%)]\tLoss: 0.197603\tAcc: 68.00\n",
      "train epoch: 34 [192128/221852 (87%)]\tLoss: 0.237718\tAcc: 69.00\n",
      "val epoch: 34 [128/221852 (0%)]\tLoss: 0.239804\tAcc: 60.00\n",
      "val epoch: 34 [12928/221852 (6%)]\tLoss: 0.223225\tAcc: 70.00\n",
      "train epoch: 35 [128/221852 (0%)]\tLoss: 0.218606\tAcc: 67.00\n",
      "train epoch: 35 [12928/221852 (6%)]\tLoss: 0.252021\tAcc: 74.00\n",
      "train epoch: 35 [25728/221852 (12%)]\tLoss: 0.201659\tAcc: 66.00\n",
      "train epoch: 35 [38528/221852 (17%)]\tLoss: 0.248265\tAcc: 71.00\n",
      "train epoch: 35 [51328/221852 (23%)]\tLoss: 0.272208\tAcc: 70.00\n",
      "train epoch: 35 [64128/221852 (29%)]\tLoss: 0.295741\tAcc: 62.00\n",
      "train epoch: 35 [76928/221852 (35%)]\tLoss: 0.411947\tAcc: 69.00\n",
      "train epoch: 35 [89728/221852 (40%)]\tLoss: 0.329230\tAcc: 68.00\n",
      "train epoch: 35 [102528/221852 (46%)]\tLoss: 0.990641\tAcc: 59.00\n",
      "train epoch: 35 [115328/221852 (52%)]\tLoss: 0.318999\tAcc: 60.00\n",
      "train epoch: 35 [128128/221852 (58%)]\tLoss: 0.229114\tAcc: 64.00\n",
      "train epoch: 35 [140928/221852 (64%)]\tLoss: 0.300620\tAcc: 77.00\n",
      "train epoch: 35 [153728/221852 (69%)]\tLoss: 0.200783\tAcc: 66.00\n",
      "train epoch: 35 [166528/221852 (75%)]\tLoss: 0.292696\tAcc: 70.00\n",
      "train epoch: 35 [179328/221852 (81%)]\tLoss: 0.225973\tAcc: 68.00\n",
      "train epoch: 35 [192128/221852 (87%)]\tLoss: 0.336188\tAcc: 62.00\n",
      "val epoch: 35 [128/221852 (0%)]\tLoss: 0.315943\tAcc: 64.00\n",
      "val epoch: 35 [12928/221852 (6%)]\tLoss: 0.268921\tAcc: 63.00\n",
      "train epoch: 36 [128/221852 (0%)]\tLoss: 0.320027\tAcc: 73.00\n",
      "train epoch: 36 [12928/221852 (6%)]\tLoss: 0.213580\tAcc: 63.00\n",
      "train epoch: 36 [25728/221852 (12%)]\tLoss: 0.368874\tAcc: 67.00\n",
      "train epoch: 36 [38528/221852 (17%)]\tLoss: 0.271361\tAcc: 64.00\n",
      "train epoch: 36 [51328/221852 (23%)]\tLoss: 0.253042\tAcc: 72.00\n",
      "train epoch: 36 [64128/221852 (29%)]\tLoss: 0.272751\tAcc: 58.00\n",
      "train epoch: 36 [76928/221852 (35%)]\tLoss: 0.287967\tAcc: 68.00\n",
      "train epoch: 36 [89728/221852 (40%)]\tLoss: 0.322308\tAcc: 62.00\n",
      "train epoch: 36 [102528/221852 (46%)]\tLoss: 0.302949\tAcc: 66.00\n",
      "train epoch: 36 [115328/221852 (52%)]\tLoss: 0.204566\tAcc: 80.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 36 [128128/221852 (58%)]\tLoss: 0.243660\tAcc: 58.00\n",
      "train epoch: 36 [140928/221852 (64%)]\tLoss: 0.196207\tAcc: 65.00\n",
      "train epoch: 36 [153728/221852 (69%)]\tLoss: 0.246473\tAcc: 63.00\n",
      "train epoch: 36 [166528/221852 (75%)]\tLoss: 0.329241\tAcc: 66.00\n",
      "train epoch: 36 [179328/221852 (81%)]\tLoss: 0.213958\tAcc: 62.00\n",
      "train epoch: 36 [192128/221852 (87%)]\tLoss: 0.199371\tAcc: 66.00\n",
      "val epoch: 36 [128/221852 (0%)]\tLoss: 0.213363\tAcc: 73.00\n",
      "val epoch: 36 [12928/221852 (6%)]\tLoss: 0.336649\tAcc: 70.00\n",
      "train epoch: 37 [128/221852 (0%)]\tLoss: 0.288052\tAcc: 66.00\n",
      "train epoch: 37 [12928/221852 (6%)]\tLoss: 0.239305\tAcc: 64.00\n",
      "train epoch: 37 [25728/221852 (12%)]\tLoss: 0.145829\tAcc: 73.00\n",
      "train epoch: 37 [38528/221852 (17%)]\tLoss: 0.227067\tAcc: 70.00\n",
      "train epoch: 37 [51328/221852 (23%)]\tLoss: 0.283482\tAcc: 55.00\n",
      "train epoch: 37 [64128/221852 (29%)]\tLoss: 0.203096\tAcc: 77.00\n",
      "train epoch: 37 [76928/221852 (35%)]\tLoss: 0.273098\tAcc: 68.00\n",
      "train epoch: 37 [89728/221852 (40%)]\tLoss: 0.233663\tAcc: 63.00\n",
      "train epoch: 37 [102528/221852 (46%)]\tLoss: 0.290015\tAcc: 66.00\n",
      "train epoch: 37 [115328/221852 (52%)]\tLoss: 0.321112\tAcc: 66.00\n",
      "train epoch: 37 [128128/221852 (58%)]\tLoss: 0.205480\tAcc: 65.00\n",
      "train epoch: 37 [140928/221852 (64%)]\tLoss: 0.321697\tAcc: 66.00\n",
      "train epoch: 37 [153728/221852 (69%)]\tLoss: 0.267876\tAcc: 61.00\n",
      "train epoch: 37 [166528/221852 (75%)]\tLoss: 0.237751\tAcc: 66.00\n",
      "train epoch: 37 [179328/221852 (81%)]\tLoss: 0.292727\tAcc: 70.00\n",
      "train epoch: 37 [192128/221852 (87%)]\tLoss: 0.401178\tAcc: 67.00\n",
      "val epoch: 37 [128/221852 (0%)]\tLoss: 0.379586\tAcc: 62.00\n",
      "val epoch: 37 [12928/221852 (6%)]\tLoss: 0.390406\tAcc: 66.00\n",
      "train epoch: 38 [128/221852 (0%)]\tLoss: 0.390069\tAcc: 64.00\n",
      "train epoch: 38 [12928/221852 (6%)]\tLoss: 0.266178\tAcc: 65.00\n",
      "train epoch: 38 [25728/221852 (12%)]\tLoss: 0.270208\tAcc: 65.00\n",
      "train epoch: 38 [38528/221852 (17%)]\tLoss: 0.289545\tAcc: 67.00\n",
      "train epoch: 38 [51328/221852 (23%)]\tLoss: 0.303746\tAcc: 70.00\n",
      "train epoch: 38 [64128/221852 (29%)]\tLoss: 0.330142\tAcc: 73.00\n",
      "train epoch: 38 [76928/221852 (35%)]\tLoss: 0.334091\tAcc: 66.00\n",
      "train epoch: 38 [89728/221852 (40%)]\tLoss: 0.209336\tAcc: 73.00\n",
      "train epoch: 38 [102528/221852 (46%)]\tLoss: 0.221176\tAcc: 77.00\n",
      "train epoch: 38 [115328/221852 (52%)]\tLoss: 0.237749\tAcc: 73.00\n",
      "train epoch: 38 [128128/221852 (58%)]\tLoss: 0.277624\tAcc: 72.00\n",
      "train epoch: 38 [140928/221852 (64%)]\tLoss: 0.229945\tAcc: 66.00\n",
      "train epoch: 38 [153728/221852 (69%)]\tLoss: 0.280788\tAcc: 72.00\n",
      "train epoch: 38 [166528/221852 (75%)]\tLoss: 0.304015\tAcc: 66.00\n",
      "train epoch: 38 [179328/221852 (81%)]\tLoss: 0.291959\tAcc: 68.00\n",
      "train epoch: 38 [192128/221852 (87%)]\tLoss: 0.204173\tAcc: 71.00\n",
      "val epoch: 38 [128/221852 (0%)]\tLoss: 0.241392\tAcc: 66.00\n",
      "val epoch: 38 [12928/221852 (6%)]\tLoss: 0.278562\tAcc: 71.00\n",
      "train epoch: 39 [128/221852 (0%)]\tLoss: 0.232417\tAcc: 73.00\n",
      "train epoch: 39 [12928/221852 (6%)]\tLoss: 0.270733\tAcc: 70.00\n",
      "train epoch: 39 [25728/221852 (12%)]\tLoss: 0.176471\tAcc: 72.00\n",
      "train epoch: 39 [38528/221852 (17%)]\tLoss: 0.254082\tAcc: 70.00\n",
      "train epoch: 39 [51328/221852 (23%)]\tLoss: 0.212696\tAcc: 77.00\n",
      "train epoch: 39 [64128/221852 (29%)]\tLoss: 0.321965\tAcc: 70.00\n",
      "train epoch: 39 [76928/221852 (35%)]\tLoss: 0.294558\tAcc: 72.00\n",
      "train epoch: 39 [89728/221852 (40%)]\tLoss: 0.240443\tAcc: 68.00\n",
      "train epoch: 39 [102528/221852 (46%)]\tLoss: 0.192710\tAcc: 68.00\n",
      "train epoch: 39 [115328/221852 (52%)]\tLoss: 0.291276\tAcc: 68.00\n",
      "train epoch: 39 [128128/221852 (58%)]\tLoss: 0.272203\tAcc: 70.00\n",
      "train epoch: 39 [140928/221852 (64%)]\tLoss: 0.327996\tAcc: 70.00\n",
      "train epoch: 39 [153728/221852 (69%)]\tLoss: 0.209757\tAcc: 70.00\n",
      "train epoch: 39 [166528/221852 (75%)]\tLoss: 0.351276\tAcc: 54.00\n",
      "train epoch: 39 [179328/221852 (81%)]\tLoss: 0.244642\tAcc: 65.00\n",
      "train epoch: 39 [192128/221852 (87%)]\tLoss: 0.262158\tAcc: 59.00\n",
      "val epoch: 39 [128/221852 (0%)]\tLoss: 0.253805\tAcc: 70.00\n",
      "val epoch: 39 [12928/221852 (6%)]\tLoss: 0.245493\tAcc: 64.00\n",
      "train epoch: 40 [128/221852 (0%)]\tLoss: 0.255013\tAcc: 70.00\n",
      "train epoch: 40 [12928/221852 (6%)]\tLoss: 0.324433\tAcc: 66.00\n",
      "train epoch: 40 [25728/221852 (12%)]\tLoss: 0.311844\tAcc: 64.00\n",
      "train epoch: 40 [38528/221852 (17%)]\tLoss: 0.283660\tAcc: 70.00\n",
      "train epoch: 40 [51328/221852 (23%)]\tLoss: 0.250863\tAcc: 76.00\n",
      "train epoch: 40 [64128/221852 (29%)]\tLoss: 0.287016\tAcc: 64.00\n",
      "train epoch: 40 [76928/221852 (35%)]\tLoss: 0.338181\tAcc: 62.00\n",
      "train epoch: 40 [89728/221852 (40%)]\tLoss: 0.182363\tAcc: 68.00\n",
      "train epoch: 40 [102528/221852 (46%)]\tLoss: 0.245253\tAcc: 66.00\n",
      "train epoch: 40 [115328/221852 (52%)]\tLoss: 0.369364\tAcc: 74.00\n",
      "train epoch: 40 [128128/221852 (58%)]\tLoss: 0.283844\tAcc: 72.00\n",
      "train epoch: 40 [140928/221852 (64%)]\tLoss: 0.312598\tAcc: 68.00\n",
      "train epoch: 40 [153728/221852 (69%)]\tLoss: 0.284622\tAcc: 62.00\n",
      "train epoch: 40 [166528/221852 (75%)]\tLoss: 0.269030\tAcc: 70.00\n",
      "train epoch: 40 [179328/221852 (81%)]\tLoss: 0.201539\tAcc: 62.00\n",
      "train epoch: 40 [192128/221852 (87%)]\tLoss: 0.253934\tAcc: 67.00\n",
      "val epoch: 40 [128/221852 (0%)]\tLoss: 0.261856\tAcc: 66.00\n",
      "val epoch: 40 [12928/221852 (6%)]\tLoss: 0.196354\tAcc: 74.00\n",
      "train epoch: 41 [128/221852 (0%)]\tLoss: 0.266667\tAcc: 72.00\n",
      "train epoch: 41 [12928/221852 (6%)]\tLoss: 0.276980\tAcc: 73.00\n",
      "train epoch: 41 [25728/221852 (12%)]\tLoss: 0.350306\tAcc: 66.00\n",
      "train epoch: 41 [38528/221852 (17%)]\tLoss: 0.298460\tAcc: 66.00\n",
      "train epoch: 41 [51328/221852 (23%)]\tLoss: 0.244401\tAcc: 60.00\n",
      "train epoch: 41 [64128/221852 (29%)]\tLoss: 0.204528\tAcc: 68.00\n",
      "train epoch: 41 [76928/221852 (35%)]\tLoss: 0.271709\tAcc: 66.00\n",
      "train epoch: 41 [89728/221852 (40%)]\tLoss: 0.421746\tAcc: 61.00\n",
      "train epoch: 41 [102528/221852 (46%)]\tLoss: 0.284348\tAcc: 66.00\n",
      "train epoch: 41 [115328/221852 (52%)]\tLoss: 0.459508\tAcc: 70.00\n",
      "train epoch: 41 [128128/221852 (58%)]\tLoss: 0.264951\tAcc: 71.00\n",
      "train epoch: 41 [140928/221852 (64%)]\tLoss: 0.299990\tAcc: 65.00\n",
      "train epoch: 41 [153728/221852 (69%)]\tLoss: 0.326039\tAcc: 66.00\n",
      "train epoch: 41 [166528/221852 (75%)]\tLoss: 0.215000\tAcc: 66.00\n",
      "train epoch: 41 [179328/221852 (81%)]\tLoss: 0.306693\tAcc: 72.00\n",
      "train epoch: 41 [192128/221852 (87%)]\tLoss: 0.194616\tAcc: 70.00\n",
      "val epoch: 41 [128/221852 (0%)]\tLoss: 0.295923\tAcc: 67.00\n",
      "val epoch: 41 [12928/221852 (6%)]\tLoss: 0.239991\tAcc: 68.00\n",
      "train epoch: 42 [128/221852 (0%)]\tLoss: 0.202522\tAcc: 77.00\n",
      "train epoch: 42 [12928/221852 (6%)]\tLoss: 0.216269\tAcc: 70.00\n",
      "train epoch: 42 [25728/221852 (12%)]\tLoss: 0.240564\tAcc: 71.00\n",
      "train epoch: 42 [38528/221852 (17%)]\tLoss: 0.342626\tAcc: 66.00\n",
      "train epoch: 42 [51328/221852 (23%)]\tLoss: 0.293993\tAcc: 69.00\n",
      "train epoch: 42 [64128/221852 (29%)]\tLoss: 0.244423\tAcc: 70.00\n",
      "train epoch: 42 [76928/221852 (35%)]\tLoss: 0.261740\tAcc: 69.00\n",
      "train epoch: 42 [89728/221852 (40%)]\tLoss: 0.279911\tAcc: 66.00\n",
      "train epoch: 42 [102528/221852 (46%)]\tLoss: 0.242931\tAcc: 66.00\n",
      "train epoch: 42 [115328/221852 (52%)]\tLoss: 0.234259\tAcc: 67.00\n",
      "train epoch: 42 [128128/221852 (58%)]\tLoss: 0.352653\tAcc: 64.00\n",
      "train epoch: 42 [140928/221852 (64%)]\tLoss: 0.254053\tAcc: 70.00\n",
      "train epoch: 42 [153728/221852 (69%)]\tLoss: 0.253859\tAcc: 65.00\n",
      "train epoch: 42 [166528/221852 (75%)]\tLoss: 0.312431\tAcc: 64.00\n",
      "train epoch: 42 [179328/221852 (81%)]\tLoss: 0.248206\tAcc: 64.00\n",
      "train epoch: 42 [192128/221852 (87%)]\tLoss: 0.227292\tAcc: 62.00\n",
      "val epoch: 42 [128/221852 (0%)]\tLoss: 0.177080\tAcc: 63.00\n",
      "val epoch: 42 [12928/221852 (6%)]\tLoss: 0.308032\tAcc: 68.00\n",
      "train epoch: 43 [128/221852 (0%)]\tLoss: 0.269256\tAcc: 70.00\n",
      "train epoch: 43 [12928/221852 (6%)]\tLoss: 0.172092\tAcc: 67.00\n",
      "train epoch: 43 [25728/221852 (12%)]\tLoss: 0.178346\tAcc: 78.00\n",
      "train epoch: 43 [38528/221852 (17%)]\tLoss: 0.186837\tAcc: 66.00\n",
      "train epoch: 43 [51328/221852 (23%)]\tLoss: 0.236470\tAcc: 66.00\n",
      "train epoch: 43 [64128/221852 (29%)]\tLoss: 0.309446\tAcc: 70.00\n",
      "train epoch: 43 [76928/221852 (35%)]\tLoss: 0.294245\tAcc: 71.00\n",
      "train epoch: 43 [89728/221852 (40%)]\tLoss: 0.267542\tAcc: 61.00\n",
      "train epoch: 43 [102528/221852 (46%)]\tLoss: 0.201043\tAcc: 73.00\n",
      "train epoch: 43 [115328/221852 (52%)]\tLoss: 0.253218\tAcc: 72.00\n",
      "train epoch: 43 [128128/221852 (58%)]\tLoss: 0.248304\tAcc: 74.00\n",
      "train epoch: 43 [140928/221852 (64%)]\tLoss: 0.324108\tAcc: 69.00\n",
      "train epoch: 43 [153728/221852 (69%)]\tLoss: 0.204995\tAcc: 73.00\n",
      "train epoch: 43 [166528/221852 (75%)]\tLoss: 0.263795\tAcc: 66.00\n",
      "train epoch: 43 [179328/221852 (81%)]\tLoss: 0.266615\tAcc: 68.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 43 [192128/221852 (87%)]\tLoss: 0.292782\tAcc: 66.00\n",
      "val epoch: 43 [128/221852 (0%)]\tLoss: 0.224567\tAcc: 67.00\n",
      "val epoch: 43 [12928/221852 (6%)]\tLoss: 0.175081\tAcc: 63.00\n",
      "train epoch: 44 [128/221852 (0%)]\tLoss: 0.337170\tAcc: 62.00\n",
      "train epoch: 44 [12928/221852 (6%)]\tLoss: 0.255966\tAcc: 65.00\n",
      "train epoch: 44 [25728/221852 (12%)]\tLoss: 0.179443\tAcc: 73.00\n",
      "train epoch: 44 [38528/221852 (17%)]\tLoss: 0.212857\tAcc: 72.00\n",
      "train epoch: 44 [51328/221852 (23%)]\tLoss: 0.212059\tAcc: 70.00\n",
      "train epoch: 44 [64128/221852 (29%)]\tLoss: 0.327727\tAcc: 68.00\n",
      "train epoch: 44 [76928/221852 (35%)]\tLoss: 0.201909\tAcc: 69.00\n",
      "train epoch: 44 [89728/221852 (40%)]\tLoss: 0.151669\tAcc: 70.00\n",
      "train epoch: 44 [102528/221852 (46%)]\tLoss: 0.289401\tAcc: 73.00\n",
      "train epoch: 44 [115328/221852 (52%)]\tLoss: 0.298423\tAcc: 71.00\n",
      "train epoch: 44 [128128/221852 (58%)]\tLoss: 0.213004\tAcc: 77.00\n",
      "train epoch: 44 [140928/221852 (64%)]\tLoss: 0.248846\tAcc: 64.00\n",
      "train epoch: 44 [153728/221852 (69%)]\tLoss: 0.278722\tAcc: 67.00\n",
      "train epoch: 44 [166528/221852 (75%)]\tLoss: 0.283767\tAcc: 72.00\n",
      "train epoch: 44 [179328/221852 (81%)]\tLoss: 0.301988\tAcc: 61.00\n",
      "train epoch: 44 [192128/221852 (87%)]\tLoss: 0.257197\tAcc: 65.00\n",
      "val epoch: 44 [128/221852 (0%)]\tLoss: 0.175824\tAcc: 79.00\n",
      "val epoch: 44 [12928/221852 (6%)]\tLoss: 0.191998\tAcc: 72.00\n",
      "train epoch: 45 [128/221852 (0%)]\tLoss: 0.349037\tAcc: 66.00\n",
      "train epoch: 45 [12928/221852 (6%)]\tLoss: 0.337650\tAcc: 62.00\n",
      "train epoch: 45 [25728/221852 (12%)]\tLoss: 0.250508\tAcc: 72.00\n",
      "train epoch: 45 [38528/221852 (17%)]\tLoss: 0.395696\tAcc: 65.00\n",
      "train epoch: 45 [51328/221852 (23%)]\tLoss: 0.253232\tAcc: 70.00\n",
      "train epoch: 45 [64128/221852 (29%)]\tLoss: 0.204047\tAcc: 72.00\n",
      "train epoch: 45 [76928/221852 (35%)]\tLoss: 0.503995\tAcc: 61.00\n",
      "train epoch: 45 [89728/221852 (40%)]\tLoss: 0.238942\tAcc: 72.00\n",
      "train epoch: 45 [102528/221852 (46%)]\tLoss: 0.285463\tAcc: 64.00\n",
      "train epoch: 45 [115328/221852 (52%)]\tLoss: 0.283155\tAcc: 66.00\n",
      "train epoch: 45 [128128/221852 (58%)]\tLoss: 0.200900\tAcc: 66.00\n",
      "train epoch: 45 [140928/221852 (64%)]\tLoss: 0.156490\tAcc: 67.00\n",
      "train epoch: 45 [153728/221852 (69%)]\tLoss: 0.241792\tAcc: 73.00\n",
      "train epoch: 45 [166528/221852 (75%)]\tLoss: 0.232675\tAcc: 69.00\n",
      "train epoch: 45 [179328/221852 (81%)]\tLoss: 0.311406\tAcc: 63.00\n",
      "train epoch: 45 [192128/221852 (87%)]\tLoss: 0.248879\tAcc: 70.00\n",
      "val epoch: 45 [128/221852 (0%)]\tLoss: 0.261779\tAcc: 76.00\n",
      "val epoch: 45 [12928/221852 (6%)]\tLoss: 0.184795\tAcc: 75.00\n",
      "train epoch: 46 [128/221852 (0%)]\tLoss: 0.216818\tAcc: 73.00\n",
      "train epoch: 46 [12928/221852 (6%)]\tLoss: 0.198999\tAcc: 72.00\n",
      "train epoch: 46 [25728/221852 (12%)]\tLoss: 0.292110\tAcc: 70.00\n",
      "train epoch: 46 [38528/221852 (17%)]\tLoss: 0.220332\tAcc: 73.00\n",
      "train epoch: 46 [51328/221852 (23%)]\tLoss: 0.249961\tAcc: 68.00\n",
      "train epoch: 46 [64128/221852 (29%)]\tLoss: 0.233637\tAcc: 63.00\n",
      "train epoch: 46 [76928/221852 (35%)]\tLoss: 0.322237\tAcc: 69.00\n",
      "train epoch: 46 [89728/221852 (40%)]\tLoss: 0.297104\tAcc: 70.00\n",
      "train epoch: 46 [102528/221852 (46%)]\tLoss: 0.261812\tAcc: 70.00\n",
      "train epoch: 46 [115328/221852 (52%)]\tLoss: 0.323202\tAcc: 68.00\n",
      "train epoch: 46 [128128/221852 (58%)]\tLoss: 0.236588\tAcc: 70.00\n",
      "train epoch: 46 [140928/221852 (64%)]\tLoss: 0.275072\tAcc: 62.00\n",
      "train epoch: 46 [153728/221852 (69%)]\tLoss: 0.243843\tAcc: 69.00\n",
      "train epoch: 46 [166528/221852 (75%)]\tLoss: 0.255479\tAcc: 74.00\n",
      "train epoch: 46 [179328/221852 (81%)]\tLoss: 0.233325\tAcc: 67.00\n",
      "train epoch: 46 [192128/221852 (87%)]\tLoss: 0.275174\tAcc: 69.00\n",
      "val epoch: 46 [128/221852 (0%)]\tLoss: 0.233078\tAcc: 69.00\n",
      "val epoch: 46 [12928/221852 (6%)]\tLoss: 0.319336\tAcc: 68.00\n",
      "train epoch: 47 [128/221852 (0%)]\tLoss: 0.263972\tAcc: 71.00\n",
      "train epoch: 47 [12928/221852 (6%)]\tLoss: 0.171812\tAcc: 66.00\n",
      "train epoch: 47 [25728/221852 (12%)]\tLoss: 0.214277\tAcc: 72.00\n",
      "train epoch: 47 [38528/221852 (17%)]\tLoss: 0.181234\tAcc: 68.00\n",
      "train epoch: 47 [51328/221852 (23%)]\tLoss: 0.312810\tAcc: 70.00\n",
      "train epoch: 47 [64128/221852 (29%)]\tLoss: 0.215835\tAcc: 64.00\n",
      "train epoch: 47 [76928/221852 (35%)]\tLoss: 0.231861\tAcc: 69.00\n",
      "train epoch: 47 [89728/221852 (40%)]\tLoss: 0.265167\tAcc: 68.00\n",
      "train epoch: 47 [102528/221852 (46%)]\tLoss: 0.216988\tAcc: 69.00\n",
      "train epoch: 47 [115328/221852 (52%)]\tLoss: 0.242564\tAcc: 73.00\n",
      "train epoch: 47 [128128/221852 (58%)]\tLoss: 0.306614\tAcc: 62.00\n",
      "train epoch: 47 [140928/221852 (64%)]\tLoss: 0.226581\tAcc: 70.00\n",
      "train epoch: 47 [153728/221852 (69%)]\tLoss: 0.245150\tAcc: 72.00\n",
      "train epoch: 47 [166528/221852 (75%)]\tLoss: 0.255835\tAcc: 68.00\n",
      "train epoch: 47 [179328/221852 (81%)]\tLoss: 0.238892\tAcc: 66.00\n",
      "train epoch: 47 [192128/221852 (87%)]\tLoss: 0.324534\tAcc: 63.00\n",
      "val epoch: 47 [128/221852 (0%)]\tLoss: 0.303306\tAcc: 66.00\n",
      "val epoch: 47 [12928/221852 (6%)]\tLoss: 0.301940\tAcc: 68.00\n",
      "train epoch: 48 [128/221852 (0%)]\tLoss: 0.264028\tAcc: 69.00\n",
      "train epoch: 48 [12928/221852 (6%)]\tLoss: 0.609182\tAcc: 66.00\n",
      "train epoch: 48 [25728/221852 (12%)]\tLoss: 0.232325\tAcc: 67.00\n",
      "train epoch: 48 [38528/221852 (17%)]\tLoss: 0.339774\tAcc: 60.00\n",
      "train epoch: 48 [51328/221852 (23%)]\tLoss: 0.369801\tAcc: 66.00\n",
      "train epoch: 48 [64128/221852 (29%)]\tLoss: 0.323842\tAcc: 70.00\n",
      "train epoch: 48 [76928/221852 (35%)]\tLoss: 0.195897\tAcc: 69.00\n",
      "train epoch: 48 [89728/221852 (40%)]\tLoss: 0.272838\tAcc: 63.00\n",
      "train epoch: 48 [102528/221852 (46%)]\tLoss: 0.306965\tAcc: 64.00\n",
      "train epoch: 48 [115328/221852 (52%)]\tLoss: 0.267730\tAcc: 76.00\n",
      "train epoch: 48 [128128/221852 (58%)]\tLoss: 0.228831\tAcc: 67.00\n",
      "train epoch: 48 [140928/221852 (64%)]\tLoss: 0.468369\tAcc: 69.00\n",
      "train epoch: 48 [153728/221852 (69%)]\tLoss: 0.259641\tAcc: 73.00\n",
      "train epoch: 48 [166528/221852 (75%)]\tLoss: 0.229333\tAcc: 67.00\n",
      "train epoch: 48 [179328/221852 (81%)]\tLoss: 0.233233\tAcc: 77.00\n",
      "train epoch: 48 [192128/221852 (87%)]\tLoss: 0.287932\tAcc: 67.00\n",
      "val epoch: 48 [128/221852 (0%)]\tLoss: 0.185111\tAcc: 72.00\n",
      "val epoch: 48 [12928/221852 (6%)]\tLoss: 0.263107\tAcc: 70.00\n",
      "train epoch: 49 [128/221852 (0%)]\tLoss: 0.313866\tAcc: 65.00\n",
      "train epoch: 49 [12928/221852 (6%)]\tLoss: 0.274051\tAcc: 66.00\n",
      "train epoch: 49 [25728/221852 (12%)]\tLoss: 0.378289\tAcc: 66.00\n",
      "train epoch: 49 [38528/221852 (17%)]\tLoss: 0.169525\tAcc: 70.00\n",
      "train epoch: 49 [51328/221852 (23%)]\tLoss: 0.252886\tAcc: 62.00\n",
      "train epoch: 49 [64128/221852 (29%)]\tLoss: 0.266827\tAcc: 70.00\n",
      "train epoch: 49 [76928/221852 (35%)]\tLoss: 0.263009\tAcc: 69.00\n",
      "train epoch: 49 [89728/221852 (40%)]\tLoss: 0.230245\tAcc: 68.00\n",
      "train epoch: 49 [102528/221852 (46%)]\tLoss: 0.255936\tAcc: 70.00\n",
      "train epoch: 49 [115328/221852 (52%)]\tLoss: 0.304780\tAcc: 68.00\n",
      "train epoch: 49 [128128/221852 (58%)]\tLoss: 0.332628\tAcc: 63.00\n",
      "train epoch: 49 [140928/221852 (64%)]\tLoss: 0.336294\tAcc: 63.00\n",
      "train epoch: 49 [153728/221852 (69%)]\tLoss: 0.182009\tAcc: 75.00\n",
      "train epoch: 49 [166528/221852 (75%)]\tLoss: 0.279274\tAcc: 68.00\n",
      "train epoch: 49 [179328/221852 (81%)]\tLoss: 0.380050\tAcc: 71.00\n",
      "train epoch: 49 [192128/221852 (87%)]\tLoss: 0.242315\tAcc: 68.00\n",
      "val epoch: 49 [128/221852 (0%)]\tLoss: 0.360148\tAcc: 69.00\n",
      "val epoch: 49 [12928/221852 (6%)]\tLoss: 0.293344\tAcc: 67.00\n",
      "train epoch: 50 [128/221852 (0%)]\tLoss: 0.462863\tAcc: 57.00\n",
      "train epoch: 50 [12928/221852 (6%)]\tLoss: 0.256062\tAcc: 66.00\n",
      "train epoch: 50 [25728/221852 (12%)]\tLoss: 0.269499\tAcc: 68.00\n",
      "train epoch: 50 [38528/221852 (17%)]\tLoss: 0.266100\tAcc: 70.00\n",
      "train epoch: 50 [51328/221852 (23%)]\tLoss: 0.283947\tAcc: 64.00\n",
      "train epoch: 50 [64128/221852 (29%)]\tLoss: 0.178824\tAcc: 71.00\n",
      "train epoch: 50 [76928/221852 (35%)]\tLoss: 0.223329\tAcc: 75.00\n",
      "train epoch: 50 [89728/221852 (40%)]\tLoss: 0.270003\tAcc: 70.00\n",
      "train epoch: 50 [102528/221852 (46%)]\tLoss: 0.325710\tAcc: 63.00\n",
      "train epoch: 50 [115328/221852 (52%)]\tLoss: 0.311816\tAcc: 63.00\n",
      "train epoch: 50 [128128/221852 (58%)]\tLoss: 0.263710\tAcc: 67.00\n",
      "train epoch: 50 [140928/221852 (64%)]\tLoss: 0.214859\tAcc: 69.00\n",
      "train epoch: 50 [153728/221852 (69%)]\tLoss: 0.219275\tAcc: 68.00\n",
      "train epoch: 50 [166528/221852 (75%)]\tLoss: 0.335392\tAcc: 63.00\n",
      "train epoch: 50 [179328/221852 (81%)]\tLoss: 0.301241\tAcc: 71.00\n",
      "train epoch: 50 [192128/221852 (87%)]\tLoss: 0.272914\tAcc: 67.00\n",
      "val epoch: 50 [128/221852 (0%)]\tLoss: 0.205491\tAcc: 72.00\n",
      "val epoch: 50 [12928/221852 (6%)]\tLoss: 0.165459\tAcc: 66.00\n",
      "train epoch: 51 [128/221852 (0%)]\tLoss: 0.220596\tAcc: 73.00\n",
      "train epoch: 51 [12928/221852 (6%)]\tLoss: 0.231884\tAcc: 70.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 51 [25728/221852 (12%)]\tLoss: 0.278136\tAcc: 70.00\n",
      "train epoch: 51 [38528/221852 (17%)]\tLoss: 0.304243\tAcc: 60.00\n",
      "train epoch: 51 [51328/221852 (23%)]\tLoss: 0.182151\tAcc: 72.00\n",
      "train epoch: 51 [64128/221852 (29%)]\tLoss: 0.283337\tAcc: 66.00\n",
      "train epoch: 51 [76928/221852 (35%)]\tLoss: 0.234145\tAcc: 67.00\n",
      "train epoch: 51 [89728/221852 (40%)]\tLoss: 0.372577\tAcc: 65.00\n",
      "train epoch: 51 [102528/221852 (46%)]\tLoss: 0.303980\tAcc: 70.00\n",
      "train epoch: 51 [115328/221852 (52%)]\tLoss: 0.215043\tAcc: 73.00\n",
      "train epoch: 51 [128128/221852 (58%)]\tLoss: 0.202466\tAcc: 59.00\n",
      "train epoch: 51 [140928/221852 (64%)]\tLoss: 0.220897\tAcc: 75.00\n",
      "train epoch: 51 [153728/221852 (69%)]\tLoss: 0.267494\tAcc: 63.00\n",
      "train epoch: 51 [166528/221852 (75%)]\tLoss: 0.237870\tAcc: 70.00\n",
      "train epoch: 51 [179328/221852 (81%)]\tLoss: 0.298591\tAcc: 65.00\n",
      "train epoch: 51 [192128/221852 (87%)]\tLoss: 0.239881\tAcc: 69.00\n",
      "val epoch: 51 [128/221852 (0%)]\tLoss: 0.246493\tAcc: 62.00\n",
      "val epoch: 51 [12928/221852 (6%)]\tLoss: 0.240810\tAcc: 69.00\n",
      "train epoch: 52 [128/221852 (0%)]\tLoss: 0.251511\tAcc: 72.00\n",
      "train epoch: 52 [12928/221852 (6%)]\tLoss: 0.298854\tAcc: 69.00\n",
      "train epoch: 52 [25728/221852 (12%)]\tLoss: 0.291611\tAcc: 68.00\n",
      "train epoch: 52 [38528/221852 (17%)]\tLoss: 0.146930\tAcc: 68.00\n",
      "train epoch: 52 [51328/221852 (23%)]\tLoss: 0.314671\tAcc: 67.00\n",
      "train epoch: 52 [64128/221852 (29%)]\tLoss: 0.229077\tAcc: 69.00\n",
      "train epoch: 52 [76928/221852 (35%)]\tLoss: 0.187726\tAcc: 70.00\n",
      "train epoch: 52 [89728/221852 (40%)]\tLoss: 0.191346\tAcc: 76.00\n",
      "train epoch: 52 [102528/221852 (46%)]\tLoss: 0.318776\tAcc: 70.00\n",
      "train epoch: 52 [115328/221852 (52%)]\tLoss: 0.296431\tAcc: 70.00\n",
      "train epoch: 52 [128128/221852 (58%)]\tLoss: 0.240581\tAcc: 67.00\n",
      "train epoch: 52 [140928/221852 (64%)]\tLoss: 0.295173\tAcc: 67.00\n",
      "train epoch: 52 [153728/221852 (69%)]\tLoss: 0.251123\tAcc: 76.00\n",
      "train epoch: 52 [166528/221852 (75%)]\tLoss: 0.325774\tAcc: 63.00\n",
      "train epoch: 52 [179328/221852 (81%)]\tLoss: 0.257974\tAcc: 70.00\n",
      "train epoch: 52 [192128/221852 (87%)]\tLoss: 0.322151\tAcc: 73.00\n",
      "val epoch: 52 [128/221852 (0%)]\tLoss: 0.241254\tAcc: 63.00\n",
      "val epoch: 52 [12928/221852 (6%)]\tLoss: 0.292498\tAcc: 73.00\n",
      "train epoch: 53 [128/221852 (0%)]\tLoss: 0.180547\tAcc: 77.00\n",
      "train epoch: 53 [12928/221852 (6%)]\tLoss: 0.293300\tAcc: 66.00\n",
      "train epoch: 53 [25728/221852 (12%)]\tLoss: 0.283154\tAcc: 73.00\n",
      "train epoch: 53 [38528/221852 (17%)]\tLoss: 0.275373\tAcc: 67.00\n",
      "train epoch: 53 [51328/221852 (23%)]\tLoss: 0.268104\tAcc: 75.00\n",
      "train epoch: 53 [64128/221852 (29%)]\tLoss: 0.169223\tAcc: 73.00\n",
      "train epoch: 53 [76928/221852 (35%)]\tLoss: 0.307871\tAcc: 73.00\n",
      "train epoch: 53 [89728/221852 (40%)]\tLoss: 0.254056\tAcc: 70.00\n",
      "train epoch: 53 [102528/221852 (46%)]\tLoss: 0.206462\tAcc: 71.00\n",
      "train epoch: 53 [115328/221852 (52%)]\tLoss: 0.267197\tAcc: 68.00\n",
      "train epoch: 53 [128128/221852 (58%)]\tLoss: 0.255712\tAcc: 70.00\n",
      "train epoch: 53 [140928/221852 (64%)]\tLoss: 0.232740\tAcc: 73.00\n",
      "train epoch: 53 [153728/221852 (69%)]\tLoss: 0.270749\tAcc: 70.00\n",
      "train epoch: 53 [166528/221852 (75%)]\tLoss: 0.275361\tAcc: 62.00\n",
      "train epoch: 53 [179328/221852 (81%)]\tLoss: 0.350051\tAcc: 59.00\n",
      "train epoch: 53 [192128/221852 (87%)]\tLoss: 0.163199\tAcc: 70.00\n",
      "val epoch: 53 [128/221852 (0%)]\tLoss: 0.244905\tAcc: 68.00\n",
      "val epoch: 53 [12928/221852 (6%)]\tLoss: 0.310296\tAcc: 77.00\n",
      "train epoch: 54 [128/221852 (0%)]\tLoss: 0.217309\tAcc: 71.00\n",
      "train epoch: 54 [12928/221852 (6%)]\tLoss: 0.232161\tAcc: 76.00\n",
      "train epoch: 54 [25728/221852 (12%)]\tLoss: 0.233560\tAcc: 71.00\n",
      "train epoch: 54 [38528/221852 (17%)]\tLoss: 0.229171\tAcc: 69.00\n",
      "train epoch: 54 [51328/221852 (23%)]\tLoss: 0.218842\tAcc: 66.00\n",
      "train epoch: 54 [64128/221852 (29%)]\tLoss: 0.282462\tAcc: 70.00\n",
      "train epoch: 54 [76928/221852 (35%)]\tLoss: 0.318043\tAcc: 66.00\n",
      "train epoch: 54 [89728/221852 (40%)]\tLoss: 0.266806\tAcc: 72.00\n",
      "train epoch: 54 [102528/221852 (46%)]\tLoss: 0.333518\tAcc: 66.00\n",
      "train epoch: 54 [115328/221852 (52%)]\tLoss: 0.308541\tAcc: 73.00\n",
      "train epoch: 54 [128128/221852 (58%)]\tLoss: 0.218505\tAcc: 71.00\n",
      "train epoch: 54 [140928/221852 (64%)]\tLoss: 0.295492\tAcc: 63.00\n",
      "train epoch: 54 [153728/221852 (69%)]\tLoss: 0.279484\tAcc: 62.00\n",
      "train epoch: 54 [166528/221852 (75%)]\tLoss: 0.284611\tAcc: 68.00\n",
      "train epoch: 54 [179328/221852 (81%)]\tLoss: 0.271539\tAcc: 70.00\n",
      "train epoch: 54 [192128/221852 (87%)]\tLoss: 0.197241\tAcc: 67.00\n",
      "val epoch: 54 [128/221852 (0%)]\tLoss: 0.325526\tAcc: 62.00\n",
      "val epoch: 54 [12928/221852 (6%)]\tLoss: 0.268356\tAcc: 66.00\n",
      "train epoch: 55 [128/221852 (0%)]\tLoss: 0.306251\tAcc: 73.00\n",
      "train epoch: 55 [12928/221852 (6%)]\tLoss: 0.220233\tAcc: 72.00\n",
      "train epoch: 55 [25728/221852 (12%)]\tLoss: 0.298410\tAcc: 66.00\n",
      "train epoch: 55 [38528/221852 (17%)]\tLoss: 0.254758\tAcc: 70.00\n",
      "train epoch: 55 [51328/221852 (23%)]\tLoss: 0.215641\tAcc: 70.00\n",
      "train epoch: 55 [64128/221852 (29%)]\tLoss: 0.268625\tAcc: 73.00\n",
      "train epoch: 55 [76928/221852 (35%)]\tLoss: 0.257806\tAcc: 68.00\n",
      "train epoch: 55 [89728/221852 (40%)]\tLoss: 0.231386\tAcc: 71.00\n",
      "train epoch: 55 [102528/221852 (46%)]\tLoss: 0.233050\tAcc: 69.00\n",
      "train epoch: 55 [115328/221852 (52%)]\tLoss: 0.256179\tAcc: 75.00\n",
      "train epoch: 55 [128128/221852 (58%)]\tLoss: 0.201292\tAcc: 78.00\n",
      "train epoch: 55 [140928/221852 (64%)]\tLoss: 0.243492\tAcc: 62.00\n",
      "train epoch: 55 [153728/221852 (69%)]\tLoss: 0.285608\tAcc: 76.00\n",
      "train epoch: 55 [166528/221852 (75%)]\tLoss: 0.211529\tAcc: 76.00\n",
      "train epoch: 55 [179328/221852 (81%)]\tLoss: 0.299955\tAcc: 68.00\n",
      "train epoch: 55 [192128/221852 (87%)]\tLoss: 0.205207\tAcc: 64.00\n",
      "val epoch: 55 [128/221852 (0%)]\tLoss: 0.239257\tAcc: 71.00\n",
      "val epoch: 55 [12928/221852 (6%)]\tLoss: 0.239284\tAcc: 75.00\n",
      "train epoch: 56 [128/221852 (0%)]\tLoss: 0.185806\tAcc: 70.00\n",
      "train epoch: 56 [12928/221852 (6%)]\tLoss: 0.297523\tAcc: 63.00\n",
      "train epoch: 56 [25728/221852 (12%)]\tLoss: 0.202684\tAcc: 70.00\n",
      "train epoch: 56 [38528/221852 (17%)]\tLoss: 0.260799\tAcc: 71.00\n",
      "train epoch: 56 [51328/221852 (23%)]\tLoss: 0.204993\tAcc: 66.00\n",
      "train epoch: 56 [64128/221852 (29%)]\tLoss: 0.283961\tAcc: 68.00\n",
      "train epoch: 56 [76928/221852 (35%)]\tLoss: 0.187341\tAcc: 66.00\n",
      "train epoch: 56 [89728/221852 (40%)]\tLoss: 0.231585\tAcc: 66.00\n",
      "train epoch: 56 [102528/221852 (46%)]\tLoss: 0.254570\tAcc: 65.00\n",
      "train epoch: 56 [115328/221852 (52%)]\tLoss: 0.282888\tAcc: 59.00\n",
      "train epoch: 56 [128128/221852 (58%)]\tLoss: 0.299982\tAcc: 70.00\n",
      "train epoch: 56 [140928/221852 (64%)]\tLoss: 0.279120\tAcc: 68.00\n",
      "train epoch: 56 [153728/221852 (69%)]\tLoss: 0.219031\tAcc: 77.00\n",
      "train epoch: 56 [166528/221852 (75%)]\tLoss: 0.274947\tAcc: 73.00\n",
      "train epoch: 56 [179328/221852 (81%)]\tLoss: 0.263498\tAcc: 68.00\n",
      "train epoch: 56 [192128/221852 (87%)]\tLoss: 0.268626\tAcc: 69.00\n",
      "val epoch: 56 [128/221852 (0%)]\tLoss: 0.227101\tAcc: 69.00\n",
      "val epoch: 56 [12928/221852 (6%)]\tLoss: 0.200972\tAcc: 72.00\n",
      "train epoch: 57 [128/221852 (0%)]\tLoss: 0.163551\tAcc: 73.00\n",
      "train epoch: 57 [12928/221852 (6%)]\tLoss: 0.225460\tAcc: 67.00\n",
      "train epoch: 57 [25728/221852 (12%)]\tLoss: 0.189891\tAcc: 78.00\n",
      "train epoch: 57 [38528/221852 (17%)]\tLoss: 0.316924\tAcc: 62.00\n",
      "train epoch: 57 [51328/221852 (23%)]\tLoss: 0.264434\tAcc: 69.00\n",
      "train epoch: 57 [64128/221852 (29%)]\tLoss: 0.131805\tAcc: 74.00\n",
      "train epoch: 57 [76928/221852 (35%)]\tLoss: 0.222232\tAcc: 69.00\n",
      "train epoch: 57 [89728/221852 (40%)]\tLoss: 0.224316\tAcc: 72.00\n",
      "train epoch: 57 [102528/221852 (46%)]\tLoss: 0.223623\tAcc: 72.00\n",
      "train epoch: 57 [115328/221852 (52%)]\tLoss: 0.154856\tAcc: 77.00\n",
      "train epoch: 57 [128128/221852 (58%)]\tLoss: 0.281856\tAcc: 66.00\n",
      "train epoch: 57 [140928/221852 (64%)]\tLoss: 0.197207\tAcc: 73.00\n",
      "train epoch: 57 [153728/221852 (69%)]\tLoss: 0.133323\tAcc: 69.00\n",
      "train epoch: 57 [166528/221852 (75%)]\tLoss: 0.246708\tAcc: 74.00\n",
      "train epoch: 57 [179328/221852 (81%)]\tLoss: 0.291884\tAcc: 72.00\n",
      "train epoch: 57 [192128/221852 (87%)]\tLoss: 0.263785\tAcc: 73.00\n",
      "val epoch: 57 [128/221852 (0%)]\tLoss: 0.186419\tAcc: 73.00\n",
      "val epoch: 57 [12928/221852 (6%)]\tLoss: 0.194231\tAcc: 74.00\n",
      "train epoch: 58 [128/221852 (0%)]\tLoss: 0.354860\tAcc: 75.00\n",
      "train epoch: 58 [12928/221852 (6%)]\tLoss: 0.231516\tAcc: 71.00\n",
      "train epoch: 58 [25728/221852 (12%)]\tLoss: 0.216363\tAcc: 69.00\n",
      "train epoch: 58 [38528/221852 (17%)]\tLoss: 0.247346\tAcc: 72.00\n",
      "train epoch: 58 [51328/221852 (23%)]\tLoss: 0.219490\tAcc: 72.00\n",
      "train epoch: 58 [64128/221852 (29%)]\tLoss: 0.267947\tAcc: 66.00\n",
      "train epoch: 58 [76928/221852 (35%)]\tLoss: 0.299484\tAcc: 66.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 58 [89728/221852 (40%)]\tLoss: 0.553530\tAcc: 74.00\n",
      "train epoch: 58 [102528/221852 (46%)]\tLoss: 0.196789\tAcc: 71.00\n",
      "train epoch: 58 [115328/221852 (52%)]\tLoss: 0.204445\tAcc: 73.00\n",
      "train epoch: 58 [128128/221852 (58%)]\tLoss: 0.319651\tAcc: 72.00\n",
      "train epoch: 58 [140928/221852 (64%)]\tLoss: 0.244281\tAcc: 62.00\n",
      "train epoch: 58 [153728/221852 (69%)]\tLoss: 0.212280\tAcc: 69.00\n",
      "train epoch: 58 [166528/221852 (75%)]\tLoss: 0.343661\tAcc: 69.00\n",
      "train epoch: 58 [179328/221852 (81%)]\tLoss: 0.228678\tAcc: 61.00\n",
      "train epoch: 58 [192128/221852 (87%)]\tLoss: 0.231226\tAcc: 71.00\n",
      "val epoch: 58 [128/221852 (0%)]\tLoss: 0.268777\tAcc: 66.00\n",
      "val epoch: 58 [12928/221852 (6%)]\tLoss: 0.193624\tAcc: 77.00\n",
      "train epoch: 59 [128/221852 (0%)]\tLoss: 0.335676\tAcc: 75.00\n",
      "train epoch: 59 [12928/221852 (6%)]\tLoss: 0.241560\tAcc: 70.00\n",
      "train epoch: 59 [25728/221852 (12%)]\tLoss: 0.348319\tAcc: 66.00\n",
      "train epoch: 59 [38528/221852 (17%)]\tLoss: 0.363147\tAcc: 62.00\n",
      "train epoch: 59 [51328/221852 (23%)]\tLoss: 0.181979\tAcc: 69.00\n",
      "train epoch: 59 [64128/221852 (29%)]\tLoss: 0.232577\tAcc: 70.00\n",
      "train epoch: 59 [76928/221852 (35%)]\tLoss: 0.213141\tAcc: 73.00\n",
      "train epoch: 59 [89728/221852 (40%)]\tLoss: 0.272699\tAcc: 68.00\n",
      "train epoch: 59 [102528/221852 (46%)]\tLoss: 0.226016\tAcc: 75.00\n",
      "train epoch: 59 [115328/221852 (52%)]\tLoss: 0.282406\tAcc: 77.00\n",
      "train epoch: 59 [128128/221852 (58%)]\tLoss: 0.289414\tAcc: 72.00\n",
      "train epoch: 59 [140928/221852 (64%)]\tLoss: 0.195568\tAcc: 74.00\n",
      "train epoch: 59 [153728/221852 (69%)]\tLoss: 0.233297\tAcc: 75.00\n",
      "train epoch: 59 [166528/221852 (75%)]\tLoss: 0.303094\tAcc: 69.00\n",
      "train epoch: 59 [179328/221852 (81%)]\tLoss: 0.192531\tAcc: 68.00\n",
      "train epoch: 59 [192128/221852 (87%)]\tLoss: 0.231484\tAcc: 73.00\n",
      "val epoch: 59 [128/221852 (0%)]\tLoss: 0.172574\tAcc: 69.00\n",
      "val epoch: 59 [12928/221852 (6%)]\tLoss: 0.305664\tAcc: 67.00\n",
      "train epoch: 60 [128/221852 (0%)]\tLoss: 0.236255\tAcc: 73.00\n",
      "train epoch: 60 [12928/221852 (6%)]\tLoss: 0.333576\tAcc: 70.00\n",
      "train epoch: 60 [25728/221852 (12%)]\tLoss: 0.318995\tAcc: 63.00\n",
      "train epoch: 60 [38528/221852 (17%)]\tLoss: 0.244744\tAcc: 73.00\n",
      "train epoch: 60 [51328/221852 (23%)]\tLoss: 0.352865\tAcc: 64.00\n",
      "train epoch: 60 [64128/221852 (29%)]\tLoss: 0.224677\tAcc: 79.00\n",
      "train epoch: 60 [76928/221852 (35%)]\tLoss: 0.343531\tAcc: 71.00\n",
      "train epoch: 60 [89728/221852 (40%)]\tLoss: 0.227520\tAcc: 75.00\n",
      "train epoch: 60 [102528/221852 (46%)]\tLoss: 0.312605\tAcc: 62.00\n",
      "train epoch: 60 [115328/221852 (52%)]\tLoss: 0.189141\tAcc: 73.00\n",
      "train epoch: 60 [128128/221852 (58%)]\tLoss: 0.229674\tAcc: 76.00\n",
      "train epoch: 60 [140928/221852 (64%)]\tLoss: 0.199094\tAcc: 70.00\n",
      "train epoch: 60 [153728/221852 (69%)]\tLoss: 0.246255\tAcc: 72.00\n",
      "train epoch: 60 [166528/221852 (75%)]\tLoss: 0.199169\tAcc: 76.00\n",
      "train epoch: 60 [179328/221852 (81%)]\tLoss: 0.181566\tAcc: 73.00\n",
      "train epoch: 60 [192128/221852 (87%)]\tLoss: 0.283995\tAcc: 61.00\n",
      "val epoch: 60 [128/221852 (0%)]\tLoss: 0.198455\tAcc: 71.00\n",
      "val epoch: 60 [12928/221852 (6%)]\tLoss: 0.188317\tAcc: 71.00\n",
      "train epoch: 61 [128/221852 (0%)]\tLoss: 0.177207\tAcc: 72.00\n",
      "train epoch: 61 [12928/221852 (6%)]\tLoss: 0.206461\tAcc: 69.00\n",
      "train epoch: 61 [25728/221852 (12%)]\tLoss: 0.285422\tAcc: 59.00\n",
      "train epoch: 61 [38528/221852 (17%)]\tLoss: 0.236675\tAcc: 70.00\n",
      "train epoch: 61 [51328/221852 (23%)]\tLoss: 0.284259\tAcc: 67.00\n",
      "train epoch: 61 [64128/221852 (29%)]\tLoss: 0.244829\tAcc: 71.00\n",
      "train epoch: 61 [76928/221852 (35%)]\tLoss: 0.259869\tAcc: 70.00\n",
      "train epoch: 61 [89728/221852 (40%)]\tLoss: 0.260106\tAcc: 66.00\n",
      "train epoch: 61 [102528/221852 (46%)]\tLoss: 0.253920\tAcc: 64.00\n",
      "train epoch: 61 [115328/221852 (52%)]\tLoss: 0.240313\tAcc: 72.00\n",
      "train epoch: 61 [128128/221852 (58%)]\tLoss: 0.229930\tAcc: 77.00\n",
      "train epoch: 61 [140928/221852 (64%)]\tLoss: 0.310955\tAcc: 72.00\n",
      "train epoch: 61 [153728/221852 (69%)]\tLoss: 0.202255\tAcc: 71.00\n",
      "train epoch: 61 [166528/221852 (75%)]\tLoss: 0.202320\tAcc: 71.00\n",
      "train epoch: 61 [179328/221852 (81%)]\tLoss: 0.246710\tAcc: 57.00\n",
      "train epoch: 61 [192128/221852 (87%)]\tLoss: 0.304101\tAcc: 70.00\n",
      "val epoch: 61 [128/221852 (0%)]\tLoss: 0.266261\tAcc: 70.00\n",
      "val epoch: 61 [12928/221852 (6%)]\tLoss: 0.249397\tAcc: 70.00\n",
      "train epoch: 62 [128/221852 (0%)]\tLoss: 0.202933\tAcc: 71.00\n",
      "train epoch: 62 [12928/221852 (6%)]\tLoss: 0.179491\tAcc: 70.00\n",
      "train epoch: 62 [25728/221852 (12%)]\tLoss: 0.213335\tAcc: 70.00\n",
      "train epoch: 62 [38528/221852 (17%)]\tLoss: 0.311435\tAcc: 68.00\n",
      "train epoch: 62 [51328/221852 (23%)]\tLoss: 0.267391\tAcc: 66.00\n",
      "train epoch: 62 [64128/221852 (29%)]\tLoss: 0.225981\tAcc: 63.00\n",
      "train epoch: 62 [76928/221852 (35%)]\tLoss: 0.298833\tAcc: 75.00\n",
      "train epoch: 62 [89728/221852 (40%)]\tLoss: 0.241324\tAcc: 70.00\n",
      "train epoch: 62 [102528/221852 (46%)]\tLoss: 0.214977\tAcc: 68.00\n",
      "train epoch: 62 [115328/221852 (52%)]\tLoss: 0.221149\tAcc: 74.00\n",
      "train epoch: 62 [128128/221852 (58%)]\tLoss: 0.268244\tAcc: 73.00\n",
      "train epoch: 62 [140928/221852 (64%)]\tLoss: 0.226017\tAcc: 66.00\n",
      "train epoch: 62 [153728/221852 (69%)]\tLoss: 0.242238\tAcc: 68.00\n",
      "train epoch: 62 [166528/221852 (75%)]\tLoss: 0.171060\tAcc: 73.00\n",
      "train epoch: 62 [179328/221852 (81%)]\tLoss: 0.174379\tAcc: 78.00\n",
      "train epoch: 62 [192128/221852 (87%)]\tLoss: 0.276655\tAcc: 63.00\n",
      "val epoch: 62 [128/221852 (0%)]\tLoss: 0.247719\tAcc: 62.00\n",
      "val epoch: 62 [12928/221852 (6%)]\tLoss: 0.184707\tAcc: 77.00\n",
      "train epoch: 63 [128/221852 (0%)]\tLoss: 0.228279\tAcc: 62.00\n",
      "train epoch: 63 [12928/221852 (6%)]\tLoss: 0.240700\tAcc: 72.00\n",
      "train epoch: 63 [25728/221852 (12%)]\tLoss: 0.220839\tAcc: 69.00\n",
      "train epoch: 63 [38528/221852 (17%)]\tLoss: 0.233893\tAcc: 66.00\n",
      "train epoch: 63 [51328/221852 (23%)]\tLoss: 0.189359\tAcc: 72.00\n",
      "train epoch: 63 [64128/221852 (29%)]\tLoss: 0.125818\tAcc: 70.00\n",
      "train epoch: 63 [76928/221852 (35%)]\tLoss: 0.224763\tAcc: 77.00\n",
      "train epoch: 63 [89728/221852 (40%)]\tLoss: 0.233842\tAcc: 69.00\n",
      "train epoch: 63 [102528/221852 (46%)]\tLoss: 0.247463\tAcc: 76.00\n",
      "train epoch: 63 [115328/221852 (52%)]\tLoss: 0.300534\tAcc: 73.00\n",
      "train epoch: 63 [128128/221852 (58%)]\tLoss: 0.202217\tAcc: 80.00\n",
      "train epoch: 63 [140928/221852 (64%)]\tLoss: 0.305308\tAcc: 66.00\n",
      "train epoch: 63 [153728/221852 (69%)]\tLoss: 0.331817\tAcc: 65.00\n",
      "train epoch: 63 [166528/221852 (75%)]\tLoss: 0.241778\tAcc: 73.00\n",
      "train epoch: 63 [179328/221852 (81%)]\tLoss: 0.311212\tAcc: 68.00\n",
      "train epoch: 63 [192128/221852 (87%)]\tLoss: 0.292466\tAcc: 74.00\n",
      "val epoch: 63 [128/221852 (0%)]\tLoss: 0.320958\tAcc: 62.00\n",
      "val epoch: 63 [12928/221852 (6%)]\tLoss: 0.228763\tAcc: 73.00\n",
      "train epoch: 64 [128/221852 (0%)]\tLoss: 0.210467\tAcc: 70.00\n",
      "train epoch: 64 [12928/221852 (6%)]\tLoss: 0.228327\tAcc: 65.00\n",
      "train epoch: 64 [25728/221852 (12%)]\tLoss: 0.312650\tAcc: 68.00\n",
      "train epoch: 64 [38528/221852 (17%)]\tLoss: 0.284792\tAcc: 66.00\n",
      "train epoch: 64 [51328/221852 (23%)]\tLoss: 0.178296\tAcc: 74.00\n",
      "train epoch: 64 [64128/221852 (29%)]\tLoss: 0.227033\tAcc: 75.00\n",
      "train epoch: 64 [76928/221852 (35%)]\tLoss: 0.269594\tAcc: 77.00\n",
      "train epoch: 64 [89728/221852 (40%)]\tLoss: 0.335171\tAcc: 72.00\n",
      "train epoch: 64 [102528/221852 (46%)]\tLoss: 0.278930\tAcc: 73.00\n",
      "train epoch: 64 [115328/221852 (52%)]\tLoss: 0.340557\tAcc: 70.00\n",
      "train epoch: 64 [128128/221852 (58%)]\tLoss: 0.245974\tAcc: 74.00\n",
      "train epoch: 64 [140928/221852 (64%)]\tLoss: 0.326402\tAcc: 67.00\n",
      "train epoch: 64 [153728/221852 (69%)]\tLoss: 0.390305\tAcc: 65.00\n",
      "train epoch: 64 [166528/221852 (75%)]\tLoss: 0.310612\tAcc: 70.00\n",
      "train epoch: 64 [179328/221852 (81%)]\tLoss: 0.223521\tAcc: 74.00\n",
      "train epoch: 64 [192128/221852 (87%)]\tLoss: 0.174067\tAcc: 70.00\n",
      "val epoch: 64 [128/221852 (0%)]\tLoss: 0.207774\tAcc: 68.00\n",
      "val epoch: 64 [12928/221852 (6%)]\tLoss: 0.215101\tAcc: 66.00\n",
      "train epoch: 65 [128/221852 (0%)]\tLoss: 0.222781\tAcc: 62.00\n",
      "train epoch: 65 [12928/221852 (6%)]\tLoss: 0.221572\tAcc: 72.00\n",
      "train epoch: 65 [25728/221852 (12%)]\tLoss: 0.231029\tAcc: 75.00\n",
      "train epoch: 65 [38528/221852 (17%)]\tLoss: 0.233718\tAcc: 66.00\n",
      "train epoch: 65 [51328/221852 (23%)]\tLoss: 0.358745\tAcc: 63.00\n",
      "train epoch: 65 [64128/221852 (29%)]\tLoss: 0.215434\tAcc: 65.00\n",
      "train epoch: 65 [76928/221852 (35%)]\tLoss: 0.248447\tAcc: 66.00\n",
      "train epoch: 65 [89728/221852 (40%)]\tLoss: 0.180110\tAcc: 69.00\n",
      "train epoch: 65 [102528/221852 (46%)]\tLoss: 0.191991\tAcc: 74.00\n",
      "train epoch: 65 [115328/221852 (52%)]\tLoss: 0.263464\tAcc: 73.00\n",
      "train epoch: 65 [128128/221852 (58%)]\tLoss: 0.215468\tAcc: 71.00\n",
      "train epoch: 65 [140928/221852 (64%)]\tLoss: 0.214420\tAcc: 80.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 65 [153728/221852 (69%)]\tLoss: 0.238931\tAcc: 72.00\n",
      "train epoch: 65 [166528/221852 (75%)]\tLoss: 0.285174\tAcc: 73.00\n",
      "train epoch: 65 [179328/221852 (81%)]\tLoss: 0.245827\tAcc: 69.00\n",
      "train epoch: 65 [192128/221852 (87%)]\tLoss: 0.306035\tAcc: 72.00\n",
      "val epoch: 65 [128/221852 (0%)]\tLoss: 0.232795\tAcc: 66.00\n",
      "val epoch: 65 [12928/221852 (6%)]\tLoss: 0.246530\tAcc: 67.00\n",
      "train epoch: 66 [128/221852 (0%)]\tLoss: 0.269724\tAcc: 65.00\n",
      "train epoch: 66 [12928/221852 (6%)]\tLoss: 0.213585\tAcc: 73.00\n",
      "train epoch: 66 [25728/221852 (12%)]\tLoss: 0.379664\tAcc: 62.00\n",
      "train epoch: 66 [38528/221852 (17%)]\tLoss: 0.233522\tAcc: 67.00\n",
      "train epoch: 66 [51328/221852 (23%)]\tLoss: 0.241223\tAcc: 75.00\n",
      "train epoch: 66 [64128/221852 (29%)]\tLoss: 0.302252\tAcc: 72.00\n",
      "train epoch: 66 [76928/221852 (35%)]\tLoss: 0.245056\tAcc: 76.00\n",
      "train epoch: 66 [89728/221852 (40%)]\tLoss: 0.278632\tAcc: 60.00\n",
      "train epoch: 66 [102528/221852 (46%)]\tLoss: 0.188880\tAcc: 72.00\n",
      "train epoch: 66 [115328/221852 (52%)]\tLoss: 0.274520\tAcc: 73.00\n",
      "train epoch: 66 [128128/221852 (58%)]\tLoss: 0.162198\tAcc: 80.00\n",
      "train epoch: 66 [140928/221852 (64%)]\tLoss: 0.233805\tAcc: 63.00\n",
      "train epoch: 66 [153728/221852 (69%)]\tLoss: 0.281341\tAcc: 66.00\n",
      "train epoch: 66 [166528/221852 (75%)]\tLoss: 0.242566\tAcc: 69.00\n",
      "train epoch: 66 [179328/221852 (81%)]\tLoss: 0.378782\tAcc: 74.00\n",
      "train epoch: 66 [192128/221852 (87%)]\tLoss: 0.182783\tAcc: 72.00\n",
      "val epoch: 66 [128/221852 (0%)]\tLoss: 0.265761\tAcc: 73.00\n",
      "val epoch: 66 [12928/221852 (6%)]\tLoss: 0.201989\tAcc: 78.00\n",
      "train epoch: 67 [128/221852 (0%)]\tLoss: 0.263010\tAcc: 66.00\n",
      "train epoch: 67 [12928/221852 (6%)]\tLoss: 0.295006\tAcc: 71.00\n",
      "train epoch: 67 [25728/221852 (12%)]\tLoss: 0.353610\tAcc: 69.00\n",
      "train epoch: 67 [38528/221852 (17%)]\tLoss: 0.224668\tAcc: 73.00\n",
      "train epoch: 67 [51328/221852 (23%)]\tLoss: 0.311184\tAcc: 63.00\n",
      "train epoch: 67 [64128/221852 (29%)]\tLoss: 0.290723\tAcc: 68.00\n",
      "train epoch: 67 [76928/221852 (35%)]\tLoss: 0.205567\tAcc: 74.00\n",
      "train epoch: 67 [89728/221852 (40%)]\tLoss: 0.218378\tAcc: 70.00\n",
      "train epoch: 67 [102528/221852 (46%)]\tLoss: 0.173204\tAcc: 70.00\n",
      "train epoch: 67 [115328/221852 (52%)]\tLoss: 0.245552\tAcc: 76.00\n",
      "train epoch: 67 [128128/221852 (58%)]\tLoss: 0.212798\tAcc: 71.00\n",
      "train epoch: 67 [140928/221852 (64%)]\tLoss: 0.242213\tAcc: 70.00\n",
      "train epoch: 67 [153728/221852 (69%)]\tLoss: 0.220735\tAcc: 70.00\n",
      "train epoch: 67 [166528/221852 (75%)]\tLoss: 0.280532\tAcc: 72.00\n",
      "train epoch: 67 [179328/221852 (81%)]\tLoss: 0.225636\tAcc: 71.00\n",
      "train epoch: 67 [192128/221852 (87%)]\tLoss: 0.187168\tAcc: 70.00\n",
      "val epoch: 67 [128/221852 (0%)]\tLoss: 0.202295\tAcc: 75.00\n",
      "val epoch: 67 [12928/221852 (6%)]\tLoss: 0.209014\tAcc: 67.00\n",
      "train epoch: 68 [128/221852 (0%)]\tLoss: 0.229953\tAcc: 69.00\n",
      "train epoch: 68 [12928/221852 (6%)]\tLoss: 0.245950\tAcc: 72.00\n",
      "train epoch: 68 [25728/221852 (12%)]\tLoss: 0.276570\tAcc: 69.00\n",
      "train epoch: 68 [38528/221852 (17%)]\tLoss: 0.272645\tAcc: 76.00\n",
      "train epoch: 68 [51328/221852 (23%)]\tLoss: 0.429315\tAcc: 71.00\n",
      "train epoch: 68 [64128/221852 (29%)]\tLoss: 0.263862\tAcc: 72.00\n",
      "train epoch: 68 [76928/221852 (35%)]\tLoss: 0.236644\tAcc: 73.00\n",
      "train epoch: 68 [89728/221852 (40%)]\tLoss: 0.330896\tAcc: 62.00\n",
      "train epoch: 68 [102528/221852 (46%)]\tLoss: 0.287832\tAcc: 66.00\n",
      "train epoch: 68 [115328/221852 (52%)]\tLoss: 0.159893\tAcc: 69.00\n",
      "train epoch: 68 [128128/221852 (58%)]\tLoss: 0.238963\tAcc: 69.00\n",
      "train epoch: 68 [140928/221852 (64%)]\tLoss: 0.167120\tAcc: 75.00\n",
      "train epoch: 68 [153728/221852 (69%)]\tLoss: 0.230286\tAcc: 73.00\n",
      "train epoch: 68 [166528/221852 (75%)]\tLoss: 0.235626\tAcc: 73.00\n",
      "train epoch: 68 [179328/221852 (81%)]\tLoss: 0.218776\tAcc: 71.00\n",
      "train epoch: 68 [192128/221852 (87%)]\tLoss: 0.226007\tAcc: 64.00\n",
      "val epoch: 68 [128/221852 (0%)]\tLoss: 0.231405\tAcc: 66.00\n",
      "val epoch: 68 [12928/221852 (6%)]\tLoss: 0.267946\tAcc: 73.00\n",
      "train epoch: 69 [128/221852 (0%)]\tLoss: 0.237737\tAcc: 68.00\n",
      "train epoch: 69 [12928/221852 (6%)]\tLoss: 0.209068\tAcc: 73.00\n",
      "train epoch: 69 [25728/221852 (12%)]\tLoss: 0.231048\tAcc: 66.00\n",
      "train epoch: 69 [38528/221852 (17%)]\tLoss: 0.198161\tAcc: 67.00\n",
      "train epoch: 69 [51328/221852 (23%)]\tLoss: 0.257663\tAcc: 77.00\n",
      "train epoch: 69 [64128/221852 (29%)]\tLoss: 0.293156\tAcc: 62.00\n",
      "train epoch: 69 [76928/221852 (35%)]\tLoss: 0.236079\tAcc: 74.00\n",
      "train epoch: 69 [89728/221852 (40%)]\tLoss: 0.227865\tAcc: 77.00\n",
      "train epoch: 69 [102528/221852 (46%)]\tLoss: 0.211328\tAcc: 69.00\n",
      "train epoch: 69 [115328/221852 (52%)]\tLoss: 0.282833\tAcc: 70.00\n",
      "train epoch: 69 [128128/221852 (58%)]\tLoss: 0.220694\tAcc: 69.00\n",
      "train epoch: 69 [140928/221852 (64%)]\tLoss: 0.283112\tAcc: 78.00\n",
      "train epoch: 69 [153728/221852 (69%)]\tLoss: 0.199451\tAcc: 69.00\n",
      "train epoch: 69 [166528/221852 (75%)]\tLoss: 0.341233\tAcc: 77.00\n",
      "train epoch: 69 [179328/221852 (81%)]\tLoss: 0.333961\tAcc: 60.00\n",
      "train epoch: 69 [192128/221852 (87%)]\tLoss: 0.266113\tAcc: 72.00\n",
      "val epoch: 69 [128/221852 (0%)]\tLoss: 0.201062\tAcc: 70.00\n",
      "val epoch: 69 [12928/221852 (6%)]\tLoss: 0.191250\tAcc: 66.00\n",
      "train epoch: 70 [128/221852 (0%)]\tLoss: 0.252191\tAcc: 74.00\n",
      "train epoch: 70 [12928/221852 (6%)]\tLoss: 0.251419\tAcc: 70.00\n",
      "train epoch: 70 [25728/221852 (12%)]\tLoss: 0.190060\tAcc: 80.00\n",
      "train epoch: 70 [38528/221852 (17%)]\tLoss: 0.200653\tAcc: 77.00\n",
      "train epoch: 70 [51328/221852 (23%)]\tLoss: 0.288881\tAcc: 72.00\n",
      "train epoch: 70 [64128/221852 (29%)]\tLoss: 0.275720\tAcc: 68.00\n",
      "train epoch: 70 [76928/221852 (35%)]\tLoss: 0.308248\tAcc: 73.00\n",
      "train epoch: 70 [89728/221852 (40%)]\tLoss: 0.324455\tAcc: 73.00\n",
      "train epoch: 70 [102528/221852 (46%)]\tLoss: 0.263288\tAcc: 73.00\n",
      "train epoch: 70 [115328/221852 (52%)]\tLoss: 0.236195\tAcc: 72.00\n",
      "train epoch: 70 [128128/221852 (58%)]\tLoss: 0.301994\tAcc: 68.00\n",
      "train epoch: 70 [140928/221852 (64%)]\tLoss: 0.224597\tAcc: 69.00\n",
      "train epoch: 70 [153728/221852 (69%)]\tLoss: 0.257756\tAcc: 70.00\n",
      "train epoch: 70 [166528/221852 (75%)]\tLoss: 0.220871\tAcc: 71.00\n",
      "train epoch: 70 [179328/221852 (81%)]\tLoss: 0.369998\tAcc: 62.00\n",
      "train epoch: 70 [192128/221852 (87%)]\tLoss: 0.185169\tAcc: 77.00\n",
      "val epoch: 70 [128/221852 (0%)]\tLoss: 0.194583\tAcc: 70.00\n",
      "val epoch: 70 [12928/221852 (6%)]\tLoss: 0.251030\tAcc: 70.00\n",
      "train epoch: 71 [128/221852 (0%)]\tLoss: 0.218093\tAcc: 70.00\n",
      "train epoch: 71 [12928/221852 (6%)]\tLoss: 0.275031\tAcc: 73.00\n",
      "train epoch: 71 [25728/221852 (12%)]\tLoss: 0.157595\tAcc: 66.00\n",
      "train epoch: 71 [38528/221852 (17%)]\tLoss: 0.217051\tAcc: 65.00\n",
      "train epoch: 71 [51328/221852 (23%)]\tLoss: 0.145067\tAcc: 78.00\n",
      "train epoch: 71 [64128/221852 (29%)]\tLoss: 0.235485\tAcc: 67.00\n",
      "train epoch: 71 [76928/221852 (35%)]\tLoss: 0.407485\tAcc: 66.00\n",
      "train epoch: 71 [89728/221852 (40%)]\tLoss: 0.255116\tAcc: 75.00\n",
      "train epoch: 71 [102528/221852 (46%)]\tLoss: 0.279813\tAcc: 63.00\n",
      "train epoch: 71 [115328/221852 (52%)]\tLoss: 0.271876\tAcc: 66.00\n",
      "train epoch: 71 [128128/221852 (58%)]\tLoss: 0.243210\tAcc: 65.00\n",
      "train epoch: 71 [140928/221852 (64%)]\tLoss: 0.244787\tAcc: 66.00\n",
      "train epoch: 71 [153728/221852 (69%)]\tLoss: 0.295263\tAcc: 68.00\n",
      "train epoch: 71 [166528/221852 (75%)]\tLoss: 0.149726\tAcc: 69.00\n",
      "train epoch: 71 [179328/221852 (81%)]\tLoss: 0.305278\tAcc: 67.00\n",
      "train epoch: 71 [192128/221852 (87%)]\tLoss: 0.277826\tAcc: 73.00\n",
      "val epoch: 71 [128/221852 (0%)]\tLoss: 0.259844\tAcc: 68.00\n",
      "val epoch: 71 [12928/221852 (6%)]\tLoss: 0.198337\tAcc: 73.00\n",
      "train epoch: 72 [128/221852 (0%)]\tLoss: 0.311260\tAcc: 76.00\n",
      "train epoch: 72 [12928/221852 (6%)]\tLoss: 0.230191\tAcc: 77.00\n",
      "train epoch: 72 [25728/221852 (12%)]\tLoss: 0.389480\tAcc: 70.00\n",
      "train epoch: 72 [38528/221852 (17%)]\tLoss: 0.532455\tAcc: 71.00\n",
      "train epoch: 72 [51328/221852 (23%)]\tLoss: 0.241172\tAcc: 73.00\n",
      "train epoch: 72 [64128/221852 (29%)]\tLoss: 0.250478\tAcc: 76.00\n",
      "train epoch: 72 [76928/221852 (35%)]\tLoss: 0.223208\tAcc: 70.00\n",
      "train epoch: 72 [89728/221852 (40%)]\tLoss: 0.227470\tAcc: 73.00\n",
      "train epoch: 72 [102528/221852 (46%)]\tLoss: 0.497887\tAcc: 69.00\n",
      "train epoch: 72 [115328/221852 (52%)]\tLoss: 0.319045\tAcc: 75.00\n",
      "train epoch: 72 [128128/221852 (58%)]\tLoss: 0.244669\tAcc: 73.00\n",
      "train epoch: 72 [140928/221852 (64%)]\tLoss: 0.231208\tAcc: 68.00\n",
      "train epoch: 72 [153728/221852 (69%)]\tLoss: 0.220962\tAcc: 69.00\n",
      "train epoch: 72 [166528/221852 (75%)]\tLoss: 0.195522\tAcc: 75.00\n",
      "train epoch: 72 [179328/221852 (81%)]\tLoss: 0.263489\tAcc: 75.00\n",
      "train epoch: 72 [192128/221852 (87%)]\tLoss: 0.251516\tAcc: 68.00\n",
      "val epoch: 72 [128/221852 (0%)]\tLoss: 0.236409\tAcc: 62.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 72 [12928/221852 (6%)]\tLoss: 0.229106\tAcc: 74.00\n",
      "train epoch: 73 [128/221852 (0%)]\tLoss: 0.259654\tAcc: 61.00\n",
      "train epoch: 73 [12928/221852 (6%)]\tLoss: 0.256427\tAcc: 68.00\n",
      "train epoch: 73 [25728/221852 (12%)]\tLoss: 0.276522\tAcc: 65.00\n",
      "train epoch: 73 [38528/221852 (17%)]\tLoss: 0.250558\tAcc: 65.00\n",
      "train epoch: 73 [51328/221852 (23%)]\tLoss: 0.256160\tAcc: 72.00\n",
      "train epoch: 73 [64128/221852 (29%)]\tLoss: 0.266156\tAcc: 72.00\n",
      "train epoch: 73 [76928/221852 (35%)]\tLoss: 0.251673\tAcc: 74.00\n",
      "train epoch: 73 [89728/221852 (40%)]\tLoss: 0.269331\tAcc: 67.00\n",
      "train epoch: 73 [102528/221852 (46%)]\tLoss: 0.190557\tAcc: 72.00\n",
      "train epoch: 73 [115328/221852 (52%)]\tLoss: 0.248887\tAcc: 72.00\n",
      "train epoch: 73 [128128/221852 (58%)]\tLoss: 0.288233\tAcc: 65.00\n",
      "train epoch: 73 [140928/221852 (64%)]\tLoss: 0.199250\tAcc: 73.00\n",
      "train epoch: 73 [153728/221852 (69%)]\tLoss: 0.191913\tAcc: 76.00\n",
      "train epoch: 73 [166528/221852 (75%)]\tLoss: 0.350239\tAcc: 69.00\n",
      "train epoch: 73 [179328/221852 (81%)]\tLoss: 0.288441\tAcc: 69.00\n",
      "train epoch: 73 [192128/221852 (87%)]\tLoss: 0.289448\tAcc: 65.00\n",
      "val epoch: 73 [128/221852 (0%)]\tLoss: 0.228954\tAcc: 68.00\n",
      "val epoch: 73 [12928/221852 (6%)]\tLoss: 0.221245\tAcc: 70.00\n",
      "train epoch: 74 [128/221852 (0%)]\tLoss: 0.263393\tAcc: 70.00\n",
      "train epoch: 74 [12928/221852 (6%)]\tLoss: 0.239043\tAcc: 72.00\n",
      "train epoch: 74 [25728/221852 (12%)]\tLoss: 0.256199\tAcc: 66.00\n",
      "train epoch: 74 [38528/221852 (17%)]\tLoss: 0.253350\tAcc: 78.00\n",
      "train epoch: 74 [51328/221852 (23%)]\tLoss: 0.275882\tAcc: 70.00\n",
      "train epoch: 74 [64128/221852 (29%)]\tLoss: 0.255803\tAcc: 67.00\n",
      "train epoch: 74 [76928/221852 (35%)]\tLoss: 0.243589\tAcc: 71.00\n",
      "train epoch: 74 [89728/221852 (40%)]\tLoss: 0.249261\tAcc: 78.00\n",
      "train epoch: 74 [102528/221852 (46%)]\tLoss: 0.302409\tAcc: 66.00\n",
      "train epoch: 74 [115328/221852 (52%)]\tLoss: 0.264301\tAcc: 68.00\n",
      "train epoch: 74 [128128/221852 (58%)]\tLoss: 0.268127\tAcc: 69.00\n",
      "train epoch: 74 [140928/221852 (64%)]\tLoss: 0.237031\tAcc: 74.00\n",
      "train epoch: 74 [153728/221852 (69%)]\tLoss: 0.204019\tAcc: 73.00\n",
      "train epoch: 74 [166528/221852 (75%)]\tLoss: 0.261091\tAcc: 73.00\n",
      "train epoch: 74 [179328/221852 (81%)]\tLoss: 0.249940\tAcc: 66.00\n",
      "train epoch: 74 [192128/221852 (87%)]\tLoss: 0.231307\tAcc: 62.00\n",
      "val epoch: 74 [128/221852 (0%)]\tLoss: 0.249349\tAcc: 64.00\n",
      "val epoch: 74 [12928/221852 (6%)]\tLoss: 0.230485\tAcc: 71.00\n",
      "train epoch: 75 [128/221852 (0%)]\tLoss: 0.229112\tAcc: 67.00\n",
      "train epoch: 75 [12928/221852 (6%)]\tLoss: 0.225818\tAcc: 66.00\n",
      "train epoch: 75 [25728/221852 (12%)]\tLoss: 0.157071\tAcc: 72.00\n",
      "train epoch: 75 [38528/221852 (17%)]\tLoss: 0.198524\tAcc: 74.00\n",
      "train epoch: 75 [51328/221852 (23%)]\tLoss: 0.202418\tAcc: 71.00\n",
      "train epoch: 75 [64128/221852 (29%)]\tLoss: 0.295295\tAcc: 75.00\n",
      "train epoch: 75 [76928/221852 (35%)]\tLoss: 0.209694\tAcc: 71.00\n",
      "train epoch: 75 [89728/221852 (40%)]\tLoss: 0.255356\tAcc: 74.00\n",
      "train epoch: 75 [102528/221852 (46%)]\tLoss: 0.238264\tAcc: 74.00\n",
      "train epoch: 75 [115328/221852 (52%)]\tLoss: 0.219637\tAcc: 72.00\n",
      "train epoch: 75 [128128/221852 (58%)]\tLoss: 0.192582\tAcc: 77.00\n",
      "train epoch: 75 [140928/221852 (64%)]\tLoss: 0.221422\tAcc: 70.00\n",
      "train epoch: 75 [153728/221852 (69%)]\tLoss: 0.234890\tAcc: 67.00\n",
      "train epoch: 75 [166528/221852 (75%)]\tLoss: 0.269520\tAcc: 69.00\n",
      "train epoch: 75 [179328/221852 (81%)]\tLoss: 0.170982\tAcc: 74.00\n",
      "train epoch: 75 [192128/221852 (87%)]\tLoss: 0.432553\tAcc: 69.00\n",
      "val epoch: 75 [128/221852 (0%)]\tLoss: 0.365689\tAcc: 66.00\n",
      "val epoch: 75 [12928/221852 (6%)]\tLoss: 0.233776\tAcc: 71.00\n",
      "train epoch: 76 [128/221852 (0%)]\tLoss: 0.304225\tAcc: 64.00\n",
      "train epoch: 76 [12928/221852 (6%)]\tLoss: 0.146447\tAcc: 75.00\n",
      "train epoch: 76 [25728/221852 (12%)]\tLoss: 0.252532\tAcc: 72.00\n",
      "train epoch: 76 [38528/221852 (17%)]\tLoss: 0.231653\tAcc: 69.00\n",
      "train epoch: 76 [51328/221852 (23%)]\tLoss: 0.247765\tAcc: 71.00\n",
      "train epoch: 76 [64128/221852 (29%)]\tLoss: 0.317234\tAcc: 74.00\n",
      "train epoch: 76 [76928/221852 (35%)]\tLoss: 0.297824\tAcc: 71.00\n",
      "train epoch: 76 [89728/221852 (40%)]\tLoss: 0.193145\tAcc: 75.00\n",
      "train epoch: 76 [102528/221852 (46%)]\tLoss: 0.277801\tAcc: 69.00\n",
      "train epoch: 76 [115328/221852 (52%)]\tLoss: 0.213647\tAcc: 73.00\n",
      "train epoch: 76 [128128/221852 (58%)]\tLoss: 0.300125\tAcc: 65.00\n",
      "train epoch: 76 [140928/221852 (64%)]\tLoss: 0.224700\tAcc: 70.00\n",
      "train epoch: 76 [153728/221852 (69%)]\tLoss: 0.211768\tAcc: 70.00\n",
      "train epoch: 76 [166528/221852 (75%)]\tLoss: 0.271798\tAcc: 70.00\n",
      "train epoch: 76 [179328/221852 (81%)]\tLoss: 0.148193\tAcc: 77.00\n",
      "train epoch: 76 [192128/221852 (87%)]\tLoss: 0.158275\tAcc: 76.00\n",
      "val epoch: 76 [128/221852 (0%)]\tLoss: 0.288599\tAcc: 71.00\n",
      "val epoch: 76 [12928/221852 (6%)]\tLoss: 0.225852\tAcc: 62.00\n",
      "train epoch: 77 [128/221852 (0%)]\tLoss: 0.169876\tAcc: 70.00\n",
      "train epoch: 77 [12928/221852 (6%)]\tLoss: 0.215906\tAcc: 68.00\n",
      "train epoch: 77 [25728/221852 (12%)]\tLoss: 0.367890\tAcc: 64.00\n",
      "train epoch: 77 [38528/221852 (17%)]\tLoss: 0.290201\tAcc: 68.00\n",
      "train epoch: 77 [51328/221852 (23%)]\tLoss: 0.255385\tAcc: 71.00\n",
      "train epoch: 77 [64128/221852 (29%)]\tLoss: 0.292644\tAcc: 70.00\n",
      "train epoch: 77 [76928/221852 (35%)]\tLoss: 0.257342\tAcc: 74.00\n",
      "train epoch: 77 [89728/221852 (40%)]\tLoss: 0.255999\tAcc: 73.00\n",
      "train epoch: 77 [102528/221852 (46%)]\tLoss: 0.219722\tAcc: 77.00\n",
      "train epoch: 77 [115328/221852 (52%)]\tLoss: 0.356194\tAcc: 75.00\n",
      "train epoch: 77 [128128/221852 (58%)]\tLoss: 0.251688\tAcc: 71.00\n",
      "train epoch: 77 [140928/221852 (64%)]\tLoss: 0.273269\tAcc: 69.00\n",
      "train epoch: 77 [153728/221852 (69%)]\tLoss: 0.253225\tAcc: 69.00\n",
      "train epoch: 77 [166528/221852 (75%)]\tLoss: 0.262190\tAcc: 66.00\n",
      "train epoch: 77 [179328/221852 (81%)]\tLoss: 0.238839\tAcc: 67.00\n",
      "train epoch: 77 [192128/221852 (87%)]\tLoss: 0.247871\tAcc: 78.00\n",
      "val epoch: 77 [128/221852 (0%)]\tLoss: 0.274971\tAcc: 75.00\n",
      "val epoch: 77 [12928/221852 (6%)]\tLoss: 0.297976\tAcc: 67.00\n",
      "train epoch: 78 [128/221852 (0%)]\tLoss: 0.277287\tAcc: 74.00\n",
      "train epoch: 78 [12928/221852 (6%)]\tLoss: 0.254111\tAcc: 77.00\n",
      "train epoch: 78 [25728/221852 (12%)]\tLoss: 0.117428\tAcc: 74.00\n",
      "train epoch: 78 [38528/221852 (17%)]\tLoss: 0.205941\tAcc: 62.00\n",
      "train epoch: 78 [51328/221852 (23%)]\tLoss: 0.246813\tAcc: 73.00\n",
      "train epoch: 78 [64128/221852 (29%)]\tLoss: 0.299776\tAcc: 71.00\n",
      "train epoch: 78 [76928/221852 (35%)]\tLoss: 0.215019\tAcc: 76.00\n",
      "train epoch: 78 [89728/221852 (40%)]\tLoss: 0.237543\tAcc: 73.00\n",
      "train epoch: 78 [102528/221852 (46%)]\tLoss: 0.257054\tAcc: 73.00\n",
      "train epoch: 78 [115328/221852 (52%)]\tLoss: 0.187795\tAcc: 77.00\n",
      "train epoch: 78 [128128/221852 (58%)]\tLoss: 0.187750\tAcc: 74.00\n",
      "train epoch: 78 [140928/221852 (64%)]\tLoss: 0.213638\tAcc: 73.00\n",
      "train epoch: 78 [153728/221852 (69%)]\tLoss: 0.254823\tAcc: 64.00\n",
      "train epoch: 78 [166528/221852 (75%)]\tLoss: 0.167174\tAcc: 73.00\n",
      "train epoch: 78 [179328/221852 (81%)]\tLoss: 0.234336\tAcc: 77.00\n",
      "train epoch: 78 [192128/221852 (87%)]\tLoss: 0.246594\tAcc: 70.00\n",
      "val epoch: 78 [128/221852 (0%)]\tLoss: 0.242482\tAcc: 60.00\n",
      "val epoch: 78 [12928/221852 (6%)]\tLoss: 0.205468\tAcc: 75.00\n",
      "train epoch: 79 [128/221852 (0%)]\tLoss: 0.225677\tAcc: 68.00\n",
      "train epoch: 79 [12928/221852 (6%)]\tLoss: 0.454335\tAcc: 73.00\n",
      "train epoch: 79 [25728/221852 (12%)]\tLoss: 0.231170\tAcc: 76.00\n",
      "train epoch: 79 [38528/221852 (17%)]\tLoss: 0.256199\tAcc: 74.00\n",
      "train epoch: 79 [51328/221852 (23%)]\tLoss: 0.324379\tAcc: 70.00\n",
      "train epoch: 79 [64128/221852 (29%)]\tLoss: 0.221512\tAcc: 70.00\n",
      "train epoch: 79 [76928/221852 (35%)]\tLoss: 0.162848\tAcc: 72.00\n",
      "train epoch: 79 [89728/221852 (40%)]\tLoss: 0.214839\tAcc: 70.00\n",
      "train epoch: 79 [102528/221852 (46%)]\tLoss: 0.241105\tAcc: 64.00\n",
      "train epoch: 79 [115328/221852 (52%)]\tLoss: 0.196041\tAcc: 84.00\n",
      "train epoch: 79 [128128/221852 (58%)]\tLoss: 0.336322\tAcc: 69.00\n",
      "train epoch: 79 [140928/221852 (64%)]\tLoss: 0.269403\tAcc: 69.00\n",
      "train epoch: 79 [153728/221852 (69%)]\tLoss: 0.146246\tAcc: 74.00\n",
      "train epoch: 79 [166528/221852 (75%)]\tLoss: 0.220953\tAcc: 66.00\n",
      "train epoch: 79 [179328/221852 (81%)]\tLoss: 0.172674\tAcc: 71.00\n",
      "train epoch: 79 [192128/221852 (87%)]\tLoss: 0.256214\tAcc: 68.00\n",
      "val epoch: 79 [128/221852 (0%)]\tLoss: 0.428816\tAcc: 68.00\n",
      "val epoch: 79 [12928/221852 (6%)]\tLoss: 0.243817\tAcc: 76.00\n",
      "train epoch: 80 [128/221852 (0%)]\tLoss: 0.308961\tAcc: 65.00\n",
      "train epoch: 80 [12928/221852 (6%)]\tLoss: 0.298637\tAcc: 69.00\n",
      "train epoch: 80 [25728/221852 (12%)]\tLoss: 0.181141\tAcc: 73.00\n",
      "train epoch: 80 [38528/221852 (17%)]\tLoss: 0.218784\tAcc: 67.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 80 [51328/221852 (23%)]\tLoss: 0.275924\tAcc: 70.00\n",
      "train epoch: 80 [64128/221852 (29%)]\tLoss: 0.280344\tAcc: 66.00\n",
      "train epoch: 80 [76928/221852 (35%)]\tLoss: 0.126956\tAcc: 77.00\n",
      "train epoch: 80 [89728/221852 (40%)]\tLoss: 0.322540\tAcc: 65.00\n",
      "train epoch: 80 [102528/221852 (46%)]\tLoss: 0.191799\tAcc: 73.00\n",
      "train epoch: 80 [115328/221852 (52%)]\tLoss: 0.213274\tAcc: 70.00\n",
      "train epoch: 80 [128128/221852 (58%)]\tLoss: 0.280294\tAcc: 66.00\n",
      "train epoch: 80 [140928/221852 (64%)]\tLoss: 0.135812\tAcc: 79.00\n",
      "train epoch: 80 [153728/221852 (69%)]\tLoss: 0.210667\tAcc: 71.00\n",
      "train epoch: 80 [166528/221852 (75%)]\tLoss: 0.243417\tAcc: 69.00\n",
      "train epoch: 80 [179328/221852 (81%)]\tLoss: 0.321141\tAcc: 75.00\n",
      "train epoch: 80 [192128/221852 (87%)]\tLoss: 0.218573\tAcc: 68.00\n",
      "val epoch: 80 [128/221852 (0%)]\tLoss: 0.138990\tAcc: 70.00\n",
      "val epoch: 80 [12928/221852 (6%)]\tLoss: 0.324016\tAcc: 66.00\n",
      "train epoch: 81 [128/221852 (0%)]\tLoss: 0.197805\tAcc: 73.00\n",
      "train epoch: 81 [12928/221852 (6%)]\tLoss: 0.214297\tAcc: 73.00\n",
      "train epoch: 81 [25728/221852 (12%)]\tLoss: 0.441140\tAcc: 62.00\n",
      "train epoch: 81 [38528/221852 (17%)]\tLoss: 0.207518\tAcc: 73.00\n",
      "train epoch: 81 [51328/221852 (23%)]\tLoss: 0.241039\tAcc: 68.00\n",
      "train epoch: 81 [64128/221852 (29%)]\tLoss: 0.244700\tAcc: 70.00\n",
      "train epoch: 81 [76928/221852 (35%)]\tLoss: 0.265935\tAcc: 70.00\n",
      "train epoch: 81 [89728/221852 (40%)]\tLoss: 0.227477\tAcc: 79.00\n",
      "train epoch: 81 [102528/221852 (46%)]\tLoss: 0.233943\tAcc: 73.00\n",
      "train epoch: 81 [115328/221852 (52%)]\tLoss: 0.231528\tAcc: 66.00\n",
      "train epoch: 81 [128128/221852 (58%)]\tLoss: 0.174902\tAcc: 66.00\n",
      "train epoch: 81 [140928/221852 (64%)]\tLoss: 0.328471\tAcc: 73.00\n",
      "train epoch: 81 [153728/221852 (69%)]\tLoss: 0.205530\tAcc: 69.00\n",
      "train epoch: 81 [166528/221852 (75%)]\tLoss: 0.266747\tAcc: 64.00\n",
      "train epoch: 81 [179328/221852 (81%)]\tLoss: 0.249454\tAcc: 72.00\n",
      "train epoch: 81 [192128/221852 (87%)]\tLoss: 0.226017\tAcc: 74.00\n",
      "val epoch: 81 [128/221852 (0%)]\tLoss: 0.179508\tAcc: 78.00\n",
      "val epoch: 81 [12928/221852 (6%)]\tLoss: 0.197501\tAcc: 74.00\n",
      "train epoch: 82 [128/221852 (0%)]\tLoss: 0.304573\tAcc: 64.00\n",
      "train epoch: 82 [12928/221852 (6%)]\tLoss: 0.234180\tAcc: 66.00\n",
      "train epoch: 82 [25728/221852 (12%)]\tLoss: 0.312841\tAcc: 69.00\n",
      "train epoch: 82 [38528/221852 (17%)]\tLoss: 0.298243\tAcc: 66.00\n",
      "train epoch: 82 [51328/221852 (23%)]\tLoss: 0.208406\tAcc: 63.00\n",
      "train epoch: 82 [64128/221852 (29%)]\tLoss: 0.329161\tAcc: 75.00\n",
      "train epoch: 82 [76928/221852 (35%)]\tLoss: 0.341245\tAcc: 70.00\n",
      "train epoch: 82 [89728/221852 (40%)]\tLoss: 0.279031\tAcc: 71.00\n",
      "train epoch: 82 [102528/221852 (46%)]\tLoss: 0.230151\tAcc: 67.00\n",
      "train epoch: 82 [115328/221852 (52%)]\tLoss: 0.188938\tAcc: 68.00\n",
      "train epoch: 82 [128128/221852 (58%)]\tLoss: 0.225201\tAcc: 78.00\n",
      "train epoch: 82 [140928/221852 (64%)]\tLoss: 0.247740\tAcc: 73.00\n",
      "train epoch: 82 [153728/221852 (69%)]\tLoss: 0.329019\tAcc: 64.00\n",
      "train epoch: 82 [166528/221852 (75%)]\tLoss: 0.222435\tAcc: 73.00\n",
      "train epoch: 82 [179328/221852 (81%)]\tLoss: 0.144070\tAcc: 77.00\n",
      "train epoch: 82 [192128/221852 (87%)]\tLoss: 0.205429\tAcc: 77.00\n",
      "val epoch: 82 [128/221852 (0%)]\tLoss: 0.309309\tAcc: 70.00\n",
      "val epoch: 82 [12928/221852 (6%)]\tLoss: 0.427026\tAcc: 62.00\n",
      "train epoch: 83 [128/221852 (0%)]\tLoss: 0.316631\tAcc: 66.00\n",
      "train epoch: 83 [12928/221852 (6%)]\tLoss: 0.262573\tAcc: 73.00\n",
      "train epoch: 83 [25728/221852 (12%)]\tLoss: 0.249794\tAcc: 68.00\n",
      "train epoch: 83 [38528/221852 (17%)]\tLoss: 0.200946\tAcc: 72.00\n",
      "train epoch: 83 [51328/221852 (23%)]\tLoss: 0.267866\tAcc: 70.00\n",
      "train epoch: 83 [64128/221852 (29%)]\tLoss: 0.210197\tAcc: 73.00\n",
      "train epoch: 83 [76928/221852 (35%)]\tLoss: 0.206440\tAcc: 71.00\n",
      "train epoch: 83 [89728/221852 (40%)]\tLoss: 0.221997\tAcc: 72.00\n",
      "train epoch: 83 [102528/221852 (46%)]\tLoss: 0.207564\tAcc: 72.00\n",
      "train epoch: 83 [115328/221852 (52%)]\tLoss: 0.275653\tAcc: 62.00\n",
      "train epoch: 83 [128128/221852 (58%)]\tLoss: 0.244533\tAcc: 73.00\n",
      "train epoch: 83 [140928/221852 (64%)]\tLoss: 0.230150\tAcc: 70.00\n",
      "train epoch: 83 [153728/221852 (69%)]\tLoss: 0.278427\tAcc: 73.00\n",
      "train epoch: 83 [166528/221852 (75%)]\tLoss: 0.198686\tAcc: 70.00\n",
      "train epoch: 83 [179328/221852 (81%)]\tLoss: 0.282175\tAcc: 72.00\n",
      "train epoch: 83 [192128/221852 (87%)]\tLoss: 0.260459\tAcc: 73.00\n",
      "val epoch: 83 [128/221852 (0%)]\tLoss: 0.229710\tAcc: 74.00\n",
      "val epoch: 83 [12928/221852 (6%)]\tLoss: 0.192591\tAcc: 66.00\n",
      "train epoch: 84 [128/221852 (0%)]\tLoss: 0.214641\tAcc: 70.00\n",
      "train epoch: 84 [12928/221852 (6%)]\tLoss: 0.205026\tAcc: 79.00\n",
      "train epoch: 84 [25728/221852 (12%)]\tLoss: 0.257720\tAcc: 73.00\n",
      "train epoch: 84 [38528/221852 (17%)]\tLoss: 0.230911\tAcc: 73.00\n",
      "train epoch: 84 [51328/221852 (23%)]\tLoss: 0.277352\tAcc: 70.00\n",
      "train epoch: 84 [64128/221852 (29%)]\tLoss: 0.310727\tAcc: 67.00\n",
      "train epoch: 84 [76928/221852 (35%)]\tLoss: 0.261464\tAcc: 66.00\n",
      "train epoch: 84 [89728/221852 (40%)]\tLoss: 0.254277\tAcc: 66.00\n",
      "train epoch: 84 [102528/221852 (46%)]\tLoss: 0.177894\tAcc: 70.00\n",
      "train epoch: 84 [115328/221852 (52%)]\tLoss: 0.179171\tAcc: 73.00\n",
      "train epoch: 84 [128128/221852 (58%)]\tLoss: 0.302203\tAcc: 75.00\n",
      "train epoch: 84 [140928/221852 (64%)]\tLoss: 0.227839\tAcc: 76.00\n",
      "train epoch: 84 [153728/221852 (69%)]\tLoss: 0.183801\tAcc: 65.00\n",
      "train epoch: 84 [166528/221852 (75%)]\tLoss: 0.161626\tAcc: 72.00\n",
      "train epoch: 84 [179328/221852 (81%)]\tLoss: 0.239204\tAcc: 73.00\n",
      "train epoch: 84 [192128/221852 (87%)]\tLoss: 0.267809\tAcc: 73.00\n",
      "val epoch: 84 [128/221852 (0%)]\tLoss: 0.239643\tAcc: 72.00\n",
      "val epoch: 84 [12928/221852 (6%)]\tLoss: 0.238708\tAcc: 74.00\n",
      "train epoch: 85 [128/221852 (0%)]\tLoss: 0.274832\tAcc: 77.00\n",
      "train epoch: 85 [12928/221852 (6%)]\tLoss: 0.267014\tAcc: 66.00\n",
      "train epoch: 85 [25728/221852 (12%)]\tLoss: 0.298620\tAcc: 70.00\n",
      "train epoch: 85 [38528/221852 (17%)]\tLoss: 0.220694\tAcc: 78.00\n",
      "train epoch: 85 [51328/221852 (23%)]\tLoss: 0.213348\tAcc: 74.00\n",
      "train epoch: 85 [64128/221852 (29%)]\tLoss: 0.278031\tAcc: 73.00\n",
      "train epoch: 85 [76928/221852 (35%)]\tLoss: 0.200087\tAcc: 73.00\n",
      "train epoch: 85 [89728/221852 (40%)]\tLoss: 0.177148\tAcc: 74.00\n",
      "train epoch: 85 [102528/221852 (46%)]\tLoss: 0.221055\tAcc: 73.00\n",
      "train epoch: 85 [115328/221852 (52%)]\tLoss: 0.236664\tAcc: 80.00\n",
      "train epoch: 85 [128128/221852 (58%)]\tLoss: 0.212294\tAcc: 73.00\n",
      "train epoch: 85 [140928/221852 (64%)]\tLoss: 0.214380\tAcc: 76.00\n",
      "train epoch: 85 [153728/221852 (69%)]\tLoss: 0.290746\tAcc: 72.00\n",
      "train epoch: 85 [166528/221852 (75%)]\tLoss: 0.212782\tAcc: 76.00\n",
      "train epoch: 85 [179328/221852 (81%)]\tLoss: 0.575017\tAcc: 68.00\n",
      "train epoch: 85 [192128/221852 (87%)]\tLoss: 0.305902\tAcc: 68.00\n",
      "val epoch: 85 [128/221852 (0%)]\tLoss: 0.297402\tAcc: 67.00\n",
      "val epoch: 85 [12928/221852 (6%)]\tLoss: 0.257614\tAcc: 70.00\n",
      "train epoch: 86 [128/221852 (0%)]\tLoss: 0.267714\tAcc: 72.00\n",
      "train epoch: 86 [12928/221852 (6%)]\tLoss: 0.248464\tAcc: 71.00\n",
      "train epoch: 86 [25728/221852 (12%)]\tLoss: 0.302686\tAcc: 70.00\n",
      "train epoch: 86 [38528/221852 (17%)]\tLoss: 0.271558\tAcc: 70.00\n",
      "train epoch: 86 [51328/221852 (23%)]\tLoss: 0.282497\tAcc: 75.00\n",
      "train epoch: 86 [64128/221852 (29%)]\tLoss: 0.276032\tAcc: 67.00\n",
      "train epoch: 86 [76928/221852 (35%)]\tLoss: 0.240191\tAcc: 66.00\n",
      "train epoch: 86 [89728/221852 (40%)]\tLoss: 0.244689\tAcc: 66.00\n",
      "train epoch: 86 [102528/221852 (46%)]\tLoss: 0.215629\tAcc: 74.00\n",
      "train epoch: 86 [115328/221852 (52%)]\tLoss: 0.234137\tAcc: 70.00\n",
      "train epoch: 86 [128128/221852 (58%)]\tLoss: 0.191962\tAcc: 80.00\n",
      "train epoch: 86 [140928/221852 (64%)]\tLoss: 0.170911\tAcc: 73.00\n",
      "train epoch: 86 [153728/221852 (69%)]\tLoss: 0.275463\tAcc: 74.00\n",
      "train epoch: 86 [166528/221852 (75%)]\tLoss: 0.272348\tAcc: 65.00\n",
      "train epoch: 86 [179328/221852 (81%)]\tLoss: 0.296919\tAcc: 73.00\n",
      "train epoch: 86 [192128/221852 (87%)]\tLoss: 0.257195\tAcc: 72.00\n",
      "val epoch: 86 [128/221852 (0%)]\tLoss: 0.256958\tAcc: 70.00\n",
      "val epoch: 86 [12928/221852 (6%)]\tLoss: 0.242087\tAcc: 73.00\n",
      "train epoch: 87 [128/221852 (0%)]\tLoss: 0.269929\tAcc: 73.00\n",
      "train epoch: 87 [12928/221852 (6%)]\tLoss: 0.156532\tAcc: 73.00\n",
      "train epoch: 87 [25728/221852 (12%)]\tLoss: 0.237629\tAcc: 73.00\n",
      "train epoch: 87 [38528/221852 (17%)]\tLoss: 0.236508\tAcc: 69.00\n",
      "train epoch: 87 [51328/221852 (23%)]\tLoss: 0.219146\tAcc: 68.00\n",
      "train epoch: 87 [64128/221852 (29%)]\tLoss: 0.156144\tAcc: 73.00\n",
      "train epoch: 87 [76928/221852 (35%)]\tLoss: 0.212429\tAcc: 76.00\n",
      "train epoch: 87 [89728/221852 (40%)]\tLoss: 0.201363\tAcc: 75.00\n",
      "train epoch: 87 [102528/221852 (46%)]\tLoss: 0.179543\tAcc: 71.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 87 [115328/221852 (52%)]\tLoss: 0.359228\tAcc: 70.00\n",
      "train epoch: 87 [128128/221852 (58%)]\tLoss: 0.208193\tAcc: 71.00\n",
      "train epoch: 87 [140928/221852 (64%)]\tLoss: 0.211434\tAcc: 72.00\n",
      "train epoch: 87 [153728/221852 (69%)]\tLoss: 0.205574\tAcc: 70.00\n",
      "train epoch: 87 [166528/221852 (75%)]\tLoss: 0.162683\tAcc: 72.00\n",
      "train epoch: 87 [179328/221852 (81%)]\tLoss: 0.186535\tAcc: 73.00\n",
      "train epoch: 87 [192128/221852 (87%)]\tLoss: 0.248437\tAcc: 69.00\n",
      "val epoch: 87 [128/221852 (0%)]\tLoss: 0.204506\tAcc: 71.00\n",
      "val epoch: 87 [12928/221852 (6%)]\tLoss: 0.302031\tAcc: 67.00\n",
      "train epoch: 88 [128/221852 (0%)]\tLoss: 0.158509\tAcc: 75.00\n",
      "train epoch: 88 [12928/221852 (6%)]\tLoss: 0.123733\tAcc: 78.00\n",
      "train epoch: 88 [25728/221852 (12%)]\tLoss: 0.826715\tAcc: 72.00\n",
      "train epoch: 88 [38528/221852 (17%)]\tLoss: 0.217863\tAcc: 77.00\n",
      "train epoch: 88 [51328/221852 (23%)]\tLoss: 0.236759\tAcc: 77.00\n",
      "train epoch: 88 [64128/221852 (29%)]\tLoss: 0.248095\tAcc: 64.00\n",
      "train epoch: 88 [76928/221852 (35%)]\tLoss: 0.359552\tAcc: 71.00\n",
      "train epoch: 88 [89728/221852 (40%)]\tLoss: 0.176861\tAcc: 68.00\n",
      "train epoch: 88 [102528/221852 (46%)]\tLoss: 0.209662\tAcc: 73.00\n",
      "train epoch: 88 [115328/221852 (52%)]\tLoss: 0.263985\tAcc: 77.00\n",
      "train epoch: 88 [128128/221852 (58%)]\tLoss: 0.248189\tAcc: 74.00\n",
      "train epoch: 88 [140928/221852 (64%)]\tLoss: 0.273840\tAcc: 72.00\n",
      "train epoch: 88 [153728/221852 (69%)]\tLoss: 0.305016\tAcc: 72.00\n",
      "train epoch: 88 [166528/221852 (75%)]\tLoss: 0.230255\tAcc: 72.00\n",
      "train epoch: 88 [179328/221852 (81%)]\tLoss: 0.200108\tAcc: 75.00\n",
      "train epoch: 88 [192128/221852 (87%)]\tLoss: 0.238247\tAcc: 71.00\n",
      "val epoch: 88 [128/221852 (0%)]\tLoss: 0.269888\tAcc: 64.00\n",
      "val epoch: 88 [12928/221852 (6%)]\tLoss: 0.300184\tAcc: 71.00\n",
      "train epoch: 89 [128/221852 (0%)]\tLoss: 0.235073\tAcc: 71.00\n",
      "train epoch: 89 [12928/221852 (6%)]\tLoss: 0.254032\tAcc: 75.00\n",
      "train epoch: 89 [25728/221852 (12%)]\tLoss: 0.217218\tAcc: 75.00\n",
      "train epoch: 89 [38528/221852 (17%)]\tLoss: 0.318816\tAcc: 75.00\n",
      "train epoch: 89 [51328/221852 (23%)]\tLoss: 0.298476\tAcc: 67.00\n",
      "train epoch: 89 [64128/221852 (29%)]\tLoss: 0.253735\tAcc: 71.00\n",
      "train epoch: 89 [76928/221852 (35%)]\tLoss: 0.210706\tAcc: 73.00\n",
      "train epoch: 89 [89728/221852 (40%)]\tLoss: 0.286790\tAcc: 70.00\n",
      "train epoch: 89 [102528/221852 (46%)]\tLoss: 0.222303\tAcc: 76.00\n",
      "train epoch: 89 [115328/221852 (52%)]\tLoss: 0.244396\tAcc: 72.00\n",
      "train epoch: 89 [128128/221852 (58%)]\tLoss: 0.155406\tAcc: 83.00\n",
      "train epoch: 89 [140928/221852 (64%)]\tLoss: 0.282949\tAcc: 72.00\n",
      "train epoch: 89 [153728/221852 (69%)]\tLoss: 0.389697\tAcc: 68.00\n",
      "train epoch: 89 [166528/221852 (75%)]\tLoss: 0.302279\tAcc: 66.00\n",
      "train epoch: 89 [179328/221852 (81%)]\tLoss: 0.186543\tAcc: 74.00\n",
      "train epoch: 89 [192128/221852 (87%)]\tLoss: 0.245614\tAcc: 68.00\n",
      "val epoch: 89 [128/221852 (0%)]\tLoss: 0.179234\tAcc: 73.00\n",
      "val epoch: 89 [12928/221852 (6%)]\tLoss: 0.215941\tAcc: 79.00\n",
      "train epoch: 90 [128/221852 (0%)]\tLoss: 0.252085\tAcc: 72.00\n",
      "train epoch: 90 [12928/221852 (6%)]\tLoss: 0.209770\tAcc: 80.00\n",
      "train epoch: 90 [25728/221852 (12%)]\tLoss: 0.283334\tAcc: 72.00\n",
      "train epoch: 90 [38528/221852 (17%)]\tLoss: 0.179415\tAcc: 67.00\n",
      "train epoch: 90 [51328/221852 (23%)]\tLoss: 0.201475\tAcc: 72.00\n",
      "train epoch: 90 [64128/221852 (29%)]\tLoss: 0.232995\tAcc: 74.00\n",
      "train epoch: 90 [76928/221852 (35%)]\tLoss: 0.222385\tAcc: 70.00\n",
      "train epoch: 90 [89728/221852 (40%)]\tLoss: 0.235721\tAcc: 70.00\n",
      "train epoch: 90 [102528/221852 (46%)]\tLoss: 0.274677\tAcc: 71.00\n",
      "train epoch: 90 [115328/221852 (52%)]\tLoss: 0.321866\tAcc: 72.00\n",
      "train epoch: 90 [128128/221852 (58%)]\tLoss: 0.449350\tAcc: 78.00\n",
      "train epoch: 90 [140928/221852 (64%)]\tLoss: 0.252416\tAcc: 64.00\n",
      "train epoch: 90 [153728/221852 (69%)]\tLoss: 0.292803\tAcc: 72.00\n",
      "train epoch: 90 [166528/221852 (75%)]\tLoss: 0.168685\tAcc: 73.00\n",
      "train epoch: 90 [179328/221852 (81%)]\tLoss: 0.294918\tAcc: 67.00\n",
      "train epoch: 90 [192128/221852 (87%)]\tLoss: 0.341454\tAcc: 69.00\n",
      "val epoch: 90 [128/221852 (0%)]\tLoss: 0.196321\tAcc: 75.00\n",
      "val epoch: 90 [12928/221852 (6%)]\tLoss: 0.225288\tAcc: 68.00\n",
      "train epoch: 91 [128/221852 (0%)]\tLoss: 0.228536\tAcc: 70.00\n",
      "train epoch: 91 [12928/221852 (6%)]\tLoss: 0.191208\tAcc: 64.00\n",
      "train epoch: 91 [25728/221852 (12%)]\tLoss: 0.214479\tAcc: 66.00\n",
      "train epoch: 91 [38528/221852 (17%)]\tLoss: 0.177809\tAcc: 75.00\n",
      "train epoch: 91 [51328/221852 (23%)]\tLoss: 0.263652\tAcc: 70.00\n",
      "train epoch: 91 [64128/221852 (29%)]\tLoss: 0.172418\tAcc: 77.00\n",
      "train epoch: 91 [76928/221852 (35%)]\tLoss: 0.237290\tAcc: 63.00\n",
      "train epoch: 91 [89728/221852 (40%)]\tLoss: 0.233904\tAcc: 69.00\n",
      "train epoch: 91 [102528/221852 (46%)]\tLoss: 0.370416\tAcc: 63.00\n",
      "train epoch: 91 [115328/221852 (52%)]\tLoss: 0.210619\tAcc: 72.00\n",
      "train epoch: 91 [128128/221852 (58%)]\tLoss: 0.237352\tAcc: 67.00\n",
      "train epoch: 91 [140928/221852 (64%)]\tLoss: 0.254494\tAcc: 69.00\n",
      "train epoch: 91 [153728/221852 (69%)]\tLoss: 0.187943\tAcc: 68.00\n",
      "train epoch: 91 [166528/221852 (75%)]\tLoss: 0.253554\tAcc: 73.00\n",
      "train epoch: 91 [179328/221852 (81%)]\tLoss: 0.358851\tAcc: 72.00\n",
      "train epoch: 91 [192128/221852 (87%)]\tLoss: 0.188758\tAcc: 66.00\n",
      "val epoch: 91 [128/221852 (0%)]\tLoss: 0.348173\tAcc: 73.00\n",
      "val epoch: 91 [12928/221852 (6%)]\tLoss: 0.237013\tAcc: 70.00\n",
      "train epoch: 92 [128/221852 (0%)]\tLoss: 0.376602\tAcc: 60.00\n",
      "train epoch: 92 [12928/221852 (6%)]\tLoss: 0.176014\tAcc: 81.00\n",
      "train epoch: 92 [25728/221852 (12%)]\tLoss: 0.434381\tAcc: 70.00\n",
      "train epoch: 92 [38528/221852 (17%)]\tLoss: 0.271214\tAcc: 67.00\n",
      "train epoch: 92 [51328/221852 (23%)]\tLoss: 0.271301\tAcc: 74.00\n",
      "train epoch: 92 [64128/221852 (29%)]\tLoss: 0.193208\tAcc: 63.00\n",
      "train epoch: 92 [76928/221852 (35%)]\tLoss: 0.112260\tAcc: 64.00\n",
      "train epoch: 92 [89728/221852 (40%)]\tLoss: 0.173465\tAcc: 75.00\n",
      "train epoch: 92 [102528/221852 (46%)]\tLoss: 0.206654\tAcc: 76.00\n",
      "train epoch: 92 [115328/221852 (52%)]\tLoss: 0.309495\tAcc: 70.00\n",
      "train epoch: 92 [128128/221852 (58%)]\tLoss: 0.218898\tAcc: 70.00\n",
      "train epoch: 92 [140928/221852 (64%)]\tLoss: 0.298446\tAcc: 70.00\n",
      "train epoch: 92 [153728/221852 (69%)]\tLoss: 0.214633\tAcc: 69.00\n",
      "train epoch: 92 [166528/221852 (75%)]\tLoss: 0.255893\tAcc: 69.00\n",
      "train epoch: 92 [179328/221852 (81%)]\tLoss: 0.215659\tAcc: 70.00\n",
      "train epoch: 92 [192128/221852 (87%)]\tLoss: 0.184195\tAcc: 76.00\n",
      "val epoch: 92 [128/221852 (0%)]\tLoss: 0.290467\tAcc: 68.00\n",
      "val epoch: 92 [12928/221852 (6%)]\tLoss: 0.203891\tAcc: 70.00\n",
      "train epoch: 93 [128/221852 (0%)]\tLoss: 0.283486\tAcc: 64.00\n",
      "train epoch: 93 [12928/221852 (6%)]\tLoss: 0.271664\tAcc: 71.00\n",
      "train epoch: 93 [25728/221852 (12%)]\tLoss: 0.248812\tAcc: 74.00\n",
      "train epoch: 93 [38528/221852 (17%)]\tLoss: 0.285208\tAcc: 65.00\n",
      "train epoch: 93 [51328/221852 (23%)]\tLoss: 0.257192\tAcc: 73.00\n",
      "train epoch: 93 [64128/221852 (29%)]\tLoss: 0.315709\tAcc: 66.00\n",
      "train epoch: 93 [76928/221852 (35%)]\tLoss: 0.210103\tAcc: 77.00\n",
      "train epoch: 93 [89728/221852 (40%)]\tLoss: 0.200652\tAcc: 77.00\n",
      "train epoch: 93 [102528/221852 (46%)]\tLoss: 0.197608\tAcc: 74.00\n",
      "train epoch: 93 [115328/221852 (52%)]\tLoss: 0.177624\tAcc: 70.00\n",
      "train epoch: 93 [128128/221852 (58%)]\tLoss: 0.286463\tAcc: 76.00\n",
      "train epoch: 93 [140928/221852 (64%)]\tLoss: 0.295253\tAcc: 70.00\n",
      "train epoch: 93 [153728/221852 (69%)]\tLoss: 0.216759\tAcc: 71.00\n",
      "train epoch: 93 [166528/221852 (75%)]\tLoss: 0.225550\tAcc: 70.00\n",
      "train epoch: 93 [179328/221852 (81%)]\tLoss: 0.253397\tAcc: 70.00\n",
      "train epoch: 93 [192128/221852 (87%)]\tLoss: 0.226307\tAcc: 73.00\n",
      "val epoch: 93 [128/221852 (0%)]\tLoss: 0.172450\tAcc: 75.00\n",
      "val epoch: 93 [12928/221852 (6%)]\tLoss: 0.247171\tAcc: 76.00\n",
      "train epoch: 94 [128/221852 (0%)]\tLoss: 0.290051\tAcc: 73.00\n",
      "train epoch: 94 [12928/221852 (6%)]\tLoss: 0.286413\tAcc: 66.00\n",
      "train epoch: 94 [25728/221852 (12%)]\tLoss: 0.224240\tAcc: 73.00\n",
      "train epoch: 94 [38528/221852 (17%)]\tLoss: 0.251930\tAcc: 73.00\n",
      "train epoch: 94 [51328/221852 (23%)]\tLoss: 0.239804\tAcc: 70.00\n",
      "train epoch: 94 [64128/221852 (29%)]\tLoss: 0.270206\tAcc: 66.00\n",
      "train epoch: 94 [76928/221852 (35%)]\tLoss: 0.243326\tAcc: 75.00\n",
      "train epoch: 94 [89728/221852 (40%)]\tLoss: 0.204174\tAcc: 72.00\n",
      "train epoch: 94 [102528/221852 (46%)]\tLoss: 0.245372\tAcc: 65.00\n",
      "train epoch: 94 [115328/221852 (52%)]\tLoss: 0.214616\tAcc: 65.00\n",
      "train epoch: 94 [128128/221852 (58%)]\tLoss: 0.161417\tAcc: 81.00\n",
      "train epoch: 94 [140928/221852 (64%)]\tLoss: 0.296386\tAcc: 69.00\n",
      "train epoch: 94 [153728/221852 (69%)]\tLoss: 0.204754\tAcc: 73.00\n",
      "train epoch: 94 [166528/221852 (75%)]\tLoss: 0.358528\tAcc: 65.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 94 [179328/221852 (81%)]\tLoss: 0.174451\tAcc: 73.00\n",
      "train epoch: 94 [192128/221852 (87%)]\tLoss: 0.167120\tAcc: 70.00\n",
      "val epoch: 94 [128/221852 (0%)]\tLoss: 0.233622\tAcc: 68.00\n",
      "val epoch: 94 [12928/221852 (6%)]\tLoss: 0.220587\tAcc: 73.00\n",
      "train epoch: 95 [128/221852 (0%)]\tLoss: 0.167760\tAcc: 76.00\n",
      "train epoch: 95 [12928/221852 (6%)]\tLoss: 0.276562\tAcc: 72.00\n",
      "train epoch: 95 [25728/221852 (12%)]\tLoss: 0.205731\tAcc: 70.00\n",
      "train epoch: 95 [38528/221852 (17%)]\tLoss: 0.270362\tAcc: 76.00\n",
      "train epoch: 95 [51328/221852 (23%)]\tLoss: 0.308252\tAcc: 68.00\n",
      "train epoch: 95 [64128/221852 (29%)]\tLoss: 0.327850\tAcc: 68.00\n",
      "train epoch: 95 [76928/221852 (35%)]\tLoss: 0.279833\tAcc: 72.00\n",
      "train epoch: 95 [89728/221852 (40%)]\tLoss: 0.232436\tAcc: 70.00\n",
      "train epoch: 95 [102528/221852 (46%)]\tLoss: 0.215752\tAcc: 70.00\n",
      "train epoch: 95 [115328/221852 (52%)]\tLoss: 0.203257\tAcc: 72.00\n",
      "train epoch: 95 [128128/221852 (58%)]\tLoss: 0.322289\tAcc: 75.00\n",
      "train epoch: 95 [140928/221852 (64%)]\tLoss: 0.278816\tAcc: 77.00\n",
      "train epoch: 95 [153728/221852 (69%)]\tLoss: 0.274815\tAcc: 64.00\n",
      "train epoch: 95 [166528/221852 (75%)]\tLoss: 0.173576\tAcc: 76.00\n",
      "train epoch: 95 [179328/221852 (81%)]\tLoss: 0.242177\tAcc: 70.00\n",
      "train epoch: 95 [192128/221852 (87%)]\tLoss: 0.253743\tAcc: 73.00\n",
      "val epoch: 95 [128/221852 (0%)]\tLoss: 0.228756\tAcc: 74.00\n",
      "val epoch: 95 [12928/221852 (6%)]\tLoss: 0.230294\tAcc: 76.00\n",
      "train epoch: 96 [128/221852 (0%)]\tLoss: 0.271769\tAcc: 71.00\n",
      "train epoch: 96 [12928/221852 (6%)]\tLoss: 0.163187\tAcc: 81.00\n",
      "train epoch: 96 [25728/221852 (12%)]\tLoss: 0.305453\tAcc: 62.00\n",
      "train epoch: 96 [38528/221852 (17%)]\tLoss: 0.247791\tAcc: 67.00\n",
      "train epoch: 96 [51328/221852 (23%)]\tLoss: 0.217602\tAcc: 73.00\n",
      "train epoch: 96 [64128/221852 (29%)]\tLoss: 0.327475\tAcc: 66.00\n",
      "train epoch: 96 [76928/221852 (35%)]\tLoss: 0.265927\tAcc: 70.00\n",
      "train epoch: 96 [89728/221852 (40%)]\tLoss: 0.215486\tAcc: 75.00\n",
      "train epoch: 96 [102528/221852 (46%)]\tLoss: 0.273387\tAcc: 77.00\n",
      "train epoch: 96 [115328/221852 (52%)]\tLoss: 0.217495\tAcc: 76.00\n",
      "train epoch: 96 [128128/221852 (58%)]\tLoss: 0.197427\tAcc: 77.00\n",
      "train epoch: 96 [140928/221852 (64%)]\tLoss: 0.254724\tAcc: 73.00\n",
      "train epoch: 96 [153728/221852 (69%)]\tLoss: 0.230695\tAcc: 73.00\n",
      "train epoch: 96 [166528/221852 (75%)]\tLoss: 0.198905\tAcc: 70.00\n",
      "train epoch: 96 [179328/221852 (81%)]\tLoss: 0.195673\tAcc: 75.00\n",
      "train epoch: 96 [192128/221852 (87%)]\tLoss: 0.203898\tAcc: 70.00\n",
      "val epoch: 96 [128/221852 (0%)]\tLoss: 0.279210\tAcc: 70.00\n",
      "val epoch: 96 [12928/221852 (6%)]\tLoss: 0.144249\tAcc: 74.00\n",
      "train epoch: 97 [128/221852 (0%)]\tLoss: 0.186568\tAcc: 77.00\n",
      "train epoch: 97 [12928/221852 (6%)]\tLoss: 0.260574\tAcc: 72.00\n",
      "train epoch: 97 [25728/221852 (12%)]\tLoss: 0.186856\tAcc: 71.00\n",
      "train epoch: 97 [38528/221852 (17%)]\tLoss: 0.254555\tAcc: 73.00\n",
      "train epoch: 97 [51328/221852 (23%)]\tLoss: 0.183833\tAcc: 73.00\n",
      "train epoch: 97 [64128/221852 (29%)]\tLoss: 0.286318\tAcc: 73.00\n",
      "train epoch: 97 [76928/221852 (35%)]\tLoss: 0.240077\tAcc: 73.00\n",
      "train epoch: 97 [89728/221852 (40%)]\tLoss: 0.241629\tAcc: 70.00\n",
      "train epoch: 97 [102528/221852 (46%)]\tLoss: 0.205227\tAcc: 76.00\n",
      "train epoch: 97 [115328/221852 (52%)]\tLoss: 0.138081\tAcc: 81.00\n",
      "train epoch: 97 [128128/221852 (58%)]\tLoss: 0.211518\tAcc: 72.00\n",
      "train epoch: 97 [140928/221852 (64%)]\tLoss: 0.219606\tAcc: 72.00\n",
      "train epoch: 97 [153728/221852 (69%)]\tLoss: 0.311930\tAcc: 77.00\n",
      "train epoch: 97 [166528/221852 (75%)]\tLoss: 0.297242\tAcc: 73.00\n",
      "train epoch: 97 [179328/221852 (81%)]\tLoss: 0.696548\tAcc: 68.00\n",
      "train epoch: 97 [192128/221852 (87%)]\tLoss: 0.306076\tAcc: 73.00\n",
      "val epoch: 97 [128/221852 (0%)]\tLoss: 0.250394\tAcc: 74.00\n",
      "val epoch: 97 [12928/221852 (6%)]\tLoss: 0.316701\tAcc: 74.00\n",
      "train epoch: 98 [128/221852 (0%)]\tLoss: 0.346333\tAcc: 67.00\n",
      "train epoch: 98 [12928/221852 (6%)]\tLoss: 0.242323\tAcc: 68.00\n",
      "train epoch: 98 [25728/221852 (12%)]\tLoss: 0.256178\tAcc: 73.00\n",
      "train epoch: 98 [38528/221852 (17%)]\tLoss: 0.223738\tAcc: 77.00\n",
      "train epoch: 98 [51328/221852 (23%)]\tLoss: 0.231796\tAcc: 73.00\n",
      "train epoch: 98 [64128/221852 (29%)]\tLoss: 0.193740\tAcc: 72.00\n",
      "train epoch: 98 [76928/221852 (35%)]\tLoss: 0.257634\tAcc: 73.00\n",
      "train epoch: 98 [89728/221852 (40%)]\tLoss: 0.224709\tAcc: 68.00\n",
      "train epoch: 98 [102528/221852 (46%)]\tLoss: 0.213427\tAcc: 72.00\n",
      "train epoch: 98 [115328/221852 (52%)]\tLoss: 0.140475\tAcc: 70.00\n",
      "train epoch: 98 [128128/221852 (58%)]\tLoss: 0.222366\tAcc: 73.00\n",
      "train epoch: 98 [140928/221852 (64%)]\tLoss: 0.203125\tAcc: 70.00\n",
      "train epoch: 98 [153728/221852 (69%)]\tLoss: 0.189667\tAcc: 68.00\n",
      "train epoch: 98 [166528/221852 (75%)]\tLoss: 0.175200\tAcc: 73.00\n",
      "train epoch: 98 [179328/221852 (81%)]\tLoss: 0.220801\tAcc: 73.00\n",
      "train epoch: 98 [192128/221852 (87%)]\tLoss: 0.150719\tAcc: 77.00\n",
      "val epoch: 98 [128/221852 (0%)]\tLoss: 0.129682\tAcc: 77.00\n",
      "val epoch: 98 [12928/221852 (6%)]\tLoss: 0.208774\tAcc: 74.00\n",
      "train epoch: 99 [128/221852 (0%)]\tLoss: 0.147405\tAcc: 79.00\n",
      "train epoch: 99 [12928/221852 (6%)]\tLoss: 0.221351\tAcc: 73.00\n",
      "train epoch: 99 [25728/221852 (12%)]\tLoss: 0.262550\tAcc: 72.00\n",
      "train epoch: 99 [38528/221852 (17%)]\tLoss: 0.190519\tAcc: 71.00\n",
      "train epoch: 99 [51328/221852 (23%)]\tLoss: 0.226809\tAcc: 72.00\n",
      "train epoch: 99 [64128/221852 (29%)]\tLoss: 0.156012\tAcc: 69.00\n",
      "train epoch: 99 [76928/221852 (35%)]\tLoss: 0.306466\tAcc: 70.00\n",
      "train epoch: 99 [89728/221852 (40%)]\tLoss: 0.286586\tAcc: 69.00\n",
      "train epoch: 99 [102528/221852 (46%)]\tLoss: 0.286632\tAcc: 70.00\n",
      "train epoch: 99 [115328/221852 (52%)]\tLoss: 0.213462\tAcc: 72.00\n",
      "train epoch: 99 [128128/221852 (58%)]\tLoss: 0.250166\tAcc: 77.00\n",
      "train epoch: 99 [140928/221852 (64%)]\tLoss: 0.175978\tAcc: 73.00\n",
      "train epoch: 99 [153728/221852 (69%)]\tLoss: 0.137602\tAcc: 77.00\n",
      "train epoch: 99 [166528/221852 (75%)]\tLoss: 0.247838\tAcc: 68.00\n",
      "train epoch: 99 [179328/221852 (81%)]\tLoss: 0.277682\tAcc: 68.00\n",
      "train epoch: 99 [192128/221852 (87%)]\tLoss: 0.208754\tAcc: 72.00\n",
      "val epoch: 99 [128/221852 (0%)]\tLoss: 0.165390\tAcc: 74.00\n",
      "val epoch: 99 [12928/221852 (6%)]\tLoss: 0.162382\tAcc: 78.00\n",
      "train epoch: 100 [128/221852 (0%)]\tLoss: 0.287390\tAcc: 67.00\n",
      "train epoch: 100 [12928/221852 (6%)]\tLoss: 0.196518\tAcc: 74.00\n",
      "train epoch: 100 [25728/221852 (12%)]\tLoss: 0.280388\tAcc: 75.00\n",
      "train epoch: 100 [38528/221852 (17%)]\tLoss: 0.191736\tAcc: 78.00\n",
      "train epoch: 100 [51328/221852 (23%)]\tLoss: 0.167190\tAcc: 71.00\n",
      "train epoch: 100 [64128/221852 (29%)]\tLoss: 0.334012\tAcc: 67.00\n",
      "train epoch: 100 [76928/221852 (35%)]\tLoss: 0.177370\tAcc: 79.00\n",
      "train epoch: 100 [89728/221852 (40%)]\tLoss: 0.268676\tAcc: 73.00\n",
      "train epoch: 100 [102528/221852 (46%)]\tLoss: 0.192335\tAcc: 75.00\n",
      "train epoch: 100 [115328/221852 (52%)]\tLoss: 0.295701\tAcc: 66.00\n",
      "train epoch: 100 [128128/221852 (58%)]\tLoss: 0.207902\tAcc: 75.00\n",
      "train epoch: 100 [140928/221852 (64%)]\tLoss: 0.321902\tAcc: 72.00\n",
      "train epoch: 100 [153728/221852 (69%)]\tLoss: 0.299419\tAcc: 74.00\n",
      "train epoch: 100 [166528/221852 (75%)]\tLoss: 0.321240\tAcc: 71.00\n",
      "train epoch: 100 [179328/221852 (81%)]\tLoss: 0.210325\tAcc: 73.00\n",
      "train epoch: 100 [192128/221852 (87%)]\tLoss: 0.218523\tAcc: 77.00\n",
      "val epoch: 100 [128/221852 (0%)]\tLoss: 0.257499\tAcc: 75.00\n",
      "val epoch: 100 [12928/221852 (6%)]\tLoss: 0.327490\tAcc: 77.00\n",
      "train epoch: 101 [128/221852 (0%)]\tLoss: 0.209509\tAcc: 68.00\n",
      "train epoch: 101 [12928/221852 (6%)]\tLoss: 0.219486\tAcc: 71.00\n",
      "train epoch: 101 [25728/221852 (12%)]\tLoss: 0.191701\tAcc: 66.00\n",
      "train epoch: 101 [38528/221852 (17%)]\tLoss: 0.173979\tAcc: 71.00\n",
      "train epoch: 101 [51328/221852 (23%)]\tLoss: 0.143740\tAcc: 68.00\n",
      "train epoch: 101 [64128/221852 (29%)]\tLoss: 0.311847\tAcc: 70.00\n",
      "train epoch: 101 [76928/221852 (35%)]\tLoss: 0.264445\tAcc: 72.00\n",
      "train epoch: 101 [89728/221852 (40%)]\tLoss: 0.228513\tAcc: 77.00\n",
      "train epoch: 101 [102528/221852 (46%)]\tLoss: 0.198724\tAcc: 73.00\n",
      "train epoch: 101 [115328/221852 (52%)]\tLoss: 0.229129\tAcc: 68.00\n",
      "train epoch: 101 [128128/221852 (58%)]\tLoss: 0.203979\tAcc: 69.00\n",
      "train epoch: 101 [140928/221852 (64%)]\tLoss: 0.228394\tAcc: 72.00\n",
      "train epoch: 101 [153728/221852 (69%)]\tLoss: 0.275882\tAcc: 68.00\n",
      "train epoch: 101 [166528/221852 (75%)]\tLoss: 0.204579\tAcc: 77.00\n",
      "train epoch: 101 [179328/221852 (81%)]\tLoss: 0.145993\tAcc: 72.00\n",
      "train epoch: 101 [192128/221852 (87%)]\tLoss: 0.225838\tAcc: 75.00\n",
      "val epoch: 101 [128/221852 (0%)]\tLoss: 0.260309\tAcc: 73.00\n",
      "val epoch: 101 [12928/221852 (6%)]\tLoss: 0.262397\tAcc: 73.00\n",
      "train epoch: 102 [128/221852 (0%)]\tLoss: 0.264759\tAcc: 69.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 102 [12928/221852 (6%)]\tLoss: 0.126283\tAcc: 77.00\n",
      "train epoch: 102 [25728/221852 (12%)]\tLoss: 0.194828\tAcc: 72.00\n",
      "train epoch: 102 [38528/221852 (17%)]\tLoss: 0.171292\tAcc: 71.00\n",
      "train epoch: 102 [51328/221852 (23%)]\tLoss: 0.260993\tAcc: 60.00\n",
      "train epoch: 102 [64128/221852 (29%)]\tLoss: 0.294188\tAcc: 78.00\n",
      "train epoch: 102 [76928/221852 (35%)]\tLoss: 0.238375\tAcc: 75.00\n",
      "train epoch: 102 [89728/221852 (40%)]\tLoss: 0.215576\tAcc: 68.00\n",
      "train epoch: 102 [102528/221852 (46%)]\tLoss: 0.142939\tAcc: 77.00\n",
      "train epoch: 102 [115328/221852 (52%)]\tLoss: 0.246706\tAcc: 67.00\n",
      "train epoch: 102 [128128/221852 (58%)]\tLoss: 0.206357\tAcc: 72.00\n",
      "train epoch: 102 [140928/221852 (64%)]\tLoss: 0.282851\tAcc: 74.00\n",
      "train epoch: 102 [153728/221852 (69%)]\tLoss: 0.284795\tAcc: 62.00\n",
      "train epoch: 102 [166528/221852 (75%)]\tLoss: 0.243687\tAcc: 68.00\n",
      "train epoch: 102 [179328/221852 (81%)]\tLoss: 0.311038\tAcc: 69.00\n",
      "train epoch: 102 [192128/221852 (87%)]\tLoss: 0.304865\tAcc: 69.00\n",
      "val epoch: 102 [128/221852 (0%)]\tLoss: 0.316198\tAcc: 73.00\n",
      "val epoch: 102 [12928/221852 (6%)]\tLoss: 0.191375\tAcc: 74.00\n",
      "train epoch: 103 [128/221852 (0%)]\tLoss: 0.268048\tAcc: 73.00\n",
      "train epoch: 103 [12928/221852 (6%)]\tLoss: 0.163194\tAcc: 76.00\n",
      "train epoch: 103 [25728/221852 (12%)]\tLoss: 0.445203\tAcc: 75.00\n",
      "train epoch: 103 [38528/221852 (17%)]\tLoss: 0.195733\tAcc: 70.00\n",
      "train epoch: 103 [51328/221852 (23%)]\tLoss: 0.433430\tAcc: 74.00\n",
      "train epoch: 103 [64128/221852 (29%)]\tLoss: 0.207714\tAcc: 69.00\n",
      "train epoch: 103 [76928/221852 (35%)]\tLoss: 0.212657\tAcc: 79.00\n",
      "train epoch: 103 [89728/221852 (40%)]\tLoss: 0.164095\tAcc: 72.00\n",
      "train epoch: 103 [102528/221852 (46%)]\tLoss: 0.296318\tAcc: 65.00\n",
      "train epoch: 103 [115328/221852 (52%)]\tLoss: 0.261118\tAcc: 77.00\n",
      "train epoch: 103 [128128/221852 (58%)]\tLoss: 0.246743\tAcc: 75.00\n",
      "train epoch: 103 [140928/221852 (64%)]\tLoss: 0.246880\tAcc: 72.00\n",
      "train epoch: 103 [153728/221852 (69%)]\tLoss: 0.299792\tAcc: 70.00\n",
      "train epoch: 103 [166528/221852 (75%)]\tLoss: 0.204917\tAcc: 73.00\n",
      "train epoch: 103 [179328/221852 (81%)]\tLoss: 0.288752\tAcc: 69.00\n",
      "train epoch: 103 [192128/221852 (87%)]\tLoss: 0.240891\tAcc: 72.00\n",
      "val epoch: 103 [128/221852 (0%)]\tLoss: 0.143178\tAcc: 75.00\n",
      "val epoch: 103 [12928/221852 (6%)]\tLoss: 0.264817\tAcc: 73.00\n",
      "train epoch: 104 [128/221852 (0%)]\tLoss: 0.224703\tAcc: 78.00\n",
      "train epoch: 104 [12928/221852 (6%)]\tLoss: 0.167160\tAcc: 75.00\n",
      "train epoch: 104 [25728/221852 (12%)]\tLoss: 0.163909\tAcc: 70.00\n",
      "train epoch: 104 [38528/221852 (17%)]\tLoss: 0.145544\tAcc: 76.00\n",
      "train epoch: 104 [51328/221852 (23%)]\tLoss: 0.226725\tAcc: 75.00\n",
      "train epoch: 104 [64128/221852 (29%)]\tLoss: 0.226829\tAcc: 66.00\n",
      "train epoch: 104 [76928/221852 (35%)]\tLoss: 0.229426\tAcc: 80.00\n",
      "train epoch: 104 [89728/221852 (40%)]\tLoss: 0.278924\tAcc: 68.00\n",
      "train epoch: 104 [102528/221852 (46%)]\tLoss: 0.270602\tAcc: 70.00\n",
      "train epoch: 104 [115328/221852 (52%)]\tLoss: 0.248340\tAcc: 73.00\n",
      "train epoch: 104 [128128/221852 (58%)]\tLoss: 0.246443\tAcc: 77.00\n",
      "train epoch: 104 [140928/221852 (64%)]\tLoss: 0.134870\tAcc: 84.00\n",
      "train epoch: 104 [153728/221852 (69%)]\tLoss: 0.228561\tAcc: 73.00\n",
      "train epoch: 104 [166528/221852 (75%)]\tLoss: 0.149592\tAcc: 71.00\n",
      "train epoch: 104 [179328/221852 (81%)]\tLoss: 0.183017\tAcc: 67.00\n",
      "train epoch: 104 [192128/221852 (87%)]\tLoss: 0.237863\tAcc: 75.00\n",
      "val epoch: 104 [128/221852 (0%)]\tLoss: 0.266793\tAcc: 79.00\n",
      "val epoch: 104 [12928/221852 (6%)]\tLoss: 0.223373\tAcc: 73.00\n",
      "train epoch: 105 [128/221852 (0%)]\tLoss: 0.272417\tAcc: 70.00\n",
      "train epoch: 105 [12928/221852 (6%)]\tLoss: 0.276494\tAcc: 73.00\n",
      "train epoch: 105 [25728/221852 (12%)]\tLoss: 0.257363\tAcc: 71.00\n",
      "train epoch: 105 [38528/221852 (17%)]\tLoss: 0.300573\tAcc: 72.00\n",
      "train epoch: 105 [51328/221852 (23%)]\tLoss: 0.276462\tAcc: 68.00\n",
      "train epoch: 105 [64128/221852 (29%)]\tLoss: 0.285271\tAcc: 72.00\n",
      "train epoch: 105 [76928/221852 (35%)]\tLoss: 0.131342\tAcc: 72.00\n",
      "train epoch: 105 [89728/221852 (40%)]\tLoss: 0.192763\tAcc: 75.00\n",
      "train epoch: 105 [102528/221852 (46%)]\tLoss: 0.227439\tAcc: 70.00\n",
      "train epoch: 105 [115328/221852 (52%)]\tLoss: 0.254672\tAcc: 70.00\n",
      "train epoch: 105 [128128/221852 (58%)]\tLoss: 0.201450\tAcc: 70.00\n",
      "train epoch: 105 [140928/221852 (64%)]\tLoss: 0.253642\tAcc: 70.00\n",
      "train epoch: 105 [153728/221852 (69%)]\tLoss: 0.253862\tAcc: 70.00\n",
      "train epoch: 105 [166528/221852 (75%)]\tLoss: 0.144727\tAcc: 80.00\n",
      "train epoch: 105 [179328/221852 (81%)]\tLoss: 0.175094\tAcc: 75.00\n",
      "train epoch: 105 [192128/221852 (87%)]\tLoss: 0.464382\tAcc: 70.00\n",
      "val epoch: 105 [128/221852 (0%)]\tLoss: 0.227055\tAcc: 70.00\n",
      "val epoch: 105 [12928/221852 (6%)]\tLoss: 0.208973\tAcc: 73.00\n",
      "train epoch: 106 [128/221852 (0%)]\tLoss: 0.322503\tAcc: 69.00\n",
      "train epoch: 106 [12928/221852 (6%)]\tLoss: 0.171965\tAcc: 71.00\n",
      "train epoch: 106 [25728/221852 (12%)]\tLoss: 0.150030\tAcc: 73.00\n",
      "train epoch: 106 [38528/221852 (17%)]\tLoss: 0.220210\tAcc: 72.00\n",
      "train epoch: 106 [51328/221852 (23%)]\tLoss: 0.231014\tAcc: 72.00\n",
      "train epoch: 106 [64128/221852 (29%)]\tLoss: 0.330714\tAcc: 73.00\n",
      "train epoch: 106 [76928/221852 (35%)]\tLoss: 0.318669\tAcc: 73.00\n",
      "train epoch: 106 [89728/221852 (40%)]\tLoss: 0.184030\tAcc: 68.00\n",
      "train epoch: 106 [102528/221852 (46%)]\tLoss: 0.274043\tAcc: 66.00\n",
      "train epoch: 106 [115328/221852 (52%)]\tLoss: 0.224804\tAcc: 78.00\n",
      "train epoch: 106 [128128/221852 (58%)]\tLoss: 0.218505\tAcc: 69.00\n",
      "train epoch: 106 [140928/221852 (64%)]\tLoss: 0.234315\tAcc: 74.00\n",
      "train epoch: 106 [153728/221852 (69%)]\tLoss: 0.237547\tAcc: 73.00\n",
      "train epoch: 106 [166528/221852 (75%)]\tLoss: 0.232774\tAcc: 69.00\n",
      "train epoch: 106 [179328/221852 (81%)]\tLoss: 0.271380\tAcc: 70.00\n",
      "train epoch: 106 [192128/221852 (87%)]\tLoss: 0.231417\tAcc: 73.00\n",
      "val epoch: 106 [128/221852 (0%)]\tLoss: 0.205835\tAcc: 73.00\n",
      "val epoch: 106 [12928/221852 (6%)]\tLoss: 0.186755\tAcc: 78.00\n",
      "train epoch: 107 [128/221852 (0%)]\tLoss: 0.159470\tAcc: 73.00\n",
      "train epoch: 107 [12928/221852 (6%)]\tLoss: 0.351884\tAcc: 66.00\n",
      "train epoch: 107 [25728/221852 (12%)]\tLoss: 0.218568\tAcc: 70.00\n",
      "train epoch: 107 [38528/221852 (17%)]\tLoss: 0.291036\tAcc: 67.00\n",
      "train epoch: 107 [51328/221852 (23%)]\tLoss: 0.165380\tAcc: 77.00\n",
      "train epoch: 107 [64128/221852 (29%)]\tLoss: 0.260791\tAcc: 73.00\n",
      "train epoch: 107 [76928/221852 (35%)]\tLoss: 0.174512\tAcc: 80.00\n",
      "train epoch: 107 [89728/221852 (40%)]\tLoss: 0.212572\tAcc: 77.00\n",
      "train epoch: 107 [102528/221852 (46%)]\tLoss: 0.214638\tAcc: 73.00\n",
      "train epoch: 107 [115328/221852 (52%)]\tLoss: 0.318199\tAcc: 72.00\n",
      "train epoch: 107 [128128/221852 (58%)]\tLoss: 0.215406\tAcc: 72.00\n",
      "train epoch: 107 [140928/221852 (64%)]\tLoss: 0.175836\tAcc: 73.00\n",
      "train epoch: 107 [153728/221852 (69%)]\tLoss: 0.213421\tAcc: 71.00\n",
      "train epoch: 107 [166528/221852 (75%)]\tLoss: 0.148318\tAcc: 73.00\n",
      "train epoch: 107 [179328/221852 (81%)]\tLoss: 0.255821\tAcc: 70.00\n",
      "train epoch: 107 [192128/221852 (87%)]\tLoss: 0.243808\tAcc: 79.00\n",
      "val epoch: 107 [128/221852 (0%)]\tLoss: 0.203449\tAcc: 73.00\n",
      "val epoch: 107 [12928/221852 (6%)]\tLoss: 0.258555\tAcc: 67.00\n",
      "train epoch: 108 [128/221852 (0%)]\tLoss: 0.326358\tAcc: 69.00\n",
      "train epoch: 108 [12928/221852 (6%)]\tLoss: 0.245573\tAcc: 77.00\n",
      "train epoch: 108 [25728/221852 (12%)]\tLoss: 0.269525\tAcc: 71.00\n",
      "train epoch: 108 [38528/221852 (17%)]\tLoss: 0.262534\tAcc: 73.00\n",
      "train epoch: 108 [51328/221852 (23%)]\tLoss: 0.195556\tAcc: 78.00\n",
      "train epoch: 108 [64128/221852 (29%)]\tLoss: 0.277859\tAcc: 71.00\n",
      "train epoch: 108 [76928/221852 (35%)]\tLoss: 0.256027\tAcc: 74.00\n",
      "train epoch: 108 [89728/221852 (40%)]\tLoss: 0.225128\tAcc: 71.00\n",
      "train epoch: 108 [102528/221852 (46%)]\tLoss: 0.149263\tAcc: 70.00\n",
      "train epoch: 108 [115328/221852 (52%)]\tLoss: 0.255997\tAcc: 69.00\n",
      "train epoch: 108 [128128/221852 (58%)]\tLoss: 0.191646\tAcc: 80.00\n",
      "train epoch: 108 [140928/221852 (64%)]\tLoss: 0.236223\tAcc: 71.00\n",
      "train epoch: 108 [153728/221852 (69%)]\tLoss: 0.207918\tAcc: 80.00\n",
      "train epoch: 108 [166528/221852 (75%)]\tLoss: 0.335970\tAcc: 74.00\n",
      "train epoch: 108 [179328/221852 (81%)]\tLoss: 0.309753\tAcc: 65.00\n",
      "train epoch: 108 [192128/221852 (87%)]\tLoss: 0.326564\tAcc: 73.00\n",
      "val epoch: 108 [128/221852 (0%)]\tLoss: 0.259313\tAcc: 68.00\n",
      "val epoch: 108 [12928/221852 (6%)]\tLoss: 0.207089\tAcc: 76.00\n",
      "train epoch: 109 [128/221852 (0%)]\tLoss: 0.259531\tAcc: 64.00\n",
      "train epoch: 109 [12928/221852 (6%)]\tLoss: 0.175459\tAcc: 71.00\n",
      "train epoch: 109 [25728/221852 (12%)]\tLoss: 0.265530\tAcc: 73.00\n",
      "train epoch: 109 [38528/221852 (17%)]\tLoss: 0.322287\tAcc: 74.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 109 [51328/221852 (23%)]\tLoss: 0.276881\tAcc: 67.00\n",
      "train epoch: 109 [64128/221852 (29%)]\tLoss: 0.220641\tAcc: 71.00\n",
      "train epoch: 109 [76928/221852 (35%)]\tLoss: 0.525133\tAcc: 68.00\n",
      "train epoch: 109 [89728/221852 (40%)]\tLoss: 0.214514\tAcc: 73.00\n",
      "train epoch: 109 [102528/221852 (46%)]\tLoss: 0.262027\tAcc: 79.00\n",
      "train epoch: 109 [115328/221852 (52%)]\tLoss: 0.279419\tAcc: 70.00\n",
      "train epoch: 109 [128128/221852 (58%)]\tLoss: 0.198322\tAcc: 66.00\n",
      "train epoch: 109 [140928/221852 (64%)]\tLoss: 0.173053\tAcc: 70.00\n",
      "train epoch: 109 [153728/221852 (69%)]\tLoss: 0.419214\tAcc: 70.00\n",
      "train epoch: 109 [166528/221852 (75%)]\tLoss: 0.209486\tAcc: 77.00\n",
      "train epoch: 109 [179328/221852 (81%)]\tLoss: 0.148881\tAcc: 78.00\n",
      "train epoch: 109 [192128/221852 (87%)]\tLoss: 0.233172\tAcc: 65.00\n",
      "val epoch: 109 [128/221852 (0%)]\tLoss: 0.257480\tAcc: 70.00\n",
      "val epoch: 109 [12928/221852 (6%)]\tLoss: 0.136975\tAcc: 77.00\n",
      "train epoch: 110 [128/221852 (0%)]\tLoss: 0.201241\tAcc: 76.00\n",
      "train epoch: 110 [12928/221852 (6%)]\tLoss: 0.241778\tAcc: 70.00\n",
      "train epoch: 110 [25728/221852 (12%)]\tLoss: 0.306243\tAcc: 71.00\n",
      "train epoch: 110 [38528/221852 (17%)]\tLoss: 0.225683\tAcc: 77.00\n",
      "train epoch: 110 [51328/221852 (23%)]\tLoss: 0.302632\tAcc: 71.00\n",
      "train epoch: 110 [64128/221852 (29%)]\tLoss: 0.325539\tAcc: 73.00\n",
      "train epoch: 110 [76928/221852 (35%)]\tLoss: 0.162829\tAcc: 79.00\n",
      "train epoch: 110 [89728/221852 (40%)]\tLoss: 0.300568\tAcc: 70.00\n",
      "train epoch: 110 [102528/221852 (46%)]\tLoss: 0.268616\tAcc: 73.00\n",
      "train epoch: 110 [115328/221852 (52%)]\tLoss: 0.310928\tAcc: 69.00\n",
      "train epoch: 110 [128128/221852 (58%)]\tLoss: 0.227050\tAcc: 69.00\n",
      "train epoch: 110 [140928/221852 (64%)]\tLoss: 0.221667\tAcc: 81.00\n",
      "train epoch: 110 [153728/221852 (69%)]\tLoss: 0.261749\tAcc: 76.00\n",
      "train epoch: 110 [166528/221852 (75%)]\tLoss: 0.214740\tAcc: 71.00\n",
      "train epoch: 110 [179328/221852 (81%)]\tLoss: 0.218570\tAcc: 77.00\n",
      "train epoch: 110 [192128/221852 (87%)]\tLoss: 0.187306\tAcc: 76.00\n",
      "val epoch: 110 [128/221852 (0%)]\tLoss: 0.207341\tAcc: 77.00\n",
      "val epoch: 110 [12928/221852 (6%)]\tLoss: 0.199269\tAcc: 81.00\n",
      "train epoch: 111 [128/221852 (0%)]\tLoss: 0.316556\tAcc: 69.00\n",
      "train epoch: 111 [12928/221852 (6%)]\tLoss: 0.189304\tAcc: 68.00\n",
      "train epoch: 111 [25728/221852 (12%)]\tLoss: 0.196870\tAcc: 80.00\n",
      "train epoch: 111 [38528/221852 (17%)]\tLoss: 0.226947\tAcc: 75.00\n",
      "train epoch: 111 [51328/221852 (23%)]\tLoss: 0.256082\tAcc: 77.00\n",
      "train epoch: 111 [64128/221852 (29%)]\tLoss: 0.167927\tAcc: 79.00\n",
      "train epoch: 111 [76928/221852 (35%)]\tLoss: 0.416175\tAcc: 68.00\n",
      "train epoch: 111 [89728/221852 (40%)]\tLoss: 0.236199\tAcc: 77.00\n",
      "train epoch: 111 [102528/221852 (46%)]\tLoss: 0.302862\tAcc: 70.00\n",
      "train epoch: 111 [115328/221852 (52%)]\tLoss: 0.282519\tAcc: 72.00\n",
      "train epoch: 111 [128128/221852 (58%)]\tLoss: 0.257807\tAcc: 68.00\n",
      "train epoch: 111 [140928/221852 (64%)]\tLoss: 0.168539\tAcc: 66.00\n",
      "train epoch: 111 [153728/221852 (69%)]\tLoss: 0.449304\tAcc: 72.00\n",
      "train epoch: 111 [166528/221852 (75%)]\tLoss: 0.212632\tAcc: 73.00\n",
      "train epoch: 111 [179328/221852 (81%)]\tLoss: 0.247350\tAcc: 68.00\n",
      "train epoch: 111 [192128/221852 (87%)]\tLoss: 0.186664\tAcc: 78.00\n",
      "val epoch: 111 [128/221852 (0%)]\tLoss: 0.228576\tAcc: 62.00\n",
      "val epoch: 111 [12928/221852 (6%)]\tLoss: 0.202774\tAcc: 66.00\n",
      "train epoch: 112 [128/221852 (0%)]\tLoss: 0.207054\tAcc: 71.00\n",
      "train epoch: 112 [12928/221852 (6%)]\tLoss: 0.317823\tAcc: 72.00\n",
      "train epoch: 112 [25728/221852 (12%)]\tLoss: 0.174175\tAcc: 77.00\n",
      "train epoch: 112 [38528/221852 (17%)]\tLoss: 0.264856\tAcc: 71.00\n",
      "train epoch: 112 [51328/221852 (23%)]\tLoss: 0.182206\tAcc: 77.00\n",
      "train epoch: 112 [64128/221852 (29%)]\tLoss: 0.306216\tAcc: 67.00\n",
      "train epoch: 112 [76928/221852 (35%)]\tLoss: 0.266017\tAcc: 70.00\n",
      "train epoch: 112 [89728/221852 (40%)]\tLoss: 0.172309\tAcc: 71.00\n",
      "train epoch: 112 [102528/221852 (46%)]\tLoss: 0.283680\tAcc: 71.00\n",
      "train epoch: 112 [115328/221852 (52%)]\tLoss: 0.205087\tAcc: 72.00\n",
      "train epoch: 112 [128128/221852 (58%)]\tLoss: 0.232371\tAcc: 73.00\n",
      "train epoch: 112 [140928/221852 (64%)]\tLoss: 0.218509\tAcc: 68.00\n",
      "train epoch: 112 [153728/221852 (69%)]\tLoss: 0.247631\tAcc: 76.00\n",
      "train epoch: 112 [166528/221852 (75%)]\tLoss: 0.237064\tAcc: 76.00\n",
      "train epoch: 112 [179328/221852 (81%)]\tLoss: 0.236900\tAcc: 74.00\n",
      "train epoch: 112 [192128/221852 (87%)]\tLoss: 0.263010\tAcc: 73.00\n",
      "val epoch: 112 [128/221852 (0%)]\tLoss: 0.283574\tAcc: 70.00\n",
      "val epoch: 112 [12928/221852 (6%)]\tLoss: 0.307883\tAcc: 72.00\n",
      "train epoch: 113 [128/221852 (0%)]\tLoss: 0.261407\tAcc: 73.00\n",
      "train epoch: 113 [12928/221852 (6%)]\tLoss: 0.255200\tAcc: 77.00\n",
      "train epoch: 113 [25728/221852 (12%)]\tLoss: 0.287060\tAcc: 66.00\n",
      "train epoch: 113 [38528/221852 (17%)]\tLoss: 0.252508\tAcc: 75.00\n",
      "train epoch: 113 [51328/221852 (23%)]\tLoss: 0.291935\tAcc: 75.00\n",
      "train epoch: 113 [64128/221852 (29%)]\tLoss: 0.180747\tAcc: 78.00\n",
      "train epoch: 113 [76928/221852 (35%)]\tLoss: 0.189589\tAcc: 69.00\n",
      "train epoch: 113 [89728/221852 (40%)]\tLoss: 0.248670\tAcc: 80.00\n",
      "train epoch: 113 [102528/221852 (46%)]\tLoss: 0.292280\tAcc: 70.00\n",
      "train epoch: 113 [115328/221852 (52%)]\tLoss: 0.269293\tAcc: 70.00\n",
      "train epoch: 113 [128128/221852 (58%)]\tLoss: 0.237592\tAcc: 74.00\n",
      "train epoch: 113 [140928/221852 (64%)]\tLoss: 0.192427\tAcc: 79.00\n",
      "train epoch: 113 [153728/221852 (69%)]\tLoss: 0.272826\tAcc: 74.00\n",
      "train epoch: 113 [166528/221852 (75%)]\tLoss: 0.208196\tAcc: 73.00\n",
      "train epoch: 113 [179328/221852 (81%)]\tLoss: 0.197687\tAcc: 77.00\n",
      "train epoch: 113 [192128/221852 (87%)]\tLoss: 0.170088\tAcc: 73.00\n",
      "val epoch: 113 [128/221852 (0%)]\tLoss: 0.160447\tAcc: 76.00\n",
      "val epoch: 113 [12928/221852 (6%)]\tLoss: 0.181912\tAcc: 75.00\n",
      "train epoch: 114 [128/221852 (0%)]\tLoss: 0.275678\tAcc: 70.00\n",
      "train epoch: 114 [12928/221852 (6%)]\tLoss: 0.220912\tAcc: 70.00\n",
      "train epoch: 114 [25728/221852 (12%)]\tLoss: 0.221676\tAcc: 70.00\n",
      "train epoch: 114 [38528/221852 (17%)]\tLoss: 0.240224\tAcc: 70.00\n",
      "train epoch: 114 [51328/221852 (23%)]\tLoss: 0.192786\tAcc: 72.00\n",
      "train epoch: 114 [64128/221852 (29%)]\tLoss: 0.251350\tAcc: 73.00\n",
      "train epoch: 114 [76928/221852 (35%)]\tLoss: 0.283550\tAcc: 73.00\n",
      "train epoch: 114 [89728/221852 (40%)]\tLoss: 0.151716\tAcc: 76.00\n",
      "train epoch: 114 [102528/221852 (46%)]\tLoss: 0.250455\tAcc: 70.00\n",
      "train epoch: 114 [115328/221852 (52%)]\tLoss: 0.205208\tAcc: 77.00\n",
      "train epoch: 114 [128128/221852 (58%)]\tLoss: 0.210321\tAcc: 73.00\n",
      "train epoch: 114 [140928/221852 (64%)]\tLoss: 0.279468\tAcc: 73.00\n",
      "train epoch: 114 [153728/221852 (69%)]\tLoss: 0.148366\tAcc: 80.00\n",
      "train epoch: 114 [166528/221852 (75%)]\tLoss: 0.265695\tAcc: 64.00\n",
      "train epoch: 114 [179328/221852 (81%)]\tLoss: 0.242935\tAcc: 67.00\n",
      "train epoch: 114 [192128/221852 (87%)]\tLoss: 0.183032\tAcc: 80.00\n",
      "val epoch: 114 [128/221852 (0%)]\tLoss: 0.124992\tAcc: 75.00\n",
      "val epoch: 114 [12928/221852 (6%)]\tLoss: 0.218687\tAcc: 75.00\n",
      "train epoch: 115 [128/221852 (0%)]\tLoss: 0.249922\tAcc: 69.00\n",
      "train epoch: 115 [12928/221852 (6%)]\tLoss: 0.200201\tAcc: 75.00\n",
      "train epoch: 115 [25728/221852 (12%)]\tLoss: 0.190762\tAcc: 73.00\n",
      "train epoch: 115 [38528/221852 (17%)]\tLoss: 0.139835\tAcc: 73.00\n",
      "train epoch: 115 [51328/221852 (23%)]\tLoss: 0.226366\tAcc: 78.00\n",
      "train epoch: 115 [64128/221852 (29%)]\tLoss: 0.181790\tAcc: 73.00\n",
      "train epoch: 115 [76928/221852 (35%)]\tLoss: 0.142533\tAcc: 80.00\n",
      "train epoch: 115 [89728/221852 (40%)]\tLoss: 0.298176\tAcc: 67.00\n",
      "train epoch: 115 [102528/221852 (46%)]\tLoss: 0.233095\tAcc: 77.00\n",
      "train epoch: 115 [115328/221852 (52%)]\tLoss: 0.181587\tAcc: 75.00\n",
      "train epoch: 115 [128128/221852 (58%)]\tLoss: 0.203242\tAcc: 74.00\n",
      "train epoch: 115 [140928/221852 (64%)]\tLoss: 0.254559\tAcc: 78.00\n",
      "train epoch: 115 [153728/221852 (69%)]\tLoss: 0.159087\tAcc: 73.00\n",
      "train epoch: 115 [166528/221852 (75%)]\tLoss: 0.210517\tAcc: 73.00\n",
      "train epoch: 115 [179328/221852 (81%)]\tLoss: 0.264357\tAcc: 64.00\n",
      "train epoch: 115 [192128/221852 (87%)]\tLoss: 0.298642\tAcc: 73.00\n",
      "val epoch: 115 [128/221852 (0%)]\tLoss: 0.184659\tAcc: 75.00\n",
      "val epoch: 115 [12928/221852 (6%)]\tLoss: 0.147194\tAcc: 80.00\n",
      "train epoch: 116 [128/221852 (0%)]\tLoss: 0.237223\tAcc: 67.00\n",
      "train epoch: 116 [12928/221852 (6%)]\tLoss: 0.169325\tAcc: 77.00\n",
      "train epoch: 116 [25728/221852 (12%)]\tLoss: 0.287944\tAcc: 74.00\n",
      "train epoch: 116 [38528/221852 (17%)]\tLoss: 0.269134\tAcc: 74.00\n",
      "train epoch: 116 [51328/221852 (23%)]\tLoss: 0.288936\tAcc: 73.00\n",
      "train epoch: 116 [64128/221852 (29%)]\tLoss: 0.197048\tAcc: 77.00\n",
      "train epoch: 116 [76928/221852 (35%)]\tLoss: 0.301807\tAcc: 66.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 116 [89728/221852 (40%)]\tLoss: 0.206800\tAcc: 76.00\n",
      "train epoch: 116 [102528/221852 (46%)]\tLoss: 0.179923\tAcc: 72.00\n",
      "train epoch: 116 [115328/221852 (52%)]\tLoss: 0.254543\tAcc: 72.00\n",
      "train epoch: 116 [128128/221852 (58%)]\tLoss: 0.257797\tAcc: 71.00\n",
      "train epoch: 116 [140928/221852 (64%)]\tLoss: 0.265364\tAcc: 67.00\n",
      "train epoch: 116 [153728/221852 (69%)]\tLoss: 0.276571\tAcc: 66.00\n",
      "train epoch: 116 [166528/221852 (75%)]\tLoss: 0.186444\tAcc: 80.00\n",
      "train epoch: 116 [179328/221852 (81%)]\tLoss: 0.247848\tAcc: 72.00\n",
      "train epoch: 116 [192128/221852 (87%)]\tLoss: 0.268162\tAcc: 77.00\n",
      "val epoch: 116 [128/221852 (0%)]\tLoss: 0.181809\tAcc: 74.00\n",
      "val epoch: 116 [12928/221852 (6%)]\tLoss: 0.144842\tAcc: 73.00\n",
      "train epoch: 117 [128/221852 (0%)]\tLoss: 0.192111\tAcc: 77.00\n",
      "train epoch: 117 [12928/221852 (6%)]\tLoss: 0.252080\tAcc: 79.00\n",
      "train epoch: 117 [25728/221852 (12%)]\tLoss: 0.145953\tAcc: 83.00\n",
      "train epoch: 117 [38528/221852 (17%)]\tLoss: 0.159911\tAcc: 80.00\n",
      "train epoch: 117 [51328/221852 (23%)]\tLoss: 0.229403\tAcc: 72.00\n",
      "train epoch: 117 [64128/221852 (29%)]\tLoss: 0.219503\tAcc: 72.00\n",
      "train epoch: 117 [76928/221852 (35%)]\tLoss: 0.252145\tAcc: 73.00\n",
      "train epoch: 117 [89728/221852 (40%)]\tLoss: 0.259168\tAcc: 68.00\n",
      "train epoch: 117 [102528/221852 (46%)]\tLoss: 0.360035\tAcc: 73.00\n",
      "train epoch: 117 [115328/221852 (52%)]\tLoss: 0.307666\tAcc: 73.00\n",
      "train epoch: 117 [128128/221852 (58%)]\tLoss: 0.172551\tAcc: 77.00\n",
      "train epoch: 117 [140928/221852 (64%)]\tLoss: 0.218931\tAcc: 74.00\n",
      "train epoch: 117 [153728/221852 (69%)]\tLoss: 0.243899\tAcc: 73.00\n",
      "train epoch: 117 [166528/221852 (75%)]\tLoss: 0.159144\tAcc: 71.00\n",
      "train epoch: 117 [179328/221852 (81%)]\tLoss: 0.176732\tAcc: 73.00\n",
      "train epoch: 117 [192128/221852 (87%)]\tLoss: 0.127862\tAcc: 80.00\n",
      "val epoch: 117 [128/221852 (0%)]\tLoss: 0.197294\tAcc: 80.00\n",
      "val epoch: 117 [12928/221852 (6%)]\tLoss: 0.271948\tAcc: 68.00\n",
      "train epoch: 118 [128/221852 (0%)]\tLoss: 0.205582\tAcc: 75.00\n",
      "train epoch: 118 [12928/221852 (6%)]\tLoss: 0.460604\tAcc: 72.00\n",
      "train epoch: 118 [25728/221852 (12%)]\tLoss: 0.274161\tAcc: 72.00\n",
      "train epoch: 118 [38528/221852 (17%)]\tLoss: 0.175648\tAcc: 79.00\n",
      "train epoch: 118 [51328/221852 (23%)]\tLoss: 0.181316\tAcc: 77.00\n",
      "train epoch: 118 [64128/221852 (29%)]\tLoss: 0.281670\tAcc: 70.00\n",
      "train epoch: 118 [76928/221852 (35%)]\tLoss: 0.241538\tAcc: 72.00\n",
      "train epoch: 118 [89728/221852 (40%)]\tLoss: 0.143648\tAcc: 71.00\n",
      "train epoch: 118 [102528/221852 (46%)]\tLoss: 0.254770\tAcc: 76.00\n",
      "train epoch: 118 [115328/221852 (52%)]\tLoss: 0.225078\tAcc: 80.00\n",
      "train epoch: 118 [128128/221852 (58%)]\tLoss: 0.300072\tAcc: 68.00\n",
      "train epoch: 118 [140928/221852 (64%)]\tLoss: 0.216242\tAcc: 76.00\n",
      "train epoch: 118 [153728/221852 (69%)]\tLoss: 0.207294\tAcc: 70.00\n",
      "train epoch: 118 [166528/221852 (75%)]\tLoss: 0.245841\tAcc: 77.00\n",
      "train epoch: 118 [179328/221852 (81%)]\tLoss: 0.212587\tAcc: 78.00\n",
      "train epoch: 118 [192128/221852 (87%)]\tLoss: 0.240711\tAcc: 71.00\n",
      "val epoch: 118 [128/221852 (0%)]\tLoss: 0.179032\tAcc: 75.00\n",
      "val epoch: 118 [12928/221852 (6%)]\tLoss: 0.212715\tAcc: 73.00\n",
      "train epoch: 119 [128/221852 (0%)]\tLoss: 0.258837\tAcc: 73.00\n",
      "train epoch: 119 [12928/221852 (6%)]\tLoss: 0.243256\tAcc: 73.00\n",
      "train epoch: 119 [25728/221852 (12%)]\tLoss: 0.148406\tAcc: 73.00\n",
      "train epoch: 119 [38528/221852 (17%)]\tLoss: 0.209405\tAcc: 70.00\n",
      "train epoch: 119 [51328/221852 (23%)]\tLoss: 0.385100\tAcc: 70.00\n",
      "train epoch: 119 [64128/221852 (29%)]\tLoss: 0.213248\tAcc: 72.00\n",
      "train epoch: 119 [76928/221852 (35%)]\tLoss: 0.259159\tAcc: 72.00\n",
      "train epoch: 119 [89728/221852 (40%)]\tLoss: 0.239575\tAcc: 72.00\n",
      "train epoch: 119 [102528/221852 (46%)]\tLoss: 0.264962\tAcc: 68.00\n",
      "train epoch: 119 [115328/221852 (52%)]\tLoss: 0.260962\tAcc: 72.00\n",
      "train epoch: 119 [128128/221852 (58%)]\tLoss: 0.243866\tAcc: 81.00\n",
      "train epoch: 119 [140928/221852 (64%)]\tLoss: 0.310700\tAcc: 70.00\n",
      "train epoch: 119 [153728/221852 (69%)]\tLoss: 0.108205\tAcc: 80.00\n",
      "train epoch: 119 [166528/221852 (75%)]\tLoss: 0.193249\tAcc: 76.00\n",
      "train epoch: 119 [179328/221852 (81%)]\tLoss: 0.217340\tAcc: 77.00\n",
      "train epoch: 119 [192128/221852 (87%)]\tLoss: 0.145746\tAcc: 71.00\n",
      "val epoch: 119 [128/221852 (0%)]\tLoss: 0.189449\tAcc: 73.00\n",
      "val epoch: 119 [12928/221852 (6%)]\tLoss: 0.158565\tAcc: 79.00\n",
      "train epoch: 120 [128/221852 (0%)]\tLoss: 0.272236\tAcc: 70.00\n",
      "train epoch: 120 [12928/221852 (6%)]\tLoss: 0.268068\tAcc: 70.00\n",
      "train epoch: 120 [25728/221852 (12%)]\tLoss: 0.222023\tAcc: 71.00\n",
      "train epoch: 120 [38528/221852 (17%)]\tLoss: 0.336802\tAcc: 66.00\n",
      "train epoch: 120 [51328/221852 (23%)]\tLoss: 0.168380\tAcc: 69.00\n",
      "train epoch: 120 [64128/221852 (29%)]\tLoss: 0.229885\tAcc: 68.00\n",
      "train epoch: 120 [76928/221852 (35%)]\tLoss: 0.132912\tAcc: 80.00\n",
      "train epoch: 120 [89728/221852 (40%)]\tLoss: 0.203042\tAcc: 76.00\n",
      "train epoch: 120 [102528/221852 (46%)]\tLoss: 0.206343\tAcc: 76.00\n",
      "train epoch: 120 [115328/221852 (52%)]\tLoss: 0.283502\tAcc: 68.00\n",
      "train epoch: 120 [128128/221852 (58%)]\tLoss: 0.174697\tAcc: 73.00\n",
      "train epoch: 120 [140928/221852 (64%)]\tLoss: 0.216778\tAcc: 74.00\n",
      "train epoch: 120 [153728/221852 (69%)]\tLoss: 0.143965\tAcc: 74.00\n",
      "train epoch: 120 [166528/221852 (75%)]\tLoss: 0.155173\tAcc: 82.00\n",
      "train epoch: 120 [179328/221852 (81%)]\tLoss: 0.197429\tAcc: 72.00\n",
      "train epoch: 120 [192128/221852 (87%)]\tLoss: 0.215077\tAcc: 67.00\n",
      "val epoch: 120 [128/221852 (0%)]\tLoss: 0.179150\tAcc: 71.00\n",
      "val epoch: 120 [12928/221852 (6%)]\tLoss: 0.302025\tAcc: 74.00\n",
      "train epoch: 121 [128/221852 (0%)]\tLoss: 0.198795\tAcc: 73.00\n",
      "train epoch: 121 [12928/221852 (6%)]\tLoss: 0.185321\tAcc: 71.00\n",
      "train epoch: 121 [25728/221852 (12%)]\tLoss: 0.218005\tAcc: 70.00\n",
      "train epoch: 121 [38528/221852 (17%)]\tLoss: 0.231162\tAcc: 76.00\n",
      "train epoch: 121 [51328/221852 (23%)]\tLoss: 0.273116\tAcc: 73.00\n",
      "train epoch: 121 [64128/221852 (29%)]\tLoss: 0.281522\tAcc: 66.00\n",
      "train epoch: 121 [76928/221852 (35%)]\tLoss: 0.277714\tAcc: 76.00\n",
      "train epoch: 121 [89728/221852 (40%)]\tLoss: 0.364826\tAcc: 65.00\n",
      "train epoch: 121 [102528/221852 (46%)]\tLoss: 0.233491\tAcc: 75.00\n",
      "train epoch: 121 [115328/221852 (52%)]\tLoss: 0.276737\tAcc: 70.00\n",
      "train epoch: 121 [128128/221852 (58%)]\tLoss: 0.246883\tAcc: 71.00\n",
      "train epoch: 121 [140928/221852 (64%)]\tLoss: 0.169921\tAcc: 71.00\n",
      "train epoch: 121 [153728/221852 (69%)]\tLoss: 0.295648\tAcc: 74.00\n",
      "train epoch: 121 [166528/221852 (75%)]\tLoss: 0.192664\tAcc: 80.00\n",
      "train epoch: 121 [179328/221852 (81%)]\tLoss: 0.158860\tAcc: 73.00\n",
      "train epoch: 121 [192128/221852 (87%)]\tLoss: 0.284669\tAcc: 73.00\n",
      "val epoch: 121 [128/221852 (0%)]\tLoss: 0.207746\tAcc: 77.00\n",
      "val epoch: 121 [12928/221852 (6%)]\tLoss: 0.208380\tAcc: 73.00\n",
      "train epoch: 122 [128/221852 (0%)]\tLoss: 0.220140\tAcc: 68.00\n",
      "train epoch: 122 [12928/221852 (6%)]\tLoss: 0.173697\tAcc: 73.00\n",
      "train epoch: 122 [25728/221852 (12%)]\tLoss: 0.336628\tAcc: 66.00\n",
      "train epoch: 122 [38528/221852 (17%)]\tLoss: 0.300322\tAcc: 73.00\n",
      "train epoch: 122 [51328/221852 (23%)]\tLoss: 0.229119\tAcc: 73.00\n",
      "train epoch: 122 [64128/221852 (29%)]\tLoss: 0.174746\tAcc: 77.00\n",
      "train epoch: 122 [76928/221852 (35%)]\tLoss: 0.215063\tAcc: 76.00\n",
      "train epoch: 122 [89728/221852 (40%)]\tLoss: 0.225270\tAcc: 79.00\n",
      "train epoch: 122 [102528/221852 (46%)]\tLoss: 0.185089\tAcc: 70.00\n",
      "train epoch: 122 [115328/221852 (52%)]\tLoss: 0.250688\tAcc: 74.00\n",
      "train epoch: 122 [128128/221852 (58%)]\tLoss: 0.209789\tAcc: 74.00\n",
      "train epoch: 122 [140928/221852 (64%)]\tLoss: 0.261283\tAcc: 66.00\n",
      "train epoch: 122 [153728/221852 (69%)]\tLoss: 0.379564\tAcc: 73.00\n",
      "train epoch: 122 [166528/221852 (75%)]\tLoss: 0.147961\tAcc: 76.00\n",
      "train epoch: 122 [179328/221852 (81%)]\tLoss: 0.206253\tAcc: 77.00\n",
      "train epoch: 122 [192128/221852 (87%)]\tLoss: 0.216050\tAcc: 73.00\n",
      "val epoch: 122 [128/221852 (0%)]\tLoss: 0.159451\tAcc: 78.00\n",
      "val epoch: 122 [12928/221852 (6%)]\tLoss: 0.276852\tAcc: 70.00\n",
      "train epoch: 123 [128/221852 (0%)]\tLoss: 0.257155\tAcc: 68.00\n",
      "train epoch: 123 [12928/221852 (6%)]\tLoss: 0.448178\tAcc: 66.00\n",
      "train epoch: 123 [25728/221852 (12%)]\tLoss: 0.219355\tAcc: 78.00\n",
      "train epoch: 123 [38528/221852 (17%)]\tLoss: 0.364897\tAcc: 67.00\n",
      "train epoch: 123 [51328/221852 (23%)]\tLoss: 0.288344\tAcc: 70.00\n",
      "train epoch: 123 [64128/221852 (29%)]\tLoss: 0.235107\tAcc: 73.00\n",
      "train epoch: 123 [76928/221852 (35%)]\tLoss: 0.282646\tAcc: 74.00\n",
      "train epoch: 123 [89728/221852 (40%)]\tLoss: 0.236551\tAcc: 76.00\n",
      "train epoch: 123 [102528/221852 (46%)]\tLoss: 0.280381\tAcc: 80.00\n",
      "train epoch: 123 [115328/221852 (52%)]\tLoss: 0.145839\tAcc: 78.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 123 [128128/221852 (58%)]\tLoss: 0.230128\tAcc: 77.00\n",
      "train epoch: 123 [140928/221852 (64%)]\tLoss: 0.175457\tAcc: 71.00\n",
      "train epoch: 123 [153728/221852 (69%)]\tLoss: 0.179201\tAcc: 78.00\n",
      "train epoch: 123 [166528/221852 (75%)]\tLoss: 0.313910\tAcc: 70.00\n",
      "train epoch: 123 [179328/221852 (81%)]\tLoss: 0.168917\tAcc: 78.00\n",
      "train epoch: 123 [192128/221852 (87%)]\tLoss: 0.263432\tAcc: 69.00\n",
      "val epoch: 123 [128/221852 (0%)]\tLoss: 0.203051\tAcc: 77.00\n",
      "val epoch: 123 [12928/221852 (6%)]\tLoss: 0.348794\tAcc: 74.00\n",
      "train epoch: 124 [128/221852 (0%)]\tLoss: 0.172135\tAcc: 74.00\n",
      "train epoch: 124 [12928/221852 (6%)]\tLoss: 0.236850\tAcc: 69.00\n",
      "train epoch: 124 [25728/221852 (12%)]\tLoss: 0.265505\tAcc: 70.00\n",
      "train epoch: 124 [38528/221852 (17%)]\tLoss: 0.189775\tAcc: 68.00\n",
      "train epoch: 124 [51328/221852 (23%)]\tLoss: 0.172653\tAcc: 83.00\n",
      "train epoch: 124 [64128/221852 (29%)]\tLoss: 0.311364\tAcc: 68.00\n",
      "train epoch: 124 [76928/221852 (35%)]\tLoss: 0.238663\tAcc: 73.00\n",
      "train epoch: 124 [89728/221852 (40%)]\tLoss: 0.241550\tAcc: 68.00\n",
      "train epoch: 124 [102528/221852 (46%)]\tLoss: 0.165658\tAcc: 73.00\n",
      "train epoch: 124 [115328/221852 (52%)]\tLoss: 0.246227\tAcc: 70.00\n",
      "train epoch: 124 [128128/221852 (58%)]\tLoss: 0.226301\tAcc: 72.00\n",
      "train epoch: 124 [140928/221852 (64%)]\tLoss: 0.220919\tAcc: 68.00\n",
      "train epoch: 124 [153728/221852 (69%)]\tLoss: 0.397897\tAcc: 62.00\n",
      "train epoch: 124 [166528/221852 (75%)]\tLoss: 0.302402\tAcc: 76.00\n",
      "train epoch: 124 [179328/221852 (81%)]\tLoss: 0.206064\tAcc: 67.00\n",
      "train epoch: 124 [192128/221852 (87%)]\tLoss: 0.224683\tAcc: 75.00\n",
      "val epoch: 124 [128/221852 (0%)]\tLoss: 0.212518\tAcc: 73.00\n",
      "val epoch: 124 [12928/221852 (6%)]\tLoss: 0.199713\tAcc: 76.00\n",
      "train epoch: 125 [128/221852 (0%)]\tLoss: 0.167772\tAcc: 74.00\n",
      "train epoch: 125 [12928/221852 (6%)]\tLoss: 0.221048\tAcc: 78.00\n",
      "train epoch: 125 [25728/221852 (12%)]\tLoss: 0.272767\tAcc: 71.00\n",
      "train epoch: 125 [38528/221852 (17%)]\tLoss: 0.243023\tAcc: 77.00\n",
      "train epoch: 125 [51328/221852 (23%)]\tLoss: 0.199315\tAcc: 70.00\n",
      "train epoch: 125 [64128/221852 (29%)]\tLoss: 0.193159\tAcc: 78.00\n",
      "train epoch: 125 [76928/221852 (35%)]\tLoss: 0.185461\tAcc: 80.00\n",
      "train epoch: 125 [89728/221852 (40%)]\tLoss: 0.289336\tAcc: 73.00\n",
      "train epoch: 125 [102528/221852 (46%)]\tLoss: 0.280681\tAcc: 73.00\n",
      "train epoch: 125 [115328/221852 (52%)]\tLoss: 0.196348\tAcc: 76.00\n",
      "train epoch: 125 [128128/221852 (58%)]\tLoss: 0.242967\tAcc: 76.00\n",
      "train epoch: 125 [140928/221852 (64%)]\tLoss: 0.156761\tAcc: 78.00\n",
      "train epoch: 125 [153728/221852 (69%)]\tLoss: 0.228780\tAcc: 76.00\n",
      "train epoch: 125 [166528/221852 (75%)]\tLoss: 0.139616\tAcc: 70.00\n",
      "train epoch: 125 [179328/221852 (81%)]\tLoss: 0.278787\tAcc: 74.00\n",
      "train epoch: 125 [192128/221852 (87%)]\tLoss: 0.227441\tAcc: 79.00\n",
      "val epoch: 125 [128/221852 (0%)]\tLoss: 0.143783\tAcc: 71.00\n",
      "val epoch: 125 [12928/221852 (6%)]\tLoss: 0.279037\tAcc: 73.00\n",
      "train epoch: 126 [128/221852 (0%)]\tLoss: 0.196313\tAcc: 77.00\n",
      "train epoch: 126 [12928/221852 (6%)]\tLoss: 0.253403\tAcc: 77.00\n",
      "train epoch: 126 [25728/221852 (12%)]\tLoss: 0.269396\tAcc: 76.00\n",
      "train epoch: 126 [38528/221852 (17%)]\tLoss: 0.257211\tAcc: 67.00\n",
      "train epoch: 126 [51328/221852 (23%)]\tLoss: 0.167532\tAcc: 70.00\n",
      "train epoch: 126 [64128/221852 (29%)]\tLoss: 0.182621\tAcc: 71.00\n",
      "train epoch: 126 [76928/221852 (35%)]\tLoss: 0.196801\tAcc: 72.00\n",
      "train epoch: 126 [89728/221852 (40%)]\tLoss: 0.203868\tAcc: 77.00\n",
      "train epoch: 126 [102528/221852 (46%)]\tLoss: 0.363470\tAcc: 75.00\n",
      "train epoch: 126 [115328/221852 (52%)]\tLoss: 0.225061\tAcc: 76.00\n",
      "train epoch: 126 [128128/221852 (58%)]\tLoss: 0.235402\tAcc: 75.00\n",
      "train epoch: 126 [140928/221852 (64%)]\tLoss: 0.250745\tAcc: 73.00\n",
      "train epoch: 126 [153728/221852 (69%)]\tLoss: 0.256825\tAcc: 78.00\n",
      "train epoch: 126 [166528/221852 (75%)]\tLoss: 0.121639\tAcc: 71.00\n",
      "train epoch: 126 [179328/221852 (81%)]\tLoss: 0.247451\tAcc: 71.00\n",
      "train epoch: 126 [192128/221852 (87%)]\tLoss: 0.223955\tAcc: 70.00\n",
      "val epoch: 126 [128/221852 (0%)]\tLoss: 0.358135\tAcc: 62.00\n",
      "val epoch: 126 [12928/221852 (6%)]\tLoss: 0.340342\tAcc: 75.00\n",
      "train epoch: 127 [128/221852 (0%)]\tLoss: 0.197054\tAcc: 80.00\n",
      "train epoch: 127 [12928/221852 (6%)]\tLoss: 0.184497\tAcc: 70.00\n",
      "train epoch: 127 [25728/221852 (12%)]\tLoss: 0.176045\tAcc: 79.00\n",
      "train epoch: 127 [38528/221852 (17%)]\tLoss: 0.196817\tAcc: 65.00\n",
      "train epoch: 127 [51328/221852 (23%)]\tLoss: 0.264733\tAcc: 69.00\n",
      "train epoch: 127 [64128/221852 (29%)]\tLoss: 0.199143\tAcc: 73.00\n",
      "train epoch: 127 [76928/221852 (35%)]\tLoss: 0.194627\tAcc: 72.00\n",
      "train epoch: 127 [89728/221852 (40%)]\tLoss: 0.219220\tAcc: 70.00\n",
      "train epoch: 127 [102528/221852 (46%)]\tLoss: 0.143774\tAcc: 76.00\n",
      "train epoch: 127 [115328/221852 (52%)]\tLoss: 0.194199\tAcc: 74.00\n",
      "train epoch: 127 [128128/221852 (58%)]\tLoss: 0.119098\tAcc: 75.00\n",
      "train epoch: 127 [140928/221852 (64%)]\tLoss: 0.180276\tAcc: 74.00\n",
      "train epoch: 127 [153728/221852 (69%)]\tLoss: 0.283487\tAcc: 66.00\n",
      "train epoch: 127 [166528/221852 (75%)]\tLoss: 0.200469\tAcc: 76.00\n",
      "train epoch: 127 [179328/221852 (81%)]\tLoss: 0.196604\tAcc: 73.00\n",
      "train epoch: 127 [192128/221852 (87%)]\tLoss: 0.215053\tAcc: 77.00\n",
      "val epoch: 127 [128/221852 (0%)]\tLoss: 0.189724\tAcc: 76.00\n",
      "val epoch: 127 [12928/221852 (6%)]\tLoss: 0.239364\tAcc: 73.00\n",
      "train epoch: 128 [128/221852 (0%)]\tLoss: 0.188624\tAcc: 73.00\n",
      "train epoch: 128 [12928/221852 (6%)]\tLoss: 0.318255\tAcc: 71.00\n",
      "train epoch: 128 [25728/221852 (12%)]\tLoss: 0.240850\tAcc: 69.00\n",
      "train epoch: 128 [38528/221852 (17%)]\tLoss: 0.187506\tAcc: 72.00\n",
      "train epoch: 128 [51328/221852 (23%)]\tLoss: 0.143988\tAcc: 74.00\n",
      "train epoch: 128 [64128/221852 (29%)]\tLoss: 0.283754\tAcc: 76.00\n",
      "train epoch: 128 [76928/221852 (35%)]\tLoss: 0.319246\tAcc: 71.00\n",
      "train epoch: 128 [89728/221852 (40%)]\tLoss: 0.208847\tAcc: 76.00\n",
      "train epoch: 128 [102528/221852 (46%)]\tLoss: 0.276763\tAcc: 72.00\n",
      "train epoch: 128 [115328/221852 (52%)]\tLoss: 0.143001\tAcc: 83.00\n",
      "train epoch: 128 [128128/221852 (58%)]\tLoss: 0.227886\tAcc: 64.00\n",
      "train epoch: 128 [140928/221852 (64%)]\tLoss: 0.191492\tAcc: 76.00\n",
      "train epoch: 128 [153728/221852 (69%)]\tLoss: 0.151305\tAcc: 70.00\n",
      "train epoch: 128 [166528/221852 (75%)]\tLoss: 0.269883\tAcc: 74.00\n",
      "train epoch: 128 [179328/221852 (81%)]\tLoss: 0.209358\tAcc: 77.00\n",
      "train epoch: 128 [192128/221852 (87%)]\tLoss: 0.239993\tAcc: 71.00\n",
      "val epoch: 128 [128/221852 (0%)]\tLoss: 0.308894\tAcc: 70.00\n",
      "val epoch: 128 [12928/221852 (6%)]\tLoss: 0.163324\tAcc: 77.00\n",
      "train epoch: 129 [128/221852 (0%)]\tLoss: 0.171110\tAcc: 73.00\n",
      "train epoch: 129 [12928/221852 (6%)]\tLoss: 0.242607\tAcc: 83.00\n",
      "train epoch: 129 [25728/221852 (12%)]\tLoss: 0.223437\tAcc: 70.00\n",
      "train epoch: 129 [38528/221852 (17%)]\tLoss: 0.177936\tAcc: 79.00\n",
      "train epoch: 129 [51328/221852 (23%)]\tLoss: 0.446855\tAcc: 77.00\n",
      "train epoch: 129 [64128/221852 (29%)]\tLoss: 0.204639\tAcc: 86.00\n",
      "train epoch: 129 [76928/221852 (35%)]\tLoss: 0.157223\tAcc: 80.00\n",
      "train epoch: 129 [89728/221852 (40%)]\tLoss: 0.171986\tAcc: 77.00\n",
      "train epoch: 129 [102528/221852 (46%)]\tLoss: 0.249043\tAcc: 75.00\n",
      "train epoch: 129 [115328/221852 (52%)]\tLoss: 0.228087\tAcc: 73.00\n",
      "train epoch: 129 [128128/221852 (58%)]\tLoss: 0.264213\tAcc: 80.00\n",
      "train epoch: 129 [140928/221852 (64%)]\tLoss: 0.206413\tAcc: 80.00\n",
      "train epoch: 129 [153728/221852 (69%)]\tLoss: 0.164807\tAcc: 77.00\n",
      "train epoch: 129 [166528/221852 (75%)]\tLoss: 0.241149\tAcc: 67.00\n",
      "train epoch: 129 [179328/221852 (81%)]\tLoss: 0.252648\tAcc: 70.00\n",
      "train epoch: 129 [192128/221852 (87%)]\tLoss: 0.235150\tAcc: 72.00\n",
      "val epoch: 129 [128/221852 (0%)]\tLoss: 0.215137\tAcc: 82.00\n",
      "val epoch: 129 [12928/221852 (6%)]\tLoss: 0.228544\tAcc: 77.00\n",
      "train epoch: 130 [128/221852 (0%)]\tLoss: 0.181404\tAcc: 72.00\n",
      "train epoch: 130 [12928/221852 (6%)]\tLoss: 0.188006\tAcc: 77.00\n",
      "train epoch: 130 [25728/221852 (12%)]\tLoss: 0.152670\tAcc: 79.00\n",
      "train epoch: 130 [38528/221852 (17%)]\tLoss: 0.158473\tAcc: 71.00\n",
      "train epoch: 130 [51328/221852 (23%)]\tLoss: 0.211951\tAcc: 70.00\n",
      "train epoch: 130 [64128/221852 (29%)]\tLoss: 0.143297\tAcc: 73.00\n",
      "train epoch: 130 [76928/221852 (35%)]\tLoss: 0.228628\tAcc: 77.00\n",
      "train epoch: 130 [89728/221852 (40%)]\tLoss: 0.198794\tAcc: 72.00\n",
      "train epoch: 130 [102528/221852 (46%)]\tLoss: 0.179882\tAcc: 70.00\n",
      "train epoch: 130 [115328/221852 (52%)]\tLoss: 0.281517\tAcc: 67.00\n",
      "train epoch: 130 [128128/221852 (58%)]\tLoss: 0.233522\tAcc: 73.00\n",
      "train epoch: 130 [140928/221852 (64%)]\tLoss: 0.184967\tAcc: 71.00\n",
      "train epoch: 130 [153728/221852 (69%)]\tLoss: 0.237002\tAcc: 76.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 130 [166528/221852 (75%)]\tLoss: 0.161899\tAcc: 76.00\n",
      "train epoch: 130 [179328/221852 (81%)]\tLoss: 0.235438\tAcc: 74.00\n",
      "train epoch: 130 [192128/221852 (87%)]\tLoss: 0.189541\tAcc: 70.00\n",
      "val epoch: 130 [128/221852 (0%)]\tLoss: 0.188496\tAcc: 77.00\n",
      "val epoch: 130 [12928/221852 (6%)]\tLoss: 0.248669\tAcc: 70.00\n",
      "train epoch: 131 [128/221852 (0%)]\tLoss: 0.237465\tAcc: 70.00\n",
      "train epoch: 131 [12928/221852 (6%)]\tLoss: 0.237644\tAcc: 73.00\n",
      "train epoch: 131 [25728/221852 (12%)]\tLoss: 0.157929\tAcc: 77.00\n",
      "train epoch: 131 [38528/221852 (17%)]\tLoss: 0.224067\tAcc: 75.00\n",
      "train epoch: 131 [51328/221852 (23%)]\tLoss: 0.233393\tAcc: 70.00\n",
      "train epoch: 131 [64128/221852 (29%)]\tLoss: 0.250683\tAcc: 77.00\n",
      "train epoch: 131 [76928/221852 (35%)]\tLoss: 0.164017\tAcc: 78.00\n",
      "train epoch: 131 [89728/221852 (40%)]\tLoss: 0.218095\tAcc: 73.00\n",
      "train epoch: 131 [102528/221852 (46%)]\tLoss: 0.291519\tAcc: 73.00\n",
      "train epoch: 131 [115328/221852 (52%)]\tLoss: 0.172220\tAcc: 74.00\n",
      "train epoch: 131 [128128/221852 (58%)]\tLoss: 0.239277\tAcc: 70.00\n",
      "train epoch: 131 [140928/221852 (64%)]\tLoss: 0.214166\tAcc: 73.00\n",
      "train epoch: 131 [153728/221852 (69%)]\tLoss: 0.236089\tAcc: 73.00\n",
      "train epoch: 131 [166528/221852 (75%)]\tLoss: 0.209158\tAcc: 80.00\n",
      "train epoch: 131 [179328/221852 (81%)]\tLoss: 0.193354\tAcc: 77.00\n",
      "train epoch: 131 [192128/221852 (87%)]\tLoss: 0.311241\tAcc: 70.00\n",
      "val epoch: 131 [128/221852 (0%)]\tLoss: 0.164635\tAcc: 84.00\n",
      "val epoch: 131 [12928/221852 (6%)]\tLoss: 0.191822\tAcc: 76.00\n",
      "train epoch: 132 [128/221852 (0%)]\tLoss: 0.165670\tAcc: 73.00\n",
      "train epoch: 132 [12928/221852 (6%)]\tLoss: 0.175089\tAcc: 80.00\n",
      "train epoch: 132 [25728/221852 (12%)]\tLoss: 0.176631\tAcc: 73.00\n",
      "train epoch: 132 [38528/221852 (17%)]\tLoss: 0.130879\tAcc: 80.00\n",
      "train epoch: 132 [51328/221852 (23%)]\tLoss: 0.193963\tAcc: 69.00\n",
      "train epoch: 132 [64128/221852 (29%)]\tLoss: 0.205374\tAcc: 74.00\n",
      "train epoch: 132 [76928/221852 (35%)]\tLoss: 0.259192\tAcc: 77.00\n",
      "train epoch: 132 [89728/221852 (40%)]\tLoss: 0.224553\tAcc: 77.00\n",
      "train epoch: 132 [102528/221852 (46%)]\tLoss: 0.284075\tAcc: 75.00\n",
      "train epoch: 132 [115328/221852 (52%)]\tLoss: 0.190679\tAcc: 77.00\n",
      "train epoch: 132 [128128/221852 (58%)]\tLoss: 0.164722\tAcc: 73.00\n",
      "train epoch: 132 [140928/221852 (64%)]\tLoss: 0.198568\tAcc: 79.00\n",
      "train epoch: 132 [153728/221852 (69%)]\tLoss: 0.205673\tAcc: 70.00\n",
      "train epoch: 132 [166528/221852 (75%)]\tLoss: 0.293669\tAcc: 71.00\n",
      "train epoch: 132 [179328/221852 (81%)]\tLoss: 0.292386\tAcc: 71.00\n",
      "train epoch: 132 [192128/221852 (87%)]\tLoss: 0.175640\tAcc: 73.00\n",
      "val epoch: 132 [128/221852 (0%)]\tLoss: 0.328799\tAcc: 72.00\n",
      "val epoch: 132 [12928/221852 (6%)]\tLoss: 0.342027\tAcc: 70.00\n",
      "train epoch: 133 [128/221852 (0%)]\tLoss: 0.208946\tAcc: 77.00\n",
      "train epoch: 133 [12928/221852 (6%)]\tLoss: 0.180025\tAcc: 71.00\n",
      "train epoch: 133 [25728/221852 (12%)]\tLoss: 0.198748\tAcc: 75.00\n",
      "train epoch: 133 [38528/221852 (17%)]\tLoss: 0.197990\tAcc: 77.00\n",
      "train epoch: 133 [51328/221852 (23%)]\tLoss: 0.211553\tAcc: 73.00\n",
      "train epoch: 133 [64128/221852 (29%)]\tLoss: 0.153072\tAcc: 80.00\n",
      "train epoch: 133 [76928/221852 (35%)]\tLoss: 0.188661\tAcc: 77.00\n",
      "train epoch: 133 [89728/221852 (40%)]\tLoss: 0.260649\tAcc: 72.00\n",
      "train epoch: 133 [102528/221852 (46%)]\tLoss: 0.175249\tAcc: 77.00\n",
      "train epoch: 133 [115328/221852 (52%)]\tLoss: 0.221209\tAcc: 80.00\n",
      "train epoch: 133 [128128/221852 (58%)]\tLoss: 0.231461\tAcc: 73.00\n",
      "train epoch: 133 [140928/221852 (64%)]\tLoss: 0.244912\tAcc: 68.00\n",
      "train epoch: 133 [153728/221852 (69%)]\tLoss: 0.254836\tAcc: 72.00\n",
      "train epoch: 133 [166528/221852 (75%)]\tLoss: 0.210703\tAcc: 77.00\n",
      "train epoch: 133 [179328/221852 (81%)]\tLoss: 0.182524\tAcc: 73.00\n",
      "train epoch: 133 [192128/221852 (87%)]\tLoss: 0.251172\tAcc: 73.00\n",
      "val epoch: 133 [128/221852 (0%)]\tLoss: 0.220333\tAcc: 79.00\n",
      "val epoch: 133 [12928/221852 (6%)]\tLoss: 0.160212\tAcc: 79.00\n",
      "train epoch: 134 [128/221852 (0%)]\tLoss: 0.274022\tAcc: 70.00\n",
      "train epoch: 134 [12928/221852 (6%)]\tLoss: 0.207710\tAcc: 70.00\n",
      "train epoch: 134 [25728/221852 (12%)]\tLoss: 0.200478\tAcc: 77.00\n",
      "train epoch: 134 [38528/221852 (17%)]\tLoss: 0.229405\tAcc: 72.00\n",
      "train epoch: 134 [51328/221852 (23%)]\tLoss: 0.328552\tAcc: 73.00\n",
      "train epoch: 134 [64128/221852 (29%)]\tLoss: 0.126783\tAcc: 71.00\n",
      "train epoch: 134 [76928/221852 (35%)]\tLoss: 0.259020\tAcc: 73.00\n",
      "train epoch: 134 [89728/221852 (40%)]\tLoss: 0.149140\tAcc: 78.00\n",
      "train epoch: 134 [102528/221852 (46%)]\tLoss: 0.146304\tAcc: 74.00\n",
      "train epoch: 134 [115328/221852 (52%)]\tLoss: 0.309678\tAcc: 72.00\n",
      "train epoch: 134 [128128/221852 (58%)]\tLoss: 0.224852\tAcc: 77.00\n",
      "train epoch: 134 [140928/221852 (64%)]\tLoss: 0.169576\tAcc: 70.00\n",
      "train epoch: 134 [153728/221852 (69%)]\tLoss: 0.225126\tAcc: 76.00\n",
      "train epoch: 134 [166528/221852 (75%)]\tLoss: 0.176368\tAcc: 78.00\n",
      "train epoch: 134 [179328/221852 (81%)]\tLoss: 0.195754\tAcc: 80.00\n",
      "train epoch: 134 [192128/221852 (87%)]\tLoss: 0.288231\tAcc: 75.00\n",
      "val epoch: 134 [128/221852 (0%)]\tLoss: 0.215190\tAcc: 77.00\n",
      "val epoch: 134 [12928/221852 (6%)]\tLoss: 0.166493\tAcc: 75.00\n",
      "train epoch: 135 [128/221852 (0%)]\tLoss: 0.166833\tAcc: 83.00\n",
      "train epoch: 135 [12928/221852 (6%)]\tLoss: 0.153732\tAcc: 83.00\n",
      "train epoch: 135 [25728/221852 (12%)]\tLoss: 0.173557\tAcc: 75.00\n",
      "train epoch: 135 [38528/221852 (17%)]\tLoss: 0.255629\tAcc: 70.00\n",
      "train epoch: 135 [51328/221852 (23%)]\tLoss: 0.265864\tAcc: 69.00\n",
      "train epoch: 135 [64128/221852 (29%)]\tLoss: 0.126356\tAcc: 81.00\n",
      "train epoch: 135 [76928/221852 (35%)]\tLoss: 0.238991\tAcc: 77.00\n",
      "train epoch: 135 [89728/221852 (40%)]\tLoss: 0.174155\tAcc: 80.00\n",
      "train epoch: 135 [102528/221852 (46%)]\tLoss: 0.159249\tAcc: 75.00\n",
      "train epoch: 135 [115328/221852 (52%)]\tLoss: 0.160585\tAcc: 76.00\n",
      "train epoch: 135 [128128/221852 (58%)]\tLoss: 0.273341\tAcc: 71.00\n",
      "train epoch: 135 [140928/221852 (64%)]\tLoss: 0.225846\tAcc: 73.00\n",
      "train epoch: 135 [153728/221852 (69%)]\tLoss: 0.272387\tAcc: 69.00\n",
      "train epoch: 135 [166528/221852 (75%)]\tLoss: 0.244001\tAcc: 70.00\n",
      "train epoch: 135 [179328/221852 (81%)]\tLoss: 0.255588\tAcc: 75.00\n",
      "train epoch: 135 [192128/221852 (87%)]\tLoss: 0.180264\tAcc: 79.00\n",
      "val epoch: 135 [128/221852 (0%)]\tLoss: 0.363461\tAcc: 74.00\n",
      "val epoch: 135 [12928/221852 (6%)]\tLoss: 0.235929\tAcc: 73.00\n",
      "train epoch: 136 [128/221852 (0%)]\tLoss: 0.292670\tAcc: 76.00\n",
      "train epoch: 136 [12928/221852 (6%)]\tLoss: 0.155987\tAcc: 80.00\n",
      "train epoch: 136 [25728/221852 (12%)]\tLoss: 0.203715\tAcc: 74.00\n",
      "train epoch: 136 [38528/221852 (17%)]\tLoss: 0.202741\tAcc: 77.00\n",
      "train epoch: 136 [51328/221852 (23%)]\tLoss: 0.200835\tAcc: 72.00\n",
      "train epoch: 136 [64128/221852 (29%)]\tLoss: 0.195946\tAcc: 77.00\n",
      "train epoch: 136 [76928/221852 (35%)]\tLoss: 0.209685\tAcc: 77.00\n",
      "train epoch: 136 [89728/221852 (40%)]\tLoss: 0.163725\tAcc: 80.00\n",
      "train epoch: 136 [102528/221852 (46%)]\tLoss: 0.174082\tAcc: 73.00\n",
      "train epoch: 136 [115328/221852 (52%)]\tLoss: 0.204038\tAcc: 77.00\n",
      "train epoch: 136 [128128/221852 (58%)]\tLoss: 0.270449\tAcc: 63.00\n",
      "train epoch: 136 [140928/221852 (64%)]\tLoss: 0.147372\tAcc: 77.00\n",
      "train epoch: 136 [153728/221852 (69%)]\tLoss: 0.184257\tAcc: 73.00\n",
      "train epoch: 136 [166528/221852 (75%)]\tLoss: 0.173397\tAcc: 77.00\n",
      "train epoch: 136 [179328/221852 (81%)]\tLoss: 0.249453\tAcc: 76.00\n",
      "train epoch: 136 [192128/221852 (87%)]\tLoss: 0.154601\tAcc: 85.00\n",
      "val epoch: 136 [128/221852 (0%)]\tLoss: 0.223963\tAcc: 77.00\n",
      "val epoch: 136 [12928/221852 (6%)]\tLoss: 0.196443\tAcc: 78.00\n",
      "train epoch: 137 [128/221852 (0%)]\tLoss: 0.229147\tAcc: 73.00\n",
      "train epoch: 137 [12928/221852 (6%)]\tLoss: 0.241301\tAcc: 68.00\n",
      "train epoch: 137 [25728/221852 (12%)]\tLoss: 0.154890\tAcc: 72.00\n",
      "train epoch: 137 [38528/221852 (17%)]\tLoss: 0.271373\tAcc: 70.00\n",
      "train epoch: 137 [51328/221852 (23%)]\tLoss: 0.282398\tAcc: 66.00\n",
      "train epoch: 137 [64128/221852 (29%)]\tLoss: 0.219070\tAcc: 74.00\n",
      "train epoch: 137 [76928/221852 (35%)]\tLoss: 0.202096\tAcc: 70.00\n",
      "train epoch: 137 [89728/221852 (40%)]\tLoss: 0.218262\tAcc: 79.00\n",
      "train epoch: 137 [102528/221852 (46%)]\tLoss: 0.252272\tAcc: 76.00\n",
      "train epoch: 137 [115328/221852 (52%)]\tLoss: 0.200973\tAcc: 74.00\n",
      "train epoch: 137 [128128/221852 (58%)]\tLoss: 0.194252\tAcc: 79.00\n",
      "train epoch: 137 [140928/221852 (64%)]\tLoss: 0.226404\tAcc: 73.00\n",
      "train epoch: 137 [153728/221852 (69%)]\tLoss: 0.259805\tAcc: 75.00\n",
      "train epoch: 137 [166528/221852 (75%)]\tLoss: 0.106908\tAcc: 80.00\n",
      "train epoch: 137 [179328/221852 (81%)]\tLoss: 0.118157\tAcc: 81.00\n",
      "train epoch: 137 [192128/221852 (87%)]\tLoss: 0.228653\tAcc: 80.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 137 [128/221852 (0%)]\tLoss: 0.231777\tAcc: 70.00\n",
      "val epoch: 137 [12928/221852 (6%)]\tLoss: 0.135409\tAcc: 74.00\n",
      "train epoch: 138 [128/221852 (0%)]\tLoss: 0.216713\tAcc: 76.00\n",
      "train epoch: 138 [12928/221852 (6%)]\tLoss: 0.268912\tAcc: 74.00\n",
      "train epoch: 138 [25728/221852 (12%)]\tLoss: 0.277255\tAcc: 73.00\n",
      "train epoch: 138 [38528/221852 (17%)]\tLoss: 0.163979\tAcc: 84.00\n",
      "train epoch: 138 [51328/221852 (23%)]\tLoss: 0.205785\tAcc: 77.00\n",
      "train epoch: 138 [64128/221852 (29%)]\tLoss: 0.256305\tAcc: 77.00\n",
      "train epoch: 138 [76928/221852 (35%)]\tLoss: 0.101630\tAcc: 80.00\n",
      "train epoch: 138 [89728/221852 (40%)]\tLoss: 0.222402\tAcc: 75.00\n",
      "train epoch: 138 [102528/221852 (46%)]\tLoss: 0.199818\tAcc: 77.00\n",
      "train epoch: 138 [115328/221852 (52%)]\tLoss: 0.281062\tAcc: 69.00\n",
      "train epoch: 138 [128128/221852 (58%)]\tLoss: 0.223884\tAcc: 70.00\n",
      "train epoch: 138 [140928/221852 (64%)]\tLoss: 0.171116\tAcc: 74.00\n",
      "train epoch: 138 [153728/221852 (69%)]\tLoss: 0.174845\tAcc: 76.00\n",
      "train epoch: 138 [166528/221852 (75%)]\tLoss: 0.159816\tAcc: 76.00\n",
      "train epoch: 138 [179328/221852 (81%)]\tLoss: 0.191233\tAcc: 80.00\n",
      "train epoch: 138 [192128/221852 (87%)]\tLoss: 0.165392\tAcc: 79.00\n",
      "val epoch: 138 [128/221852 (0%)]\tLoss: 0.156481\tAcc: 74.00\n",
      "val epoch: 138 [12928/221852 (6%)]\tLoss: 0.203196\tAcc: 77.00\n",
      "train epoch: 139 [128/221852 (0%)]\tLoss: 0.253251\tAcc: 74.00\n",
      "train epoch: 139 [12928/221852 (6%)]\tLoss: 0.195775\tAcc: 80.00\n",
      "train epoch: 139 [25728/221852 (12%)]\tLoss: 0.196037\tAcc: 84.00\n",
      "train epoch: 139 [38528/221852 (17%)]\tLoss: 0.182182\tAcc: 74.00\n",
      "train epoch: 139 [51328/221852 (23%)]\tLoss: 0.236395\tAcc: 75.00\n",
      "train epoch: 139 [64128/221852 (29%)]\tLoss: 0.219463\tAcc: 73.00\n",
      "train epoch: 139 [76928/221852 (35%)]\tLoss: 0.259307\tAcc: 73.00\n",
      "train epoch: 139 [89728/221852 (40%)]\tLoss: 0.204572\tAcc: 70.00\n",
      "train epoch: 139 [102528/221852 (46%)]\tLoss: 0.218891\tAcc: 73.00\n",
      "train epoch: 139 [115328/221852 (52%)]\tLoss: 0.282373\tAcc: 73.00\n",
      "train epoch: 139 [128128/221852 (58%)]\tLoss: 0.235919\tAcc: 77.00\n",
      "train epoch: 139 [140928/221852 (64%)]\tLoss: 0.174224\tAcc: 80.00\n",
      "train epoch: 139 [153728/221852 (69%)]\tLoss: 0.258621\tAcc: 73.00\n",
      "train epoch: 139 [166528/221852 (75%)]\tLoss: 0.166156\tAcc: 77.00\n",
      "train epoch: 139 [179328/221852 (81%)]\tLoss: 0.240729\tAcc: 80.00\n",
      "train epoch: 139 [192128/221852 (87%)]\tLoss: 0.185046\tAcc: 79.00\n",
      "val epoch: 139 [128/221852 (0%)]\tLoss: 0.251393\tAcc: 73.00\n",
      "val epoch: 139 [12928/221852 (6%)]\tLoss: 0.256725\tAcc: 76.00\n",
      "train epoch: 140 [128/221852 (0%)]\tLoss: 0.338386\tAcc: 75.00\n",
      "train epoch: 140 [12928/221852 (6%)]\tLoss: 0.196724\tAcc: 77.00\n",
      "train epoch: 140 [25728/221852 (12%)]\tLoss: 0.188429\tAcc: 69.00\n",
      "train epoch: 140 [38528/221852 (17%)]\tLoss: 0.238703\tAcc: 74.00\n",
      "train epoch: 140 [51328/221852 (23%)]\tLoss: 0.160484\tAcc: 82.00\n",
      "train epoch: 140 [64128/221852 (29%)]\tLoss: 0.224615\tAcc: 88.00\n",
      "train epoch: 140 [76928/221852 (35%)]\tLoss: 0.200189\tAcc: 74.00\n",
      "train epoch: 140 [89728/221852 (40%)]\tLoss: 0.230256\tAcc: 84.00\n",
      "train epoch: 140 [102528/221852 (46%)]\tLoss: 0.187304\tAcc: 73.00\n",
      "train epoch: 140 [115328/221852 (52%)]\tLoss: 0.218197\tAcc: 70.00\n",
      "train epoch: 140 [128128/221852 (58%)]\tLoss: 0.195153\tAcc: 80.00\n",
      "train epoch: 140 [140928/221852 (64%)]\tLoss: 0.163934\tAcc: 72.00\n",
      "train epoch: 140 [153728/221852 (69%)]\tLoss: 0.138116\tAcc: 79.00\n",
      "train epoch: 140 [166528/221852 (75%)]\tLoss: 0.272118\tAcc: 72.00\n",
      "train epoch: 140 [179328/221852 (81%)]\tLoss: 0.230317\tAcc: 73.00\n",
      "train epoch: 140 [192128/221852 (87%)]\tLoss: 0.183744\tAcc: 69.00\n",
      "val epoch: 140 [128/221852 (0%)]\tLoss: 0.169786\tAcc: 77.00\n",
      "val epoch: 140 [12928/221852 (6%)]\tLoss: 0.217536\tAcc: 73.00\n",
      "train epoch: 141 [128/221852 (0%)]\tLoss: 0.191313\tAcc: 74.00\n",
      "train epoch: 141 [12928/221852 (6%)]\tLoss: 0.276522\tAcc: 70.00\n",
      "train epoch: 141 [25728/221852 (12%)]\tLoss: 0.129768\tAcc: 83.00\n",
      "train epoch: 141 [38528/221852 (17%)]\tLoss: 0.230075\tAcc: 74.00\n",
      "train epoch: 141 [51328/221852 (23%)]\tLoss: 0.242782\tAcc: 72.00\n",
      "train epoch: 141 [64128/221852 (29%)]\tLoss: 0.251871\tAcc: 66.00\n",
      "train epoch: 141 [76928/221852 (35%)]\tLoss: 0.165569\tAcc: 82.00\n",
      "train epoch: 141 [89728/221852 (40%)]\tLoss: 0.207688\tAcc: 79.00\n",
      "train epoch: 141 [102528/221852 (46%)]\tLoss: 0.208659\tAcc: 78.00\n",
      "train epoch: 141 [115328/221852 (52%)]\tLoss: 0.238741\tAcc: 74.00\n",
      "train epoch: 141 [128128/221852 (58%)]\tLoss: 0.310302\tAcc: 75.00\n",
      "train epoch: 141 [140928/221852 (64%)]\tLoss: 0.210232\tAcc: 76.00\n",
      "train epoch: 141 [153728/221852 (69%)]\tLoss: 0.324112\tAcc: 66.00\n",
      "train epoch: 141 [166528/221852 (75%)]\tLoss: 0.237437\tAcc: 78.00\n",
      "train epoch: 141 [179328/221852 (81%)]\tLoss: 0.269304\tAcc: 70.00\n",
      "train epoch: 141 [192128/221852 (87%)]\tLoss: 0.237797\tAcc: 75.00\n",
      "val epoch: 141 [128/221852 (0%)]\tLoss: 0.199503\tAcc: 73.00\n",
      "val epoch: 141 [12928/221852 (6%)]\tLoss: 0.220146\tAcc: 79.00\n",
      "train epoch: 142 [128/221852 (0%)]\tLoss: 0.265618\tAcc: 76.00\n",
      "train epoch: 142 [12928/221852 (6%)]\tLoss: 0.257362\tAcc: 74.00\n",
      "train epoch: 142 [25728/221852 (12%)]\tLoss: 0.195404\tAcc: 77.00\n",
      "train epoch: 142 [38528/221852 (17%)]\tLoss: 0.183357\tAcc: 76.00\n",
      "train epoch: 142 [51328/221852 (23%)]\tLoss: 0.170163\tAcc: 71.00\n",
      "train epoch: 142 [64128/221852 (29%)]\tLoss: 0.215732\tAcc: 70.00\n",
      "train epoch: 142 [76928/221852 (35%)]\tLoss: 0.168689\tAcc: 77.00\n",
      "train epoch: 142 [89728/221852 (40%)]\tLoss: 0.218989\tAcc: 76.00\n",
      "train epoch: 142 [102528/221852 (46%)]\tLoss: 0.199174\tAcc: 76.00\n",
      "train epoch: 142 [115328/221852 (52%)]\tLoss: 0.218592\tAcc: 71.00\n",
      "train epoch: 142 [128128/221852 (58%)]\tLoss: 0.274710\tAcc: 73.00\n",
      "train epoch: 142 [140928/221852 (64%)]\tLoss: 0.217136\tAcc: 76.00\n",
      "train epoch: 142 [153728/221852 (69%)]\tLoss: 0.247326\tAcc: 73.00\n",
      "train epoch: 142 [166528/221852 (75%)]\tLoss: 0.203343\tAcc: 80.00\n",
      "train epoch: 142 [179328/221852 (81%)]\tLoss: 0.216931\tAcc: 65.00\n",
      "train epoch: 142 [192128/221852 (87%)]\tLoss: 0.183422\tAcc: 77.00\n",
      "val epoch: 142 [128/221852 (0%)]\tLoss: 0.144001\tAcc: 80.00\n",
      "val epoch: 142 [12928/221852 (6%)]\tLoss: 0.173822\tAcc: 77.00\n",
      "train epoch: 143 [128/221852 (0%)]\tLoss: 0.268744\tAcc: 73.00\n",
      "train epoch: 143 [12928/221852 (6%)]\tLoss: 0.176680\tAcc: 73.00\n",
      "train epoch: 143 [25728/221852 (12%)]\tLoss: 0.150442\tAcc: 77.00\n",
      "train epoch: 143 [38528/221852 (17%)]\tLoss: 0.162811\tAcc: 79.00\n",
      "train epoch: 143 [51328/221852 (23%)]\tLoss: 0.307526\tAcc: 76.00\n",
      "train epoch: 143 [64128/221852 (29%)]\tLoss: 0.162679\tAcc: 80.00\n",
      "train epoch: 143 [76928/221852 (35%)]\tLoss: 0.168502\tAcc: 79.00\n",
      "train epoch: 143 [89728/221852 (40%)]\tLoss: 0.162581\tAcc: 80.00\n",
      "train epoch: 143 [102528/221852 (46%)]\tLoss: 0.139368\tAcc: 80.00\n",
      "train epoch: 143 [115328/221852 (52%)]\tLoss: 0.178909\tAcc: 73.00\n",
      "train epoch: 143 [128128/221852 (58%)]\tLoss: 0.220404\tAcc: 77.00\n",
      "train epoch: 143 [140928/221852 (64%)]\tLoss: 0.284725\tAcc: 70.00\n",
      "train epoch: 143 [153728/221852 (69%)]\tLoss: 0.205220\tAcc: 75.00\n",
      "train epoch: 143 [166528/221852 (75%)]\tLoss: 0.217397\tAcc: 72.00\n",
      "train epoch: 143 [179328/221852 (81%)]\tLoss: 0.226712\tAcc: 76.00\n",
      "train epoch: 143 [192128/221852 (87%)]\tLoss: 0.214913\tAcc: 73.00\n",
      "val epoch: 143 [128/221852 (0%)]\tLoss: 0.224867\tAcc: 76.00\n",
      "val epoch: 143 [12928/221852 (6%)]\tLoss: 0.132420\tAcc: 74.00\n",
      "train epoch: 144 [128/221852 (0%)]\tLoss: 0.207971\tAcc: 70.00\n",
      "train epoch: 144 [12928/221852 (6%)]\tLoss: 0.213052\tAcc: 75.00\n",
      "train epoch: 144 [25728/221852 (12%)]\tLoss: 0.189244\tAcc: 77.00\n",
      "train epoch: 144 [38528/221852 (17%)]\tLoss: 0.231129\tAcc: 77.00\n",
      "train epoch: 144 [51328/221852 (23%)]\tLoss: 0.192524\tAcc: 74.00\n",
      "train epoch: 144 [64128/221852 (29%)]\tLoss: 0.199898\tAcc: 77.00\n",
      "train epoch: 144 [76928/221852 (35%)]\tLoss: 0.222940\tAcc: 77.00\n",
      "train epoch: 144 [89728/221852 (40%)]\tLoss: 0.144463\tAcc: 80.00\n",
      "train epoch: 144 [102528/221852 (46%)]\tLoss: 0.336060\tAcc: 68.00\n",
      "train epoch: 144 [115328/221852 (52%)]\tLoss: 0.188745\tAcc: 74.00\n",
      "train epoch: 144 [128128/221852 (58%)]\tLoss: 0.282074\tAcc: 81.00\n",
      "train epoch: 144 [140928/221852 (64%)]\tLoss: 0.190814\tAcc: 80.00\n",
      "train epoch: 144 [153728/221852 (69%)]\tLoss: 0.212660\tAcc: 77.00\n",
      "train epoch: 144 [166528/221852 (75%)]\tLoss: 0.199015\tAcc: 74.00\n",
      "train epoch: 144 [179328/221852 (81%)]\tLoss: 0.261374\tAcc: 77.00\n",
      "train epoch: 144 [192128/221852 (87%)]\tLoss: 0.228002\tAcc: 77.00\n",
      "val epoch: 144 [128/221852 (0%)]\tLoss: 0.211342\tAcc: 77.00\n",
      "val epoch: 144 [12928/221852 (6%)]\tLoss: 0.204081\tAcc: 73.00\n",
      "train epoch: 145 [128/221852 (0%)]\tLoss: 0.286836\tAcc: 71.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 145 [12928/221852 (6%)]\tLoss: 0.224395\tAcc: 69.00\n",
      "train epoch: 145 [25728/221852 (12%)]\tLoss: 0.242155\tAcc: 84.00\n",
      "train epoch: 145 [38528/221852 (17%)]\tLoss: 0.168754\tAcc: 74.00\n",
      "train epoch: 145 [51328/221852 (23%)]\tLoss: 0.242344\tAcc: 74.00\n",
      "train epoch: 145 [64128/221852 (29%)]\tLoss: 0.174432\tAcc: 77.00\n",
      "train epoch: 145 [76928/221852 (35%)]\tLoss: 0.213856\tAcc: 78.00\n",
      "train epoch: 145 [89728/221852 (40%)]\tLoss: 0.229330\tAcc: 69.00\n",
      "train epoch: 145 [102528/221852 (46%)]\tLoss: 0.179426\tAcc: 74.00\n",
      "train epoch: 145 [115328/221852 (52%)]\tLoss: 0.221610\tAcc: 75.00\n",
      "train epoch: 145 [128128/221852 (58%)]\tLoss: 0.204426\tAcc: 79.00\n",
      "train epoch: 145 [140928/221852 (64%)]\tLoss: 0.150683\tAcc: 73.00\n",
      "train epoch: 145 [153728/221852 (69%)]\tLoss: 0.225183\tAcc: 76.00\n",
      "train epoch: 145 [166528/221852 (75%)]\tLoss: 0.202179\tAcc: 77.00\n",
      "train epoch: 145 [179328/221852 (81%)]\tLoss: 0.213501\tAcc: 79.00\n",
      "train epoch: 145 [192128/221852 (87%)]\tLoss: 0.228469\tAcc: 71.00\n",
      "val epoch: 145 [128/221852 (0%)]\tLoss: 0.316528\tAcc: 74.00\n",
      "val epoch: 145 [12928/221852 (6%)]\tLoss: 0.174826\tAcc: 79.00\n",
      "train epoch: 146 [128/221852 (0%)]\tLoss: 0.157398\tAcc: 73.00\n",
      "train epoch: 146 [12928/221852 (6%)]\tLoss: 0.324772\tAcc: 73.00\n",
      "train epoch: 146 [25728/221852 (12%)]\tLoss: 0.151085\tAcc: 77.00\n",
      "train epoch: 146 [38528/221852 (17%)]\tLoss: 0.285322\tAcc: 78.00\n",
      "train epoch: 146 [51328/221852 (23%)]\tLoss: 0.271433\tAcc: 74.00\n",
      "train epoch: 146 [64128/221852 (29%)]\tLoss: 0.270181\tAcc: 66.00\n",
      "train epoch: 146 [76928/221852 (35%)]\tLoss: 0.297680\tAcc: 68.00\n",
      "train epoch: 146 [89728/221852 (40%)]\tLoss: 0.265019\tAcc: 73.00\n",
      "train epoch: 146 [102528/221852 (46%)]\tLoss: 0.127290\tAcc: 83.00\n",
      "train epoch: 146 [115328/221852 (52%)]\tLoss: 0.246093\tAcc: 71.00\n",
      "train epoch: 146 [128128/221852 (58%)]\tLoss: 0.295735\tAcc: 76.00\n",
      "train epoch: 146 [140928/221852 (64%)]\tLoss: 0.260001\tAcc: 72.00\n",
      "train epoch: 146 [153728/221852 (69%)]\tLoss: 0.188018\tAcc: 71.00\n",
      "train epoch: 146 [166528/221852 (75%)]\tLoss: 0.165794\tAcc: 79.00\n",
      "train epoch: 146 [179328/221852 (81%)]\tLoss: 0.319257\tAcc: 70.00\n",
      "train epoch: 146 [192128/221852 (87%)]\tLoss: 0.196654\tAcc: 77.00\n",
      "val epoch: 146 [128/221852 (0%)]\tLoss: 0.139712\tAcc: 77.00\n",
      "val epoch: 146 [12928/221852 (6%)]\tLoss: 0.193274\tAcc: 73.00\n",
      "train epoch: 147 [128/221852 (0%)]\tLoss: 0.192353\tAcc: 70.00\n",
      "train epoch: 147 [12928/221852 (6%)]\tLoss: 0.141121\tAcc: 75.00\n",
      "train epoch: 147 [25728/221852 (12%)]\tLoss: 0.229574\tAcc: 71.00\n",
      "train epoch: 147 [38528/221852 (17%)]\tLoss: 0.194841\tAcc: 75.00\n",
      "train epoch: 147 [51328/221852 (23%)]\tLoss: 0.223997\tAcc: 78.00\n",
      "train epoch: 147 [64128/221852 (29%)]\tLoss: 0.336629\tAcc: 66.00\n",
      "train epoch: 147 [76928/221852 (35%)]\tLoss: 0.210709\tAcc: 82.00\n",
      "train epoch: 147 [89728/221852 (40%)]\tLoss: 0.192568\tAcc: 75.00\n",
      "train epoch: 147 [102528/221852 (46%)]\tLoss: 0.249937\tAcc: 77.00\n",
      "train epoch: 147 [115328/221852 (52%)]\tLoss: 0.276715\tAcc: 73.00\n",
      "train epoch: 147 [128128/221852 (58%)]\tLoss: 0.215560\tAcc: 73.00\n",
      "train epoch: 147 [140928/221852 (64%)]\tLoss: 0.276021\tAcc: 73.00\n",
      "train epoch: 147 [153728/221852 (69%)]\tLoss: 0.234333\tAcc: 81.00\n",
      "train epoch: 147 [166528/221852 (75%)]\tLoss: 0.158711\tAcc: 75.00\n",
      "train epoch: 147 [179328/221852 (81%)]\tLoss: 0.243203\tAcc: 77.00\n",
      "train epoch: 147 [192128/221852 (87%)]\tLoss: 0.301905\tAcc: 74.00\n",
      "val epoch: 147 [128/221852 (0%)]\tLoss: 0.350131\tAcc: 73.00\n",
      "val epoch: 147 [12928/221852 (6%)]\tLoss: 0.209511\tAcc: 74.00\n",
      "train epoch: 148 [128/221852 (0%)]\tLoss: 0.241582\tAcc: 70.00\n",
      "train epoch: 148 [12928/221852 (6%)]\tLoss: 0.322666\tAcc: 77.00\n",
      "train epoch: 148 [25728/221852 (12%)]\tLoss: 0.206122\tAcc: 79.00\n",
      "train epoch: 148 [38528/221852 (17%)]\tLoss: 0.146785\tAcc: 79.00\n",
      "train epoch: 148 [51328/221852 (23%)]\tLoss: 0.224377\tAcc: 75.00\n",
      "train epoch: 148 [64128/221852 (29%)]\tLoss: 0.269543\tAcc: 75.00\n",
      "train epoch: 148 [76928/221852 (35%)]\tLoss: 0.180323\tAcc: 73.00\n",
      "train epoch: 148 [89728/221852 (40%)]\tLoss: 0.228809\tAcc: 73.00\n",
      "train epoch: 148 [102528/221852 (46%)]\tLoss: 0.143427\tAcc: 81.00\n",
      "train epoch: 148 [115328/221852 (52%)]\tLoss: 0.250366\tAcc: 79.00\n",
      "train epoch: 148 [128128/221852 (58%)]\tLoss: 0.158631\tAcc: 83.00\n",
      "train epoch: 148 [140928/221852 (64%)]\tLoss: 0.201058\tAcc: 72.00\n",
      "train epoch: 148 [153728/221852 (69%)]\tLoss: 0.226674\tAcc: 73.00\n",
      "train epoch: 148 [166528/221852 (75%)]\tLoss: 0.189453\tAcc: 72.00\n",
      "train epoch: 148 [179328/221852 (81%)]\tLoss: 0.252301\tAcc: 73.00\n",
      "train epoch: 148 [192128/221852 (87%)]\tLoss: 0.279544\tAcc: 76.00\n",
      "val epoch: 148 [128/221852 (0%)]\tLoss: 0.358876\tAcc: 67.00\n",
      "val epoch: 148 [12928/221852 (6%)]\tLoss: 0.294698\tAcc: 81.00\n",
      "train epoch: 149 [128/221852 (0%)]\tLoss: 0.297273\tAcc: 79.00\n",
      "train epoch: 149 [12928/221852 (6%)]\tLoss: 0.159649\tAcc: 80.00\n",
      "train epoch: 149 [25728/221852 (12%)]\tLoss: 0.196614\tAcc: 80.00\n",
      "train epoch: 149 [38528/221852 (17%)]\tLoss: 0.205862\tAcc: 82.00\n",
      "train epoch: 149 [51328/221852 (23%)]\tLoss: 0.160604\tAcc: 82.00\n",
      "train epoch: 149 [64128/221852 (29%)]\tLoss: 0.219825\tAcc: 73.00\n",
      "train epoch: 149 [76928/221852 (35%)]\tLoss: 0.206429\tAcc: 73.00\n",
      "train epoch: 149 [89728/221852 (40%)]\tLoss: 0.187586\tAcc: 71.00\n",
      "train epoch: 149 [102528/221852 (46%)]\tLoss: 0.141870\tAcc: 72.00\n",
      "train epoch: 149 [115328/221852 (52%)]\tLoss: 0.255239\tAcc: 77.00\n",
      "train epoch: 149 [128128/221852 (58%)]\tLoss: 0.210249\tAcc: 82.00\n",
      "train epoch: 149 [140928/221852 (64%)]\tLoss: 0.178196\tAcc: 77.00\n",
      "train epoch: 149 [153728/221852 (69%)]\tLoss: 0.159090\tAcc: 77.00\n",
      "train epoch: 149 [166528/221852 (75%)]\tLoss: 0.534007\tAcc: 68.00\n",
      "train epoch: 149 [179328/221852 (81%)]\tLoss: 0.260802\tAcc: 70.00\n",
      "train epoch: 149 [192128/221852 (87%)]\tLoss: 0.176749\tAcc: 80.00\n",
      "val epoch: 149 [128/221852 (0%)]\tLoss: 0.233952\tAcc: 70.00\n",
      "val epoch: 149 [12928/221852 (6%)]\tLoss: 0.257616\tAcc: 72.00\n",
      "train epoch: 150 [128/221852 (0%)]\tLoss: 0.313013\tAcc: 77.00\n",
      "train epoch: 150 [12928/221852 (6%)]\tLoss: 0.190438\tAcc: 73.00\n",
      "train epoch: 150 [25728/221852 (12%)]\tLoss: 0.202780\tAcc: 71.00\n",
      "train epoch: 150 [38528/221852 (17%)]\tLoss: 0.219265\tAcc: 73.00\n",
      "train epoch: 150 [51328/221852 (23%)]\tLoss: 0.208321\tAcc: 74.00\n",
      "train epoch: 150 [64128/221852 (29%)]\tLoss: 0.207705\tAcc: 73.00\n",
      "train epoch: 150 [76928/221852 (35%)]\tLoss: 0.277293\tAcc: 70.00\n",
      "train epoch: 150 [89728/221852 (40%)]\tLoss: 0.260846\tAcc: 74.00\n",
      "train epoch: 150 [102528/221852 (46%)]\tLoss: 0.195515\tAcc: 80.00\n",
      "train epoch: 150 [115328/221852 (52%)]\tLoss: 0.175310\tAcc: 77.00\n",
      "train epoch: 150 [128128/221852 (58%)]\tLoss: 0.185597\tAcc: 78.00\n",
      "train epoch: 150 [140928/221852 (64%)]\tLoss: 0.252561\tAcc: 79.00\n",
      "train epoch: 150 [153728/221852 (69%)]\tLoss: 0.215956\tAcc: 73.00\n",
      "train epoch: 150 [166528/221852 (75%)]\tLoss: 0.201884\tAcc: 77.00\n",
      "train epoch: 150 [179328/221852 (81%)]\tLoss: 0.217464\tAcc: 73.00\n",
      "train epoch: 150 [192128/221852 (87%)]\tLoss: 0.205470\tAcc: 77.00\n",
      "val epoch: 150 [128/221852 (0%)]\tLoss: 0.199448\tAcc: 74.00\n",
      "val epoch: 150 [12928/221852 (6%)]\tLoss: 0.192374\tAcc: 73.00\n",
      "train epoch: 151 [128/221852 (0%)]\tLoss: 0.194664\tAcc: 74.00\n",
      "train epoch: 151 [12928/221852 (6%)]\tLoss: 0.184451\tAcc: 75.00\n",
      "train epoch: 151 [25728/221852 (12%)]\tLoss: 0.218634\tAcc: 80.00\n",
      "train epoch: 151 [38528/221852 (17%)]\tLoss: 0.292224\tAcc: 72.00\n",
      "train epoch: 151 [51328/221852 (23%)]\tLoss: 0.170612\tAcc: 78.00\n",
      "train epoch: 151 [64128/221852 (29%)]\tLoss: 0.248903\tAcc: 71.00\n",
      "train epoch: 151 [76928/221852 (35%)]\tLoss: 0.217558\tAcc: 70.00\n",
      "train epoch: 151 [89728/221852 (40%)]\tLoss: 0.217399\tAcc: 73.00\n",
      "train epoch: 151 [102528/221852 (46%)]\tLoss: 0.190815\tAcc: 80.00\n",
      "train epoch: 151 [115328/221852 (52%)]\tLoss: 0.262494\tAcc: 73.00\n",
      "train epoch: 151 [128128/221852 (58%)]\tLoss: 0.232930\tAcc: 78.00\n",
      "train epoch: 151 [140928/221852 (64%)]\tLoss: 0.174916\tAcc: 79.00\n",
      "train epoch: 151 [153728/221852 (69%)]\tLoss: 0.179639\tAcc: 77.00\n",
      "train epoch: 151 [166528/221852 (75%)]\tLoss: 0.223727\tAcc: 73.00\n",
      "train epoch: 151 [179328/221852 (81%)]\tLoss: 0.239890\tAcc: 80.00\n",
      "train epoch: 151 [192128/221852 (87%)]\tLoss: 0.202222\tAcc: 66.00\n",
      "val epoch: 151 [128/221852 (0%)]\tLoss: 0.188034\tAcc: 75.00\n",
      "val epoch: 151 [12928/221852 (6%)]\tLoss: 0.250970\tAcc: 68.00\n",
      "train epoch: 152 [128/221852 (0%)]\tLoss: 0.122619\tAcc: 72.00\n",
      "train epoch: 152 [12928/221852 (6%)]\tLoss: 0.186129\tAcc: 70.00\n",
      "train epoch: 152 [25728/221852 (12%)]\tLoss: 0.472546\tAcc: 70.00\n",
      "train epoch: 152 [38528/221852 (17%)]\tLoss: 0.291539\tAcc: 73.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 152 [51328/221852 (23%)]\tLoss: 0.250673\tAcc: 77.00\n",
      "train epoch: 152 [64128/221852 (29%)]\tLoss: 0.216161\tAcc: 70.00\n",
      "train epoch: 152 [76928/221852 (35%)]\tLoss: 0.218701\tAcc: 71.00\n",
      "train epoch: 152 [89728/221852 (40%)]\tLoss: 0.290710\tAcc: 70.00\n",
      "train epoch: 152 [102528/221852 (46%)]\tLoss: 0.291807\tAcc: 73.00\n",
      "train epoch: 152 [115328/221852 (52%)]\tLoss: 0.215668\tAcc: 73.00\n",
      "train epoch: 152 [128128/221852 (58%)]\tLoss: 0.122211\tAcc: 75.00\n",
      "train epoch: 152 [140928/221852 (64%)]\tLoss: 0.204317\tAcc: 73.00\n",
      "train epoch: 152 [153728/221852 (69%)]\tLoss: 0.175478\tAcc: 81.00\n",
      "train epoch: 152 [166528/221852 (75%)]\tLoss: 0.177725\tAcc: 77.00\n",
      "train epoch: 152 [179328/221852 (81%)]\tLoss: 0.204598\tAcc: 70.00\n",
      "train epoch: 152 [192128/221852 (87%)]\tLoss: 0.213415\tAcc: 78.00\n",
      "val epoch: 152 [128/221852 (0%)]\tLoss: 0.199111\tAcc: 73.00\n",
      "val epoch: 152 [12928/221852 (6%)]\tLoss: 0.153790\tAcc: 82.00\n",
      "train epoch: 153 [128/221852 (0%)]\tLoss: 0.238233\tAcc: 76.00\n",
      "train epoch: 153 [12928/221852 (6%)]\tLoss: 0.179052\tAcc: 77.00\n",
      "train epoch: 153 [25728/221852 (12%)]\tLoss: 0.183353\tAcc: 79.00\n",
      "train epoch: 153 [38528/221852 (17%)]\tLoss: 0.159292\tAcc: 78.00\n",
      "train epoch: 153 [51328/221852 (23%)]\tLoss: 0.425359\tAcc: 78.00\n",
      "train epoch: 153 [64128/221852 (29%)]\tLoss: 0.139258\tAcc: 75.00\n",
      "train epoch: 153 [76928/221852 (35%)]\tLoss: 0.203900\tAcc: 73.00\n",
      "train epoch: 153 [89728/221852 (40%)]\tLoss: 0.206501\tAcc: 72.00\n",
      "train epoch: 153 [102528/221852 (46%)]\tLoss: 0.150662\tAcc: 81.00\n",
      "train epoch: 153 [115328/221852 (52%)]\tLoss: 0.199506\tAcc: 75.00\n",
      "train epoch: 153 [128128/221852 (58%)]\tLoss: 0.237286\tAcc: 78.00\n",
      "train epoch: 153 [140928/221852 (64%)]\tLoss: 0.263174\tAcc: 77.00\n",
      "train epoch: 153 [153728/221852 (69%)]\tLoss: 0.215099\tAcc: 74.00\n",
      "train epoch: 153 [166528/221852 (75%)]\tLoss: 0.195051\tAcc: 78.00\n",
      "train epoch: 153 [179328/221852 (81%)]\tLoss: 0.177695\tAcc: 78.00\n",
      "train epoch: 153 [192128/221852 (87%)]\tLoss: 0.279486\tAcc: 73.00\n",
      "val epoch: 153 [128/221852 (0%)]\tLoss: 0.128394\tAcc: 81.00\n",
      "val epoch: 153 [12928/221852 (6%)]\tLoss: 0.227570\tAcc: 79.00\n",
      "train epoch: 154 [128/221852 (0%)]\tLoss: 0.237308\tAcc: 77.00\n",
      "train epoch: 154 [12928/221852 (6%)]\tLoss: 0.195811\tAcc: 76.00\n",
      "train epoch: 154 [25728/221852 (12%)]\tLoss: 0.265149\tAcc: 70.00\n",
      "train epoch: 154 [38528/221852 (17%)]\tLoss: 0.181143\tAcc: 81.00\n",
      "train epoch: 154 [51328/221852 (23%)]\tLoss: 0.160856\tAcc: 80.00\n",
      "train epoch: 154 [64128/221852 (29%)]\tLoss: 0.303574\tAcc: 76.00\n",
      "train epoch: 154 [76928/221852 (35%)]\tLoss: 0.409212\tAcc: 75.00\n",
      "train epoch: 154 [89728/221852 (40%)]\tLoss: 0.211803\tAcc: 79.00\n",
      "train epoch: 154 [102528/221852 (46%)]\tLoss: 0.233632\tAcc: 77.00\n",
      "train epoch: 154 [115328/221852 (52%)]\tLoss: 0.216472\tAcc: 76.00\n",
      "train epoch: 154 [128128/221852 (58%)]\tLoss: 0.189440\tAcc: 73.00\n",
      "train epoch: 154 [140928/221852 (64%)]\tLoss: 0.282351\tAcc: 70.00\n",
      "train epoch: 154 [153728/221852 (69%)]\tLoss: 0.240154\tAcc: 76.00\n",
      "train epoch: 154 [166528/221852 (75%)]\tLoss: 0.223883\tAcc: 80.00\n",
      "train epoch: 154 [179328/221852 (81%)]\tLoss: 0.195387\tAcc: 72.00\n",
      "train epoch: 154 [192128/221852 (87%)]\tLoss: 0.167000\tAcc: 78.00\n",
      "val epoch: 154 [128/221852 (0%)]\tLoss: 0.165003\tAcc: 80.00\n",
      "val epoch: 154 [12928/221852 (6%)]\tLoss: 0.126540\tAcc: 75.00\n",
      "train epoch: 155 [128/221852 (0%)]\tLoss: 0.164301\tAcc: 68.00\n",
      "train epoch: 155 [12928/221852 (6%)]\tLoss: 0.175380\tAcc: 82.00\n",
      "train epoch: 155 [25728/221852 (12%)]\tLoss: 0.208750\tAcc: 74.00\n",
      "train epoch: 155 [38528/221852 (17%)]\tLoss: 0.307861\tAcc: 76.00\n",
      "train epoch: 155 [51328/221852 (23%)]\tLoss: 0.171357\tAcc: 80.00\n",
      "train epoch: 155 [64128/221852 (29%)]\tLoss: 0.191179\tAcc: 77.00\n",
      "train epoch: 155 [76928/221852 (35%)]\tLoss: 0.257809\tAcc: 67.00\n",
      "train epoch: 155 [89728/221852 (40%)]\tLoss: 0.207451\tAcc: 73.00\n",
      "train epoch: 155 [102528/221852 (46%)]\tLoss: 0.161256\tAcc: 84.00\n",
      "train epoch: 155 [115328/221852 (52%)]\tLoss: 0.198529\tAcc: 78.00\n",
      "train epoch: 155 [128128/221852 (58%)]\tLoss: 0.259840\tAcc: 80.00\n",
      "train epoch: 155 [140928/221852 (64%)]\tLoss: 0.206681\tAcc: 75.00\n",
      "train epoch: 155 [153728/221852 (69%)]\tLoss: 0.209141\tAcc: 77.00\n",
      "train epoch: 155 [166528/221852 (75%)]\tLoss: 0.206082\tAcc: 75.00\n",
      "train epoch: 155 [179328/221852 (81%)]\tLoss: 0.436850\tAcc: 80.00\n",
      "train epoch: 155 [192128/221852 (87%)]\tLoss: 0.205270\tAcc: 72.00\n",
      "val epoch: 155 [128/221852 (0%)]\tLoss: 0.250534\tAcc: 81.00\n",
      "val epoch: 155 [12928/221852 (6%)]\tLoss: 0.254323\tAcc: 80.00\n",
      "train epoch: 156 [128/221852 (0%)]\tLoss: 0.209358\tAcc: 74.00\n",
      "train epoch: 156 [12928/221852 (6%)]\tLoss: 0.206290\tAcc: 78.00\n",
      "train epoch: 156 [25728/221852 (12%)]\tLoss: 0.273619\tAcc: 73.00\n",
      "train epoch: 156 [38528/221852 (17%)]\tLoss: 0.265917\tAcc: 77.00\n",
      "train epoch: 156 [51328/221852 (23%)]\tLoss: 0.512090\tAcc: 61.00\n",
      "train epoch: 156 [64128/221852 (29%)]\tLoss: 0.242120\tAcc: 65.00\n",
      "train epoch: 156 [76928/221852 (35%)]\tLoss: 0.206233\tAcc: 69.00\n",
      "train epoch: 156 [89728/221852 (40%)]\tLoss: 0.227304\tAcc: 68.00\n",
      "train epoch: 156 [102528/221852 (46%)]\tLoss: 0.185610\tAcc: 83.00\n",
      "train epoch: 156 [115328/221852 (52%)]\tLoss: 0.239721\tAcc: 70.00\n",
      "train epoch: 156 [128128/221852 (58%)]\tLoss: 0.335900\tAcc: 73.00\n",
      "train epoch: 156 [140928/221852 (64%)]\tLoss: 0.196543\tAcc: 83.00\n",
      "train epoch: 156 [153728/221852 (69%)]\tLoss: 0.230005\tAcc: 77.00\n",
      "train epoch: 156 [166528/221852 (75%)]\tLoss: 0.298364\tAcc: 73.00\n",
      "train epoch: 156 [179328/221852 (81%)]\tLoss: 0.217190\tAcc: 74.00\n",
      "train epoch: 156 [192128/221852 (87%)]\tLoss: 0.208523\tAcc: 76.00\n",
      "val epoch: 156 [128/221852 (0%)]\tLoss: 0.204803\tAcc: 77.00\n",
      "val epoch: 156 [12928/221852 (6%)]\tLoss: 0.186239\tAcc: 80.00\n",
      "train epoch: 157 [128/221852 (0%)]\tLoss: 0.248393\tAcc: 72.00\n",
      "train epoch: 157 [12928/221852 (6%)]\tLoss: 0.188958\tAcc: 77.00\n",
      "train epoch: 157 [25728/221852 (12%)]\tLoss: 0.263653\tAcc: 78.00\n",
      "train epoch: 157 [38528/221852 (17%)]\tLoss: 0.307691\tAcc: 69.00\n",
      "train epoch: 157 [51328/221852 (23%)]\tLoss: 0.227999\tAcc: 77.00\n",
      "train epoch: 157 [64128/221852 (29%)]\tLoss: 0.147801\tAcc: 78.00\n",
      "train epoch: 157 [76928/221852 (35%)]\tLoss: 0.251021\tAcc: 77.00\n",
      "train epoch: 157 [89728/221852 (40%)]\tLoss: 0.187306\tAcc: 69.00\n",
      "train epoch: 157 [102528/221852 (46%)]\tLoss: 0.198326\tAcc: 79.00\n",
      "train epoch: 157 [115328/221852 (52%)]\tLoss: 0.190760\tAcc: 78.00\n",
      "train epoch: 157 [128128/221852 (58%)]\tLoss: 0.207841\tAcc: 79.00\n",
      "train epoch: 157 [140928/221852 (64%)]\tLoss: 0.181004\tAcc: 83.00\n",
      "train epoch: 157 [153728/221852 (69%)]\tLoss: 0.201594\tAcc: 77.00\n",
      "train epoch: 157 [166528/221852 (75%)]\tLoss: 0.251527\tAcc: 73.00\n",
      "train epoch: 157 [179328/221852 (81%)]\tLoss: 0.179298\tAcc: 82.00\n",
      "train epoch: 157 [192128/221852 (87%)]\tLoss: 0.157109\tAcc: 83.00\n",
      "val epoch: 157 [128/221852 (0%)]\tLoss: 0.233318\tAcc: 77.00\n",
      "val epoch: 157 [12928/221852 (6%)]\tLoss: 0.320887\tAcc: 75.00\n",
      "train epoch: 158 [128/221852 (0%)]\tLoss: 0.271778\tAcc: 84.00\n",
      "train epoch: 158 [12928/221852 (6%)]\tLoss: 0.236697\tAcc: 73.00\n",
      "train epoch: 158 [25728/221852 (12%)]\tLoss: 0.154280\tAcc: 79.00\n",
      "train epoch: 158 [38528/221852 (17%)]\tLoss: 0.302315\tAcc: 74.00\n",
      "train epoch: 158 [51328/221852 (23%)]\tLoss: 0.189325\tAcc: 73.00\n",
      "train epoch: 158 [64128/221852 (29%)]\tLoss: 0.230526\tAcc: 73.00\n",
      "train epoch: 158 [76928/221852 (35%)]\tLoss: 0.212913\tAcc: 77.00\n",
      "train epoch: 158 [89728/221852 (40%)]\tLoss: 0.215350\tAcc: 82.00\n",
      "train epoch: 158 [102528/221852 (46%)]\tLoss: 0.266086\tAcc: 77.00\n",
      "train epoch: 158 [115328/221852 (52%)]\tLoss: 0.225190\tAcc: 77.00\n",
      "train epoch: 158 [128128/221852 (58%)]\tLoss: 0.179755\tAcc: 72.00\n",
      "train epoch: 158 [140928/221852 (64%)]\tLoss: 0.219657\tAcc: 73.00\n",
      "train epoch: 158 [153728/221852 (69%)]\tLoss: 0.170705\tAcc: 80.00\n",
      "train epoch: 158 [166528/221852 (75%)]\tLoss: 0.172421\tAcc: 76.00\n",
      "train epoch: 158 [179328/221852 (81%)]\tLoss: 0.299303\tAcc: 70.00\n",
      "train epoch: 158 [192128/221852 (87%)]\tLoss: 0.212691\tAcc: 73.00\n",
      "val epoch: 158 [128/221852 (0%)]\tLoss: 0.195932\tAcc: 81.00\n",
      "val epoch: 158 [12928/221852 (6%)]\tLoss: 0.119292\tAcc: 81.00\n",
      "train epoch: 159 [128/221852 (0%)]\tLoss: 0.206958\tAcc: 76.00\n",
      "train epoch: 159 [12928/221852 (6%)]\tLoss: 0.285839\tAcc: 71.00\n",
      "train epoch: 159 [25728/221852 (12%)]\tLoss: 0.128988\tAcc: 80.00\n",
      "train epoch: 159 [38528/221852 (17%)]\tLoss: 0.330180\tAcc: 79.00\n",
      "train epoch: 159 [51328/221852 (23%)]\tLoss: 0.211595\tAcc: 76.00\n",
      "train epoch: 159 [64128/221852 (29%)]\tLoss: 0.266428\tAcc: 75.00\n",
      "train epoch: 159 [76928/221852 (35%)]\tLoss: 0.217478\tAcc: 77.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 159 [89728/221852 (40%)]\tLoss: 0.226586\tAcc: 80.00\n",
      "train epoch: 159 [102528/221852 (46%)]\tLoss: 0.213393\tAcc: 77.00\n",
      "train epoch: 159 [115328/221852 (52%)]\tLoss: 0.183800\tAcc: 77.00\n",
      "train epoch: 159 [128128/221852 (58%)]\tLoss: 0.231905\tAcc: 71.00\n",
      "train epoch: 159 [140928/221852 (64%)]\tLoss: 0.257036\tAcc: 77.00\n",
      "train epoch: 159 [153728/221852 (69%)]\tLoss: 0.359299\tAcc: 76.00\n",
      "train epoch: 159 [166528/221852 (75%)]\tLoss: 0.223030\tAcc: 66.00\n",
      "train epoch: 159 [179328/221852 (81%)]\tLoss: 0.218940\tAcc: 73.00\n",
      "train epoch: 159 [192128/221852 (87%)]\tLoss: 0.203768\tAcc: 73.00\n",
      "val epoch: 159 [128/221852 (0%)]\tLoss: 0.111565\tAcc: 75.00\n",
      "val epoch: 159 [12928/221852 (6%)]\tLoss: 0.227880\tAcc: 76.00\n",
      "train epoch: 160 [128/221852 (0%)]\tLoss: 0.163409\tAcc: 70.00\n",
      "train epoch: 160 [12928/221852 (6%)]\tLoss: 0.224015\tAcc: 77.00\n",
      "train epoch: 160 [25728/221852 (12%)]\tLoss: 0.213375\tAcc: 73.00\n",
      "train epoch: 160 [38528/221852 (17%)]\tLoss: 0.173490\tAcc: 80.00\n",
      "train epoch: 160 [51328/221852 (23%)]\tLoss: 0.196247\tAcc: 79.00\n",
      "train epoch: 160 [64128/221852 (29%)]\tLoss: 0.199871\tAcc: 68.00\n",
      "train epoch: 160 [76928/221852 (35%)]\tLoss: 0.184370\tAcc: 78.00\n",
      "train epoch: 160 [89728/221852 (40%)]\tLoss: 0.205864\tAcc: 77.00\n",
      "train epoch: 160 [102528/221852 (46%)]\tLoss: 0.145777\tAcc: 81.00\n",
      "train epoch: 160 [115328/221852 (52%)]\tLoss: 0.200048\tAcc: 76.00\n",
      "train epoch: 160 [128128/221852 (58%)]\tLoss: 0.196250\tAcc: 72.00\n",
      "train epoch: 160 [140928/221852 (64%)]\tLoss: 0.222022\tAcc: 74.00\n",
      "train epoch: 160 [153728/221852 (69%)]\tLoss: 0.169805\tAcc: 77.00\n",
      "train epoch: 160 [166528/221852 (75%)]\tLoss: 0.200440\tAcc: 73.00\n",
      "train epoch: 160 [179328/221852 (81%)]\tLoss: 0.167138\tAcc: 81.00\n",
      "train epoch: 160 [192128/221852 (87%)]\tLoss: 0.195720\tAcc: 76.00\n",
      "val epoch: 160 [128/221852 (0%)]\tLoss: 0.194339\tAcc: 77.00\n",
      "val epoch: 160 [12928/221852 (6%)]\tLoss: 0.175166\tAcc: 82.00\n",
      "train epoch: 161 [128/221852 (0%)]\tLoss: 0.160598\tAcc: 68.00\n",
      "train epoch: 161 [12928/221852 (6%)]\tLoss: 0.146306\tAcc: 75.00\n",
      "train epoch: 161 [25728/221852 (12%)]\tLoss: 0.186992\tAcc: 80.00\n",
      "train epoch: 161 [38528/221852 (17%)]\tLoss: 0.181223\tAcc: 73.00\n",
      "train epoch: 161 [51328/221852 (23%)]\tLoss: 0.325140\tAcc: 75.00\n",
      "train epoch: 161 [64128/221852 (29%)]\tLoss: 0.221830\tAcc: 77.00\n",
      "train epoch: 161 [76928/221852 (35%)]\tLoss: 0.254161\tAcc: 72.00\n",
      "train epoch: 161 [89728/221852 (40%)]\tLoss: 0.387418\tAcc: 70.00\n",
      "train epoch: 161 [102528/221852 (46%)]\tLoss: 0.266020\tAcc: 73.00\n",
      "train epoch: 161 [115328/221852 (52%)]\tLoss: 0.177601\tAcc: 73.00\n",
      "train epoch: 161 [128128/221852 (58%)]\tLoss: 0.208780\tAcc: 80.00\n",
      "train epoch: 161 [140928/221852 (64%)]\tLoss: 0.285224\tAcc: 72.00\n",
      "train epoch: 161 [153728/221852 (69%)]\tLoss: 0.189980\tAcc: 82.00\n",
      "train epoch: 161 [166528/221852 (75%)]\tLoss: 0.256873\tAcc: 75.00\n",
      "train epoch: 161 [179328/221852 (81%)]\tLoss: 0.151615\tAcc: 80.00\n",
      "train epoch: 161 [192128/221852 (87%)]\tLoss: 0.204725\tAcc: 80.00\n",
      "val epoch: 161 [128/221852 (0%)]\tLoss: 0.235601\tAcc: 73.00\n",
      "val epoch: 161 [12928/221852 (6%)]\tLoss: 0.213510\tAcc: 81.00\n",
      "train epoch: 162 [128/221852 (0%)]\tLoss: 0.229439\tAcc: 77.00\n",
      "train epoch: 162 [12928/221852 (6%)]\tLoss: 0.224577\tAcc: 77.00\n",
      "train epoch: 162 [25728/221852 (12%)]\tLoss: 0.126656\tAcc: 80.00\n",
      "train epoch: 162 [38528/221852 (17%)]\tLoss: 0.171353\tAcc: 76.00\n",
      "train epoch: 162 [51328/221852 (23%)]\tLoss: 0.173382\tAcc: 77.00\n",
      "train epoch: 162 [64128/221852 (29%)]\tLoss: 0.225013\tAcc: 81.00\n",
      "train epoch: 162 [76928/221852 (35%)]\tLoss: 0.231279\tAcc: 76.00\n",
      "train epoch: 162 [89728/221852 (40%)]\tLoss: 0.200527\tAcc: 73.00\n",
      "train epoch: 162 [102528/221852 (46%)]\tLoss: 0.183307\tAcc: 77.00\n",
      "train epoch: 162 [115328/221852 (52%)]\tLoss: 0.208376\tAcc: 78.00\n",
      "train epoch: 162 [128128/221852 (58%)]\tLoss: 0.193732\tAcc: 76.00\n",
      "train epoch: 162 [140928/221852 (64%)]\tLoss: 0.188515\tAcc: 78.00\n",
      "train epoch: 162 [153728/221852 (69%)]\tLoss: 0.172754\tAcc: 82.00\n",
      "train epoch: 162 [166528/221852 (75%)]\tLoss: 0.298398\tAcc: 73.00\n",
      "train epoch: 162 [179328/221852 (81%)]\tLoss: 0.263612\tAcc: 73.00\n",
      "train epoch: 162 [192128/221852 (87%)]\tLoss: 0.259291\tAcc: 77.00\n",
      "val epoch: 162 [128/221852 (0%)]\tLoss: 0.160179\tAcc: 80.00\n",
      "val epoch: 162 [12928/221852 (6%)]\tLoss: 0.242610\tAcc: 70.00\n",
      "train epoch: 163 [128/221852 (0%)]\tLoss: 0.225423\tAcc: 77.00\n",
      "train epoch: 163 [12928/221852 (6%)]\tLoss: 0.123446\tAcc: 78.00\n",
      "train epoch: 163 [25728/221852 (12%)]\tLoss: 0.128891\tAcc: 83.00\n",
      "train epoch: 163 [38528/221852 (17%)]\tLoss: 0.182585\tAcc: 74.00\n",
      "train epoch: 163 [51328/221852 (23%)]\tLoss: 0.182909\tAcc: 79.00\n",
      "train epoch: 163 [64128/221852 (29%)]\tLoss: 0.298418\tAcc: 73.00\n",
      "train epoch: 163 [76928/221852 (35%)]\tLoss: 0.202363\tAcc: 78.00\n",
      "train epoch: 163 [89728/221852 (40%)]\tLoss: 0.255941\tAcc: 77.00\n",
      "train epoch: 163 [102528/221852 (46%)]\tLoss: 0.248947\tAcc: 77.00\n",
      "train epoch: 163 [115328/221852 (52%)]\tLoss: 0.205285\tAcc: 71.00\n",
      "train epoch: 163 [128128/221852 (58%)]\tLoss: 0.203260\tAcc: 73.00\n",
      "train epoch: 163 [140928/221852 (64%)]\tLoss: 0.164117\tAcc: 84.00\n",
      "train epoch: 163 [153728/221852 (69%)]\tLoss: 0.212516\tAcc: 74.00\n",
      "train epoch: 163 [166528/221852 (75%)]\tLoss: 0.189949\tAcc: 75.00\n",
      "train epoch: 163 [179328/221852 (81%)]\tLoss: 0.263463\tAcc: 76.00\n",
      "train epoch: 163 [192128/221852 (87%)]\tLoss: 0.274372\tAcc: 79.00\n",
      "val epoch: 163 [128/221852 (0%)]\tLoss: 0.207730\tAcc: 78.00\n",
      "val epoch: 163 [12928/221852 (6%)]\tLoss: 0.205167\tAcc: 74.00\n",
      "train epoch: 164 [128/221852 (0%)]\tLoss: 0.222857\tAcc: 77.00\n",
      "train epoch: 164 [12928/221852 (6%)]\tLoss: 0.182075\tAcc: 77.00\n",
      "train epoch: 164 [25728/221852 (12%)]\tLoss: 0.199882\tAcc: 71.00\n",
      "train epoch: 164 [38528/221852 (17%)]\tLoss: 0.210947\tAcc: 73.00\n",
      "train epoch: 164 [51328/221852 (23%)]\tLoss: 0.129958\tAcc: 78.00\n",
      "train epoch: 164 [64128/221852 (29%)]\tLoss: 0.240148\tAcc: 80.00\n",
      "train epoch: 164 [76928/221852 (35%)]\tLoss: 0.120420\tAcc: 77.00\n",
      "train epoch: 164 [89728/221852 (40%)]\tLoss: 0.193794\tAcc: 79.00\n",
      "train epoch: 164 [102528/221852 (46%)]\tLoss: 0.233596\tAcc: 81.00\n",
      "train epoch: 164 [115328/221852 (52%)]\tLoss: 0.208254\tAcc: 74.00\n",
      "train epoch: 164 [128128/221852 (58%)]\tLoss: 0.252772\tAcc: 70.00\n",
      "train epoch: 164 [140928/221852 (64%)]\tLoss: 0.228769\tAcc: 77.00\n",
      "train epoch: 164 [153728/221852 (69%)]\tLoss: 0.194549\tAcc: 77.00\n",
      "train epoch: 164 [166528/221852 (75%)]\tLoss: 0.248844\tAcc: 72.00\n",
      "train epoch: 164 [179328/221852 (81%)]\tLoss: 0.216721\tAcc: 78.00\n",
      "train epoch: 164 [192128/221852 (87%)]\tLoss: 0.213466\tAcc: 72.00\n",
      "val epoch: 164 [128/221852 (0%)]\tLoss: 0.240530\tAcc: 75.00\n",
      "val epoch: 164 [12928/221852 (6%)]\tLoss: 0.182507\tAcc: 81.00\n",
      "train epoch: 165 [128/221852 (0%)]\tLoss: 0.270441\tAcc: 74.00\n",
      "train epoch: 165 [12928/221852 (6%)]\tLoss: 0.156831\tAcc: 81.00\n",
      "train epoch: 165 [25728/221852 (12%)]\tLoss: 0.231018\tAcc: 76.00\n",
      "train epoch: 165 [38528/221852 (17%)]\tLoss: 0.184503\tAcc: 83.00\n",
      "train epoch: 165 [51328/221852 (23%)]\tLoss: 0.191593\tAcc: 79.00\n",
      "train epoch: 165 [64128/221852 (29%)]\tLoss: 0.223939\tAcc: 77.00\n",
      "train epoch: 165 [76928/221852 (35%)]\tLoss: 0.136218\tAcc: 84.00\n",
      "train epoch: 165 [89728/221852 (40%)]\tLoss: 0.177400\tAcc: 75.00\n",
      "train epoch: 165 [102528/221852 (46%)]\tLoss: 0.170743\tAcc: 83.00\n",
      "train epoch: 165 [115328/221852 (52%)]\tLoss: 0.275557\tAcc: 77.00\n",
      "train epoch: 165 [128128/221852 (58%)]\tLoss: 0.301902\tAcc: 74.00\n",
      "train epoch: 165 [140928/221852 (64%)]\tLoss: 0.150655\tAcc: 78.00\n",
      "train epoch: 165 [153728/221852 (69%)]\tLoss: 0.149242\tAcc: 72.00\n",
      "train epoch: 165 [166528/221852 (75%)]\tLoss: 0.281691\tAcc: 66.00\n",
      "train epoch: 165 [179328/221852 (81%)]\tLoss: 0.228665\tAcc: 71.00\n",
      "train epoch: 165 [192128/221852 (87%)]\tLoss: 0.324462\tAcc: 73.00\n",
      "val epoch: 165 [128/221852 (0%)]\tLoss: 0.280594\tAcc: 73.00\n",
      "val epoch: 165 [12928/221852 (6%)]\tLoss: 0.195070\tAcc: 77.00\n",
      "train epoch: 166 [128/221852 (0%)]\tLoss: 0.241549\tAcc: 72.00\n",
      "train epoch: 166 [12928/221852 (6%)]\tLoss: 0.183610\tAcc: 75.00\n",
      "train epoch: 166 [25728/221852 (12%)]\tLoss: 0.155950\tAcc: 81.00\n",
      "train epoch: 166 [38528/221852 (17%)]\tLoss: 0.208659\tAcc: 78.00\n",
      "train epoch: 166 [51328/221852 (23%)]\tLoss: 0.328365\tAcc: 70.00\n",
      "train epoch: 166 [64128/221852 (29%)]\tLoss: 0.186100\tAcc: 76.00\n",
      "train epoch: 166 [76928/221852 (35%)]\tLoss: 0.262877\tAcc: 76.00\n",
      "train epoch: 166 [89728/221852 (40%)]\tLoss: 0.227404\tAcc: 80.00\n",
      "train epoch: 166 [102528/221852 (46%)]\tLoss: 0.221508\tAcc: 70.00\n",
      "train epoch: 166 [115328/221852 (52%)]\tLoss: 0.261682\tAcc: 74.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 166 [128128/221852 (58%)]\tLoss: 0.247128\tAcc: 68.00\n",
      "train epoch: 166 [140928/221852 (64%)]\tLoss: 0.188612\tAcc: 77.00\n",
      "train epoch: 166 [153728/221852 (69%)]\tLoss: 0.233104\tAcc: 80.00\n",
      "train epoch: 166 [166528/221852 (75%)]\tLoss: 0.141931\tAcc: 79.00\n",
      "train epoch: 166 [179328/221852 (81%)]\tLoss: 0.188325\tAcc: 74.00\n",
      "train epoch: 166 [192128/221852 (87%)]\tLoss: 0.217170\tAcc: 77.00\n",
      "val epoch: 166 [128/221852 (0%)]\tLoss: 0.170086\tAcc: 77.00\n",
      "val epoch: 166 [12928/221852 (6%)]\tLoss: 0.166914\tAcc: 83.00\n",
      "train epoch: 167 [128/221852 (0%)]\tLoss: 0.223415\tAcc: 77.00\n",
      "train epoch: 167 [12928/221852 (6%)]\tLoss: 0.235174\tAcc: 77.00\n",
      "train epoch: 167 [25728/221852 (12%)]\tLoss: 0.247361\tAcc: 78.00\n",
      "train epoch: 167 [38528/221852 (17%)]\tLoss: 0.146368\tAcc: 78.00\n",
      "train epoch: 167 [51328/221852 (23%)]\tLoss: 0.240059\tAcc: 72.00\n",
      "train epoch: 167 [64128/221852 (29%)]\tLoss: 0.261216\tAcc: 76.00\n",
      "train epoch: 167 [76928/221852 (35%)]\tLoss: 0.286090\tAcc: 69.00\n",
      "train epoch: 167 [89728/221852 (40%)]\tLoss: 0.211288\tAcc: 72.00\n",
      "train epoch: 167 [102528/221852 (46%)]\tLoss: 0.212692\tAcc: 75.00\n",
      "train epoch: 167 [115328/221852 (52%)]\tLoss: 0.204871\tAcc: 79.00\n",
      "train epoch: 167 [128128/221852 (58%)]\tLoss: 0.214469\tAcc: 76.00\n",
      "train epoch: 167 [140928/221852 (64%)]\tLoss: 0.242339\tAcc: 68.00\n",
      "train epoch: 167 [153728/221852 (69%)]\tLoss: 0.202267\tAcc: 76.00\n",
      "train epoch: 167 [166528/221852 (75%)]\tLoss: 0.218700\tAcc: 83.00\n",
      "train epoch: 167 [179328/221852 (81%)]\tLoss: 0.179240\tAcc: 81.00\n",
      "train epoch: 167 [192128/221852 (87%)]\tLoss: 0.268934\tAcc: 75.00\n",
      "val epoch: 167 [128/221852 (0%)]\tLoss: 0.167047\tAcc: 78.00\n",
      "val epoch: 167 [12928/221852 (6%)]\tLoss: 0.247074\tAcc: 69.00\n",
      "train epoch: 168 [128/221852 (0%)]\tLoss: 0.159493\tAcc: 83.00\n",
      "train epoch: 168 [12928/221852 (6%)]\tLoss: 0.217435\tAcc: 71.00\n",
      "train epoch: 168 [25728/221852 (12%)]\tLoss: 0.154440\tAcc: 70.00\n",
      "train epoch: 168 [38528/221852 (17%)]\tLoss: 0.307834\tAcc: 73.00\n",
      "train epoch: 168 [51328/221852 (23%)]\tLoss: 0.198677\tAcc: 80.00\n",
      "train epoch: 168 [64128/221852 (29%)]\tLoss: 0.181749\tAcc: 80.00\n",
      "train epoch: 168 [76928/221852 (35%)]\tLoss: 0.165129\tAcc: 75.00\n",
      "train epoch: 168 [89728/221852 (40%)]\tLoss: 0.183153\tAcc: 76.00\n",
      "train epoch: 168 [102528/221852 (46%)]\tLoss: 0.243335\tAcc: 72.00\n",
      "train epoch: 168 [115328/221852 (52%)]\tLoss: 0.188676\tAcc: 81.00\n",
      "train epoch: 168 [128128/221852 (58%)]\tLoss: 0.213485\tAcc: 72.00\n",
      "train epoch: 168 [140928/221852 (64%)]\tLoss: 0.314814\tAcc: 73.00\n",
      "train epoch: 168 [153728/221852 (69%)]\tLoss: 0.179987\tAcc: 80.00\n",
      "train epoch: 168 [166528/221852 (75%)]\tLoss: 0.133321\tAcc: 80.00\n",
      "train epoch: 168 [179328/221852 (81%)]\tLoss: 0.202016\tAcc: 85.00\n",
      "train epoch: 168 [192128/221852 (87%)]\tLoss: 0.243739\tAcc: 77.00\n",
      "val epoch: 168 [128/221852 (0%)]\tLoss: 0.137660\tAcc: 81.00\n",
      "val epoch: 168 [12928/221852 (6%)]\tLoss: 0.205526\tAcc: 80.00\n",
      "train epoch: 169 [128/221852 (0%)]\tLoss: 0.225063\tAcc: 80.00\n",
      "train epoch: 169 [12928/221852 (6%)]\tLoss: 0.210776\tAcc: 78.00\n",
      "train epoch: 169 [25728/221852 (12%)]\tLoss: 0.117169\tAcc: 81.00\n",
      "train epoch: 169 [38528/221852 (17%)]\tLoss: 0.273631\tAcc: 73.00\n",
      "train epoch: 169 [51328/221852 (23%)]\tLoss: 0.115241\tAcc: 83.00\n",
      "train epoch: 169 [64128/221852 (29%)]\tLoss: 0.174498\tAcc: 74.00\n",
      "train epoch: 169 [76928/221852 (35%)]\tLoss: 0.219727\tAcc: 77.00\n",
      "train epoch: 169 [89728/221852 (40%)]\tLoss: 0.254460\tAcc: 79.00\n",
      "train epoch: 169 [102528/221852 (46%)]\tLoss: 0.288611\tAcc: 70.00\n",
      "train epoch: 169 [115328/221852 (52%)]\tLoss: 0.212776\tAcc: 80.00\n",
      "train epoch: 169 [128128/221852 (58%)]\tLoss: 0.244346\tAcc: 70.00\n",
      "train epoch: 169 [140928/221852 (64%)]\tLoss: 0.240534\tAcc: 80.00\n",
      "train epoch: 169 [153728/221852 (69%)]\tLoss: 0.188036\tAcc: 73.00\n",
      "train epoch: 169 [166528/221852 (75%)]\tLoss: 0.218879\tAcc: 83.00\n",
      "train epoch: 169 [179328/221852 (81%)]\tLoss: 0.208983\tAcc: 79.00\n",
      "train epoch: 169 [192128/221852 (87%)]\tLoss: 0.184197\tAcc: 76.00\n",
      "val epoch: 169 [128/221852 (0%)]\tLoss: 0.224130\tAcc: 73.00\n",
      "val epoch: 169 [12928/221852 (6%)]\tLoss: 0.224635\tAcc: 75.00\n",
      "train epoch: 170 [128/221852 (0%)]\tLoss: 0.182389\tAcc: 76.00\n",
      "train epoch: 170 [12928/221852 (6%)]\tLoss: 0.108876\tAcc: 79.00\n",
      "train epoch: 170 [25728/221852 (12%)]\tLoss: 0.294635\tAcc: 69.00\n",
      "train epoch: 170 [38528/221852 (17%)]\tLoss: 0.192969\tAcc: 70.00\n",
      "train epoch: 170 [51328/221852 (23%)]\tLoss: 0.208172\tAcc: 77.00\n",
      "train epoch: 170 [64128/221852 (29%)]\tLoss: 0.251305\tAcc: 78.00\n",
      "train epoch: 170 [76928/221852 (35%)]\tLoss: 0.204476\tAcc: 78.00\n",
      "train epoch: 170 [89728/221852 (40%)]\tLoss: 0.213768\tAcc: 76.00\n",
      "train epoch: 170 [102528/221852 (46%)]\tLoss: 0.229323\tAcc: 78.00\n",
      "train epoch: 170 [115328/221852 (52%)]\tLoss: 0.190092\tAcc: 73.00\n",
      "train epoch: 170 [128128/221852 (58%)]\tLoss: 0.257271\tAcc: 73.00\n",
      "train epoch: 170 [140928/221852 (64%)]\tLoss: 0.254826\tAcc: 75.00\n",
      "train epoch: 170 [153728/221852 (69%)]\tLoss: 0.269066\tAcc: 69.00\n",
      "train epoch: 170 [166528/221852 (75%)]\tLoss: 0.150838\tAcc: 73.00\n",
      "train epoch: 170 [179328/221852 (81%)]\tLoss: 0.170575\tAcc: 77.00\n",
      "train epoch: 170 [192128/221852 (87%)]\tLoss: 0.198483\tAcc: 75.00\n",
      "val epoch: 170 [128/221852 (0%)]\tLoss: 0.251597\tAcc: 72.00\n",
      "val epoch: 170 [12928/221852 (6%)]\tLoss: 0.243749\tAcc: 75.00\n",
      "train epoch: 171 [128/221852 (0%)]\tLoss: 0.221116\tAcc: 66.00\n",
      "train epoch: 171 [12928/221852 (6%)]\tLoss: 0.118462\tAcc: 84.00\n",
      "train epoch: 171 [25728/221852 (12%)]\tLoss: 0.473664\tAcc: 81.00\n",
      "train epoch: 171 [38528/221852 (17%)]\tLoss: 0.283147\tAcc: 78.00\n",
      "train epoch: 171 [51328/221852 (23%)]\tLoss: 0.214207\tAcc: 78.00\n",
      "train epoch: 171 [64128/221852 (29%)]\tLoss: 0.283377\tAcc: 72.00\n",
      "train epoch: 171 [76928/221852 (35%)]\tLoss: 0.190856\tAcc: 82.00\n",
      "train epoch: 171 [89728/221852 (40%)]\tLoss: 0.200377\tAcc: 74.00\n",
      "train epoch: 171 [102528/221852 (46%)]\tLoss: 0.234524\tAcc: 73.00\n",
      "train epoch: 171 [115328/221852 (52%)]\tLoss: 0.197445\tAcc: 73.00\n",
      "train epoch: 171 [128128/221852 (58%)]\tLoss: 0.226462\tAcc: 79.00\n",
      "train epoch: 171 [140928/221852 (64%)]\tLoss: 0.223262\tAcc: 78.00\n",
      "train epoch: 171 [153728/221852 (69%)]\tLoss: 0.177181\tAcc: 77.00\n",
      "train epoch: 171 [166528/221852 (75%)]\tLoss: 0.206516\tAcc: 76.00\n",
      "train epoch: 171 [179328/221852 (81%)]\tLoss: 0.218854\tAcc: 77.00\n",
      "train epoch: 171 [192128/221852 (87%)]\tLoss: 0.147429\tAcc: 80.00\n",
      "val epoch: 171 [128/221852 (0%)]\tLoss: 0.225414\tAcc: 74.00\n",
      "val epoch: 171 [12928/221852 (6%)]\tLoss: 0.275903\tAcc: 77.00\n",
      "train epoch: 172 [128/221852 (0%)]\tLoss: 0.229346\tAcc: 80.00\n",
      "train epoch: 172 [12928/221852 (6%)]\tLoss: 0.156640\tAcc: 80.00\n",
      "train epoch: 172 [25728/221852 (12%)]\tLoss: 0.202308\tAcc: 75.00\n",
      "train epoch: 172 [38528/221852 (17%)]\tLoss: 0.190952\tAcc: 82.00\n",
      "train epoch: 172 [51328/221852 (23%)]\tLoss: 0.211348\tAcc: 78.00\n",
      "train epoch: 172 [64128/221852 (29%)]\tLoss: 0.172523\tAcc: 79.00\n",
      "train epoch: 172 [76928/221852 (35%)]\tLoss: 0.168710\tAcc: 81.00\n",
      "train epoch: 172 [89728/221852 (40%)]\tLoss: 0.130061\tAcc: 84.00\n",
      "train epoch: 172 [102528/221852 (46%)]\tLoss: 0.163648\tAcc: 73.00\n",
      "train epoch: 172 [115328/221852 (52%)]\tLoss: 0.205312\tAcc: 69.00\n",
      "train epoch: 172 [128128/221852 (58%)]\tLoss: 0.285424\tAcc: 77.00\n",
      "train epoch: 172 [140928/221852 (64%)]\tLoss: 0.213055\tAcc: 77.00\n",
      "train epoch: 172 [153728/221852 (69%)]\tLoss: 0.110601\tAcc: 75.00\n",
      "train epoch: 172 [166528/221852 (75%)]\tLoss: 0.213981\tAcc: 80.00\n",
      "train epoch: 172 [179328/221852 (81%)]\tLoss: 0.163987\tAcc: 77.00\n",
      "train epoch: 172 [192128/221852 (87%)]\tLoss: 0.178298\tAcc: 79.00\n",
      "val epoch: 172 [128/221852 (0%)]\tLoss: 0.141935\tAcc: 82.00\n",
      "val epoch: 172 [12928/221852 (6%)]\tLoss: 0.190789\tAcc: 76.00\n",
      "train epoch: 173 [128/221852 (0%)]\tLoss: 0.222484\tAcc: 79.00\n",
      "train epoch: 173 [12928/221852 (6%)]\tLoss: 0.170878\tAcc: 75.00\n",
      "train epoch: 173 [25728/221852 (12%)]\tLoss: 0.280868\tAcc: 80.00\n",
      "train epoch: 173 [38528/221852 (17%)]\tLoss: 0.156184\tAcc: 74.00\n",
      "train epoch: 173 [51328/221852 (23%)]\tLoss: 0.144849\tAcc: 82.00\n",
      "train epoch: 173 [64128/221852 (29%)]\tLoss: 0.164762\tAcc: 79.00\n",
      "train epoch: 173 [76928/221852 (35%)]\tLoss: 0.260892\tAcc: 73.00\n",
      "train epoch: 173 [89728/221852 (40%)]\tLoss: 0.343374\tAcc: 70.00\n",
      "train epoch: 173 [102528/221852 (46%)]\tLoss: 0.169404\tAcc: 79.00\n",
      "train epoch: 173 [115328/221852 (52%)]\tLoss: 0.199348\tAcc: 78.00\n",
      "train epoch: 173 [128128/221852 (58%)]\tLoss: 0.296014\tAcc: 74.00\n",
      "train epoch: 173 [140928/221852 (64%)]\tLoss: 0.240287\tAcc: 78.00\n",
      "train epoch: 173 [153728/221852 (69%)]\tLoss: 0.482477\tAcc: 63.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 173 [166528/221852 (75%)]\tLoss: 0.159648\tAcc: 73.00\n",
      "train epoch: 173 [179328/221852 (81%)]\tLoss: 0.186321\tAcc: 73.00\n",
      "train epoch: 173 [192128/221852 (87%)]\tLoss: 0.182339\tAcc: 82.00\n",
      "val epoch: 173 [128/221852 (0%)]\tLoss: 0.252320\tAcc: 70.00\n",
      "val epoch: 173 [12928/221852 (6%)]\tLoss: 0.203136\tAcc: 77.00\n",
      "train epoch: 174 [128/221852 (0%)]\tLoss: 0.126241\tAcc: 84.00\n",
      "train epoch: 174 [12928/221852 (6%)]\tLoss: 0.168909\tAcc: 80.00\n",
      "train epoch: 174 [25728/221852 (12%)]\tLoss: 0.211829\tAcc: 74.00\n",
      "train epoch: 174 [38528/221852 (17%)]\tLoss: 0.180522\tAcc: 77.00\n",
      "train epoch: 174 [51328/221852 (23%)]\tLoss: 0.210856\tAcc: 87.00\n",
      "train epoch: 174 [64128/221852 (29%)]\tLoss: 0.177303\tAcc: 85.00\n",
      "train epoch: 174 [76928/221852 (35%)]\tLoss: 0.210346\tAcc: 73.00\n",
      "train epoch: 174 [89728/221852 (40%)]\tLoss: 0.254688\tAcc: 77.00\n",
      "train epoch: 174 [102528/221852 (46%)]\tLoss: 0.150978\tAcc: 79.00\n",
      "train epoch: 174 [115328/221852 (52%)]\tLoss: 0.219350\tAcc: 82.00\n",
      "train epoch: 174 [128128/221852 (58%)]\tLoss: 0.288800\tAcc: 74.00\n",
      "train epoch: 174 [140928/221852 (64%)]\tLoss: 0.131669\tAcc: 77.00\n",
      "train epoch: 174 [153728/221852 (69%)]\tLoss: 0.160094\tAcc: 80.00\n",
      "train epoch: 174 [166528/221852 (75%)]\tLoss: 0.138091\tAcc: 81.00\n",
      "train epoch: 174 [179328/221852 (81%)]\tLoss: 0.149622\tAcc: 80.00\n",
      "train epoch: 174 [192128/221852 (87%)]\tLoss: 0.245670\tAcc: 77.00\n",
      "val epoch: 174 [128/221852 (0%)]\tLoss: 0.265741\tAcc: 73.00\n",
      "val epoch: 174 [12928/221852 (6%)]\tLoss: 0.213409\tAcc: 76.00\n",
      "train epoch: 175 [128/221852 (0%)]\tLoss: 0.254354\tAcc: 70.00\n",
      "train epoch: 175 [12928/221852 (6%)]\tLoss: 0.198582\tAcc: 77.00\n",
      "train epoch: 175 [25728/221852 (12%)]\tLoss: 0.236199\tAcc: 77.00\n",
      "train epoch: 175 [38528/221852 (17%)]\tLoss: 0.245278\tAcc: 77.00\n",
      "train epoch: 175 [51328/221852 (23%)]\tLoss: 0.203616\tAcc: 78.00\n",
      "train epoch: 175 [64128/221852 (29%)]\tLoss: 0.204206\tAcc: 78.00\n",
      "train epoch: 175 [76928/221852 (35%)]\tLoss: 0.233854\tAcc: 77.00\n",
      "train epoch: 175 [89728/221852 (40%)]\tLoss: 0.167658\tAcc: 81.00\n",
      "train epoch: 175 [102528/221852 (46%)]\tLoss: 0.158113\tAcc: 78.00\n",
      "train epoch: 175 [115328/221852 (52%)]\tLoss: 0.162457\tAcc: 77.00\n",
      "train epoch: 175 [128128/221852 (58%)]\tLoss: 0.227739\tAcc: 77.00\n",
      "train epoch: 175 [140928/221852 (64%)]\tLoss: 0.135010\tAcc: 86.00\n",
      "train epoch: 175 [153728/221852 (69%)]\tLoss: 0.265582\tAcc: 76.00\n",
      "train epoch: 175 [166528/221852 (75%)]\tLoss: 0.134923\tAcc: 74.00\n",
      "train epoch: 175 [179328/221852 (81%)]\tLoss: 0.292605\tAcc: 76.00\n",
      "train epoch: 175 [192128/221852 (87%)]\tLoss: 0.216017\tAcc: 81.00\n",
      "val epoch: 175 [128/221852 (0%)]\tLoss: 0.189696\tAcc: 73.00\n",
      "val epoch: 175 [12928/221852 (6%)]\tLoss: 0.353135\tAcc: 73.00\n",
      "train epoch: 176 [128/221852 (0%)]\tLoss: 0.246710\tAcc: 74.00\n",
      "train epoch: 176 [12928/221852 (6%)]\tLoss: 0.320947\tAcc: 71.00\n",
      "train epoch: 176 [25728/221852 (12%)]\tLoss: 0.200141\tAcc: 70.00\n",
      "train epoch: 176 [38528/221852 (17%)]\tLoss: 0.243309\tAcc: 74.00\n",
      "train epoch: 176 [51328/221852 (23%)]\tLoss: 0.226907\tAcc: 76.00\n",
      "train epoch: 176 [64128/221852 (29%)]\tLoss: 0.217128\tAcc: 77.00\n",
      "train epoch: 176 [76928/221852 (35%)]\tLoss: 0.290181\tAcc: 73.00\n",
      "train epoch: 176 [89728/221852 (40%)]\tLoss: 0.179878\tAcc: 77.00\n",
      "train epoch: 176 [102528/221852 (46%)]\tLoss: 0.179637\tAcc: 80.00\n",
      "train epoch: 176 [115328/221852 (52%)]\tLoss: 0.226994\tAcc: 77.00\n",
      "train epoch: 176 [128128/221852 (58%)]\tLoss: 0.231858\tAcc: 71.00\n",
      "train epoch: 176 [140928/221852 (64%)]\tLoss: 0.166770\tAcc: 80.00\n",
      "train epoch: 176 [153728/221852 (69%)]\tLoss: 0.225343\tAcc: 78.00\n",
      "train epoch: 176 [166528/221852 (75%)]\tLoss: 0.236151\tAcc: 80.00\n",
      "train epoch: 176 [179328/221852 (81%)]\tLoss: 0.259963\tAcc: 74.00\n",
      "train epoch: 176 [192128/221852 (87%)]\tLoss: 0.200760\tAcc: 76.00\n",
      "val epoch: 176 [128/221852 (0%)]\tLoss: 0.214869\tAcc: 78.00\n",
      "val epoch: 176 [12928/221852 (6%)]\tLoss: 0.261516\tAcc: 73.00\n",
      "train epoch: 177 [128/221852 (0%)]\tLoss: 0.143799\tAcc: 81.00\n",
      "train epoch: 177 [12928/221852 (6%)]\tLoss: 0.246999\tAcc: 74.00\n",
      "train epoch: 177 [25728/221852 (12%)]\tLoss: 0.160481\tAcc: 77.00\n",
      "train epoch: 177 [38528/221852 (17%)]\tLoss: 0.254416\tAcc: 80.00\n",
      "train epoch: 177 [51328/221852 (23%)]\tLoss: 0.255369\tAcc: 70.00\n",
      "train epoch: 177 [64128/221852 (29%)]\tLoss: 0.241467\tAcc: 69.00\n",
      "train epoch: 177 [76928/221852 (35%)]\tLoss: 0.195414\tAcc: 76.00\n",
      "train epoch: 177 [89728/221852 (40%)]\tLoss: 0.115185\tAcc: 86.00\n",
      "train epoch: 177 [102528/221852 (46%)]\tLoss: 0.245808\tAcc: 70.00\n",
      "train epoch: 177 [115328/221852 (52%)]\tLoss: 0.299577\tAcc: 75.00\n",
      "train epoch: 177 [128128/221852 (58%)]\tLoss: 0.156027\tAcc: 73.00\n",
      "train epoch: 177 [140928/221852 (64%)]\tLoss: 0.172211\tAcc: 84.00\n",
      "train epoch: 177 [153728/221852 (69%)]\tLoss: 0.170182\tAcc: 84.00\n",
      "train epoch: 177 [166528/221852 (75%)]\tLoss: 0.239177\tAcc: 70.00\n",
      "train epoch: 177 [179328/221852 (81%)]\tLoss: 0.234775\tAcc: 74.00\n",
      "train epoch: 177 [192128/221852 (87%)]\tLoss: 0.291511\tAcc: 85.00\n",
      "val epoch: 177 [128/221852 (0%)]\tLoss: 0.127253\tAcc: 81.00\n",
      "val epoch: 177 [12928/221852 (6%)]\tLoss: 0.173663\tAcc: 77.00\n",
      "train epoch: 178 [128/221852 (0%)]\tLoss: 0.160576\tAcc: 74.00\n",
      "train epoch: 178 [12928/221852 (6%)]\tLoss: 0.257660\tAcc: 77.00\n",
      "train epoch: 178 [25728/221852 (12%)]\tLoss: 0.228865\tAcc: 77.00\n",
      "train epoch: 178 [38528/221852 (17%)]\tLoss: 0.245884\tAcc: 77.00\n",
      "train epoch: 178 [51328/221852 (23%)]\tLoss: 0.188403\tAcc: 75.00\n",
      "train epoch: 178 [64128/221852 (29%)]\tLoss: 0.338689\tAcc: 70.00\n",
      "train epoch: 178 [76928/221852 (35%)]\tLoss: 0.206485\tAcc: 83.00\n",
      "train epoch: 178 [89728/221852 (40%)]\tLoss: 0.255625\tAcc: 67.00\n",
      "train epoch: 178 [102528/221852 (46%)]\tLoss: 0.145346\tAcc: 77.00\n",
      "train epoch: 178 [115328/221852 (52%)]\tLoss: 0.132656\tAcc: 80.00\n",
      "train epoch: 178 [128128/221852 (58%)]\tLoss: 0.171805\tAcc: 77.00\n",
      "train epoch: 178 [140928/221852 (64%)]\tLoss: 0.189692\tAcc: 80.00\n",
      "train epoch: 178 [153728/221852 (69%)]\tLoss: 0.201716\tAcc: 73.00\n",
      "train epoch: 178 [166528/221852 (75%)]\tLoss: 0.164850\tAcc: 80.00\n",
      "train epoch: 178 [179328/221852 (81%)]\tLoss: 0.338629\tAcc: 74.00\n",
      "train epoch: 178 [192128/221852 (87%)]\tLoss: 0.190665\tAcc: 70.00\n",
      "val epoch: 178 [128/221852 (0%)]\tLoss: 0.215908\tAcc: 83.00\n",
      "val epoch: 178 [12928/221852 (6%)]\tLoss: 0.164797\tAcc: 76.00\n",
      "train epoch: 179 [128/221852 (0%)]\tLoss: 0.154913\tAcc: 83.00\n",
      "train epoch: 179 [12928/221852 (6%)]\tLoss: 0.203415\tAcc: 80.00\n",
      "train epoch: 179 [25728/221852 (12%)]\tLoss: 0.146619\tAcc: 76.00\n",
      "train epoch: 179 [38528/221852 (17%)]\tLoss: 0.191465\tAcc: 80.00\n",
      "train epoch: 179 [51328/221852 (23%)]\tLoss: 0.197974\tAcc: 76.00\n",
      "train epoch: 179 [64128/221852 (29%)]\tLoss: 0.164131\tAcc: 82.00\n",
      "train epoch: 179 [76928/221852 (35%)]\tLoss: 0.199051\tAcc: 75.00\n",
      "train epoch: 179 [89728/221852 (40%)]\tLoss: 0.263227\tAcc: 73.00\n",
      "train epoch: 179 [102528/221852 (46%)]\tLoss: 0.217419\tAcc: 76.00\n",
      "train epoch: 179 [115328/221852 (52%)]\tLoss: 0.152732\tAcc: 78.00\n",
      "train epoch: 179 [128128/221852 (58%)]\tLoss: 0.214548\tAcc: 83.00\n",
      "train epoch: 179 [140928/221852 (64%)]\tLoss: 0.202954\tAcc: 74.00\n",
      "train epoch: 179 [153728/221852 (69%)]\tLoss: 0.173999\tAcc: 79.00\n",
      "train epoch: 179 [166528/221852 (75%)]\tLoss: 0.216155\tAcc: 79.00\n",
      "train epoch: 179 [179328/221852 (81%)]\tLoss: 0.242414\tAcc: 73.00\n",
      "train epoch: 179 [192128/221852 (87%)]\tLoss: 0.123691\tAcc: 80.00\n",
      "val epoch: 179 [128/221852 (0%)]\tLoss: 0.175751\tAcc: 82.00\n",
      "val epoch: 179 [12928/221852 (6%)]\tLoss: 0.210939\tAcc: 88.00\n",
      "train epoch: 180 [128/221852 (0%)]\tLoss: 0.172189\tAcc: 80.00\n",
      "train epoch: 180 [12928/221852 (6%)]\tLoss: 0.153696\tAcc: 80.00\n",
      "train epoch: 180 [25728/221852 (12%)]\tLoss: 0.244742\tAcc: 80.00\n",
      "train epoch: 180 [38528/221852 (17%)]\tLoss: 0.317888\tAcc: 71.00\n",
      "train epoch: 180 [51328/221852 (23%)]\tLoss: 0.270923\tAcc: 75.00\n",
      "train epoch: 180 [64128/221852 (29%)]\tLoss: 0.174991\tAcc: 77.00\n",
      "train epoch: 180 [76928/221852 (35%)]\tLoss: 0.210959\tAcc: 78.00\n",
      "train epoch: 180 [89728/221852 (40%)]\tLoss: 0.174119\tAcc: 80.00\n",
      "train epoch: 180 [102528/221852 (46%)]\tLoss: 0.249406\tAcc: 84.00\n",
      "train epoch: 180 [115328/221852 (52%)]\tLoss: 0.140609\tAcc: 78.00\n",
      "train epoch: 180 [128128/221852 (58%)]\tLoss: 0.272800\tAcc: 77.00\n",
      "train epoch: 180 [140928/221852 (64%)]\tLoss: 0.260587\tAcc: 75.00\n",
      "train epoch: 180 [153728/221852 (69%)]\tLoss: 0.238617\tAcc: 80.00\n",
      "train epoch: 180 [166528/221852 (75%)]\tLoss: 0.249689\tAcc: 74.00\n",
      "train epoch: 180 [179328/221852 (81%)]\tLoss: 0.094270\tAcc: 81.00\n",
      "train epoch: 180 [192128/221852 (87%)]\tLoss: 0.242770\tAcc: 79.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 180 [128/221852 (0%)]\tLoss: 0.279630\tAcc: 73.00\n",
      "val epoch: 180 [12928/221852 (6%)]\tLoss: 0.251519\tAcc: 72.00\n",
      "train epoch: 181 [128/221852 (0%)]\tLoss: 0.250522\tAcc: 73.00\n",
      "train epoch: 181 [12928/221852 (6%)]\tLoss: 0.149620\tAcc: 75.00\n",
      "train epoch: 181 [25728/221852 (12%)]\tLoss: 0.226905\tAcc: 79.00\n",
      "train epoch: 181 [38528/221852 (17%)]\tLoss: 0.150785\tAcc: 81.00\n",
      "train epoch: 181 [51328/221852 (23%)]\tLoss: 0.233342\tAcc: 71.00\n",
      "train epoch: 181 [64128/221852 (29%)]\tLoss: 0.317559\tAcc: 76.00\n",
      "train epoch: 181 [76928/221852 (35%)]\tLoss: 0.234042\tAcc: 70.00\n",
      "train epoch: 181 [89728/221852 (40%)]\tLoss: 0.226365\tAcc: 75.00\n",
      "train epoch: 181 [102528/221852 (46%)]\tLoss: 0.259968\tAcc: 77.00\n",
      "train epoch: 181 [115328/221852 (52%)]\tLoss: 0.173639\tAcc: 73.00\n",
      "train epoch: 181 [128128/221852 (58%)]\tLoss: 0.165804\tAcc: 78.00\n",
      "train epoch: 181 [140928/221852 (64%)]\tLoss: 0.316208\tAcc: 70.00\n",
      "train epoch: 181 [153728/221852 (69%)]\tLoss: 0.236988\tAcc: 76.00\n",
      "train epoch: 181 [166528/221852 (75%)]\tLoss: 0.218920\tAcc: 75.00\n",
      "train epoch: 181 [179328/221852 (81%)]\tLoss: 0.277853\tAcc: 78.00\n",
      "train epoch: 181 [192128/221852 (87%)]\tLoss: 0.191700\tAcc: 76.00\n",
      "val epoch: 181 [128/221852 (0%)]\tLoss: 0.224431\tAcc: 73.00\n",
      "val epoch: 181 [12928/221852 (6%)]\tLoss: 0.254023\tAcc: 77.00\n",
      "train epoch: 182 [128/221852 (0%)]\tLoss: 0.239589\tAcc: 81.00\n",
      "train epoch: 182 [12928/221852 (6%)]\tLoss: 0.176985\tAcc: 76.00\n",
      "train epoch: 182 [25728/221852 (12%)]\tLoss: 0.302651\tAcc: 75.00\n",
      "train epoch: 182 [38528/221852 (17%)]\tLoss: 0.149566\tAcc: 81.00\n",
      "train epoch: 182 [51328/221852 (23%)]\tLoss: 0.184245\tAcc: 79.00\n",
      "train epoch: 182 [64128/221852 (29%)]\tLoss: 0.240872\tAcc: 75.00\n",
      "train epoch: 182 [76928/221852 (35%)]\tLoss: 0.232775\tAcc: 70.00\n",
      "train epoch: 182 [89728/221852 (40%)]\tLoss: 0.187531\tAcc: 71.00\n",
      "train epoch: 182 [102528/221852 (46%)]\tLoss: 0.163685\tAcc: 81.00\n",
      "train epoch: 182 [115328/221852 (52%)]\tLoss: 0.247970\tAcc: 74.00\n",
      "train epoch: 182 [128128/221852 (58%)]\tLoss: 0.244623\tAcc: 79.00\n",
      "train epoch: 182 [140928/221852 (64%)]\tLoss: 0.263105\tAcc: 81.00\n",
      "train epoch: 182 [153728/221852 (69%)]\tLoss: 0.168305\tAcc: 80.00\n",
      "train epoch: 182 [166528/221852 (75%)]\tLoss: 0.311985\tAcc: 76.00\n",
      "train epoch: 182 [179328/221852 (81%)]\tLoss: 0.171626\tAcc: 80.00\n",
      "train epoch: 182 [192128/221852 (87%)]\tLoss: 0.126008\tAcc: 83.00\n",
      "val epoch: 182 [128/221852 (0%)]\tLoss: 0.260658\tAcc: 75.00\n",
      "val epoch: 182 [12928/221852 (6%)]\tLoss: 0.269314\tAcc: 77.00\n",
      "train epoch: 183 [128/221852 (0%)]\tLoss: 0.204848\tAcc: 71.00\n",
      "train epoch: 183 [12928/221852 (6%)]\tLoss: 0.194354\tAcc: 82.00\n",
      "train epoch: 183 [25728/221852 (12%)]\tLoss: 0.173777\tAcc: 81.00\n",
      "train epoch: 183 [38528/221852 (17%)]\tLoss: 0.234164\tAcc: 78.00\n",
      "train epoch: 183 [51328/221852 (23%)]\tLoss: 0.254976\tAcc: 78.00\n",
      "train epoch: 183 [64128/221852 (29%)]\tLoss: 0.239954\tAcc: 74.00\n",
      "train epoch: 183 [76928/221852 (35%)]\tLoss: 0.151297\tAcc: 80.00\n",
      "train epoch: 183 [89728/221852 (40%)]\tLoss: 0.203040\tAcc: 73.00\n",
      "train epoch: 183 [102528/221852 (46%)]\tLoss: 0.156018\tAcc: 84.00\n",
      "train epoch: 183 [115328/221852 (52%)]\tLoss: 0.213789\tAcc: 75.00\n",
      "train epoch: 183 [128128/221852 (58%)]\tLoss: 0.111665\tAcc: 86.00\n",
      "train epoch: 183 [140928/221852 (64%)]\tLoss: 0.269666\tAcc: 75.00\n",
      "train epoch: 183 [153728/221852 (69%)]\tLoss: 0.224793\tAcc: 83.00\n",
      "train epoch: 183 [166528/221852 (75%)]\tLoss: 0.179389\tAcc: 83.00\n",
      "train epoch: 183 [179328/221852 (81%)]\tLoss: 0.108308\tAcc: 82.00\n",
      "train epoch: 183 [192128/221852 (87%)]\tLoss: 0.207738\tAcc: 78.00\n",
      "val epoch: 183 [128/221852 (0%)]\tLoss: 0.182457\tAcc: 83.00\n",
      "val epoch: 183 [12928/221852 (6%)]\tLoss: 0.208085\tAcc: 76.00\n",
      "train epoch: 184 [128/221852 (0%)]\tLoss: 0.228452\tAcc: 77.00\n",
      "train epoch: 184 [12928/221852 (6%)]\tLoss: 0.188749\tAcc: 80.00\n",
      "train epoch: 184 [25728/221852 (12%)]\tLoss: 0.138071\tAcc: 82.00\n",
      "train epoch: 184 [38528/221852 (17%)]\tLoss: 0.242326\tAcc: 74.00\n",
      "train epoch: 184 [51328/221852 (23%)]\tLoss: 0.184126\tAcc: 81.00\n",
      "train epoch: 184 [64128/221852 (29%)]\tLoss: 0.157897\tAcc: 79.00\n",
      "train epoch: 184 [76928/221852 (35%)]\tLoss: 0.211701\tAcc: 83.00\n",
      "train epoch: 184 [89728/221852 (40%)]\tLoss: 0.276312\tAcc: 82.00\n",
      "train epoch: 184 [102528/221852 (46%)]\tLoss: 0.216917\tAcc: 75.00\n",
      "train epoch: 184 [115328/221852 (52%)]\tLoss: 0.136685\tAcc: 77.00\n",
      "train epoch: 184 [128128/221852 (58%)]\tLoss: 0.215872\tAcc: 76.00\n",
      "train epoch: 184 [140928/221852 (64%)]\tLoss: 0.271262\tAcc: 78.00\n",
      "train epoch: 184 [153728/221852 (69%)]\tLoss: 0.210648\tAcc: 76.00\n",
      "train epoch: 184 [166528/221852 (75%)]\tLoss: 0.226955\tAcc: 70.00\n",
      "train epoch: 184 [179328/221852 (81%)]\tLoss: 0.200480\tAcc: 76.00\n",
      "train epoch: 184 [192128/221852 (87%)]\tLoss: 0.205324\tAcc: 75.00\n",
      "val epoch: 184 [128/221852 (0%)]\tLoss: 0.146829\tAcc: 77.00\n",
      "val epoch: 184 [12928/221852 (6%)]\tLoss: 0.146724\tAcc: 71.00\n",
      "train epoch: 185 [128/221852 (0%)]\tLoss: 0.188692\tAcc: 84.00\n",
      "train epoch: 185 [12928/221852 (6%)]\tLoss: 0.262471\tAcc: 77.00\n",
      "train epoch: 185 [25728/221852 (12%)]\tLoss: 0.209637\tAcc: 74.00\n",
      "train epoch: 185 [38528/221852 (17%)]\tLoss: 0.212273\tAcc: 78.00\n",
      "train epoch: 185 [51328/221852 (23%)]\tLoss: 0.162682\tAcc: 77.00\n",
      "train epoch: 185 [64128/221852 (29%)]\tLoss: 0.155221\tAcc: 81.00\n",
      "train epoch: 185 [76928/221852 (35%)]\tLoss: 0.222021\tAcc: 74.00\n",
      "train epoch: 185 [89728/221852 (40%)]\tLoss: 0.303764\tAcc: 73.00\n",
      "train epoch: 185 [102528/221852 (46%)]\tLoss: 0.214892\tAcc: 76.00\n",
      "train epoch: 185 [115328/221852 (52%)]\tLoss: 0.186546\tAcc: 84.00\n",
      "train epoch: 185 [128128/221852 (58%)]\tLoss: 0.135262\tAcc: 80.00\n",
      "train epoch: 185 [140928/221852 (64%)]\tLoss: 0.201431\tAcc: 74.00\n",
      "train epoch: 185 [153728/221852 (69%)]\tLoss: 0.178628\tAcc: 79.00\n",
      "train epoch: 185 [166528/221852 (75%)]\tLoss: 0.252017\tAcc: 76.00\n",
      "train epoch: 185 [179328/221852 (81%)]\tLoss: 0.202549\tAcc: 73.00\n",
      "train epoch: 185 [192128/221852 (87%)]\tLoss: 0.164536\tAcc: 76.00\n",
      "val epoch: 185 [128/221852 (0%)]\tLoss: 0.194633\tAcc: 80.00\n",
      "val epoch: 185 [12928/221852 (6%)]\tLoss: 0.192956\tAcc: 74.00\n",
      "train epoch: 186 [128/221852 (0%)]\tLoss: 0.163684\tAcc: 74.00\n",
      "train epoch: 186 [12928/221852 (6%)]\tLoss: 0.108906\tAcc: 79.00\n",
      "train epoch: 186 [25728/221852 (12%)]\tLoss: 0.159422\tAcc: 78.00\n",
      "train epoch: 186 [38528/221852 (17%)]\tLoss: 0.221661\tAcc: 73.00\n",
      "train epoch: 186 [51328/221852 (23%)]\tLoss: 0.165654\tAcc: 77.00\n",
      "train epoch: 186 [64128/221852 (29%)]\tLoss: 0.287510\tAcc: 78.00\n",
      "train epoch: 186 [76928/221852 (35%)]\tLoss: 0.186312\tAcc: 74.00\n",
      "train epoch: 186 [89728/221852 (40%)]\tLoss: 0.149562\tAcc: 79.00\n",
      "train epoch: 186 [102528/221852 (46%)]\tLoss: 0.273951\tAcc: 71.00\n",
      "train epoch: 186 [115328/221852 (52%)]\tLoss: 0.160712\tAcc: 80.00\n",
      "train epoch: 186 [128128/221852 (58%)]\tLoss: 0.139133\tAcc: 84.00\n",
      "train epoch: 186 [140928/221852 (64%)]\tLoss: 0.200621\tAcc: 76.00\n",
      "train epoch: 186 [153728/221852 (69%)]\tLoss: 0.168331\tAcc: 82.00\n",
      "train epoch: 186 [166528/221852 (75%)]\tLoss: 0.305168\tAcc: 77.00\n",
      "train epoch: 186 [179328/221852 (81%)]\tLoss: 0.177375\tAcc: 78.00\n",
      "train epoch: 186 [192128/221852 (87%)]\tLoss: 0.229565\tAcc: 80.00\n",
      "val epoch: 186 [128/221852 (0%)]\tLoss: 0.184185\tAcc: 69.00\n",
      "val epoch: 186 [12928/221852 (6%)]\tLoss: 0.194149\tAcc: 76.00\n",
      "train epoch: 187 [128/221852 (0%)]\tLoss: 0.195355\tAcc: 80.00\n",
      "train epoch: 187 [12928/221852 (6%)]\tLoss: 0.147927\tAcc: 79.00\n",
      "train epoch: 187 [25728/221852 (12%)]\tLoss: 0.179275\tAcc: 82.00\n",
      "train epoch: 187 [38528/221852 (17%)]\tLoss: 0.304412\tAcc: 73.00\n",
      "train epoch: 187 [51328/221852 (23%)]\tLoss: 0.359174\tAcc: 75.00\n",
      "train epoch: 187 [64128/221852 (29%)]\tLoss: 0.214231\tAcc: 70.00\n",
      "train epoch: 187 [76928/221852 (35%)]\tLoss: 0.131243\tAcc: 88.00\n",
      "train epoch: 187 [89728/221852 (40%)]\tLoss: 0.253080\tAcc: 80.00\n",
      "train epoch: 187 [102528/221852 (46%)]\tLoss: 0.287765\tAcc: 81.00\n",
      "train epoch: 187 [115328/221852 (52%)]\tLoss: 0.216614\tAcc: 72.00\n",
      "train epoch: 187 [128128/221852 (58%)]\tLoss: 0.197538\tAcc: 78.00\n",
      "train epoch: 187 [140928/221852 (64%)]\tLoss: 0.128707\tAcc: 79.00\n",
      "train epoch: 187 [153728/221852 (69%)]\tLoss: 0.190192\tAcc: 76.00\n",
      "train epoch: 187 [166528/221852 (75%)]\tLoss: 0.172870\tAcc: 80.00\n",
      "train epoch: 187 [179328/221852 (81%)]\tLoss: 0.357878\tAcc: 77.00\n",
      "train epoch: 187 [192128/221852 (87%)]\tLoss: 0.311092\tAcc: 74.00\n",
      "val epoch: 187 [128/221852 (0%)]\tLoss: 0.145568\tAcc: 77.00\n",
      "val epoch: 187 [12928/221852 (6%)]\tLoss: 0.203413\tAcc: 76.00\n",
      "train epoch: 188 [128/221852 (0%)]\tLoss: 0.210798\tAcc: 69.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 188 [12928/221852 (6%)]\tLoss: 0.240140\tAcc: 74.00\n",
      "train epoch: 188 [25728/221852 (12%)]\tLoss: 0.267136\tAcc: 75.00\n",
      "train epoch: 188 [38528/221852 (17%)]\tLoss: 0.206437\tAcc: 75.00\n",
      "train epoch: 188 [51328/221852 (23%)]\tLoss: 0.244485\tAcc: 79.00\n",
      "train epoch: 188 [64128/221852 (29%)]\tLoss: 0.151350\tAcc: 77.00\n",
      "train epoch: 188 [76928/221852 (35%)]\tLoss: 0.289881\tAcc: 70.00\n",
      "train epoch: 188 [89728/221852 (40%)]\tLoss: 0.119414\tAcc: 80.00\n",
      "train epoch: 188 [102528/221852 (46%)]\tLoss: 0.233991\tAcc: 79.00\n",
      "train epoch: 188 [115328/221852 (52%)]\tLoss: 0.423454\tAcc: 75.00\n",
      "train epoch: 188 [128128/221852 (58%)]\tLoss: 0.244060\tAcc: 77.00\n",
      "train epoch: 188 [140928/221852 (64%)]\tLoss: 0.185604\tAcc: 72.00\n",
      "train epoch: 188 [153728/221852 (69%)]\tLoss: 0.189321\tAcc: 70.00\n",
      "train epoch: 188 [166528/221852 (75%)]\tLoss: 0.241791\tAcc: 77.00\n",
      "train epoch: 188 [179328/221852 (81%)]\tLoss: 0.282013\tAcc: 74.00\n",
      "train epoch: 188 [192128/221852 (87%)]\tLoss: 0.155067\tAcc: 80.00\n",
      "val epoch: 188 [128/221852 (0%)]\tLoss: 0.194732\tAcc: 71.00\n",
      "val epoch: 188 [12928/221852 (6%)]\tLoss: 0.129654\tAcc: 79.00\n",
      "train epoch: 189 [128/221852 (0%)]\tLoss: 0.246815\tAcc: 70.00\n",
      "train epoch: 189 [12928/221852 (6%)]\tLoss: 0.170859\tAcc: 77.00\n",
      "train epoch: 189 [25728/221852 (12%)]\tLoss: 0.154570\tAcc: 78.00\n",
      "train epoch: 189 [38528/221852 (17%)]\tLoss: 0.208205\tAcc: 76.00\n",
      "train epoch: 189 [51328/221852 (23%)]\tLoss: 0.231739\tAcc: 79.00\n",
      "train epoch: 189 [64128/221852 (29%)]\tLoss: 0.362014\tAcc: 78.00\n",
      "train epoch: 189 [76928/221852 (35%)]\tLoss: 0.214276\tAcc: 82.00\n",
      "train epoch: 189 [89728/221852 (40%)]\tLoss: 0.185693\tAcc: 74.00\n",
      "train epoch: 189 [102528/221852 (46%)]\tLoss: 0.175789\tAcc: 82.00\n",
      "train epoch: 189 [115328/221852 (52%)]\tLoss: 0.168436\tAcc: 81.00\n",
      "train epoch: 189 [128128/221852 (58%)]\tLoss: 0.184230\tAcc: 84.00\n",
      "train epoch: 189 [140928/221852 (64%)]\tLoss: 0.260492\tAcc: 80.00\n",
      "train epoch: 189 [153728/221852 (69%)]\tLoss: 0.245219\tAcc: 73.00\n",
      "train epoch: 189 [166528/221852 (75%)]\tLoss: 0.100459\tAcc: 80.00\n",
      "train epoch: 189 [179328/221852 (81%)]\tLoss: 0.258312\tAcc: 77.00\n",
      "train epoch: 189 [192128/221852 (87%)]\tLoss: 0.220617\tAcc: 77.00\n",
      "val epoch: 189 [128/221852 (0%)]\tLoss: 0.142677\tAcc: 80.00\n",
      "val epoch: 189 [12928/221852 (6%)]\tLoss: 0.152975\tAcc: 78.00\n",
      "train epoch: 190 [128/221852 (0%)]\tLoss: 0.142959\tAcc: 87.00\n",
      "train epoch: 190 [12928/221852 (6%)]\tLoss: 0.293516\tAcc: 74.00\n",
      "train epoch: 190 [25728/221852 (12%)]\tLoss: 0.142288\tAcc: 81.00\n",
      "train epoch: 190 [38528/221852 (17%)]\tLoss: 0.177932\tAcc: 72.00\n",
      "train epoch: 190 [51328/221852 (23%)]\tLoss: 0.171774\tAcc: 79.00\n",
      "train epoch: 190 [64128/221852 (29%)]\tLoss: 0.181115\tAcc: 78.00\n",
      "train epoch: 190 [76928/221852 (35%)]\tLoss: 0.281532\tAcc: 84.00\n",
      "train epoch: 190 [89728/221852 (40%)]\tLoss: 0.185930\tAcc: 77.00\n",
      "train epoch: 190 [102528/221852 (46%)]\tLoss: 0.274973\tAcc: 72.00\n",
      "train epoch: 190 [115328/221852 (52%)]\tLoss: 0.189698\tAcc: 77.00\n",
      "train epoch: 190 [128128/221852 (58%)]\tLoss: 0.223724\tAcc: 80.00\n",
      "train epoch: 190 [140928/221852 (64%)]\tLoss: 0.207840\tAcc: 82.00\n",
      "train epoch: 190 [153728/221852 (69%)]\tLoss: 0.156846\tAcc: 82.00\n",
      "train epoch: 190 [166528/221852 (75%)]\tLoss: 0.176838\tAcc: 82.00\n",
      "train epoch: 190 [179328/221852 (81%)]\tLoss: 0.170764\tAcc: 79.00\n",
      "train epoch: 190 [192128/221852 (87%)]\tLoss: 0.165912\tAcc: 77.00\n",
      "val epoch: 190 [128/221852 (0%)]\tLoss: 0.242133\tAcc: 76.00\n",
      "val epoch: 190 [12928/221852 (6%)]\tLoss: 0.237345\tAcc: 80.00\n",
      "train epoch: 191 [128/221852 (0%)]\tLoss: 0.176397\tAcc: 77.00\n",
      "train epoch: 191 [12928/221852 (6%)]\tLoss: 0.179623\tAcc: 84.00\n",
      "train epoch: 191 [25728/221852 (12%)]\tLoss: 0.204569\tAcc: 76.00\n",
      "train epoch: 191 [38528/221852 (17%)]\tLoss: 0.262456\tAcc: 78.00\n",
      "train epoch: 191 [51328/221852 (23%)]\tLoss: 0.262928\tAcc: 88.00\n",
      "train epoch: 191 [64128/221852 (29%)]\tLoss: 0.287064\tAcc: 77.00\n",
      "train epoch: 191 [76928/221852 (35%)]\tLoss: 0.193098\tAcc: 77.00\n",
      "train epoch: 191 [89728/221852 (40%)]\tLoss: 0.158981\tAcc: 73.00\n",
      "train epoch: 191 [102528/221852 (46%)]\tLoss: 0.256908\tAcc: 70.00\n",
      "train epoch: 191 [115328/221852 (52%)]\tLoss: 0.149636\tAcc: 80.00\n",
      "train epoch: 191 [128128/221852 (58%)]\tLoss: 0.192064\tAcc: 78.00\n",
      "train epoch: 191 [140928/221852 (64%)]\tLoss: 0.314083\tAcc: 68.00\n",
      "train epoch: 191 [153728/221852 (69%)]\tLoss: 0.153513\tAcc: 83.00\n",
      "train epoch: 191 [166528/221852 (75%)]\tLoss: 0.163659\tAcc: 78.00\n",
      "train epoch: 191 [179328/221852 (81%)]\tLoss: 0.280958\tAcc: 80.00\n",
      "train epoch: 191 [192128/221852 (87%)]\tLoss: 0.283606\tAcc: 79.00\n",
      "val epoch: 191 [128/221852 (0%)]\tLoss: 0.205024\tAcc: 77.00\n",
      "val epoch: 191 [12928/221852 (6%)]\tLoss: 0.156312\tAcc: 77.00\n",
      "train epoch: 192 [128/221852 (0%)]\tLoss: 0.233776\tAcc: 73.00\n",
      "train epoch: 192 [12928/221852 (6%)]\tLoss: 0.271876\tAcc: 76.00\n",
      "train epoch: 192 [25728/221852 (12%)]\tLoss: 0.159640\tAcc: 82.00\n",
      "train epoch: 192 [38528/221852 (17%)]\tLoss: 0.146645\tAcc: 78.00\n",
      "train epoch: 192 [51328/221852 (23%)]\tLoss: 0.243208\tAcc: 76.00\n",
      "train epoch: 192 [64128/221852 (29%)]\tLoss: 0.165458\tAcc: 72.00\n",
      "train epoch: 192 [76928/221852 (35%)]\tLoss: 0.163367\tAcc: 75.00\n",
      "train epoch: 192 [89728/221852 (40%)]\tLoss: 0.150312\tAcc: 82.00\n",
      "train epoch: 192 [102528/221852 (46%)]\tLoss: 0.250625\tAcc: 84.00\n",
      "train epoch: 192 [115328/221852 (52%)]\tLoss: 0.202504\tAcc: 85.00\n",
      "train epoch: 192 [128128/221852 (58%)]\tLoss: 0.204229\tAcc: 77.00\n",
      "train epoch: 192 [140928/221852 (64%)]\tLoss: 0.169530\tAcc: 77.00\n",
      "train epoch: 192 [153728/221852 (69%)]\tLoss: 0.154457\tAcc: 87.00\n",
      "train epoch: 192 [166528/221852 (75%)]\tLoss: 0.188664\tAcc: 83.00\n",
      "train epoch: 192 [179328/221852 (81%)]\tLoss: 0.223044\tAcc: 76.00\n",
      "train epoch: 192 [192128/221852 (87%)]\tLoss: 0.875943\tAcc: 74.00\n",
      "val epoch: 192 [128/221852 (0%)]\tLoss: 0.301670\tAcc: 73.00\n",
      "val epoch: 192 [12928/221852 (6%)]\tLoss: 0.325330\tAcc: 67.00\n",
      "train epoch: 193 [128/221852 (0%)]\tLoss: 0.198248\tAcc: 73.00\n",
      "train epoch: 193 [12928/221852 (6%)]\tLoss: 0.232940\tAcc: 74.00\n",
      "train epoch: 193 [25728/221852 (12%)]\tLoss: 0.196528\tAcc: 71.00\n",
      "train epoch: 193 [38528/221852 (17%)]\tLoss: 0.221497\tAcc: 83.00\n",
      "train epoch: 193 [51328/221852 (23%)]\tLoss: 0.235117\tAcc: 83.00\n",
      "train epoch: 193 [64128/221852 (29%)]\tLoss: 0.173352\tAcc: 83.00\n",
      "train epoch: 193 [76928/221852 (35%)]\tLoss: 0.181157\tAcc: 79.00\n",
      "train epoch: 193 [89728/221852 (40%)]\tLoss: 0.233915\tAcc: 77.00\n",
      "train epoch: 193 [102528/221852 (46%)]\tLoss: 0.195466\tAcc: 84.00\n",
      "train epoch: 193 [115328/221852 (52%)]\tLoss: 0.189440\tAcc: 78.00\n",
      "train epoch: 193 [128128/221852 (58%)]\tLoss: 0.161225\tAcc: 77.00\n",
      "train epoch: 193 [140928/221852 (64%)]\tLoss: 0.224024\tAcc: 81.00\n",
      "train epoch: 193 [153728/221852 (69%)]\tLoss: 0.264627\tAcc: 77.00\n",
      "train epoch: 193 [166528/221852 (75%)]\tLoss: 0.242564\tAcc: 83.00\n",
      "train epoch: 193 [179328/221852 (81%)]\tLoss: 0.150453\tAcc: 80.00\n",
      "train epoch: 193 [192128/221852 (87%)]\tLoss: 0.161678\tAcc: 82.00\n",
      "val epoch: 193 [128/221852 (0%)]\tLoss: 0.309176\tAcc: 74.00\n",
      "val epoch: 193 [12928/221852 (6%)]\tLoss: 0.167243\tAcc: 74.00\n",
      "train epoch: 194 [128/221852 (0%)]\tLoss: 0.251119\tAcc: 74.00\n",
      "train epoch: 194 [12928/221852 (6%)]\tLoss: 0.236115\tAcc: 68.00\n",
      "train epoch: 194 [25728/221852 (12%)]\tLoss: 0.167474\tAcc: 74.00\n",
      "train epoch: 194 [38528/221852 (17%)]\tLoss: 0.175680\tAcc: 81.00\n",
      "train epoch: 194 [51328/221852 (23%)]\tLoss: 0.141308\tAcc: 77.00\n",
      "train epoch: 194 [64128/221852 (29%)]\tLoss: 0.172577\tAcc: 76.00\n",
      "train epoch: 194 [76928/221852 (35%)]\tLoss: 0.135816\tAcc: 77.00\n",
      "train epoch: 194 [89728/221852 (40%)]\tLoss: 0.208596\tAcc: 79.00\n",
      "train epoch: 194 [102528/221852 (46%)]\tLoss: 0.140958\tAcc: 84.00\n",
      "train epoch: 194 [115328/221852 (52%)]\tLoss: 0.112357\tAcc: 74.00\n",
      "train epoch: 194 [128128/221852 (58%)]\tLoss: 0.213180\tAcc: 78.00\n",
      "train epoch: 194 [140928/221852 (64%)]\tLoss: 0.186837\tAcc: 74.00\n",
      "train epoch: 194 [153728/221852 (69%)]\tLoss: 0.261937\tAcc: 80.00\n",
      "train epoch: 194 [166528/221852 (75%)]\tLoss: 0.320005\tAcc: 69.00\n",
      "train epoch: 194 [179328/221852 (81%)]\tLoss: 0.218190\tAcc: 76.00\n",
      "train epoch: 194 [192128/221852 (87%)]\tLoss: 0.177292\tAcc: 81.00\n",
      "val epoch: 194 [128/221852 (0%)]\tLoss: 0.261727\tAcc: 81.00\n",
      "val epoch: 194 [12928/221852 (6%)]\tLoss: 0.205391\tAcc: 71.00\n",
      "train epoch: 195 [128/221852 (0%)]\tLoss: 0.204096\tAcc: 70.00\n",
      "train epoch: 195 [12928/221852 (6%)]\tLoss: 0.207447\tAcc: 75.00\n",
      "train epoch: 195 [25728/221852 (12%)]\tLoss: 0.203269\tAcc: 76.00\n",
      "train epoch: 195 [38528/221852 (17%)]\tLoss: 0.262748\tAcc: 77.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 195 [51328/221852 (23%)]\tLoss: 0.238191\tAcc: 79.00\n",
      "train epoch: 195 [64128/221852 (29%)]\tLoss: 0.129672\tAcc: 80.00\n",
      "train epoch: 195 [76928/221852 (35%)]\tLoss: 0.204407\tAcc: 65.00\n",
      "train epoch: 195 [89728/221852 (40%)]\tLoss: 0.217617\tAcc: 78.00\n",
      "train epoch: 195 [102528/221852 (46%)]\tLoss: 0.168514\tAcc: 76.00\n",
      "train epoch: 195 [115328/221852 (52%)]\tLoss: 0.190952\tAcc: 83.00\n",
      "train epoch: 195 [128128/221852 (58%)]\tLoss: 0.213976\tAcc: 77.00\n",
      "train epoch: 195 [140928/221852 (64%)]\tLoss: 0.237371\tAcc: 73.00\n",
      "train epoch: 195 [153728/221852 (69%)]\tLoss: 0.216199\tAcc: 74.00\n",
      "train epoch: 195 [166528/221852 (75%)]\tLoss: 0.258536\tAcc: 75.00\n",
      "train epoch: 195 [179328/221852 (81%)]\tLoss: 0.308365\tAcc: 69.00\n",
      "train epoch: 195 [192128/221852 (87%)]\tLoss: 0.134175\tAcc: 84.00\n",
      "val epoch: 195 [128/221852 (0%)]\tLoss: 0.205633\tAcc: 81.00\n",
      "val epoch: 195 [12928/221852 (6%)]\tLoss: 0.180723\tAcc: 84.00\n",
      "train epoch: 196 [128/221852 (0%)]\tLoss: 0.224100\tAcc: 70.00\n",
      "train epoch: 196 [12928/221852 (6%)]\tLoss: 0.239587\tAcc: 76.00\n",
      "train epoch: 196 [25728/221852 (12%)]\tLoss: 0.228744\tAcc: 77.00\n",
      "train epoch: 196 [38528/221852 (17%)]\tLoss: 0.187290\tAcc: 81.00\n",
      "train epoch: 196 [51328/221852 (23%)]\tLoss: 0.176077\tAcc: 79.00\n",
      "train epoch: 196 [64128/221852 (29%)]\tLoss: 0.236168\tAcc: 72.00\n",
      "train epoch: 196 [76928/221852 (35%)]\tLoss: 0.181236\tAcc: 79.00\n",
      "train epoch: 196 [89728/221852 (40%)]\tLoss: 0.143592\tAcc: 79.00\n",
      "train epoch: 196 [102528/221852 (46%)]\tLoss: 0.151127\tAcc: 83.00\n",
      "train epoch: 196 [115328/221852 (52%)]\tLoss: 0.253536\tAcc: 72.00\n",
      "train epoch: 196 [128128/221852 (58%)]\tLoss: 0.462376\tAcc: 80.00\n",
      "train epoch: 196 [140928/221852 (64%)]\tLoss: 0.175231\tAcc: 77.00\n",
      "train epoch: 196 [153728/221852 (69%)]\tLoss: 0.158402\tAcc: 74.00\n",
      "train epoch: 196 [166528/221852 (75%)]\tLoss: 0.176432\tAcc: 82.00\n",
      "train epoch: 196 [179328/221852 (81%)]\tLoss: 0.219967\tAcc: 69.00\n",
      "train epoch: 196 [192128/221852 (87%)]\tLoss: 0.213829\tAcc: 79.00\n",
      "val epoch: 196 [128/221852 (0%)]\tLoss: 0.234360\tAcc: 79.00\n",
      "val epoch: 196 [12928/221852 (6%)]\tLoss: 0.205788\tAcc: 86.00\n",
      "train epoch: 197 [128/221852 (0%)]\tLoss: 0.190527\tAcc: 81.00\n",
      "train epoch: 197 [12928/221852 (6%)]\tLoss: 0.254671\tAcc: 77.00\n",
      "train epoch: 197 [25728/221852 (12%)]\tLoss: 0.146413\tAcc: 84.00\n",
      "train epoch: 197 [38528/221852 (17%)]\tLoss: 0.186710\tAcc: 80.00\n",
      "train epoch: 197 [51328/221852 (23%)]\tLoss: 0.171278\tAcc: 78.00\n",
      "train epoch: 197 [64128/221852 (29%)]\tLoss: 0.240848\tAcc: 73.00\n",
      "train epoch: 197 [76928/221852 (35%)]\tLoss: 0.111493\tAcc: 76.00\n",
      "train epoch: 197 [89728/221852 (40%)]\tLoss: 0.194576\tAcc: 73.00\n",
      "train epoch: 197 [102528/221852 (46%)]\tLoss: 0.179947\tAcc: 78.00\n",
      "train epoch: 197 [115328/221852 (52%)]\tLoss: 0.250026\tAcc: 77.00\n",
      "train epoch: 197 [128128/221852 (58%)]\tLoss: 0.248503\tAcc: 73.00\n",
      "train epoch: 197 [140928/221852 (64%)]\tLoss: 0.207538\tAcc: 72.00\n",
      "train epoch: 197 [153728/221852 (69%)]\tLoss: 0.168454\tAcc: 78.00\n",
      "train epoch: 197 [166528/221852 (75%)]\tLoss: 0.160011\tAcc: 81.00\n",
      "train epoch: 197 [179328/221852 (81%)]\tLoss: 0.240474\tAcc: 78.00\n",
      "train epoch: 197 [192128/221852 (87%)]\tLoss: 0.162195\tAcc: 80.00\n",
      "val epoch: 197 [128/221852 (0%)]\tLoss: 0.149258\tAcc: 82.00\n",
      "val epoch: 197 [12928/221852 (6%)]\tLoss: 0.132743\tAcc: 83.00\n",
      "train epoch: 198 [128/221852 (0%)]\tLoss: 0.236133\tAcc: 83.00\n",
      "train epoch: 198 [12928/221852 (6%)]\tLoss: 0.204034\tAcc: 77.00\n",
      "train epoch: 198 [25728/221852 (12%)]\tLoss: 0.168310\tAcc: 79.00\n",
      "train epoch: 198 [38528/221852 (17%)]\tLoss: 0.380480\tAcc: 79.00\n",
      "train epoch: 198 [51328/221852 (23%)]\tLoss: 0.236426\tAcc: 77.00\n",
      "train epoch: 198 [64128/221852 (29%)]\tLoss: 0.378380\tAcc: 75.00\n",
      "train epoch: 198 [76928/221852 (35%)]\tLoss: 0.131184\tAcc: 83.00\n",
      "train epoch: 198 [89728/221852 (40%)]\tLoss: 0.240182\tAcc: 75.00\n",
      "train epoch: 198 [102528/221852 (46%)]\tLoss: 0.166537\tAcc: 83.00\n",
      "train epoch: 198 [115328/221852 (52%)]\tLoss: 0.191441\tAcc: 80.00\n",
      "train epoch: 198 [128128/221852 (58%)]\tLoss: 0.250303\tAcc: 78.00\n",
      "train epoch: 198 [140928/221852 (64%)]\tLoss: 0.303182\tAcc: 74.00\n",
      "train epoch: 198 [153728/221852 (69%)]\tLoss: 0.189369\tAcc: 73.00\n",
      "train epoch: 198 [166528/221852 (75%)]\tLoss: 0.256000\tAcc: 74.00\n",
      "train epoch: 198 [179328/221852 (81%)]\tLoss: 0.267759\tAcc: 78.00\n",
      "train epoch: 198 [192128/221852 (87%)]\tLoss: 0.310269\tAcc: 67.00\n",
      "val epoch: 198 [128/221852 (0%)]\tLoss: 0.232526\tAcc: 77.00\n",
      "val epoch: 198 [12928/221852 (6%)]\tLoss: 0.197908\tAcc: 79.00\n",
      "train epoch: 199 [128/221852 (0%)]\tLoss: 0.208851\tAcc: 73.00\n",
      "train epoch: 199 [12928/221852 (6%)]\tLoss: 0.179443\tAcc: 80.00\n",
      "train epoch: 199 [25728/221852 (12%)]\tLoss: 0.147933\tAcc: 84.00\n",
      "train epoch: 199 [38528/221852 (17%)]\tLoss: 0.183717\tAcc: 81.00\n",
      "train epoch: 199 [51328/221852 (23%)]\tLoss: 0.184050\tAcc: 79.00\n",
      "train epoch: 199 [64128/221852 (29%)]\tLoss: 0.190097\tAcc: 82.00\n",
      "train epoch: 199 [76928/221852 (35%)]\tLoss: 0.228666\tAcc: 73.00\n",
      "train epoch: 199 [89728/221852 (40%)]\tLoss: 0.238191\tAcc: 73.00\n",
      "train epoch: 199 [102528/221852 (46%)]\tLoss: 0.163637\tAcc: 79.00\n",
      "train epoch: 199 [115328/221852 (52%)]\tLoss: 0.127985\tAcc: 77.00\n",
      "train epoch: 199 [128128/221852 (58%)]\tLoss: 0.235775\tAcc: 77.00\n",
      "train epoch: 199 [140928/221852 (64%)]\tLoss: 0.298713\tAcc: 84.00\n",
      "train epoch: 199 [153728/221852 (69%)]\tLoss: 0.169589\tAcc: 71.00\n",
      "train epoch: 199 [166528/221852 (75%)]\tLoss: 0.200850\tAcc: 77.00\n",
      "train epoch: 199 [179328/221852 (81%)]\tLoss: 0.172453\tAcc: 81.00\n",
      "train epoch: 199 [192128/221852 (87%)]\tLoss: 0.151749\tAcc: 83.00\n",
      "val epoch: 199 [128/221852 (0%)]\tLoss: 0.212151\tAcc: 74.00\n",
      "val epoch: 199 [12928/221852 (6%)]\tLoss: 0.132466\tAcc: 80.00\n",
      "saving\n",
      "train epoch: 0 [128/221852 (0%)]\tLoss: 0.697016\tAcc: 52.00\n",
      "train epoch: 0 [12928/221852 (6%)]\tLoss: 0.692761\tAcc: 45.00\n",
      "train epoch: 0 [25728/221852 (12%)]\tLoss: 0.692645\tAcc: 49.00\n",
      "train epoch: 0 [38528/221852 (17%)]\tLoss: 0.695676\tAcc: 53.00\n",
      "train epoch: 0 [51328/221852 (23%)]\tLoss: 0.690019\tAcc: 62.00\n",
      "train epoch: 0 [64128/221852 (29%)]\tLoss: 0.675763\tAcc: 45.00\n",
      "train epoch: 0 [76928/221852 (35%)]\tLoss: 0.667756\tAcc: 56.00\n",
      "train epoch: 0 [89728/221852 (40%)]\tLoss: 0.624160\tAcc: 51.00\n",
      "train epoch: 0 [102528/221852 (46%)]\tLoss: 0.612621\tAcc: 52.00\n",
      "train epoch: 0 [115328/221852 (52%)]\tLoss: 0.583606\tAcc: 53.00\n",
      "train epoch: 0 [128128/221852 (58%)]\tLoss: 0.559685\tAcc: 46.00\n",
      "train epoch: 0 [140928/221852 (64%)]\tLoss: 0.518671\tAcc: 48.00\n",
      "train epoch: 0 [153728/221852 (69%)]\tLoss: 0.505199\tAcc: 46.00\n",
      "train epoch: 0 [166528/221852 (75%)]\tLoss: 0.502633\tAcc: 56.00\n",
      "train epoch: 0 [179328/221852 (81%)]\tLoss: 0.426215\tAcc: 47.00\n",
      "train epoch: 0 [192128/221852 (87%)]\tLoss: 0.479763\tAcc: 57.00\n",
      "val epoch: 0 [128/221852 (0%)]\tLoss: 0.486495\tAcc: 48.00\n",
      "val epoch: 0 [12928/221852 (6%)]\tLoss: 0.472527\tAcc: 46.00\n",
      "train epoch: 1 [128/221852 (0%)]\tLoss: 0.479639\tAcc: 48.00\n",
      "train epoch: 1 [12928/221852 (6%)]\tLoss: 0.393276\tAcc: 42.00\n",
      "train epoch: 1 [25728/221852 (12%)]\tLoss: 0.491307\tAcc: 46.00\n",
      "train epoch: 1 [38528/221852 (17%)]\tLoss: 0.398241\tAcc: 48.00\n",
      "train epoch: 1 [51328/221852 (23%)]\tLoss: 0.489639\tAcc: 49.00\n",
      "train epoch: 1 [64128/221852 (29%)]\tLoss: 0.440486\tAcc: 48.00\n",
      "train epoch: 1 [76928/221852 (35%)]\tLoss: 0.392741\tAcc: 52.00\n",
      "train epoch: 1 [89728/221852 (40%)]\tLoss: 0.421706\tAcc: 58.00\n",
      "train epoch: 1 [102528/221852 (46%)]\tLoss: 0.395428\tAcc: 53.00\n",
      "train epoch: 1 [115328/221852 (52%)]\tLoss: 0.420554\tAcc: 54.00\n",
      "train epoch: 1 [128128/221852 (58%)]\tLoss: 0.480470\tAcc: 52.00\n",
      "train epoch: 1 [140928/221852 (64%)]\tLoss: 0.445702\tAcc: 44.00\n",
      "train epoch: 1 [153728/221852 (69%)]\tLoss: 0.539250\tAcc: 41.00\n",
      "train epoch: 1 [166528/221852 (75%)]\tLoss: 0.408855\tAcc: 55.00\n",
      "train epoch: 1 [179328/221852 (81%)]\tLoss: 0.458078\tAcc: 55.00\n",
      "train epoch: 1 [192128/221852 (87%)]\tLoss: 0.439596\tAcc: 41.00\n",
      "val epoch: 1 [128/221852 (0%)]\tLoss: 0.497826\tAcc: 52.00\n",
      "val epoch: 1 [12928/221852 (6%)]\tLoss: 0.385964\tAcc: 52.00\n",
      "train epoch: 2 [128/221852 (0%)]\tLoss: 0.360374\tAcc: 51.00\n",
      "train epoch: 2 [12928/221852 (6%)]\tLoss: 0.417290\tAcc: 46.00\n",
      "train epoch: 2 [25728/221852 (12%)]\tLoss: 0.353391\tAcc: 48.00\n",
      "train epoch: 2 [38528/221852 (17%)]\tLoss: 0.352747\tAcc: 57.00\n",
      "train epoch: 2 [51328/221852 (23%)]\tLoss: 0.394786\tAcc: 52.00\n",
      "train epoch: 2 [64128/221852 (29%)]\tLoss: 0.498532\tAcc: 52.00\n",
      "train epoch: 2 [76928/221852 (35%)]\tLoss: 0.361168\tAcc: 48.00\n",
      "train epoch: 2 [89728/221852 (40%)]\tLoss: 0.408328\tAcc: 55.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 2 [102528/221852 (46%)]\tLoss: 0.355642\tAcc: 50.00\n",
      "train epoch: 2 [115328/221852 (52%)]\tLoss: 0.448070\tAcc: 45.00\n",
      "train epoch: 2 [128128/221852 (58%)]\tLoss: 0.368829\tAcc: 42.00\n",
      "train epoch: 2 [140928/221852 (64%)]\tLoss: 0.376254\tAcc: 52.00\n",
      "train epoch: 2 [153728/221852 (69%)]\tLoss: 0.390937\tAcc: 48.00\n",
      "train epoch: 2 [166528/221852 (75%)]\tLoss: 0.439135\tAcc: 49.00\n",
      "train epoch: 2 [179328/221852 (81%)]\tLoss: 0.384435\tAcc: 48.00\n",
      "train epoch: 2 [192128/221852 (87%)]\tLoss: 0.461827\tAcc: 45.00\n",
      "val epoch: 2 [128/221852 (0%)]\tLoss: 0.424163\tAcc: 46.00\n",
      "val epoch: 2 [12928/221852 (6%)]\tLoss: 0.325701\tAcc: 52.00\n",
      "train epoch: 3 [128/221852 (0%)]\tLoss: 0.356127\tAcc: 55.00\n",
      "train epoch: 3 [12928/221852 (6%)]\tLoss: 0.350999\tAcc: 55.00\n",
      "train epoch: 3 [25728/221852 (12%)]\tLoss: 0.372775\tAcc: 45.00\n",
      "train epoch: 3 [38528/221852 (17%)]\tLoss: 0.346590\tAcc: 43.00\n",
      "train epoch: 3 [51328/221852 (23%)]\tLoss: 0.418199\tAcc: 49.00\n",
      "train epoch: 3 [64128/221852 (29%)]\tLoss: 0.627102\tAcc: 52.00\n",
      "train epoch: 3 [76928/221852 (35%)]\tLoss: 0.423928\tAcc: 42.00\n",
      "train epoch: 3 [89728/221852 (40%)]\tLoss: 0.262585\tAcc: 54.00\n",
      "train epoch: 3 [102528/221852 (46%)]\tLoss: 0.416323\tAcc: 52.00\n",
      "train epoch: 3 [115328/221852 (52%)]\tLoss: 0.412847\tAcc: 52.00\n",
      "train epoch: 3 [128128/221852 (58%)]\tLoss: 0.397680\tAcc: 41.00\n",
      "train epoch: 3 [140928/221852 (64%)]\tLoss: 0.320809\tAcc: 48.00\n",
      "train epoch: 3 [153728/221852 (69%)]\tLoss: 0.389439\tAcc: 48.00\n",
      "train epoch: 3 [166528/221852 (75%)]\tLoss: 0.347529\tAcc: 46.00\n",
      "train epoch: 3 [179328/221852 (81%)]\tLoss: 0.266386\tAcc: 54.00\n",
      "train epoch: 3 [192128/221852 (87%)]\tLoss: 0.348938\tAcc: 41.00\n",
      "val epoch: 3 [128/221852 (0%)]\tLoss: 0.266473\tAcc: 54.00\n",
      "val epoch: 3 [12928/221852 (6%)]\tLoss: 0.339018\tAcc: 54.00\n",
      "train epoch: 4 [128/221852 (0%)]\tLoss: 0.343535\tAcc: 50.00\n",
      "train epoch: 4 [12928/221852 (6%)]\tLoss: 0.310037\tAcc: 51.00\n",
      "train epoch: 4 [25728/221852 (12%)]\tLoss: 0.320920\tAcc: 56.00\n",
      "train epoch: 4 [38528/221852 (17%)]\tLoss: 0.411216\tAcc: 48.00\n",
      "train epoch: 4 [51328/221852 (23%)]\tLoss: 0.295344\tAcc: 54.00\n",
      "train epoch: 4 [64128/221852 (29%)]\tLoss: 0.490106\tAcc: 51.00\n",
      "train epoch: 4 [76928/221852 (35%)]\tLoss: 0.331617\tAcc: 56.00\n",
      "train epoch: 4 [89728/221852 (40%)]\tLoss: 0.353318\tAcc: 52.00\n",
      "train epoch: 4 [102528/221852 (46%)]\tLoss: 0.312195\tAcc: 53.00\n",
      "train epoch: 4 [115328/221852 (52%)]\tLoss: 0.333579\tAcc: 49.00\n",
      "train epoch: 4 [128128/221852 (58%)]\tLoss: 0.317340\tAcc: 47.00\n",
      "train epoch: 4 [140928/221852 (64%)]\tLoss: 0.416883\tAcc: 45.00\n",
      "train epoch: 4 [153728/221852 (69%)]\tLoss: 0.346259\tAcc: 55.00\n",
      "train epoch: 4 [166528/221852 (75%)]\tLoss: 0.326130\tAcc: 62.00\n",
      "train epoch: 4 [179328/221852 (81%)]\tLoss: 0.337600\tAcc: 52.00\n",
      "train epoch: 4 [192128/221852 (87%)]\tLoss: 0.411080\tAcc: 48.00\n",
      "val epoch: 4 [128/221852 (0%)]\tLoss: 0.319080\tAcc: 59.00\n",
      "val epoch: 4 [12928/221852 (6%)]\tLoss: 0.346791\tAcc: 55.00\n",
      "train epoch: 5 [128/221852 (0%)]\tLoss: 0.362427\tAcc: 52.00\n",
      "train epoch: 5 [12928/221852 (6%)]\tLoss: 0.357462\tAcc: 54.00\n",
      "train epoch: 5 [25728/221852 (12%)]\tLoss: 0.349075\tAcc: 49.00\n",
      "train epoch: 5 [38528/221852 (17%)]\tLoss: 0.376638\tAcc: 51.00\n",
      "train epoch: 5 [51328/221852 (23%)]\tLoss: 0.442984\tAcc: 53.00\n",
      "train epoch: 5 [64128/221852 (29%)]\tLoss: 0.361083\tAcc: 53.00\n",
      "train epoch: 5 [76928/221852 (35%)]\tLoss: 0.412584\tAcc: 59.00\n",
      "train epoch: 5 [89728/221852 (40%)]\tLoss: 0.408277\tAcc: 57.00\n",
      "train epoch: 5 [102528/221852 (46%)]\tLoss: 0.428313\tAcc: 52.00\n",
      "train epoch: 5 [115328/221852 (52%)]\tLoss: 0.404044\tAcc: 49.00\n",
      "train epoch: 5 [128128/221852 (58%)]\tLoss: 0.310579\tAcc: 58.00\n",
      "train epoch: 5 [140928/221852 (64%)]\tLoss: 0.357779\tAcc: 54.00\n",
      "train epoch: 5 [153728/221852 (69%)]\tLoss: 0.326861\tAcc: 57.00\n",
      "train epoch: 5 [166528/221852 (75%)]\tLoss: 0.436870\tAcc: 54.00\n",
      "train epoch: 5 [179328/221852 (81%)]\tLoss: 0.498626\tAcc: 56.00\n",
      "train epoch: 5 [192128/221852 (87%)]\tLoss: 0.382163\tAcc: 53.00\n",
      "val epoch: 5 [128/221852 (0%)]\tLoss: 0.432109\tAcc: 54.00\n",
      "val epoch: 5 [12928/221852 (6%)]\tLoss: 0.436008\tAcc: 57.00\n",
      "train epoch: 6 [128/221852 (0%)]\tLoss: 0.302563\tAcc: 56.00\n",
      "train epoch: 6 [12928/221852 (6%)]\tLoss: 0.367026\tAcc: 52.00\n",
      "train epoch: 6 [25728/221852 (12%)]\tLoss: 0.326075\tAcc: 52.00\n",
      "train epoch: 6 [38528/221852 (17%)]\tLoss: 0.343183\tAcc: 59.00\n",
      "train epoch: 6 [51328/221852 (23%)]\tLoss: 0.417395\tAcc: 56.00\n",
      "train epoch: 6 [64128/221852 (29%)]\tLoss: 0.309281\tAcc: 53.00\n",
      "train epoch: 6 [76928/221852 (35%)]\tLoss: 0.370665\tAcc: 59.00\n",
      "train epoch: 6 [89728/221852 (40%)]\tLoss: 0.341812\tAcc: 59.00\n",
      "train epoch: 6 [102528/221852 (46%)]\tLoss: 0.325237\tAcc: 54.00\n",
      "train epoch: 6 [115328/221852 (52%)]\tLoss: 0.490594\tAcc: 50.00\n",
      "train epoch: 6 [128128/221852 (58%)]\tLoss: 0.394341\tAcc: 48.00\n",
      "train epoch: 6 [140928/221852 (64%)]\tLoss: 0.283946\tAcc: 56.00\n",
      "train epoch: 6 [153728/221852 (69%)]\tLoss: 0.296233\tAcc: 46.00\n",
      "train epoch: 6 [166528/221852 (75%)]\tLoss: 0.246921\tAcc: 58.00\n",
      "train epoch: 6 [179328/221852 (81%)]\tLoss: 0.387348\tAcc: 52.00\n",
      "train epoch: 6 [192128/221852 (87%)]\tLoss: 0.333589\tAcc: 55.00\n",
      "val epoch: 6 [128/221852 (0%)]\tLoss: 0.267051\tAcc: 57.00\n",
      "val epoch: 6 [12928/221852 (6%)]\tLoss: 0.380949\tAcc: 62.00\n",
      "train epoch: 7 [128/221852 (0%)]\tLoss: 0.432750\tAcc: 56.00\n",
      "train epoch: 7 [12928/221852 (6%)]\tLoss: 0.394993\tAcc: 55.00\n",
      "train epoch: 7 [25728/221852 (12%)]\tLoss: 0.291895\tAcc: 54.00\n",
      "train epoch: 7 [38528/221852 (17%)]\tLoss: 0.464898\tAcc: 51.00\n",
      "train epoch: 7 [51328/221852 (23%)]\tLoss: 0.360642\tAcc: 51.00\n",
      "train epoch: 7 [64128/221852 (29%)]\tLoss: 0.318578\tAcc: 55.00\n",
      "train epoch: 7 [76928/221852 (35%)]\tLoss: 0.453058\tAcc: 61.00\n",
      "train epoch: 7 [89728/221852 (40%)]\tLoss: 0.461307\tAcc: 52.00\n",
      "train epoch: 7 [102528/221852 (46%)]\tLoss: 0.289648\tAcc: 61.00\n",
      "train epoch: 7 [115328/221852 (52%)]\tLoss: 0.338144\tAcc: 54.00\n",
      "train epoch: 7 [128128/221852 (58%)]\tLoss: 0.409154\tAcc: 54.00\n",
      "train epoch: 7 [140928/221852 (64%)]\tLoss: 0.388835\tAcc: 50.00\n",
      "train epoch: 7 [153728/221852 (69%)]\tLoss: 0.383616\tAcc: 50.00\n",
      "train epoch: 7 [166528/221852 (75%)]\tLoss: 0.295176\tAcc: 52.00\n",
      "train epoch: 7 [179328/221852 (81%)]\tLoss: 0.297365\tAcc: 60.00\n",
      "train epoch: 7 [192128/221852 (87%)]\tLoss: 0.261625\tAcc: 62.00\n",
      "val epoch: 7 [128/221852 (0%)]\tLoss: 0.327631\tAcc: 49.00\n",
      "val epoch: 7 [12928/221852 (6%)]\tLoss: 0.369083\tAcc: 56.00\n",
      "train epoch: 8 [128/221852 (0%)]\tLoss: 0.321464\tAcc: 59.00\n",
      "train epoch: 8 [12928/221852 (6%)]\tLoss: 0.323218\tAcc: 59.00\n",
      "train epoch: 8 [25728/221852 (12%)]\tLoss: 0.340085\tAcc: 54.00\n",
      "train epoch: 8 [38528/221852 (17%)]\tLoss: 0.274672\tAcc: 56.00\n",
      "train epoch: 8 [51328/221852 (23%)]\tLoss: 0.258285\tAcc: 65.00\n",
      "train epoch: 8 [64128/221852 (29%)]\tLoss: 0.637062\tAcc: 55.00\n",
      "train epoch: 8 [76928/221852 (35%)]\tLoss: 0.378953\tAcc: 56.00\n",
      "train epoch: 8 [89728/221852 (40%)]\tLoss: 0.268136\tAcc: 55.00\n",
      "train epoch: 8 [102528/221852 (46%)]\tLoss: 0.364788\tAcc: 55.00\n",
      "train epoch: 8 [115328/221852 (52%)]\tLoss: 0.402700\tAcc: 56.00\n",
      "train epoch: 8 [128128/221852 (58%)]\tLoss: 0.326505\tAcc: 55.00\n",
      "train epoch: 8 [140928/221852 (64%)]\tLoss: 0.349958\tAcc: 53.00\n",
      "train epoch: 8 [153728/221852 (69%)]\tLoss: 0.279565\tAcc: 65.00\n",
      "train epoch: 8 [166528/221852 (75%)]\tLoss: 0.365072\tAcc: 55.00\n",
      "train epoch: 8 [179328/221852 (81%)]\tLoss: 0.379564\tAcc: 55.00\n",
      "train epoch: 8 [192128/221852 (87%)]\tLoss: 0.274976\tAcc: 53.00\n",
      "val epoch: 8 [128/221852 (0%)]\tLoss: 0.421865\tAcc: 49.00\n",
      "val epoch: 8 [12928/221852 (6%)]\tLoss: 0.385614\tAcc: 57.00\n",
      "train epoch: 9 [128/221852 (0%)]\tLoss: 0.375353\tAcc: 52.00\n",
      "train epoch: 9 [12928/221852 (6%)]\tLoss: 0.403937\tAcc: 55.00\n",
      "train epoch: 9 [25728/221852 (12%)]\tLoss: 0.323450\tAcc: 59.00\n",
      "train epoch: 9 [38528/221852 (17%)]\tLoss: 0.337958\tAcc: 59.00\n",
      "train epoch: 9 [51328/221852 (23%)]\tLoss: 0.379311\tAcc: 58.00\n",
      "train epoch: 9 [64128/221852 (29%)]\tLoss: 0.389170\tAcc: 56.00\n",
      "train epoch: 9 [76928/221852 (35%)]\tLoss: 0.237045\tAcc: 57.00\n",
      "train epoch: 9 [89728/221852 (40%)]\tLoss: 0.319807\tAcc: 58.00\n",
      "train epoch: 9 [102528/221852 (46%)]\tLoss: 0.288381\tAcc: 52.00\n",
      "train epoch: 9 [115328/221852 (52%)]\tLoss: 0.280781\tAcc: 59.00\n",
      "train epoch: 9 [128128/221852 (58%)]\tLoss: 0.326201\tAcc: 52.00\n",
      "train epoch: 9 [140928/221852 (64%)]\tLoss: 0.249178\tAcc: 54.00\n",
      "train epoch: 9 [153728/221852 (69%)]\tLoss: 0.295624\tAcc: 58.00\n",
      "train epoch: 9 [166528/221852 (75%)]\tLoss: 0.239743\tAcc: 54.00\n",
      "train epoch: 9 [179328/221852 (81%)]\tLoss: 0.278700\tAcc: 59.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 9 [192128/221852 (87%)]\tLoss: 0.270224\tAcc: 55.00\n",
      "val epoch: 9 [128/221852 (0%)]\tLoss: 0.276263\tAcc: 57.00\n",
      "val epoch: 9 [12928/221852 (6%)]\tLoss: 0.315980\tAcc: 49.00\n",
      "train epoch: 10 [128/221852 (0%)]\tLoss: 0.286008\tAcc: 52.00\n",
      "train epoch: 10 [12928/221852 (6%)]\tLoss: 0.322621\tAcc: 62.00\n",
      "train epoch: 10 [25728/221852 (12%)]\tLoss: 0.293724\tAcc: 62.00\n",
      "train epoch: 10 [38528/221852 (17%)]\tLoss: 0.323854\tAcc: 64.00\n",
      "train epoch: 10 [51328/221852 (23%)]\tLoss: 0.322629\tAcc: 60.00\n",
      "train epoch: 10 [64128/221852 (29%)]\tLoss: 0.290124\tAcc: 61.00\n",
      "train epoch: 10 [76928/221852 (35%)]\tLoss: 0.308793\tAcc: 59.00\n",
      "train epoch: 10 [89728/221852 (40%)]\tLoss: 0.222446\tAcc: 62.00\n",
      "train epoch: 10 [102528/221852 (46%)]\tLoss: 0.437723\tAcc: 66.00\n",
      "train epoch: 10 [115328/221852 (52%)]\tLoss: 0.428407\tAcc: 55.00\n",
      "train epoch: 10 [128128/221852 (58%)]\tLoss: 0.350034\tAcc: 57.00\n",
      "train epoch: 10 [140928/221852 (64%)]\tLoss: 0.377392\tAcc: 58.00\n",
      "train epoch: 10 [153728/221852 (69%)]\tLoss: 0.279490\tAcc: 55.00\n",
      "train epoch: 10 [166528/221852 (75%)]\tLoss: 0.476833\tAcc: 58.00\n",
      "train epoch: 10 [179328/221852 (81%)]\tLoss: 0.291345\tAcc: 60.00\n",
      "train epoch: 10 [192128/221852 (87%)]\tLoss: 0.347772\tAcc: 56.00\n",
      "val epoch: 10 [128/221852 (0%)]\tLoss: 0.352662\tAcc: 57.00\n",
      "val epoch: 10 [12928/221852 (6%)]\tLoss: 0.386182\tAcc: 49.00\n",
      "train epoch: 11 [128/221852 (0%)]\tLoss: 0.349957\tAcc: 54.00\n",
      "train epoch: 11 [12928/221852 (6%)]\tLoss: 0.277538\tAcc: 56.00\n",
      "train epoch: 11 [25728/221852 (12%)]\tLoss: 0.387728\tAcc: 52.00\n",
      "train epoch: 11 [38528/221852 (17%)]\tLoss: 0.406296\tAcc: 55.00\n",
      "train epoch: 11 [51328/221852 (23%)]\tLoss: 0.309099\tAcc: 58.00\n",
      "train epoch: 11 [64128/221852 (29%)]\tLoss: 0.312769\tAcc: 51.00\n",
      "train epoch: 11 [76928/221852 (35%)]\tLoss: 0.266515\tAcc: 63.00\n",
      "train epoch: 11 [89728/221852 (40%)]\tLoss: 0.316433\tAcc: 53.00\n",
      "train epoch: 11 [102528/221852 (46%)]\tLoss: 0.347493\tAcc: 61.00\n",
      "train epoch: 11 [115328/221852 (52%)]\tLoss: 0.302265\tAcc: 61.00\n",
      "train epoch: 11 [128128/221852 (58%)]\tLoss: 0.376532\tAcc: 50.00\n",
      "train epoch: 11 [140928/221852 (64%)]\tLoss: 0.304445\tAcc: 60.00\n",
      "train epoch: 11 [153728/221852 (69%)]\tLoss: 0.263071\tAcc: 55.00\n",
      "train epoch: 11 [166528/221852 (75%)]\tLoss: 0.346892\tAcc: 61.00\n",
      "train epoch: 11 [179328/221852 (81%)]\tLoss: 0.310031\tAcc: 55.00\n",
      "train epoch: 11 [192128/221852 (87%)]\tLoss: 0.299878\tAcc: 56.00\n",
      "val epoch: 11 [128/221852 (0%)]\tLoss: 0.405026\tAcc: 61.00\n",
      "val epoch: 11 [12928/221852 (6%)]\tLoss: 0.322738\tAcc: 55.00\n",
      "train epoch: 12 [128/221852 (0%)]\tLoss: 0.300738\tAcc: 66.00\n",
      "train epoch: 12 [12928/221852 (6%)]\tLoss: 0.357768\tAcc: 56.00\n",
      "train epoch: 12 [25728/221852 (12%)]\tLoss: 0.333405\tAcc: 58.00\n",
      "train epoch: 12 [38528/221852 (17%)]\tLoss: 0.299865\tAcc: 57.00\n",
      "train epoch: 12 [51328/221852 (23%)]\tLoss: 0.406366\tAcc: 56.00\n",
      "train epoch: 12 [64128/221852 (29%)]\tLoss: 0.240562\tAcc: 62.00\n",
      "train epoch: 12 [76928/221852 (35%)]\tLoss: 0.217141\tAcc: 58.00\n",
      "train epoch: 12 [89728/221852 (40%)]\tLoss: 0.281584\tAcc: 48.00\n",
      "train epoch: 12 [102528/221852 (46%)]\tLoss: 0.239732\tAcc: 62.00\n",
      "train epoch: 12 [115328/221852 (52%)]\tLoss: 0.335541\tAcc: 63.00\n",
      "train epoch: 12 [128128/221852 (58%)]\tLoss: 0.287134\tAcc: 65.00\n",
      "train epoch: 12 [140928/221852 (64%)]\tLoss: 0.377889\tAcc: 55.00\n",
      "train epoch: 12 [153728/221852 (69%)]\tLoss: 0.253969\tAcc: 55.00\n",
      "train epoch: 12 [166528/221852 (75%)]\tLoss: 0.310410\tAcc: 61.00\n",
      "train epoch: 12 [179328/221852 (81%)]\tLoss: 0.386927\tAcc: 54.00\n",
      "train epoch: 12 [192128/221852 (87%)]\tLoss: 0.353869\tAcc: 60.00\n",
      "val epoch: 12 [128/221852 (0%)]\tLoss: 0.340571\tAcc: 58.00\n",
      "val epoch: 12 [12928/221852 (6%)]\tLoss: 0.217026\tAcc: 63.00\n",
      "train epoch: 13 [128/221852 (0%)]\tLoss: 0.242205\tAcc: 59.00\n",
      "train epoch: 13 [12928/221852 (6%)]\tLoss: 0.360364\tAcc: 62.00\n",
      "train epoch: 13 [25728/221852 (12%)]\tLoss: 0.326120\tAcc: 59.00\n",
      "train epoch: 13 [38528/221852 (17%)]\tLoss: 0.265194\tAcc: 56.00\n",
      "train epoch: 13 [51328/221852 (23%)]\tLoss: 0.549312\tAcc: 62.00\n",
      "train epoch: 13 [64128/221852 (29%)]\tLoss: 0.281914\tAcc: 57.00\n",
      "train epoch: 13 [76928/221852 (35%)]\tLoss: 0.313379\tAcc: 59.00\n",
      "train epoch: 13 [89728/221852 (40%)]\tLoss: 0.305158\tAcc: 54.00\n",
      "train epoch: 13 [102528/221852 (46%)]\tLoss: 0.283765\tAcc: 54.00\n",
      "train epoch: 13 [115328/221852 (52%)]\tLoss: 0.267341\tAcc: 54.00\n",
      "train epoch: 13 [128128/221852 (58%)]\tLoss: 0.346463\tAcc: 66.00\n",
      "train epoch: 13 [140928/221852 (64%)]\tLoss: 0.264973\tAcc: 56.00\n",
      "train epoch: 13 [153728/221852 (69%)]\tLoss: 0.363119\tAcc: 55.00\n",
      "train epoch: 13 [166528/221852 (75%)]\tLoss: 0.223981\tAcc: 59.00\n",
      "train epoch: 13 [179328/221852 (81%)]\tLoss: 0.240233\tAcc: 60.00\n",
      "train epoch: 13 [192128/221852 (87%)]\tLoss: 0.272631\tAcc: 56.00\n",
      "val epoch: 13 [128/221852 (0%)]\tLoss: 0.301152\tAcc: 56.00\n",
      "val epoch: 13 [12928/221852 (6%)]\tLoss: 0.290765\tAcc: 48.00\n",
      "train epoch: 14 [128/221852 (0%)]\tLoss: 0.268411\tAcc: 59.00\n",
      "train epoch: 14 [12928/221852 (6%)]\tLoss: 0.529222\tAcc: 62.00\n",
      "train epoch: 14 [25728/221852 (12%)]\tLoss: 0.308732\tAcc: 64.00\n",
      "train epoch: 14 [38528/221852 (17%)]\tLoss: 0.377650\tAcc: 59.00\n",
      "train epoch: 14 [51328/221852 (23%)]\tLoss: 0.294500\tAcc: 62.00\n",
      "train epoch: 14 [64128/221852 (29%)]\tLoss: 0.307659\tAcc: 51.00\n",
      "train epoch: 14 [76928/221852 (35%)]\tLoss: 0.263618\tAcc: 59.00\n",
      "train epoch: 14 [89728/221852 (40%)]\tLoss: 0.283870\tAcc: 66.00\n",
      "train epoch: 14 [102528/221852 (46%)]\tLoss: 0.275133\tAcc: 63.00\n",
      "train epoch: 14 [115328/221852 (52%)]\tLoss: 0.273667\tAcc: 54.00\n",
      "train epoch: 14 [128128/221852 (58%)]\tLoss: 0.347328\tAcc: 57.00\n",
      "train epoch: 14 [140928/221852 (64%)]\tLoss: 0.316343\tAcc: 62.00\n",
      "train epoch: 14 [153728/221852 (69%)]\tLoss: 0.245378\tAcc: 59.00\n",
      "train epoch: 14 [166528/221852 (75%)]\tLoss: 0.365283\tAcc: 62.00\n",
      "train epoch: 14 [179328/221852 (81%)]\tLoss: 0.273608\tAcc: 62.00\n",
      "train epoch: 14 [192128/221852 (87%)]\tLoss: 0.285631\tAcc: 58.00\n",
      "val epoch: 14 [128/221852 (0%)]\tLoss: 0.365283\tAcc: 51.00\n",
      "val epoch: 14 [12928/221852 (6%)]\tLoss: 0.303891\tAcc: 60.00\n",
      "train epoch: 15 [128/221852 (0%)]\tLoss: 0.371201\tAcc: 50.00\n",
      "train epoch: 15 [12928/221852 (6%)]\tLoss: 0.283189\tAcc: 65.00\n",
      "train epoch: 15 [25728/221852 (12%)]\tLoss: 0.309373\tAcc: 56.00\n",
      "train epoch: 15 [38528/221852 (17%)]\tLoss: 0.251750\tAcc: 63.00\n",
      "train epoch: 15 [51328/221852 (23%)]\tLoss: 0.352589\tAcc: 57.00\n",
      "train epoch: 15 [64128/221852 (29%)]\tLoss: 0.283704\tAcc: 64.00\n",
      "train epoch: 15 [76928/221852 (35%)]\tLoss: 0.288201\tAcc: 62.00\n",
      "train epoch: 15 [89728/221852 (40%)]\tLoss: 0.255301\tAcc: 59.00\n",
      "train epoch: 15 [102528/221852 (46%)]\tLoss: 0.392877\tAcc: 63.00\n",
      "train epoch: 15 [115328/221852 (52%)]\tLoss: 0.324934\tAcc: 62.00\n",
      "train epoch: 15 [128128/221852 (58%)]\tLoss: 0.341044\tAcc: 62.00\n",
      "train epoch: 15 [140928/221852 (64%)]\tLoss: 0.266214\tAcc: 66.00\n",
      "train epoch: 15 [153728/221852 (69%)]\tLoss: 0.302922\tAcc: 62.00\n",
      "train epoch: 15 [166528/221852 (75%)]\tLoss: 0.291421\tAcc: 63.00\n",
      "train epoch: 15 [179328/221852 (81%)]\tLoss: 0.283332\tAcc: 58.00\n",
      "train epoch: 15 [192128/221852 (87%)]\tLoss: 0.253347\tAcc: 55.00\n",
      "val epoch: 15 [128/221852 (0%)]\tLoss: 0.333469\tAcc: 57.00\n",
      "val epoch: 15 [12928/221852 (6%)]\tLoss: 0.362977\tAcc: 58.00\n",
      "train epoch: 16 [128/221852 (0%)]\tLoss: 0.261553\tAcc: 62.00\n",
      "train epoch: 16 [12928/221852 (6%)]\tLoss: 0.315566\tAcc: 61.00\n",
      "train epoch: 16 [25728/221852 (12%)]\tLoss: 0.248157\tAcc: 63.00\n",
      "train epoch: 16 [38528/221852 (17%)]\tLoss: 0.238315\tAcc: 64.00\n",
      "train epoch: 16 [51328/221852 (23%)]\tLoss: 0.309286\tAcc: 57.00\n",
      "train epoch: 16 [64128/221852 (29%)]\tLoss: 0.206235\tAcc: 69.00\n",
      "train epoch: 16 [76928/221852 (35%)]\tLoss: 0.402354\tAcc: 62.00\n",
      "train epoch: 16 [89728/221852 (40%)]\tLoss: 0.397106\tAcc: 62.00\n",
      "train epoch: 16 [102528/221852 (46%)]\tLoss: 0.196782\tAcc: 65.00\n",
      "train epoch: 16 [115328/221852 (52%)]\tLoss: 0.328668\tAcc: 64.00\n",
      "train epoch: 16 [128128/221852 (58%)]\tLoss: 0.290459\tAcc: 60.00\n",
      "train epoch: 16 [140928/221852 (64%)]\tLoss: 0.298939\tAcc: 56.00\n",
      "train epoch: 16 [153728/221852 (69%)]\tLoss: 0.282786\tAcc: 66.00\n",
      "train epoch: 16 [166528/221852 (75%)]\tLoss: 0.298804\tAcc: 65.00\n",
      "train epoch: 16 [179328/221852 (81%)]\tLoss: 0.451059\tAcc: 49.00\n",
      "train epoch: 16 [192128/221852 (87%)]\tLoss: 0.303379\tAcc: 60.00\n",
      "val epoch: 16 [128/221852 (0%)]\tLoss: 0.336225\tAcc: 59.00\n",
      "val epoch: 16 [12928/221852 (6%)]\tLoss: 0.305856\tAcc: 64.00\n",
      "train epoch: 17 [128/221852 (0%)]\tLoss: 0.244612\tAcc: 63.00\n",
      "train epoch: 17 [12928/221852 (6%)]\tLoss: 0.288205\tAcc: 66.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 17 [25728/221852 (12%)]\tLoss: 0.325910\tAcc: 55.00\n",
      "train epoch: 17 [38528/221852 (17%)]\tLoss: 0.271020\tAcc: 67.00\n",
      "train epoch: 17 [51328/221852 (23%)]\tLoss: 0.302555\tAcc: 67.00\n",
      "train epoch: 17 [64128/221852 (29%)]\tLoss: 0.357567\tAcc: 62.00\n",
      "train epoch: 17 [76928/221852 (35%)]\tLoss: 0.246021\tAcc: 58.00\n",
      "train epoch: 17 [89728/221852 (40%)]\tLoss: 0.328579\tAcc: 56.00\n",
      "train epoch: 17 [102528/221852 (46%)]\tLoss: 0.299042\tAcc: 62.00\n",
      "train epoch: 17 [115328/221852 (52%)]\tLoss: 0.313967\tAcc: 62.00\n",
      "train epoch: 17 [128128/221852 (58%)]\tLoss: 0.284260\tAcc: 62.00\n",
      "train epoch: 17 [140928/221852 (64%)]\tLoss: 0.316240\tAcc: 63.00\n",
      "train epoch: 17 [153728/221852 (69%)]\tLoss: 0.300962\tAcc: 55.00\n",
      "train epoch: 17 [166528/221852 (75%)]\tLoss: 0.419276\tAcc: 58.00\n",
      "train epoch: 17 [179328/221852 (81%)]\tLoss: 0.259298\tAcc: 59.00\n",
      "train epoch: 17 [192128/221852 (87%)]\tLoss: 0.300686\tAcc: 68.00\n",
      "val epoch: 17 [128/221852 (0%)]\tLoss: 0.296118\tAcc: 65.00\n",
      "val epoch: 17 [12928/221852 (6%)]\tLoss: 0.355010\tAcc: 62.00\n",
      "train epoch: 18 [128/221852 (0%)]\tLoss: 0.268370\tAcc: 63.00\n",
      "train epoch: 18 [12928/221852 (6%)]\tLoss: 0.255890\tAcc: 61.00\n",
      "train epoch: 18 [25728/221852 (12%)]\tLoss: 0.242035\tAcc: 61.00\n",
      "train epoch: 18 [38528/221852 (17%)]\tLoss: 0.330626\tAcc: 57.00\n",
      "train epoch: 18 [51328/221852 (23%)]\tLoss: 0.223301\tAcc: 61.00\n",
      "train epoch: 18 [64128/221852 (29%)]\tLoss: 0.307110\tAcc: 62.00\n",
      "train epoch: 18 [76928/221852 (35%)]\tLoss: 0.254703\tAcc: 64.00\n",
      "train epoch: 18 [89728/221852 (40%)]\tLoss: 0.255629\tAcc: 61.00\n",
      "train epoch: 18 [102528/221852 (46%)]\tLoss: 0.343305\tAcc: 66.00\n",
      "train epoch: 18 [115328/221852 (52%)]\tLoss: 0.255837\tAcc: 63.00\n",
      "train epoch: 18 [128128/221852 (58%)]\tLoss: 0.312673\tAcc: 59.00\n",
      "train epoch: 18 [140928/221852 (64%)]\tLoss: 0.297164\tAcc: 54.00\n",
      "train epoch: 18 [153728/221852 (69%)]\tLoss: 0.213703\tAcc: 70.00\n",
      "train epoch: 18 [166528/221852 (75%)]\tLoss: 0.256012\tAcc: 65.00\n",
      "train epoch: 18 [179328/221852 (81%)]\tLoss: 0.259704\tAcc: 63.00\n",
      "train epoch: 18 [192128/221852 (87%)]\tLoss: 0.276493\tAcc: 67.00\n",
      "val epoch: 18 [128/221852 (0%)]\tLoss: 0.346541\tAcc: 66.00\n",
      "val epoch: 18 [12928/221852 (6%)]\tLoss: 0.331695\tAcc: 66.00\n",
      "train epoch: 19 [128/221852 (0%)]\tLoss: 0.266602\tAcc: 64.00\n",
      "train epoch: 19 [12928/221852 (6%)]\tLoss: 0.299225\tAcc: 64.00\n",
      "train epoch: 19 [25728/221852 (12%)]\tLoss: 0.270496\tAcc: 62.00\n",
      "train epoch: 19 [38528/221852 (17%)]\tLoss: 0.313663\tAcc: 56.00\n",
      "train epoch: 19 [51328/221852 (23%)]\tLoss: 0.298682\tAcc: 54.00\n",
      "train epoch: 19 [64128/221852 (29%)]\tLoss: 0.294042\tAcc: 67.00\n",
      "train epoch: 19 [76928/221852 (35%)]\tLoss: 0.331119\tAcc: 64.00\n",
      "train epoch: 19 [89728/221852 (40%)]\tLoss: 0.291439\tAcc: 56.00\n",
      "train epoch: 19 [102528/221852 (46%)]\tLoss: 0.234526\tAcc: 60.00\n",
      "train epoch: 19 [115328/221852 (52%)]\tLoss: 0.245597\tAcc: 63.00\n",
      "train epoch: 19 [128128/221852 (58%)]\tLoss: 0.385026\tAcc: 67.00\n",
      "train epoch: 19 [140928/221852 (64%)]\tLoss: 0.314824\tAcc: 62.00\n",
      "train epoch: 19 [153728/221852 (69%)]\tLoss: 0.280210\tAcc: 62.00\n",
      "train epoch: 19 [166528/221852 (75%)]\tLoss: 0.316849\tAcc: 56.00\n",
      "train epoch: 19 [179328/221852 (81%)]\tLoss: 0.247743\tAcc: 67.00\n",
      "train epoch: 19 [192128/221852 (87%)]\tLoss: 0.304740\tAcc: 61.00\n",
      "val epoch: 19 [128/221852 (0%)]\tLoss: 0.310315\tAcc: 63.00\n",
      "val epoch: 19 [12928/221852 (6%)]\tLoss: 0.294133\tAcc: 62.00\n",
      "train epoch: 20 [128/221852 (0%)]\tLoss: 0.364487\tAcc: 59.00\n",
      "train epoch: 20 [12928/221852 (6%)]\tLoss: 0.329968\tAcc: 59.00\n",
      "train epoch: 20 [25728/221852 (12%)]\tLoss: 0.244467\tAcc: 66.00\n",
      "train epoch: 20 [38528/221852 (17%)]\tLoss: 0.289425\tAcc: 63.00\n",
      "train epoch: 20 [51328/221852 (23%)]\tLoss: 0.357720\tAcc: 55.00\n",
      "train epoch: 20 [64128/221852 (29%)]\tLoss: 0.276411\tAcc: 62.00\n",
      "train epoch: 20 [76928/221852 (35%)]\tLoss: 0.231425\tAcc: 64.00\n",
      "train epoch: 20 [89728/221852 (40%)]\tLoss: 0.305268\tAcc: 64.00\n",
      "train epoch: 20 [102528/221852 (46%)]\tLoss: 0.386552\tAcc: 58.00\n",
      "train epoch: 20 [115328/221852 (52%)]\tLoss: 0.235784\tAcc: 65.00\n",
      "train epoch: 20 [128128/221852 (58%)]\tLoss: 0.217119\tAcc: 64.00\n",
      "train epoch: 20 [140928/221852 (64%)]\tLoss: 0.373757\tAcc: 62.00\n",
      "train epoch: 20 [153728/221852 (69%)]\tLoss: 0.246307\tAcc: 59.00\n",
      "train epoch: 20 [166528/221852 (75%)]\tLoss: 0.275083\tAcc: 65.00\n",
      "train epoch: 20 [179328/221852 (81%)]\tLoss: 0.287970\tAcc: 65.00\n",
      "train epoch: 20 [192128/221852 (87%)]\tLoss: 0.373696\tAcc: 58.00\n",
      "val epoch: 20 [128/221852 (0%)]\tLoss: 0.194504\tAcc: 69.00\n",
      "val epoch: 20 [12928/221852 (6%)]\tLoss: 0.312667\tAcc: 52.00\n",
      "train epoch: 21 [128/221852 (0%)]\tLoss: 0.208095\tAcc: 67.00\n",
      "train epoch: 21 [12928/221852 (6%)]\tLoss: 0.360282\tAcc: 66.00\n",
      "train epoch: 21 [25728/221852 (12%)]\tLoss: 0.410842\tAcc: 66.00\n",
      "train epoch: 21 [38528/221852 (17%)]\tLoss: 0.253745\tAcc: 62.00\n",
      "train epoch: 21 [51328/221852 (23%)]\tLoss: 0.331395\tAcc: 63.00\n",
      "train epoch: 21 [64128/221852 (29%)]\tLoss: 0.279200\tAcc: 59.00\n",
      "train epoch: 21 [76928/221852 (35%)]\tLoss: 0.315295\tAcc: 66.00\n",
      "train epoch: 21 [89728/221852 (40%)]\tLoss: 0.308644\tAcc: 59.00\n",
      "train epoch: 21 [102528/221852 (46%)]\tLoss: 0.281453\tAcc: 58.00\n",
      "train epoch: 21 [115328/221852 (52%)]\tLoss: 0.239309\tAcc: 61.00\n",
      "train epoch: 21 [128128/221852 (58%)]\tLoss: 0.411642\tAcc: 54.00\n",
      "train epoch: 21 [140928/221852 (64%)]\tLoss: 0.305309\tAcc: 64.00\n",
      "train epoch: 21 [153728/221852 (69%)]\tLoss: 0.482944\tAcc: 58.00\n",
      "train epoch: 21 [166528/221852 (75%)]\tLoss: 0.364563\tAcc: 67.00\n",
      "train epoch: 21 [179328/221852 (81%)]\tLoss: 0.277501\tAcc: 70.00\n",
      "train epoch: 21 [192128/221852 (87%)]\tLoss: 0.313251\tAcc: 59.00\n",
      "val epoch: 21 [128/221852 (0%)]\tLoss: 0.263548\tAcc: 70.00\n",
      "val epoch: 21 [12928/221852 (6%)]\tLoss: 0.303776\tAcc: 65.00\n",
      "train epoch: 22 [128/221852 (0%)]\tLoss: 0.226575\tAcc: 59.00\n",
      "train epoch: 22 [12928/221852 (6%)]\tLoss: 0.416359\tAcc: 52.00\n",
      "train epoch: 22 [25728/221852 (12%)]\tLoss: 0.288117\tAcc: 59.00\n",
      "train epoch: 22 [38528/221852 (17%)]\tLoss: 0.284693\tAcc: 63.00\n",
      "train epoch: 22 [51328/221852 (23%)]\tLoss: 0.246585\tAcc: 57.00\n",
      "train epoch: 22 [64128/221852 (29%)]\tLoss: 0.266656\tAcc: 61.00\n",
      "train epoch: 22 [76928/221852 (35%)]\tLoss: 0.278421\tAcc: 70.00\n",
      "train epoch: 22 [89728/221852 (40%)]\tLoss: 0.320834\tAcc: 65.00\n",
      "train epoch: 22 [102528/221852 (46%)]\tLoss: 0.333658\tAcc: 55.00\n",
      "train epoch: 22 [115328/221852 (52%)]\tLoss: 0.291515\tAcc: 66.00\n",
      "train epoch: 22 [128128/221852 (58%)]\tLoss: 0.319990\tAcc: 66.00\n",
      "train epoch: 22 [140928/221852 (64%)]\tLoss: 0.322974\tAcc: 53.00\n",
      "train epoch: 22 [153728/221852 (69%)]\tLoss: 0.274720\tAcc: 62.00\n",
      "train epoch: 22 [166528/221852 (75%)]\tLoss: 0.291072\tAcc: 59.00\n",
      "train epoch: 22 [179328/221852 (81%)]\tLoss: 0.304074\tAcc: 67.00\n",
      "train epoch: 22 [192128/221852 (87%)]\tLoss: 0.388153\tAcc: 66.00\n",
      "val epoch: 22 [128/221852 (0%)]\tLoss: 0.441420\tAcc: 59.00\n",
      "val epoch: 22 [12928/221852 (6%)]\tLoss: 0.362418\tAcc: 64.00\n",
      "train epoch: 23 [128/221852 (0%)]\tLoss: 0.362398\tAcc: 59.00\n",
      "train epoch: 23 [12928/221852 (6%)]\tLoss: 0.351315\tAcc: 56.00\n",
      "train epoch: 23 [25728/221852 (12%)]\tLoss: 0.295045\tAcc: 69.00\n",
      "train epoch: 23 [38528/221852 (17%)]\tLoss: 0.309618\tAcc: 65.00\n",
      "train epoch: 23 [51328/221852 (23%)]\tLoss: 0.267126\tAcc: 62.00\n",
      "train epoch: 23 [64128/221852 (29%)]\tLoss: 0.236240\tAcc: 66.00\n",
      "train epoch: 23 [76928/221852 (35%)]\tLoss: 0.292580\tAcc: 66.00\n",
      "train epoch: 23 [89728/221852 (40%)]\tLoss: 0.313791\tAcc: 56.00\n",
      "train epoch: 23 [102528/221852 (46%)]\tLoss: 0.299787\tAcc: 66.00\n",
      "train epoch: 23 [115328/221852 (52%)]\tLoss: 0.282621\tAcc: 68.00\n",
      "train epoch: 23 [128128/221852 (58%)]\tLoss: 0.326361\tAcc: 65.00\n",
      "train epoch: 23 [140928/221852 (64%)]\tLoss: 0.333685\tAcc: 64.00\n",
      "train epoch: 23 [153728/221852 (69%)]\tLoss: 0.274141\tAcc: 66.00\n",
      "train epoch: 23 [166528/221852 (75%)]\tLoss: 0.300492\tAcc: 66.00\n",
      "train epoch: 23 [179328/221852 (81%)]\tLoss: 0.248779\tAcc: 58.00\n",
      "train epoch: 23 [192128/221852 (87%)]\tLoss: 0.343533\tAcc: 62.00\n",
      "val epoch: 23 [128/221852 (0%)]\tLoss: 0.283487\tAcc: 66.00\n",
      "val epoch: 23 [12928/221852 (6%)]\tLoss: 0.247180\tAcc: 68.00\n",
      "train epoch: 24 [128/221852 (0%)]\tLoss: 0.304862\tAcc: 70.00\n",
      "train epoch: 24 [12928/221852 (6%)]\tLoss: 0.312016\tAcc: 62.00\n",
      "train epoch: 24 [25728/221852 (12%)]\tLoss: 0.347510\tAcc: 70.00\n",
      "train epoch: 24 [38528/221852 (17%)]\tLoss: 0.343110\tAcc: 65.00\n",
      "train epoch: 24 [51328/221852 (23%)]\tLoss: 0.243948\tAcc: 58.00\n",
      "train epoch: 24 [64128/221852 (29%)]\tLoss: 0.244177\tAcc: 69.00\n",
      "train epoch: 24 [76928/221852 (35%)]\tLoss: 0.360950\tAcc: 65.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 24 [89728/221852 (40%)]\tLoss: 0.354309\tAcc: 59.00\n",
      "train epoch: 24 [102528/221852 (46%)]\tLoss: 0.215585\tAcc: 65.00\n",
      "train epoch: 24 [115328/221852 (52%)]\tLoss: 0.172343\tAcc: 62.00\n",
      "train epoch: 24 [128128/221852 (58%)]\tLoss: 0.227303\tAcc: 62.00\n",
      "train epoch: 24 [140928/221852 (64%)]\tLoss: 0.203086\tAcc: 69.00\n",
      "train epoch: 24 [153728/221852 (69%)]\tLoss: 0.296938\tAcc: 59.00\n",
      "train epoch: 24 [166528/221852 (75%)]\tLoss: 0.327526\tAcc: 58.00\n",
      "train epoch: 24 [179328/221852 (81%)]\tLoss: 0.325462\tAcc: 68.00\n",
      "train epoch: 24 [192128/221852 (87%)]\tLoss: 0.265418\tAcc: 72.00\n",
      "val epoch: 24 [128/221852 (0%)]\tLoss: 0.241319\tAcc: 66.00\n",
      "val epoch: 24 [12928/221852 (6%)]\tLoss: 0.255808\tAcc: 61.00\n",
      "train epoch: 25 [128/221852 (0%)]\tLoss: 0.166913\tAcc: 65.00\n",
      "train epoch: 25 [12928/221852 (6%)]\tLoss: 0.259971\tAcc: 63.00\n",
      "train epoch: 25 [25728/221852 (12%)]\tLoss: 0.255238\tAcc: 66.00\n",
      "train epoch: 25 [38528/221852 (17%)]\tLoss: 0.299047\tAcc: 70.00\n",
      "train epoch: 25 [51328/221852 (23%)]\tLoss: 0.363829\tAcc: 59.00\n",
      "train epoch: 25 [64128/221852 (29%)]\tLoss: 0.489092\tAcc: 64.00\n",
      "train epoch: 25 [76928/221852 (35%)]\tLoss: 0.233189\tAcc: 60.00\n",
      "train epoch: 25 [89728/221852 (40%)]\tLoss: 0.428840\tAcc: 67.00\n",
      "train epoch: 25 [102528/221852 (46%)]\tLoss: 0.504602\tAcc: 68.00\n",
      "train epoch: 25 [115328/221852 (52%)]\tLoss: 0.216973\tAcc: 63.00\n",
      "train epoch: 25 [128128/221852 (58%)]\tLoss: 0.256370\tAcc: 68.00\n",
      "train epoch: 25 [140928/221852 (64%)]\tLoss: 0.236017\tAcc: 60.00\n",
      "train epoch: 25 [153728/221852 (69%)]\tLoss: 0.425938\tAcc: 59.00\n",
      "train epoch: 25 [166528/221852 (75%)]\tLoss: 0.363266\tAcc: 62.00\n",
      "train epoch: 25 [179328/221852 (81%)]\tLoss: 0.216832\tAcc: 65.00\n",
      "train epoch: 25 [192128/221852 (87%)]\tLoss: 0.310407\tAcc: 64.00\n",
      "val epoch: 25 [128/221852 (0%)]\tLoss: 0.292334\tAcc: 63.00\n",
      "val epoch: 25 [12928/221852 (6%)]\tLoss: 0.295279\tAcc: 66.00\n",
      "train epoch: 26 [128/221852 (0%)]\tLoss: 0.304345\tAcc: 67.00\n",
      "train epoch: 26 [12928/221852 (6%)]\tLoss: 0.310839\tAcc: 63.00\n",
      "train epoch: 26 [25728/221852 (12%)]\tLoss: 0.316356\tAcc: 60.00\n",
      "train epoch: 26 [38528/221852 (17%)]\tLoss: 0.218520\tAcc: 72.00\n",
      "train epoch: 26 [51328/221852 (23%)]\tLoss: 0.353613\tAcc: 68.00\n",
      "train epoch: 26 [64128/221852 (29%)]\tLoss: 0.250337\tAcc: 73.00\n",
      "train epoch: 26 [76928/221852 (35%)]\tLoss: 0.283904\tAcc: 62.00\n",
      "train epoch: 26 [89728/221852 (40%)]\tLoss: 0.247453\tAcc: 62.00\n",
      "train epoch: 26 [102528/221852 (46%)]\tLoss: 0.231428\tAcc: 72.00\n",
      "train epoch: 26 [115328/221852 (52%)]\tLoss: 0.208181\tAcc: 69.00\n",
      "train epoch: 26 [128128/221852 (58%)]\tLoss: 0.250187\tAcc: 76.00\n",
      "train epoch: 26 [140928/221852 (64%)]\tLoss: 0.246184\tAcc: 67.00\n",
      "train epoch: 26 [153728/221852 (69%)]\tLoss: 0.242081\tAcc: 70.00\n",
      "train epoch: 26 [166528/221852 (75%)]\tLoss: 0.175917\tAcc: 66.00\n",
      "train epoch: 26 [179328/221852 (81%)]\tLoss: 0.226597\tAcc: 65.00\n",
      "train epoch: 26 [192128/221852 (87%)]\tLoss: 0.223440\tAcc: 67.00\n",
      "val epoch: 26 [128/221852 (0%)]\tLoss: 0.285640\tAcc: 63.00\n",
      "val epoch: 26 [12928/221852 (6%)]\tLoss: 0.285436\tAcc: 62.00\n",
      "train epoch: 27 [128/221852 (0%)]\tLoss: 0.301214\tAcc: 66.00\n",
      "train epoch: 27 [12928/221852 (6%)]\tLoss: 0.254736\tAcc: 68.00\n",
      "train epoch: 27 [25728/221852 (12%)]\tLoss: 0.289583\tAcc: 74.00\n",
      "train epoch: 27 [38528/221852 (17%)]\tLoss: 0.348987\tAcc: 65.00\n",
      "train epoch: 27 [51328/221852 (23%)]\tLoss: 0.232512\tAcc: 68.00\n",
      "train epoch: 27 [64128/221852 (29%)]\tLoss: 0.204212\tAcc: 72.00\n",
      "train epoch: 27 [76928/221852 (35%)]\tLoss: 0.309921\tAcc: 63.00\n",
      "train epoch: 27 [89728/221852 (40%)]\tLoss: 0.253007\tAcc: 61.00\n",
      "train epoch: 27 [102528/221852 (46%)]\tLoss: 0.412041\tAcc: 62.00\n",
      "train epoch: 27 [115328/221852 (52%)]\tLoss: 0.263302\tAcc: 68.00\n",
      "train epoch: 27 [128128/221852 (58%)]\tLoss: 0.171676\tAcc: 73.00\n",
      "train epoch: 27 [140928/221852 (64%)]\tLoss: 0.371031\tAcc: 61.00\n",
      "train epoch: 27 [153728/221852 (69%)]\tLoss: 0.258435\tAcc: 67.00\n",
      "train epoch: 27 [166528/221852 (75%)]\tLoss: 0.298107\tAcc: 74.00\n",
      "train epoch: 27 [179328/221852 (81%)]\tLoss: 0.200606\tAcc: 69.00\n",
      "train epoch: 27 [192128/221852 (87%)]\tLoss: 0.239964\tAcc: 68.00\n",
      "val epoch: 27 [128/221852 (0%)]\tLoss: 0.369439\tAcc: 59.00\n",
      "val epoch: 27 [12928/221852 (6%)]\tLoss: 0.405750\tAcc: 65.00\n",
      "train epoch: 28 [128/221852 (0%)]\tLoss: 0.318708\tAcc: 66.00\n",
      "train epoch: 28 [12928/221852 (6%)]\tLoss: 0.222084\tAcc: 70.00\n",
      "train epoch: 28 [25728/221852 (12%)]\tLoss: 0.484997\tAcc: 70.00\n",
      "train epoch: 28 [38528/221852 (17%)]\tLoss: 0.322175\tAcc: 58.00\n",
      "train epoch: 28 [51328/221852 (23%)]\tLoss: 0.334730\tAcc: 64.00\n",
      "train epoch: 28 [64128/221852 (29%)]\tLoss: 0.195529\tAcc: 72.00\n",
      "train epoch: 28 [76928/221852 (35%)]\tLoss: 0.362163\tAcc: 68.00\n",
      "train epoch: 28 [89728/221852 (40%)]\tLoss: 0.217744\tAcc: 70.00\n",
      "train epoch: 28 [102528/221852 (46%)]\tLoss: 0.369938\tAcc: 62.00\n",
      "train epoch: 28 [115328/221852 (52%)]\tLoss: 0.201741\tAcc: 66.00\n",
      "train epoch: 28 [128128/221852 (58%)]\tLoss: 0.176176\tAcc: 74.00\n",
      "train epoch: 28 [140928/221852 (64%)]\tLoss: 0.260563\tAcc: 66.00\n",
      "train epoch: 28 [153728/221852 (69%)]\tLoss: 0.381579\tAcc: 67.00\n",
      "train epoch: 28 [166528/221852 (75%)]\tLoss: 0.204534\tAcc: 67.00\n",
      "train epoch: 28 [179328/221852 (81%)]\tLoss: 0.264526\tAcc: 73.00\n",
      "train epoch: 28 [192128/221852 (87%)]\tLoss: 0.277278\tAcc: 66.00\n",
      "val epoch: 28 [128/221852 (0%)]\tLoss: 0.255102\tAcc: 59.00\n",
      "val epoch: 28 [12928/221852 (6%)]\tLoss: 0.176817\tAcc: 69.00\n",
      "train epoch: 29 [128/221852 (0%)]\tLoss: 0.213614\tAcc: 66.00\n",
      "train epoch: 29 [12928/221852 (6%)]\tLoss: 0.289537\tAcc: 69.00\n",
      "train epoch: 29 [25728/221852 (12%)]\tLoss: 0.304726\tAcc: 66.00\n",
      "train epoch: 29 [38528/221852 (17%)]\tLoss: 0.336695\tAcc: 67.00\n",
      "train epoch: 29 [51328/221852 (23%)]\tLoss: 0.215553\tAcc: 65.00\n",
      "train epoch: 29 [64128/221852 (29%)]\tLoss: 0.261153\tAcc: 68.00\n",
      "train epoch: 29 [76928/221852 (35%)]\tLoss: 0.213358\tAcc: 68.00\n",
      "train epoch: 29 [89728/221852 (40%)]\tLoss: 0.212129\tAcc: 73.00\n",
      "train epoch: 29 [102528/221852 (46%)]\tLoss: 0.300324\tAcc: 66.00\n",
      "train epoch: 29 [115328/221852 (52%)]\tLoss: 0.236219\tAcc: 74.00\n",
      "train epoch: 29 [128128/221852 (58%)]\tLoss: 0.348883\tAcc: 69.00\n",
      "train epoch: 29 [140928/221852 (64%)]\tLoss: 0.280654\tAcc: 59.00\n",
      "train epoch: 29 [153728/221852 (69%)]\tLoss: 0.221182\tAcc: 69.00\n",
      "train epoch: 29 [166528/221852 (75%)]\tLoss: 0.251454\tAcc: 64.00\n",
      "train epoch: 29 [179328/221852 (81%)]\tLoss: 0.235882\tAcc: 73.00\n",
      "train epoch: 29 [192128/221852 (87%)]\tLoss: 0.361689\tAcc: 62.00\n",
      "val epoch: 29 [128/221852 (0%)]\tLoss: 0.243536\tAcc: 62.00\n",
      "val epoch: 29 [12928/221852 (6%)]\tLoss: 0.269220\tAcc: 61.00\n",
      "train epoch: 30 [128/221852 (0%)]\tLoss: 0.262447\tAcc: 66.00\n",
      "train epoch: 30 [12928/221852 (6%)]\tLoss: 0.237420\tAcc: 60.00\n",
      "train epoch: 30 [25728/221852 (12%)]\tLoss: 0.273510\tAcc: 65.00\n",
      "train epoch: 30 [38528/221852 (17%)]\tLoss: 0.314225\tAcc: 67.00\n",
      "train epoch: 30 [51328/221852 (23%)]\tLoss: 0.255993\tAcc: 72.00\n",
      "train epoch: 30 [64128/221852 (29%)]\tLoss: 0.257775\tAcc: 63.00\n",
      "train epoch: 30 [76928/221852 (35%)]\tLoss: 0.274120\tAcc: 66.00\n",
      "train epoch: 30 [89728/221852 (40%)]\tLoss: 0.378741\tAcc: 65.00\n",
      "train epoch: 30 [102528/221852 (46%)]\tLoss: 0.313762\tAcc: 70.00\n",
      "train epoch: 30 [115328/221852 (52%)]\tLoss: 0.227213\tAcc: 66.00\n",
      "train epoch: 30 [128128/221852 (58%)]\tLoss: 0.237897\tAcc: 62.00\n",
      "train epoch: 30 [140928/221852 (64%)]\tLoss: 0.343268\tAcc: 66.00\n",
      "train epoch: 30 [153728/221852 (69%)]\tLoss: 0.242264\tAcc: 75.00\n",
      "train epoch: 30 [166528/221852 (75%)]\tLoss: 0.303464\tAcc: 63.00\n",
      "train epoch: 30 [179328/221852 (81%)]\tLoss: 0.436244\tAcc: 61.00\n",
      "train epoch: 30 [192128/221852 (87%)]\tLoss: 0.325552\tAcc: 55.00\n",
      "val epoch: 30 [128/221852 (0%)]\tLoss: 0.201357\tAcc: 72.00\n",
      "val epoch: 30 [12928/221852 (6%)]\tLoss: 0.242390\tAcc: 62.00\n",
      "train epoch: 31 [128/221852 (0%)]\tLoss: 0.210195\tAcc: 67.00\n",
      "train epoch: 31 [12928/221852 (6%)]\tLoss: 0.183740\tAcc: 76.00\n",
      "train epoch: 31 [25728/221852 (12%)]\tLoss: 0.304338\tAcc: 66.00\n",
      "train epoch: 31 [38528/221852 (17%)]\tLoss: 0.307277\tAcc: 62.00\n",
      "train epoch: 31 [51328/221852 (23%)]\tLoss: 0.267016\tAcc: 64.00\n",
      "train epoch: 31 [64128/221852 (29%)]\tLoss: 0.264269\tAcc: 66.00\n",
      "train epoch: 31 [76928/221852 (35%)]\tLoss: 0.335857\tAcc: 59.00\n",
      "train epoch: 31 [89728/221852 (40%)]\tLoss: 0.372711\tAcc: 66.00\n",
      "train epoch: 31 [102528/221852 (46%)]\tLoss: 0.192896\tAcc: 76.00\n",
      "train epoch: 31 [115328/221852 (52%)]\tLoss: 0.268562\tAcc: 59.00\n",
      "train epoch: 31 [128128/221852 (58%)]\tLoss: 0.204065\tAcc: 70.00\n",
      "train epoch: 31 [140928/221852 (64%)]\tLoss: 0.282683\tAcc: 69.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 31 [153728/221852 (69%)]\tLoss: 0.555544\tAcc: 65.00\n",
      "train epoch: 31 [166528/221852 (75%)]\tLoss: 0.261876\tAcc: 74.00\n",
      "train epoch: 31 [179328/221852 (81%)]\tLoss: 0.222187\tAcc: 69.00\n",
      "train epoch: 31 [192128/221852 (87%)]\tLoss: 0.179421\tAcc: 67.00\n",
      "val epoch: 31 [128/221852 (0%)]\tLoss: 0.217979\tAcc: 77.00\n",
      "val epoch: 31 [12928/221852 (6%)]\tLoss: 0.175993\tAcc: 70.00\n",
      "train epoch: 32 [128/221852 (0%)]\tLoss: 0.202831\tAcc: 75.00\n",
      "train epoch: 32 [12928/221852 (6%)]\tLoss: 0.379873\tAcc: 66.00\n",
      "train epoch: 32 [25728/221852 (12%)]\tLoss: 0.287129\tAcc: 58.00\n",
      "train epoch: 32 [38528/221852 (17%)]\tLoss: 0.192252\tAcc: 71.00\n",
      "train epoch: 32 [51328/221852 (23%)]\tLoss: 0.248227\tAcc: 70.00\n",
      "train epoch: 32 [64128/221852 (29%)]\tLoss: 0.199446\tAcc: 71.00\n",
      "train epoch: 32 [76928/221852 (35%)]\tLoss: 0.358389\tAcc: 66.00\n",
      "train epoch: 32 [89728/221852 (40%)]\tLoss: 0.384189\tAcc: 61.00\n",
      "train epoch: 32 [102528/221852 (46%)]\tLoss: 0.274046\tAcc: 57.00\n",
      "train epoch: 32 [115328/221852 (52%)]\tLoss: 0.276950\tAcc: 66.00\n",
      "train epoch: 32 [128128/221852 (58%)]\tLoss: 0.281561\tAcc: 64.00\n",
      "train epoch: 32 [140928/221852 (64%)]\tLoss: 0.175462\tAcc: 71.00\n",
      "train epoch: 32 [153728/221852 (69%)]\tLoss: 0.258245\tAcc: 69.00\n",
      "train epoch: 32 [166528/221852 (75%)]\tLoss: 0.255279\tAcc: 71.00\n",
      "train epoch: 32 [179328/221852 (81%)]\tLoss: 0.263061\tAcc: 77.00\n",
      "train epoch: 32 [192128/221852 (87%)]\tLoss: 0.250183\tAcc: 67.00\n",
      "val epoch: 32 [128/221852 (0%)]\tLoss: 0.213378\tAcc: 64.00\n",
      "val epoch: 32 [12928/221852 (6%)]\tLoss: 0.299018\tAcc: 65.00\n",
      "train epoch: 33 [128/221852 (0%)]\tLoss: 0.231708\tAcc: 65.00\n",
      "train epoch: 33 [12928/221852 (6%)]\tLoss: 0.186411\tAcc: 77.00\n",
      "train epoch: 33 [25728/221852 (12%)]\tLoss: 0.220097\tAcc: 68.00\n",
      "train epoch: 33 [38528/221852 (17%)]\tLoss: 0.326854\tAcc: 65.00\n",
      "train epoch: 33 [51328/221852 (23%)]\tLoss: 0.200648\tAcc: 72.00\n",
      "train epoch: 33 [64128/221852 (29%)]\tLoss: 0.254707\tAcc: 72.00\n",
      "train epoch: 33 [76928/221852 (35%)]\tLoss: 0.256941\tAcc: 70.00\n",
      "train epoch: 33 [89728/221852 (40%)]\tLoss: 0.265923\tAcc: 66.00\n",
      "train epoch: 33 [102528/221852 (46%)]\tLoss: 0.266901\tAcc: 66.00\n",
      "train epoch: 33 [115328/221852 (52%)]\tLoss: 0.192473\tAcc: 66.00\n",
      "train epoch: 33 [128128/221852 (58%)]\tLoss: 0.225937\tAcc: 70.00\n",
      "train epoch: 33 [140928/221852 (64%)]\tLoss: 0.192212\tAcc: 64.00\n",
      "train epoch: 33 [153728/221852 (69%)]\tLoss: 0.267206\tAcc: 67.00\n",
      "train epoch: 33 [166528/221852 (75%)]\tLoss: 0.306983\tAcc: 70.00\n",
      "train epoch: 33 [179328/221852 (81%)]\tLoss: 0.246227\tAcc: 72.00\n",
      "train epoch: 33 [192128/221852 (87%)]\tLoss: 0.363185\tAcc: 62.00\n",
      "val epoch: 33 [128/221852 (0%)]\tLoss: 0.169042\tAcc: 71.00\n",
      "val epoch: 33 [12928/221852 (6%)]\tLoss: 0.215049\tAcc: 67.00\n",
      "train epoch: 34 [128/221852 (0%)]\tLoss: 0.251965\tAcc: 72.00\n",
      "train epoch: 34 [12928/221852 (6%)]\tLoss: 0.318896\tAcc: 66.00\n",
      "train epoch: 34 [25728/221852 (12%)]\tLoss: 0.224643\tAcc: 71.00\n",
      "train epoch: 34 [38528/221852 (17%)]\tLoss: 0.313696\tAcc: 70.00\n",
      "train epoch: 34 [51328/221852 (23%)]\tLoss: 0.231887\tAcc: 67.00\n",
      "train epoch: 34 [64128/221852 (29%)]\tLoss: 0.321873\tAcc: 61.00\n",
      "train epoch: 34 [76928/221852 (35%)]\tLoss: 0.204358\tAcc: 68.00\n",
      "train epoch: 34 [89728/221852 (40%)]\tLoss: 0.214772\tAcc: 69.00\n",
      "train epoch: 34 [102528/221852 (46%)]\tLoss: 0.167211\tAcc: 72.00\n",
      "train epoch: 34 [115328/221852 (52%)]\tLoss: 0.289969\tAcc: 68.00\n",
      "train epoch: 34 [128128/221852 (58%)]\tLoss: 0.328569\tAcc: 68.00\n",
      "train epoch: 34 [140928/221852 (64%)]\tLoss: 0.253911\tAcc: 66.00\n",
      "train epoch: 34 [153728/221852 (69%)]\tLoss: 0.261541\tAcc: 66.00\n",
      "train epoch: 34 [166528/221852 (75%)]\tLoss: 0.224277\tAcc: 67.00\n",
      "train epoch: 34 [179328/221852 (81%)]\tLoss: 0.266987\tAcc: 68.00\n",
      "train epoch: 34 [192128/221852 (87%)]\tLoss: 0.198265\tAcc: 74.00\n",
      "val epoch: 34 [128/221852 (0%)]\tLoss: 0.184280\tAcc: 66.00\n",
      "val epoch: 34 [12928/221852 (6%)]\tLoss: 0.263148\tAcc: 74.00\n",
      "train epoch: 35 [128/221852 (0%)]\tLoss: 0.259362\tAcc: 72.00\n",
      "train epoch: 35 [12928/221852 (6%)]\tLoss: 0.228980\tAcc: 77.00\n",
      "train epoch: 35 [25728/221852 (12%)]\tLoss: 0.285433\tAcc: 73.00\n",
      "train epoch: 35 [38528/221852 (17%)]\tLoss: 0.189526\tAcc: 68.00\n",
      "train epoch: 35 [51328/221852 (23%)]\tLoss: 0.246756\tAcc: 61.00\n",
      "train epoch: 35 [64128/221852 (29%)]\tLoss: 0.255271\tAcc: 65.00\n",
      "train epoch: 35 [76928/221852 (35%)]\tLoss: 0.182818\tAcc: 62.00\n",
      "train epoch: 35 [89728/221852 (40%)]\tLoss: 0.293308\tAcc: 62.00\n",
      "train epoch: 35 [102528/221852 (46%)]\tLoss: 0.213792\tAcc: 67.00\n",
      "train epoch: 35 [115328/221852 (52%)]\tLoss: 0.308027\tAcc: 65.00\n",
      "train epoch: 35 [128128/221852 (58%)]\tLoss: 0.224773\tAcc: 74.00\n",
      "train epoch: 35 [140928/221852 (64%)]\tLoss: 0.404064\tAcc: 62.00\n",
      "train epoch: 35 [153728/221852 (69%)]\tLoss: 0.284084\tAcc: 58.00\n",
      "train epoch: 35 [166528/221852 (75%)]\tLoss: 0.284531\tAcc: 70.00\n",
      "train epoch: 35 [179328/221852 (81%)]\tLoss: 0.343178\tAcc: 66.00\n",
      "train epoch: 35 [192128/221852 (87%)]\tLoss: 0.248579\tAcc: 66.00\n",
      "val epoch: 35 [128/221852 (0%)]\tLoss: 0.215865\tAcc: 69.00\n",
      "val epoch: 35 [12928/221852 (6%)]\tLoss: 0.248429\tAcc: 69.00\n",
      "train epoch: 36 [128/221852 (0%)]\tLoss: 0.314604\tAcc: 63.00\n",
      "train epoch: 36 [12928/221852 (6%)]\tLoss: 0.281765\tAcc: 70.00\n",
      "train epoch: 36 [25728/221852 (12%)]\tLoss: 0.261823\tAcc: 68.00\n",
      "train epoch: 36 [38528/221852 (17%)]\tLoss: 0.192448\tAcc: 71.00\n",
      "train epoch: 36 [51328/221852 (23%)]\tLoss: 0.253254\tAcc: 70.00\n",
      "train epoch: 36 [64128/221852 (29%)]\tLoss: 0.216531\tAcc: 66.00\n",
      "train epoch: 36 [76928/221852 (35%)]\tLoss: 0.242682\tAcc: 68.00\n",
      "train epoch: 36 [89728/221852 (40%)]\tLoss: 0.216885\tAcc: 69.00\n",
      "train epoch: 36 [102528/221852 (46%)]\tLoss: 0.338792\tAcc: 58.00\n",
      "train epoch: 36 [115328/221852 (52%)]\tLoss: 0.220598\tAcc: 71.00\n",
      "train epoch: 36 [128128/221852 (58%)]\tLoss: 0.310099\tAcc: 59.00\n",
      "train epoch: 36 [140928/221852 (64%)]\tLoss: 0.191356\tAcc: 78.00\n",
      "train epoch: 36 [153728/221852 (69%)]\tLoss: 0.315187\tAcc: 63.00\n",
      "train epoch: 36 [166528/221852 (75%)]\tLoss: 0.386144\tAcc: 60.00\n",
      "train epoch: 36 [179328/221852 (81%)]\tLoss: 0.299916\tAcc: 63.00\n",
      "train epoch: 36 [192128/221852 (87%)]\tLoss: 0.192090\tAcc: 70.00\n",
      "val epoch: 36 [128/221852 (0%)]\tLoss: 0.219047\tAcc: 74.00\n",
      "val epoch: 36 [12928/221852 (6%)]\tLoss: 0.207956\tAcc: 72.00\n",
      "train epoch: 37 [128/221852 (0%)]\tLoss: 0.235929\tAcc: 62.00\n",
      "train epoch: 37 [12928/221852 (6%)]\tLoss: 0.301546\tAcc: 70.00\n",
      "train epoch: 37 [25728/221852 (12%)]\tLoss: 0.318650\tAcc: 69.00\n",
      "train epoch: 37 [38528/221852 (17%)]\tLoss: 0.245034\tAcc: 73.00\n",
      "train epoch: 37 [51328/221852 (23%)]\tLoss: 0.308060\tAcc: 69.00\n",
      "train epoch: 37 [64128/221852 (29%)]\tLoss: 0.280289\tAcc: 71.00\n",
      "train epoch: 37 [76928/221852 (35%)]\tLoss: 0.268982\tAcc: 65.00\n",
      "train epoch: 37 [89728/221852 (40%)]\tLoss: 0.300863\tAcc: 73.00\n",
      "train epoch: 37 [102528/221852 (46%)]\tLoss: 0.215706\tAcc: 71.00\n",
      "train epoch: 37 [115328/221852 (52%)]\tLoss: 0.267340\tAcc: 66.00\n",
      "train epoch: 37 [128128/221852 (58%)]\tLoss: 0.297325\tAcc: 74.00\n",
      "train epoch: 37 [140928/221852 (64%)]\tLoss: 0.187571\tAcc: 70.00\n",
      "train epoch: 37 [153728/221852 (69%)]\tLoss: 0.209734\tAcc: 69.00\n",
      "train epoch: 37 [166528/221852 (75%)]\tLoss: 0.242818\tAcc: 69.00\n",
      "train epoch: 37 [179328/221852 (81%)]\tLoss: 0.186214\tAcc: 73.00\n",
      "train epoch: 37 [192128/221852 (87%)]\tLoss: 0.254699\tAcc: 74.00\n",
      "val epoch: 37 [128/221852 (0%)]\tLoss: 0.158423\tAcc: 73.00\n",
      "val epoch: 37 [12928/221852 (6%)]\tLoss: 0.222884\tAcc: 70.00\n",
      "train epoch: 38 [128/221852 (0%)]\tLoss: 0.209370\tAcc: 77.00\n",
      "train epoch: 38 [12928/221852 (6%)]\tLoss: 0.296669\tAcc: 66.00\n",
      "train epoch: 38 [25728/221852 (12%)]\tLoss: 0.164515\tAcc: 74.00\n",
      "train epoch: 38 [38528/221852 (17%)]\tLoss: 0.385513\tAcc: 61.00\n",
      "train epoch: 38 [51328/221852 (23%)]\tLoss: 0.249263\tAcc: 64.00\n",
      "train epoch: 38 [64128/221852 (29%)]\tLoss: 0.203033\tAcc: 76.00\n",
      "train epoch: 38 [76928/221852 (35%)]\tLoss: 0.322575\tAcc: 69.00\n",
      "train epoch: 38 [89728/221852 (40%)]\tLoss: 0.262263\tAcc: 75.00\n",
      "train epoch: 38 [102528/221852 (46%)]\tLoss: 0.332203\tAcc: 66.00\n",
      "train epoch: 38 [115328/221852 (52%)]\tLoss: 0.271777\tAcc: 69.00\n",
      "train epoch: 38 [128128/221852 (58%)]\tLoss: 0.189170\tAcc: 67.00\n",
      "train epoch: 38 [140928/221852 (64%)]\tLoss: 0.379688\tAcc: 63.00\n",
      "train epoch: 38 [153728/221852 (69%)]\tLoss: 0.249461\tAcc: 73.00\n",
      "train epoch: 38 [166528/221852 (75%)]\tLoss: 0.274253\tAcc: 71.00\n",
      "train epoch: 38 [179328/221852 (81%)]\tLoss: 0.214111\tAcc: 72.00\n",
      "train epoch: 38 [192128/221852 (87%)]\tLoss: 0.175156\tAcc: 71.00\n",
      "val epoch: 38 [128/221852 (0%)]\tLoss: 0.175003\tAcc: 68.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 38 [12928/221852 (6%)]\tLoss: 0.255428\tAcc: 70.00\n",
      "train epoch: 39 [128/221852 (0%)]\tLoss: 0.234199\tAcc: 80.00\n",
      "train epoch: 39 [12928/221852 (6%)]\tLoss: 0.306879\tAcc: 71.00\n",
      "train epoch: 39 [25728/221852 (12%)]\tLoss: 0.246099\tAcc: 63.00\n",
      "train epoch: 39 [38528/221852 (17%)]\tLoss: 0.523568\tAcc: 64.00\n",
      "train epoch: 39 [51328/221852 (23%)]\tLoss: 0.238034\tAcc: 71.00\n",
      "train epoch: 39 [64128/221852 (29%)]\tLoss: 0.277153\tAcc: 66.00\n",
      "train epoch: 39 [76928/221852 (35%)]\tLoss: 0.227176\tAcc: 73.00\n",
      "train epoch: 39 [89728/221852 (40%)]\tLoss: 0.248472\tAcc: 73.00\n",
      "train epoch: 39 [102528/221852 (46%)]\tLoss: 0.157463\tAcc: 71.00\n",
      "train epoch: 39 [115328/221852 (52%)]\tLoss: 0.237491\tAcc: 72.00\n",
      "train epoch: 39 [128128/221852 (58%)]\tLoss: 0.289542\tAcc: 70.00\n",
      "train epoch: 39 [140928/221852 (64%)]\tLoss: 0.212116\tAcc: 76.00\n",
      "train epoch: 39 [153728/221852 (69%)]\tLoss: 0.284886\tAcc: 70.00\n",
      "train epoch: 39 [166528/221852 (75%)]\tLoss: 0.253228\tAcc: 74.00\n",
      "train epoch: 39 [179328/221852 (81%)]\tLoss: 0.248000\tAcc: 74.00\n",
      "train epoch: 39 [192128/221852 (87%)]\tLoss: 0.206788\tAcc: 77.00\n",
      "val epoch: 39 [128/221852 (0%)]\tLoss: 0.459920\tAcc: 60.00\n",
      "val epoch: 39 [12928/221852 (6%)]\tLoss: 0.473253\tAcc: 60.00\n",
      "train epoch: 40 [128/221852 (0%)]\tLoss: 0.494379\tAcc: 68.00\n",
      "train epoch: 40 [12928/221852 (6%)]\tLoss: 0.288858\tAcc: 56.00\n",
      "train epoch: 40 [25728/221852 (12%)]\tLoss: 0.280217\tAcc: 58.00\n",
      "train epoch: 40 [38528/221852 (17%)]\tLoss: 0.265445\tAcc: 61.00\n",
      "train epoch: 40 [51328/221852 (23%)]\tLoss: 0.265105\tAcc: 67.00\n",
      "train epoch: 40 [64128/221852 (29%)]\tLoss: 0.277892\tAcc: 61.00\n",
      "train epoch: 40 [76928/221852 (35%)]\tLoss: 0.267175\tAcc: 63.00\n",
      "train epoch: 40 [89728/221852 (40%)]\tLoss: 0.323621\tAcc: 61.00\n",
      "train epoch: 40 [102528/221852 (46%)]\tLoss: 0.356694\tAcc: 64.00\n",
      "train epoch: 40 [115328/221852 (52%)]\tLoss: 0.401793\tAcc: 64.00\n",
      "train epoch: 40 [128128/221852 (58%)]\tLoss: 0.205804\tAcc: 64.00\n",
      "train epoch: 40 [140928/221852 (64%)]\tLoss: 0.200640\tAcc: 73.00\n",
      "train epoch: 40 [153728/221852 (69%)]\tLoss: 0.198126\tAcc: 69.00\n",
      "train epoch: 40 [166528/221852 (75%)]\tLoss: 0.220971\tAcc: 74.00\n",
      "train epoch: 40 [179328/221852 (81%)]\tLoss: 0.290268\tAcc: 74.00\n",
      "train epoch: 40 [192128/221852 (87%)]\tLoss: 0.231676\tAcc: 71.00\n",
      "val epoch: 40 [128/221852 (0%)]\tLoss: 0.337952\tAcc: 63.00\n",
      "val epoch: 40 [12928/221852 (6%)]\tLoss: 0.325672\tAcc: 62.00\n",
      "train epoch: 41 [128/221852 (0%)]\tLoss: 0.285880\tAcc: 65.00\n",
      "train epoch: 41 [12928/221852 (6%)]\tLoss: 0.262636\tAcc: 63.00\n",
      "train epoch: 41 [25728/221852 (12%)]\tLoss: 0.264961\tAcc: 80.00\n",
      "train epoch: 41 [38528/221852 (17%)]\tLoss: 0.283444\tAcc: 73.00\n",
      "train epoch: 41 [51328/221852 (23%)]\tLoss: 0.837687\tAcc: 73.00\n",
      "train epoch: 41 [64128/221852 (29%)]\tLoss: 0.321775\tAcc: 61.00\n",
      "train epoch: 41 [76928/221852 (35%)]\tLoss: 0.225906\tAcc: 67.00\n",
      "train epoch: 41 [89728/221852 (40%)]\tLoss: 0.245760\tAcc: 65.00\n",
      "train epoch: 41 [102528/221852 (46%)]\tLoss: 0.245571\tAcc: 72.00\n",
      "train epoch: 41 [115328/221852 (52%)]\tLoss: 0.291854\tAcc: 75.00\n",
      "train epoch: 41 [128128/221852 (58%)]\tLoss: 0.256988\tAcc: 70.00\n",
      "train epoch: 41 [140928/221852 (64%)]\tLoss: 0.356716\tAcc: 71.00\n",
      "train epoch: 41 [153728/221852 (69%)]\tLoss: 0.223547\tAcc: 76.00\n",
      "train epoch: 41 [166528/221852 (75%)]\tLoss: 0.221255\tAcc: 70.00\n",
      "train epoch: 41 [179328/221852 (81%)]\tLoss: 0.494931\tAcc: 54.00\n",
      "train epoch: 41 [192128/221852 (87%)]\tLoss: 0.322825\tAcc: 63.00\n",
      "val epoch: 41 [128/221852 (0%)]\tLoss: 0.304626\tAcc: 61.00\n",
      "val epoch: 41 [12928/221852 (6%)]\tLoss: 0.297300\tAcc: 66.00\n",
      "train epoch: 42 [128/221852 (0%)]\tLoss: 0.179893\tAcc: 66.00\n",
      "train epoch: 42 [12928/221852 (6%)]\tLoss: 0.331829\tAcc: 62.00\n",
      "train epoch: 42 [25728/221852 (12%)]\tLoss: 0.467633\tAcc: 64.00\n",
      "train epoch: 42 [38528/221852 (17%)]\tLoss: 0.231703\tAcc: 65.00\n",
      "train epoch: 42 [51328/221852 (23%)]\tLoss: 0.252601\tAcc: 72.00\n",
      "train epoch: 42 [64128/221852 (29%)]\tLoss: 0.231583\tAcc: 73.00\n",
      "train epoch: 42 [76928/221852 (35%)]\tLoss: 0.223444\tAcc: 81.00\n",
      "train epoch: 42 [89728/221852 (40%)]\tLoss: 0.314753\tAcc: 71.00\n",
      "train epoch: 42 [102528/221852 (46%)]\tLoss: 0.217201\tAcc: 75.00\n",
      "train epoch: 42 [115328/221852 (52%)]\tLoss: 0.262523\tAcc: 76.00\n",
      "train epoch: 42 [128128/221852 (58%)]\tLoss: 0.290578\tAcc: 69.00\n",
      "train epoch: 42 [140928/221852 (64%)]\tLoss: 0.296310\tAcc: 62.00\n",
      "train epoch: 42 [153728/221852 (69%)]\tLoss: 0.258699\tAcc: 73.00\n",
      "train epoch: 42 [166528/221852 (75%)]\tLoss: 0.209605\tAcc: 78.00\n",
      "train epoch: 42 [179328/221852 (81%)]\tLoss: 0.655205\tAcc: 73.00\n",
      "train epoch: 42 [192128/221852 (87%)]\tLoss: 0.371705\tAcc: 67.00\n",
      "val epoch: 42 [128/221852 (0%)]\tLoss: 0.301605\tAcc: 55.00\n",
      "val epoch: 42 [12928/221852 (6%)]\tLoss: 0.280218\tAcc: 60.00\n",
      "train epoch: 43 [128/221852 (0%)]\tLoss: 0.241456\tAcc: 70.00\n",
      "train epoch: 43 [12928/221852 (6%)]\tLoss: 0.357982\tAcc: 64.00\n",
      "train epoch: 43 [25728/221852 (12%)]\tLoss: 0.204894\tAcc: 71.00\n",
      "train epoch: 43 [38528/221852 (17%)]\tLoss: 0.312301\tAcc: 66.00\n",
      "train epoch: 43 [51328/221852 (23%)]\tLoss: 0.281278\tAcc: 66.00\n",
      "train epoch: 43 [64128/221852 (29%)]\tLoss: 0.225615\tAcc: 70.00\n",
      "train epoch: 43 [76928/221852 (35%)]\tLoss: 0.309669\tAcc: 69.00\n",
      "train epoch: 43 [89728/221852 (40%)]\tLoss: 0.274178\tAcc: 70.00\n",
      "train epoch: 43 [102528/221852 (46%)]\tLoss: 0.219495\tAcc: 69.00\n",
      "train epoch: 43 [115328/221852 (52%)]\tLoss: 0.204421\tAcc: 74.00\n",
      "train epoch: 43 [128128/221852 (58%)]\tLoss: 0.256103\tAcc: 73.00\n",
      "train epoch: 43 [140928/221852 (64%)]\tLoss: 0.273165\tAcc: 74.00\n",
      "train epoch: 43 [153728/221852 (69%)]\tLoss: 0.290972\tAcc: 67.00\n",
      "train epoch: 43 [166528/221852 (75%)]\tLoss: 0.194155\tAcc: 71.00\n",
      "train epoch: 43 [179328/221852 (81%)]\tLoss: 0.194621\tAcc: 70.00\n",
      "train epoch: 43 [192128/221852 (87%)]\tLoss: 0.379083\tAcc: 66.00\n",
      "val epoch: 43 [128/221852 (0%)]\tLoss: 0.299477\tAcc: 73.00\n",
      "val epoch: 43 [12928/221852 (6%)]\tLoss: 0.258730\tAcc: 59.00\n",
      "train epoch: 44 [128/221852 (0%)]\tLoss: 0.328018\tAcc: 67.00\n",
      "train epoch: 44 [12928/221852 (6%)]\tLoss: 0.293335\tAcc: 67.00\n",
      "train epoch: 44 [25728/221852 (12%)]\tLoss: 0.286716\tAcc: 70.00\n",
      "train epoch: 44 [38528/221852 (17%)]\tLoss: 0.238564\tAcc: 68.00\n",
      "train epoch: 44 [51328/221852 (23%)]\tLoss: 0.177080\tAcc: 75.00\n",
      "train epoch: 44 [64128/221852 (29%)]\tLoss: 0.260504\tAcc: 70.00\n",
      "train epoch: 44 [76928/221852 (35%)]\tLoss: 0.209209\tAcc: 75.00\n",
      "train epoch: 44 [89728/221852 (40%)]\tLoss: 0.311209\tAcc: 73.00\n",
      "train epoch: 44 [102528/221852 (46%)]\tLoss: 0.217299\tAcc: 74.00\n",
      "train epoch: 44 [115328/221852 (52%)]\tLoss: 0.285812\tAcc: 67.00\n",
      "train epoch: 44 [128128/221852 (58%)]\tLoss: 0.299211\tAcc: 73.00\n",
      "train epoch: 44 [140928/221852 (64%)]\tLoss: 0.300568\tAcc: 71.00\n",
      "train epoch: 44 [153728/221852 (69%)]\tLoss: 0.258696\tAcc: 70.00\n",
      "train epoch: 44 [166528/221852 (75%)]\tLoss: 0.225828\tAcc: 70.00\n",
      "train epoch: 44 [179328/221852 (81%)]\tLoss: 0.215042\tAcc: 62.00\n",
      "train epoch: 44 [192128/221852 (87%)]\tLoss: 0.201633\tAcc: 73.00\n",
      "val epoch: 44 [128/221852 (0%)]\tLoss: 0.192188\tAcc: 75.00\n",
      "val epoch: 44 [12928/221852 (6%)]\tLoss: 0.203568\tAcc: 76.00\n",
      "train epoch: 45 [128/221852 (0%)]\tLoss: 0.287882\tAcc: 67.00\n",
      "train epoch: 45 [12928/221852 (6%)]\tLoss: 0.257580\tAcc: 66.00\n",
      "train epoch: 45 [25728/221852 (12%)]\tLoss: 0.294823\tAcc: 76.00\n",
      "train epoch: 45 [38528/221852 (17%)]\tLoss: 0.263435\tAcc: 70.00\n",
      "train epoch: 45 [51328/221852 (23%)]\tLoss: 0.188901\tAcc: 77.00\n",
      "train epoch: 45 [64128/221852 (29%)]\tLoss: 0.188393\tAcc: 77.00\n",
      "train epoch: 45 [76928/221852 (35%)]\tLoss: 0.213319\tAcc: 66.00\n",
      "train epoch: 45 [89728/221852 (40%)]\tLoss: 0.210095\tAcc: 64.00\n",
      "train epoch: 45 [102528/221852 (46%)]\tLoss: 0.192392\tAcc: 67.00\n",
      "train epoch: 45 [115328/221852 (52%)]\tLoss: 0.297549\tAcc: 70.00\n",
      "train epoch: 45 [128128/221852 (58%)]\tLoss: 0.179572\tAcc: 75.00\n",
      "train epoch: 45 [140928/221852 (64%)]\tLoss: 0.167467\tAcc: 73.00\n",
      "train epoch: 45 [153728/221852 (69%)]\tLoss: 0.390626\tAcc: 62.00\n",
      "train epoch: 45 [166528/221852 (75%)]\tLoss: 0.251512\tAcc: 61.00\n",
      "train epoch: 45 [179328/221852 (81%)]\tLoss: 0.261357\tAcc: 71.00\n",
      "train epoch: 45 [192128/221852 (87%)]\tLoss: 0.174492\tAcc: 74.00\n",
      "val epoch: 45 [128/221852 (0%)]\tLoss: 0.209061\tAcc: 67.00\n",
      "val epoch: 45 [12928/221852 (6%)]\tLoss: 0.182321\tAcc: 70.00\n",
      "train epoch: 46 [128/221852 (0%)]\tLoss: 0.175604\tAcc: 70.00\n",
      "train epoch: 46 [12928/221852 (6%)]\tLoss: 0.246028\tAcc: 74.00\n",
      "train epoch: 46 [25728/221852 (12%)]\tLoss: 0.242110\tAcc: 69.00\n",
      "train epoch: 46 [38528/221852 (17%)]\tLoss: 0.291052\tAcc: 68.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 46 [51328/221852 (23%)]\tLoss: 0.203902\tAcc: 83.00\n",
      "train epoch: 46 [64128/221852 (29%)]\tLoss: 0.241831\tAcc: 75.00\n",
      "train epoch: 46 [76928/221852 (35%)]\tLoss: 0.216156\tAcc: 69.00\n",
      "train epoch: 46 [89728/221852 (40%)]\tLoss: 0.166310\tAcc: 73.00\n",
      "train epoch: 46 [102528/221852 (46%)]\tLoss: 0.300743\tAcc: 77.00\n",
      "train epoch: 46 [115328/221852 (52%)]\tLoss: 0.396956\tAcc: 62.00\n",
      "train epoch: 46 [128128/221852 (58%)]\tLoss: 0.257423\tAcc: 65.00\n",
      "train epoch: 46 [140928/221852 (64%)]\tLoss: 0.185259\tAcc: 67.00\n",
      "train epoch: 46 [153728/221852 (69%)]\tLoss: 0.205700\tAcc: 69.00\n",
      "train epoch: 46 [166528/221852 (75%)]\tLoss: 0.481759\tAcc: 73.00\n",
      "train epoch: 46 [179328/221852 (81%)]\tLoss: 0.246745\tAcc: 73.00\n",
      "train epoch: 46 [192128/221852 (87%)]\tLoss: 0.177126\tAcc: 72.00\n",
      "val epoch: 46 [128/221852 (0%)]\tLoss: 0.157312\tAcc: 78.00\n",
      "val epoch: 46 [12928/221852 (6%)]\tLoss: 0.193296\tAcc: 70.00\n",
      "train epoch: 47 [128/221852 (0%)]\tLoss: 0.154451\tAcc: 77.00\n",
      "train epoch: 47 [12928/221852 (6%)]\tLoss: 0.233585\tAcc: 62.00\n",
      "train epoch: 47 [25728/221852 (12%)]\tLoss: 0.106194\tAcc: 71.00\n",
      "train epoch: 47 [38528/221852 (17%)]\tLoss: 0.258356\tAcc: 64.00\n",
      "train epoch: 47 [51328/221852 (23%)]\tLoss: 0.268021\tAcc: 71.00\n",
      "train epoch: 47 [64128/221852 (29%)]\tLoss: 0.218065\tAcc: 73.00\n",
      "train epoch: 47 [76928/221852 (35%)]\tLoss: 0.191786\tAcc: 70.00\n",
      "train epoch: 47 [89728/221852 (40%)]\tLoss: 0.278640\tAcc: 72.00\n",
      "train epoch: 47 [102528/221852 (46%)]\tLoss: 0.288315\tAcc: 73.00\n",
      "train epoch: 47 [115328/221852 (52%)]\tLoss: 0.213142\tAcc: 70.00\n",
      "train epoch: 47 [128128/221852 (58%)]\tLoss: 0.265593\tAcc: 67.00\n",
      "train epoch: 47 [140928/221852 (64%)]\tLoss: 0.247553\tAcc: 68.00\n",
      "train epoch: 47 [153728/221852 (69%)]\tLoss: 0.186874\tAcc: 72.00\n",
      "train epoch: 47 [166528/221852 (75%)]\tLoss: 0.220808\tAcc: 77.00\n",
      "train epoch: 47 [179328/221852 (81%)]\tLoss: 0.251479\tAcc: 72.00\n",
      "train epoch: 47 [192128/221852 (87%)]\tLoss: 0.249641\tAcc: 66.00\n",
      "val epoch: 47 [128/221852 (0%)]\tLoss: 0.205040\tAcc: 66.00\n",
      "val epoch: 47 [12928/221852 (6%)]\tLoss: 0.293486\tAcc: 77.00\n",
      "train epoch: 48 [128/221852 (0%)]\tLoss: 0.262847\tAcc: 62.00\n",
      "train epoch: 48 [12928/221852 (6%)]\tLoss: 0.249087\tAcc: 71.00\n",
      "train epoch: 48 [25728/221852 (12%)]\tLoss: 0.219025\tAcc: 71.00\n",
      "train epoch: 48 [38528/221852 (17%)]\tLoss: 0.415539\tAcc: 62.00\n",
      "train epoch: 48 [51328/221852 (23%)]\tLoss: 0.243550\tAcc: 77.00\n",
      "train epoch: 48 [64128/221852 (29%)]\tLoss: 0.209559\tAcc: 70.00\n",
      "train epoch: 48 [76928/221852 (35%)]\tLoss: 0.306147\tAcc: 71.00\n",
      "train epoch: 48 [89728/221852 (40%)]\tLoss: 0.141217\tAcc: 79.00\n",
      "train epoch: 48 [102528/221852 (46%)]\tLoss: 0.284195\tAcc: 77.00\n",
      "train epoch: 48 [115328/221852 (52%)]\tLoss: 0.147503\tAcc: 80.00\n",
      "train epoch: 48 [128128/221852 (58%)]\tLoss: 0.445350\tAcc: 71.00\n",
      "train epoch: 48 [140928/221852 (64%)]\tLoss: 0.228814\tAcc: 73.00\n",
      "train epoch: 48 [153728/221852 (69%)]\tLoss: 0.404987\tAcc: 66.00\n",
      "train epoch: 48 [166528/221852 (75%)]\tLoss: 0.337265\tAcc: 71.00\n",
      "train epoch: 48 [179328/221852 (81%)]\tLoss: 0.266641\tAcc: 76.00\n",
      "train epoch: 48 [192128/221852 (87%)]\tLoss: 0.333027\tAcc: 75.00\n",
      "val epoch: 48 [128/221852 (0%)]\tLoss: 0.283599\tAcc: 73.00\n",
      "val epoch: 48 [12928/221852 (6%)]\tLoss: 0.204205\tAcc: 78.00\n",
      "train epoch: 49 [128/221852 (0%)]\tLoss: 0.174897\tAcc: 73.00\n",
      "train epoch: 49 [12928/221852 (6%)]\tLoss: 0.257192\tAcc: 70.00\n",
      "train epoch: 49 [25728/221852 (12%)]\tLoss: 0.223453\tAcc: 75.00\n",
      "train epoch: 49 [38528/221852 (17%)]\tLoss: 0.200018\tAcc: 70.00\n",
      "train epoch: 49 [51328/221852 (23%)]\tLoss: 0.234764\tAcc: 72.00\n",
      "train epoch: 49 [64128/221852 (29%)]\tLoss: 0.254102\tAcc: 73.00\n",
      "train epoch: 49 [76928/221852 (35%)]\tLoss: 0.273782\tAcc: 82.00\n",
      "train epoch: 49 [89728/221852 (40%)]\tLoss: 0.252222\tAcc: 72.00\n",
      "train epoch: 49 [102528/221852 (46%)]\tLoss: 0.225247\tAcc: 80.00\n",
      "train epoch: 49 [115328/221852 (52%)]\tLoss: 0.310410\tAcc: 70.00\n",
      "train epoch: 49 [128128/221852 (58%)]\tLoss: 0.339444\tAcc: 62.00\n",
      "train epoch: 49 [140928/221852 (64%)]\tLoss: 0.187523\tAcc: 74.00\n",
      "train epoch: 49 [153728/221852 (69%)]\tLoss: 0.217247\tAcc: 76.00\n",
      "train epoch: 49 [166528/221852 (75%)]\tLoss: 0.241697\tAcc: 65.00\n",
      "train epoch: 49 [179328/221852 (81%)]\tLoss: 0.237622\tAcc: 68.00\n",
      "train epoch: 49 [192128/221852 (87%)]\tLoss: 0.265076\tAcc: 74.00\n",
      "val epoch: 49 [128/221852 (0%)]\tLoss: 0.197611\tAcc: 84.00\n",
      "val epoch: 49 [12928/221852 (6%)]\tLoss: 0.269598\tAcc: 77.00\n",
      "train epoch: 50 [128/221852 (0%)]\tLoss: 0.208593\tAcc: 80.00\n",
      "train epoch: 50 [12928/221852 (6%)]\tLoss: 0.293691\tAcc: 74.00\n",
      "train epoch: 50 [25728/221852 (12%)]\tLoss: 0.240706\tAcc: 68.00\n",
      "train epoch: 50 [38528/221852 (17%)]\tLoss: 0.116081\tAcc: 73.00\n",
      "train epoch: 50 [51328/221852 (23%)]\tLoss: 0.206265\tAcc: 75.00\n",
      "train epoch: 50 [64128/221852 (29%)]\tLoss: 0.217337\tAcc: 73.00\n",
      "train epoch: 50 [76928/221852 (35%)]\tLoss: 0.261055\tAcc: 66.00\n",
      "train epoch: 50 [89728/221852 (40%)]\tLoss: 0.209103\tAcc: 70.00\n",
      "train epoch: 50 [102528/221852 (46%)]\tLoss: 0.209300\tAcc: 78.00\n",
      "train epoch: 50 [115328/221852 (52%)]\tLoss: 0.174066\tAcc: 77.00\n",
      "train epoch: 50 [128128/221852 (58%)]\tLoss: 0.270648\tAcc: 80.00\n",
      "train epoch: 50 [140928/221852 (64%)]\tLoss: 0.211767\tAcc: 75.00\n",
      "train epoch: 50 [153728/221852 (69%)]\tLoss: 0.286694\tAcc: 71.00\n",
      "train epoch: 50 [166528/221852 (75%)]\tLoss: 0.252498\tAcc: 76.00\n",
      "train epoch: 50 [179328/221852 (81%)]\tLoss: 0.184607\tAcc: 74.00\n",
      "train epoch: 50 [192128/221852 (87%)]\tLoss: 0.234394\tAcc: 78.00\n",
      "val epoch: 50 [128/221852 (0%)]\tLoss: 0.326098\tAcc: 66.00\n",
      "val epoch: 50 [12928/221852 (6%)]\tLoss: 0.324561\tAcc: 78.00\n",
      "train epoch: 51 [128/221852 (0%)]\tLoss: 0.240004\tAcc: 69.00\n",
      "train epoch: 51 [12928/221852 (6%)]\tLoss: 0.310099\tAcc: 75.00\n",
      "train epoch: 51 [25728/221852 (12%)]\tLoss: 0.231857\tAcc: 73.00\n",
      "train epoch: 51 [38528/221852 (17%)]\tLoss: 0.217303\tAcc: 73.00\n",
      "train epoch: 51 [51328/221852 (23%)]\tLoss: 0.186167\tAcc: 77.00\n",
      "train epoch: 51 [64128/221852 (29%)]\tLoss: 0.238944\tAcc: 74.00\n",
      "train epoch: 51 [76928/221852 (35%)]\tLoss: 0.252493\tAcc: 77.00\n",
      "train epoch: 51 [89728/221852 (40%)]\tLoss: 0.210665\tAcc: 72.00\n",
      "train epoch: 51 [102528/221852 (46%)]\tLoss: 0.300193\tAcc: 70.00\n",
      "train epoch: 51 [115328/221852 (52%)]\tLoss: 0.156336\tAcc: 71.00\n",
      "train epoch: 51 [128128/221852 (58%)]\tLoss: 0.281675\tAcc: 71.00\n",
      "train epoch: 51 [140928/221852 (64%)]\tLoss: 0.277324\tAcc: 66.00\n",
      "train epoch: 51 [153728/221852 (69%)]\tLoss: 0.185206\tAcc: 77.00\n",
      "train epoch: 51 [166528/221852 (75%)]\tLoss: 0.190302\tAcc: 71.00\n",
      "train epoch: 51 [179328/221852 (81%)]\tLoss: 0.214203\tAcc: 72.00\n",
      "train epoch: 51 [192128/221852 (87%)]\tLoss: 0.169711\tAcc: 76.00\n",
      "val epoch: 51 [128/221852 (0%)]\tLoss: 0.253162\tAcc: 71.00\n",
      "val epoch: 51 [12928/221852 (6%)]\tLoss: 0.202400\tAcc: 77.00\n",
      "train epoch: 52 [128/221852 (0%)]\tLoss: 0.223275\tAcc: 77.00\n",
      "train epoch: 52 [12928/221852 (6%)]\tLoss: 0.273433\tAcc: 73.00\n",
      "train epoch: 52 [25728/221852 (12%)]\tLoss: 0.742328\tAcc: 67.00\n",
      "train epoch: 52 [38528/221852 (17%)]\tLoss: 0.281831\tAcc: 72.00\n",
      "train epoch: 52 [51328/221852 (23%)]\tLoss: 0.250409\tAcc: 73.00\n",
      "train epoch: 52 [64128/221852 (29%)]\tLoss: 0.209521\tAcc: 74.00\n",
      "train epoch: 52 [76928/221852 (35%)]\tLoss: 0.236758\tAcc: 78.00\n",
      "train epoch: 52 [89728/221852 (40%)]\tLoss: 0.291257\tAcc: 75.00\n",
      "train epoch: 52 [102528/221852 (46%)]\tLoss: 0.284573\tAcc: 73.00\n",
      "train epoch: 52 [115328/221852 (52%)]\tLoss: 0.243943\tAcc: 76.00\n",
      "train epoch: 52 [128128/221852 (58%)]\tLoss: 0.198446\tAcc: 73.00\n",
      "train epoch: 52 [140928/221852 (64%)]\tLoss: 0.209959\tAcc: 73.00\n",
      "train epoch: 52 [153728/221852 (69%)]\tLoss: 0.249850\tAcc: 71.00\n",
      "train epoch: 52 [166528/221852 (75%)]\tLoss: 0.197864\tAcc: 77.00\n",
      "train epoch: 52 [179328/221852 (81%)]\tLoss: 0.298101\tAcc: 74.00\n",
      "train epoch: 52 [192128/221852 (87%)]\tLoss: 0.249900\tAcc: 73.00\n",
      "val epoch: 52 [128/221852 (0%)]\tLoss: 0.301736\tAcc: 67.00\n",
      "val epoch: 52 [12928/221852 (6%)]\tLoss: 0.218186\tAcc: 74.00\n",
      "train epoch: 53 [128/221852 (0%)]\tLoss: 0.262930\tAcc: 73.00\n",
      "train epoch: 53 [12928/221852 (6%)]\tLoss: 0.199100\tAcc: 80.00\n",
      "train epoch: 53 [25728/221852 (12%)]\tLoss: 0.277588\tAcc: 73.00\n",
      "train epoch: 53 [38528/221852 (17%)]\tLoss: 0.268249\tAcc: 68.00\n",
      "train epoch: 53 [51328/221852 (23%)]\tLoss: 0.183707\tAcc: 72.00\n",
      "train epoch: 53 [64128/221852 (29%)]\tLoss: 0.241994\tAcc: 75.00\n",
      "train epoch: 53 [76928/221852 (35%)]\tLoss: 0.146001\tAcc: 73.00\n",
      "train epoch: 53 [89728/221852 (40%)]\tLoss: 0.150051\tAcc: 76.00\n",
      "train epoch: 53 [102528/221852 (46%)]\tLoss: 0.284820\tAcc: 72.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 53 [115328/221852 (52%)]\tLoss: 0.328581\tAcc: 65.00\n",
      "train epoch: 53 [128128/221852 (58%)]\tLoss: 0.226450\tAcc: 77.00\n",
      "train epoch: 53 [140928/221852 (64%)]\tLoss: 0.305491\tAcc: 65.00\n",
      "train epoch: 53 [153728/221852 (69%)]\tLoss: 0.187132\tAcc: 71.00\n",
      "train epoch: 53 [166528/221852 (75%)]\tLoss: 0.160248\tAcc: 74.00\n",
      "train epoch: 53 [179328/221852 (81%)]\tLoss: 0.255382\tAcc: 73.00\n",
      "train epoch: 53 [192128/221852 (87%)]\tLoss: 0.207234\tAcc: 76.00\n",
      "val epoch: 53 [128/221852 (0%)]\tLoss: 0.199316\tAcc: 78.00\n",
      "val epoch: 53 [12928/221852 (6%)]\tLoss: 0.202244\tAcc: 80.00\n",
      "train epoch: 54 [128/221852 (0%)]\tLoss: 0.146367\tAcc: 77.00\n",
      "train epoch: 54 [12928/221852 (6%)]\tLoss: 0.224873\tAcc: 78.00\n",
      "train epoch: 54 [25728/221852 (12%)]\tLoss: 0.287814\tAcc: 67.00\n",
      "train epoch: 54 [38528/221852 (17%)]\tLoss: 0.184540\tAcc: 80.00\n",
      "train epoch: 54 [51328/221852 (23%)]\tLoss: 0.182078\tAcc: 80.00\n",
      "train epoch: 54 [64128/221852 (29%)]\tLoss: 0.233517\tAcc: 78.00\n",
      "train epoch: 54 [76928/221852 (35%)]\tLoss: 0.257937\tAcc: 70.00\n",
      "train epoch: 54 [89728/221852 (40%)]\tLoss: 0.154422\tAcc: 81.00\n",
      "train epoch: 54 [102528/221852 (46%)]\tLoss: 0.157958\tAcc: 79.00\n",
      "train epoch: 54 [115328/221852 (52%)]\tLoss: 0.213661\tAcc: 77.00\n",
      "train epoch: 54 [128128/221852 (58%)]\tLoss: 0.171378\tAcc: 72.00\n",
      "train epoch: 54 [140928/221852 (64%)]\tLoss: 0.147563\tAcc: 80.00\n",
      "train epoch: 54 [153728/221852 (69%)]\tLoss: 0.251772\tAcc: 80.00\n",
      "train epoch: 54 [166528/221852 (75%)]\tLoss: 0.623888\tAcc: 73.00\n",
      "train epoch: 54 [179328/221852 (81%)]\tLoss: 0.225060\tAcc: 75.00\n",
      "train epoch: 54 [192128/221852 (87%)]\tLoss: 0.215654\tAcc: 70.00\n",
      "val epoch: 54 [128/221852 (0%)]\tLoss: 0.190791\tAcc: 82.00\n",
      "val epoch: 54 [12928/221852 (6%)]\tLoss: 0.273696\tAcc: 72.00\n",
      "train epoch: 55 [128/221852 (0%)]\tLoss: 0.240139\tAcc: 73.00\n",
      "train epoch: 55 [12928/221852 (6%)]\tLoss: 0.166669\tAcc: 79.00\n",
      "train epoch: 55 [25728/221852 (12%)]\tLoss: 0.187020\tAcc: 77.00\n",
      "train epoch: 55 [38528/221852 (17%)]\tLoss: 0.256230\tAcc: 79.00\n",
      "train epoch: 55 [51328/221852 (23%)]\tLoss: 0.155454\tAcc: 80.00\n",
      "train epoch: 55 [64128/221852 (29%)]\tLoss: 0.259225\tAcc: 81.00\n",
      "train epoch: 55 [76928/221852 (35%)]\tLoss: 0.193289\tAcc: 76.00\n",
      "train epoch: 55 [89728/221852 (40%)]\tLoss: 0.184444\tAcc: 83.00\n",
      "train epoch: 55 [102528/221852 (46%)]\tLoss: 0.130329\tAcc: 73.00\n",
      "train epoch: 55 [115328/221852 (52%)]\tLoss: 0.135552\tAcc: 77.00\n",
      "train epoch: 55 [128128/221852 (58%)]\tLoss: 0.305005\tAcc: 70.00\n",
      "train epoch: 55 [140928/221852 (64%)]\tLoss: 0.275295\tAcc: 73.00\n",
      "train epoch: 55 [153728/221852 (69%)]\tLoss: 0.144893\tAcc: 77.00\n",
      "train epoch: 55 [166528/221852 (75%)]\tLoss: 0.145501\tAcc: 76.00\n",
      "train epoch: 55 [179328/221852 (81%)]\tLoss: 0.300445\tAcc: 80.00\n",
      "train epoch: 55 [192128/221852 (87%)]\tLoss: 0.220735\tAcc: 84.00\n",
      "val epoch: 55 [128/221852 (0%)]\tLoss: 0.187350\tAcc: 68.00\n",
      "val epoch: 55 [12928/221852 (6%)]\tLoss: 0.184095\tAcc: 66.00\n",
      "train epoch: 56 [128/221852 (0%)]\tLoss: 0.221777\tAcc: 67.00\n",
      "train epoch: 56 [12928/221852 (6%)]\tLoss: 0.260390\tAcc: 74.00\n",
      "train epoch: 56 [25728/221852 (12%)]\tLoss: 0.429936\tAcc: 68.00\n",
      "train epoch: 56 [38528/221852 (17%)]\tLoss: 0.277721\tAcc: 72.00\n",
      "train epoch: 56 [51328/221852 (23%)]\tLoss: 0.202058\tAcc: 81.00\n",
      "train epoch: 56 [64128/221852 (29%)]\tLoss: 0.150432\tAcc: 79.00\n",
      "train epoch: 56 [76928/221852 (35%)]\tLoss: 0.268927\tAcc: 79.00\n",
      "train epoch: 56 [89728/221852 (40%)]\tLoss: 0.260244\tAcc: 75.00\n",
      "train epoch: 56 [102528/221852 (46%)]\tLoss: 0.274904\tAcc: 73.00\n",
      "train epoch: 56 [115328/221852 (52%)]\tLoss: 0.358736\tAcc: 75.00\n",
      "train epoch: 56 [128128/221852 (58%)]\tLoss: 0.270420\tAcc: 68.00\n",
      "train epoch: 56 [140928/221852 (64%)]\tLoss: 0.168007\tAcc: 73.00\n",
      "train epoch: 56 [153728/221852 (69%)]\tLoss: 0.176660\tAcc: 75.00\n",
      "train epoch: 56 [166528/221852 (75%)]\tLoss: 0.232581\tAcc: 73.00\n",
      "train epoch: 56 [179328/221852 (81%)]\tLoss: 0.200559\tAcc: 74.00\n",
      "train epoch: 56 [192128/221852 (87%)]\tLoss: 0.271282\tAcc: 72.00\n",
      "val epoch: 56 [128/221852 (0%)]\tLoss: 0.227353\tAcc: 75.00\n",
      "val epoch: 56 [12928/221852 (6%)]\tLoss: 0.305440\tAcc: 73.00\n",
      "train epoch: 57 [128/221852 (0%)]\tLoss: 0.217858\tAcc: 76.00\n",
      "train epoch: 57 [12928/221852 (6%)]\tLoss: 0.185783\tAcc: 79.00\n",
      "train epoch: 57 [25728/221852 (12%)]\tLoss: 0.150879\tAcc: 76.00\n",
      "train epoch: 57 [38528/221852 (17%)]\tLoss: 0.308204\tAcc: 66.00\n",
      "train epoch: 57 [51328/221852 (23%)]\tLoss: 0.241096\tAcc: 79.00\n",
      "train epoch: 57 [64128/221852 (29%)]\tLoss: 0.204524\tAcc: 80.00\n",
      "train epoch: 57 [76928/221852 (35%)]\tLoss: 0.114504\tAcc: 81.00\n",
      "train epoch: 57 [89728/221852 (40%)]\tLoss: 0.218772\tAcc: 80.00\n",
      "train epoch: 57 [102528/221852 (46%)]\tLoss: 0.209701\tAcc: 73.00\n",
      "train epoch: 57 [115328/221852 (52%)]\tLoss: 0.234536\tAcc: 79.00\n",
      "train epoch: 57 [128128/221852 (58%)]\tLoss: 0.162379\tAcc: 76.00\n",
      "train epoch: 57 [140928/221852 (64%)]\tLoss: 0.145097\tAcc: 77.00\n",
      "train epoch: 57 [153728/221852 (69%)]\tLoss: 0.176598\tAcc: 79.00\n",
      "train epoch: 57 [166528/221852 (75%)]\tLoss: 0.244636\tAcc: 75.00\n",
      "train epoch: 57 [179328/221852 (81%)]\tLoss: 0.249264\tAcc: 65.00\n",
      "train epoch: 57 [192128/221852 (87%)]\tLoss: 0.202782\tAcc: 73.00\n",
      "val epoch: 57 [128/221852 (0%)]\tLoss: 0.207048\tAcc: 77.00\n",
      "val epoch: 57 [12928/221852 (6%)]\tLoss: 0.217298\tAcc: 73.00\n",
      "train epoch: 58 [128/221852 (0%)]\tLoss: 0.279757\tAcc: 73.00\n",
      "train epoch: 58 [12928/221852 (6%)]\tLoss: 0.137386\tAcc: 82.00\n",
      "train epoch: 58 [25728/221852 (12%)]\tLoss: 0.185619\tAcc: 76.00\n",
      "train epoch: 58 [38528/221852 (17%)]\tLoss: 0.199361\tAcc: 73.00\n",
      "train epoch: 58 [51328/221852 (23%)]\tLoss: 0.170346\tAcc: 73.00\n",
      "train epoch: 58 [64128/221852 (29%)]\tLoss: 0.210203\tAcc: 76.00\n",
      "train epoch: 58 [76928/221852 (35%)]\tLoss: 0.112662\tAcc: 74.00\n",
      "train epoch: 58 [89728/221852 (40%)]\tLoss: 0.174416\tAcc: 72.00\n",
      "train epoch: 58 [102528/221852 (46%)]\tLoss: 0.331900\tAcc: 72.00\n",
      "train epoch: 58 [115328/221852 (52%)]\tLoss: 0.240686\tAcc: 70.00\n",
      "train epoch: 58 [128128/221852 (58%)]\tLoss: 0.177126\tAcc: 80.00\n",
      "train epoch: 58 [140928/221852 (64%)]\tLoss: 0.189259\tAcc: 76.00\n",
      "train epoch: 58 [153728/221852 (69%)]\tLoss: 0.254742\tAcc: 76.00\n",
      "train epoch: 58 [166528/221852 (75%)]\tLoss: 0.283753\tAcc: 70.00\n",
      "train epoch: 58 [179328/221852 (81%)]\tLoss: 0.223701\tAcc: 70.00\n",
      "train epoch: 58 [192128/221852 (87%)]\tLoss: 0.162425\tAcc: 75.00\n",
      "val epoch: 58 [128/221852 (0%)]\tLoss: 0.299421\tAcc: 73.00\n",
      "val epoch: 58 [12928/221852 (6%)]\tLoss: 0.161229\tAcc: 67.00\n",
      "train epoch: 59 [128/221852 (0%)]\tLoss: 0.220982\tAcc: 78.00\n",
      "train epoch: 59 [12928/221852 (6%)]\tLoss: 0.209554\tAcc: 73.00\n",
      "train epoch: 59 [25728/221852 (12%)]\tLoss: 0.251298\tAcc: 74.00\n",
      "train epoch: 59 [38528/221852 (17%)]\tLoss: 0.234180\tAcc: 70.00\n",
      "train epoch: 59 [51328/221852 (23%)]\tLoss: 0.147299\tAcc: 79.00\n",
      "train epoch: 59 [64128/221852 (29%)]\tLoss: 0.256585\tAcc: 76.00\n",
      "train epoch: 59 [76928/221852 (35%)]\tLoss: 0.218370\tAcc: 74.00\n",
      "train epoch: 59 [89728/221852 (40%)]\tLoss: 0.331213\tAcc: 72.00\n",
      "train epoch: 59 [102528/221852 (46%)]\tLoss: 0.171355\tAcc: 79.00\n",
      "train epoch: 59 [115328/221852 (52%)]\tLoss: 0.159024\tAcc: 73.00\n",
      "train epoch: 59 [128128/221852 (58%)]\tLoss: 0.165339\tAcc: 77.00\n",
      "train epoch: 59 [140928/221852 (64%)]\tLoss: 0.185022\tAcc: 76.00\n",
      "train epoch: 59 [153728/221852 (69%)]\tLoss: 0.204016\tAcc: 77.00\n",
      "train epoch: 59 [166528/221852 (75%)]\tLoss: 0.169436\tAcc: 73.00\n",
      "train epoch: 59 [179328/221852 (81%)]\tLoss: 0.185064\tAcc: 77.00\n",
      "train epoch: 59 [192128/221852 (87%)]\tLoss: 0.180667\tAcc: 77.00\n",
      "val epoch: 59 [128/221852 (0%)]\tLoss: 0.220515\tAcc: 73.00\n",
      "val epoch: 59 [12928/221852 (6%)]\tLoss: 0.244778\tAcc: 71.00\n",
      "train epoch: 60 [128/221852 (0%)]\tLoss: 0.384265\tAcc: 68.00\n",
      "train epoch: 60 [12928/221852 (6%)]\tLoss: 0.271766\tAcc: 80.00\n",
      "train epoch: 60 [25728/221852 (12%)]\tLoss: 0.215779\tAcc: 77.00\n",
      "train epoch: 60 [38528/221852 (17%)]\tLoss: 0.233451\tAcc: 73.00\n",
      "train epoch: 60 [51328/221852 (23%)]\tLoss: 0.293724\tAcc: 72.00\n",
      "train epoch: 60 [64128/221852 (29%)]\tLoss: 0.262782\tAcc: 72.00\n",
      "train epoch: 60 [76928/221852 (35%)]\tLoss: 0.221448\tAcc: 78.00\n",
      "train epoch: 60 [89728/221852 (40%)]\tLoss: 0.289585\tAcc: 74.00\n",
      "train epoch: 60 [102528/221852 (46%)]\tLoss: 0.158287\tAcc: 75.00\n",
      "train epoch: 60 [115328/221852 (52%)]\tLoss: 0.253949\tAcc: 78.00\n",
      "train epoch: 60 [128128/221852 (58%)]\tLoss: 0.328990\tAcc: 62.00\n",
      "train epoch: 60 [140928/221852 (64%)]\tLoss: 0.295012\tAcc: 75.00\n",
      "train epoch: 60 [153728/221852 (69%)]\tLoss: 0.221617\tAcc: 73.00\n",
      "train epoch: 60 [166528/221852 (75%)]\tLoss: 0.184249\tAcc: 81.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 60 [179328/221852 (81%)]\tLoss: 0.230889\tAcc: 69.00\n",
      "train epoch: 60 [192128/221852 (87%)]\tLoss: 0.181229\tAcc: 74.00\n",
      "val epoch: 60 [128/221852 (0%)]\tLoss: 0.179081\tAcc: 83.00\n",
      "val epoch: 60 [12928/221852 (6%)]\tLoss: 0.125457\tAcc: 79.00\n",
      "train epoch: 61 [128/221852 (0%)]\tLoss: 0.183645\tAcc: 84.00\n",
      "train epoch: 61 [12928/221852 (6%)]\tLoss: 0.220066\tAcc: 77.00\n",
      "train epoch: 61 [25728/221852 (12%)]\tLoss: 0.230073\tAcc: 78.00\n",
      "train epoch: 61 [38528/221852 (17%)]\tLoss: 0.215578\tAcc: 80.00\n",
      "train epoch: 61 [51328/221852 (23%)]\tLoss: 0.193780\tAcc: 81.00\n",
      "train epoch: 61 [64128/221852 (29%)]\tLoss: 0.156474\tAcc: 80.00\n",
      "train epoch: 61 [76928/221852 (35%)]\tLoss: 0.214613\tAcc: 80.00\n",
      "train epoch: 61 [89728/221852 (40%)]\tLoss: 0.351266\tAcc: 71.00\n",
      "train epoch: 61 [102528/221852 (46%)]\tLoss: 0.186008\tAcc: 80.00\n",
      "train epoch: 61 [115328/221852 (52%)]\tLoss: 0.179045\tAcc: 75.00\n",
      "train epoch: 61 [128128/221852 (58%)]\tLoss: 0.253199\tAcc: 74.00\n",
      "train epoch: 61 [140928/221852 (64%)]\tLoss: 0.187457\tAcc: 77.00\n",
      "train epoch: 61 [153728/221852 (69%)]\tLoss: 0.237096\tAcc: 80.00\n",
      "train epoch: 61 [166528/221852 (75%)]\tLoss: 0.191718\tAcc: 80.00\n",
      "train epoch: 61 [179328/221852 (81%)]\tLoss: 0.141747\tAcc: 80.00\n",
      "train epoch: 61 [192128/221852 (87%)]\tLoss: 0.156874\tAcc: 79.00\n",
      "val epoch: 61 [128/221852 (0%)]\tLoss: 0.210035\tAcc: 77.00\n",
      "val epoch: 61 [12928/221852 (6%)]\tLoss: 0.254061\tAcc: 80.00\n",
      "train epoch: 62 [128/221852 (0%)]\tLoss: 0.204069\tAcc: 73.00\n",
      "train epoch: 62 [12928/221852 (6%)]\tLoss: 0.289785\tAcc: 70.00\n",
      "train epoch: 62 [25728/221852 (12%)]\tLoss: 0.276582\tAcc: 75.00\n",
      "train epoch: 62 [38528/221852 (17%)]\tLoss: 0.239215\tAcc: 73.00\n",
      "train epoch: 62 [51328/221852 (23%)]\tLoss: 0.245346\tAcc: 84.00\n",
      "train epoch: 62 [64128/221852 (29%)]\tLoss: 0.247423\tAcc: 76.00\n",
      "train epoch: 62 [76928/221852 (35%)]\tLoss: 0.276649\tAcc: 80.00\n",
      "train epoch: 62 [89728/221852 (40%)]\tLoss: 0.237620\tAcc: 71.00\n",
      "train epoch: 62 [102528/221852 (46%)]\tLoss: 0.161278\tAcc: 77.00\n",
      "train epoch: 62 [115328/221852 (52%)]\tLoss: 0.240456\tAcc: 76.00\n",
      "train epoch: 62 [128128/221852 (58%)]\tLoss: 0.185229\tAcc: 74.00\n",
      "train epoch: 62 [140928/221852 (64%)]\tLoss: 0.268574\tAcc: 73.00\n",
      "train epoch: 62 [153728/221852 (69%)]\tLoss: 0.196718\tAcc: 80.00\n",
      "train epoch: 62 [166528/221852 (75%)]\tLoss: 0.244026\tAcc: 77.00\n",
      "train epoch: 62 [179328/221852 (81%)]\tLoss: 0.117531\tAcc: 83.00\n",
      "train epoch: 62 [192128/221852 (87%)]\tLoss: 0.250400\tAcc: 79.00\n",
      "val epoch: 62 [128/221852 (0%)]\tLoss: 0.160689\tAcc: 78.00\n",
      "val epoch: 62 [12928/221852 (6%)]\tLoss: 0.151177\tAcc: 80.00\n",
      "train epoch: 63 [128/221852 (0%)]\tLoss: 0.223098\tAcc: 79.00\n",
      "train epoch: 63 [12928/221852 (6%)]\tLoss: 0.230364\tAcc: 72.00\n",
      "train epoch: 63 [25728/221852 (12%)]\tLoss: 0.143315\tAcc: 70.00\n",
      "train epoch: 63 [38528/221852 (17%)]\tLoss: 0.260359\tAcc: 78.00\n",
      "train epoch: 63 [51328/221852 (23%)]\tLoss: 0.237192\tAcc: 77.00\n",
      "train epoch: 63 [64128/221852 (29%)]\tLoss: 0.160833\tAcc: 76.00\n",
      "train epoch: 63 [76928/221852 (35%)]\tLoss: 0.169813\tAcc: 78.00\n",
      "train epoch: 63 [89728/221852 (40%)]\tLoss: 0.206876\tAcc: 83.00\n",
      "train epoch: 63 [102528/221852 (46%)]\tLoss: 0.144750\tAcc: 83.00\n",
      "train epoch: 63 [115328/221852 (52%)]\tLoss: 0.170960\tAcc: 80.00\n",
      "train epoch: 63 [128128/221852 (58%)]\tLoss: 0.209243\tAcc: 80.00\n",
      "train epoch: 63 [140928/221852 (64%)]\tLoss: 0.157534\tAcc: 80.00\n",
      "train epoch: 63 [153728/221852 (69%)]\tLoss: 0.226800\tAcc: 80.00\n",
      "train epoch: 63 [166528/221852 (75%)]\tLoss: 0.438402\tAcc: 73.00\n",
      "train epoch: 63 [179328/221852 (81%)]\tLoss: 0.168169\tAcc: 77.00\n",
      "train epoch: 63 [192128/221852 (87%)]\tLoss: 0.389505\tAcc: 65.00\n",
      "val epoch: 63 [128/221852 (0%)]\tLoss: 0.191716\tAcc: 74.00\n",
      "val epoch: 63 [12928/221852 (6%)]\tLoss: 0.301467\tAcc: 73.00\n",
      "train epoch: 64 [128/221852 (0%)]\tLoss: 0.252805\tAcc: 77.00\n",
      "train epoch: 64 [12928/221852 (6%)]\tLoss: 0.295605\tAcc: 70.00\n",
      "train epoch: 64 [25728/221852 (12%)]\tLoss: 0.206642\tAcc: 73.00\n",
      "train epoch: 64 [38528/221852 (17%)]\tLoss: 0.167542\tAcc: 77.00\n",
      "train epoch: 64 [51328/221852 (23%)]\tLoss: 0.230888\tAcc: 75.00\n",
      "train epoch: 64 [64128/221852 (29%)]\tLoss: 0.318655\tAcc: 70.00\n",
      "train epoch: 64 [76928/221852 (35%)]\tLoss: 0.232021\tAcc: 71.00\n",
      "train epoch: 64 [89728/221852 (40%)]\tLoss: 0.310185\tAcc: 69.00\n",
      "train epoch: 64 [102528/221852 (46%)]\tLoss: 0.262471\tAcc: 70.00\n",
      "train epoch: 64 [115328/221852 (52%)]\tLoss: 0.296283\tAcc: 68.00\n",
      "train epoch: 64 [128128/221852 (58%)]\tLoss: 0.188562\tAcc: 73.00\n",
      "train epoch: 64 [140928/221852 (64%)]\tLoss: 0.198244\tAcc: 77.00\n",
      "train epoch: 64 [153728/221852 (69%)]\tLoss: 0.254268\tAcc: 69.00\n",
      "train epoch: 64 [166528/221852 (75%)]\tLoss: 0.240822\tAcc: 77.00\n",
      "train epoch: 64 [179328/221852 (81%)]\tLoss: 0.243275\tAcc: 70.00\n",
      "train epoch: 64 [192128/221852 (87%)]\tLoss: 0.159253\tAcc: 84.00\n",
      "val epoch: 64 [128/221852 (0%)]\tLoss: 0.239965\tAcc: 80.00\n",
      "val epoch: 64 [12928/221852 (6%)]\tLoss: 0.206360\tAcc: 76.00\n",
      "train epoch: 65 [128/221852 (0%)]\tLoss: 0.303968\tAcc: 73.00\n",
      "train epoch: 65 [12928/221852 (6%)]\tLoss: 0.181814\tAcc: 81.00\n",
      "train epoch: 65 [25728/221852 (12%)]\tLoss: 0.204475\tAcc: 80.00\n",
      "train epoch: 65 [38528/221852 (17%)]\tLoss: 0.252628\tAcc: 66.00\n",
      "train epoch: 65 [51328/221852 (23%)]\tLoss: 0.206746\tAcc: 77.00\n",
      "train epoch: 65 [64128/221852 (29%)]\tLoss: 0.133524\tAcc: 84.00\n",
      "train epoch: 65 [76928/221852 (35%)]\tLoss: 0.237497\tAcc: 70.00\n",
      "train epoch: 65 [89728/221852 (40%)]\tLoss: 0.163999\tAcc: 78.00\n",
      "train epoch: 65 [102528/221852 (46%)]\tLoss: 0.166849\tAcc: 70.00\n",
      "train epoch: 65 [115328/221852 (52%)]\tLoss: 0.189308\tAcc: 84.00\n",
      "train epoch: 65 [128128/221852 (58%)]\tLoss: 0.126226\tAcc: 73.00\n",
      "train epoch: 65 [140928/221852 (64%)]\tLoss: 0.320235\tAcc: 80.00\n",
      "train epoch: 65 [153728/221852 (69%)]\tLoss: 0.307060\tAcc: 72.00\n",
      "train epoch: 65 [166528/221852 (75%)]\tLoss: 0.184138\tAcc: 75.00\n",
      "train epoch: 65 [179328/221852 (81%)]\tLoss: 0.155269\tAcc: 84.00\n",
      "train epoch: 65 [192128/221852 (87%)]\tLoss: 0.351220\tAcc: 80.00\n",
      "val epoch: 65 [128/221852 (0%)]\tLoss: 0.206665\tAcc: 80.00\n",
      "val epoch: 65 [12928/221852 (6%)]\tLoss: 0.153949\tAcc: 83.00\n",
      "train epoch: 66 [128/221852 (0%)]\tLoss: 0.262378\tAcc: 76.00\n",
      "train epoch: 66 [12928/221852 (6%)]\tLoss: 0.199704\tAcc: 81.00\n",
      "train epoch: 66 [25728/221852 (12%)]\tLoss: 0.377560\tAcc: 67.00\n",
      "train epoch: 66 [38528/221852 (17%)]\tLoss: 0.228764\tAcc: 78.00\n",
      "train epoch: 66 [51328/221852 (23%)]\tLoss: 0.183232\tAcc: 76.00\n",
      "train epoch: 66 [64128/221852 (29%)]\tLoss: 0.174608\tAcc: 72.00\n",
      "train epoch: 66 [76928/221852 (35%)]\tLoss: 0.222701\tAcc: 78.00\n",
      "train epoch: 66 [89728/221852 (40%)]\tLoss: 0.246895\tAcc: 75.00\n",
      "train epoch: 66 [102528/221852 (46%)]\tLoss: 0.260780\tAcc: 77.00\n",
      "train epoch: 66 [115328/221852 (52%)]\tLoss: 0.194874\tAcc: 81.00\n",
      "train epoch: 66 [128128/221852 (58%)]\tLoss: 0.195756\tAcc: 81.00\n",
      "train epoch: 66 [140928/221852 (64%)]\tLoss: 0.126928\tAcc: 81.00\n",
      "train epoch: 66 [153728/221852 (69%)]\tLoss: 0.268000\tAcc: 70.00\n",
      "train epoch: 66 [166528/221852 (75%)]\tLoss: 0.242158\tAcc: 77.00\n",
      "train epoch: 66 [179328/221852 (81%)]\tLoss: 0.182134\tAcc: 74.00\n",
      "train epoch: 66 [192128/221852 (87%)]\tLoss: 0.233374\tAcc: 78.00\n",
      "val epoch: 66 [128/221852 (0%)]\tLoss: 0.156417\tAcc: 83.00\n",
      "val epoch: 66 [12928/221852 (6%)]\tLoss: 0.158698\tAcc: 80.00\n",
      "train epoch: 67 [128/221852 (0%)]\tLoss: 0.227988\tAcc: 78.00\n",
      "train epoch: 67 [12928/221852 (6%)]\tLoss: 0.294796\tAcc: 75.00\n",
      "train epoch: 67 [25728/221852 (12%)]\tLoss: 0.215520\tAcc: 79.00\n",
      "train epoch: 67 [38528/221852 (17%)]\tLoss: 0.244519\tAcc: 76.00\n",
      "train epoch: 67 [51328/221852 (23%)]\tLoss: 0.172584\tAcc: 78.00\n",
      "train epoch: 67 [64128/221852 (29%)]\tLoss: 0.127045\tAcc: 77.00\n",
      "train epoch: 67 [76928/221852 (35%)]\tLoss: 0.213049\tAcc: 88.00\n",
      "train epoch: 67 [89728/221852 (40%)]\tLoss: 0.163813\tAcc: 80.00\n",
      "train epoch: 67 [102528/221852 (46%)]\tLoss: 0.201616\tAcc: 76.00\n",
      "train epoch: 67 [115328/221852 (52%)]\tLoss: 0.178923\tAcc: 73.00\n",
      "train epoch: 67 [128128/221852 (58%)]\tLoss: 0.162399\tAcc: 81.00\n",
      "train epoch: 67 [140928/221852 (64%)]\tLoss: 0.180206\tAcc: 76.00\n",
      "train epoch: 67 [153728/221852 (69%)]\tLoss: 0.268924\tAcc: 80.00\n",
      "train epoch: 67 [166528/221852 (75%)]\tLoss: 0.194463\tAcc: 80.00\n",
      "train epoch: 67 [179328/221852 (81%)]\tLoss: 0.326023\tAcc: 66.00\n",
      "train epoch: 67 [192128/221852 (87%)]\tLoss: 0.239093\tAcc: 71.00\n",
      "val epoch: 67 [128/221852 (0%)]\tLoss: 0.295038\tAcc: 72.00\n",
      "val epoch: 67 [12928/221852 (6%)]\tLoss: 0.192967\tAcc: 81.00\n",
      "train epoch: 68 [128/221852 (0%)]\tLoss: 0.207110\tAcc: 73.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 68 [12928/221852 (6%)]\tLoss: 0.270436\tAcc: 71.00\n",
      "train epoch: 68 [25728/221852 (12%)]\tLoss: 0.174817\tAcc: 79.00\n",
      "train epoch: 68 [38528/221852 (17%)]\tLoss: 0.252135\tAcc: 76.00\n",
      "train epoch: 68 [51328/221852 (23%)]\tLoss: 0.173717\tAcc: 81.00\n",
      "train epoch: 68 [64128/221852 (29%)]\tLoss: 0.184366\tAcc: 77.00\n",
      "train epoch: 68 [76928/221852 (35%)]\tLoss: 0.174678\tAcc: 80.00\n",
      "train epoch: 68 [89728/221852 (40%)]\tLoss: 0.298607\tAcc: 71.00\n",
      "train epoch: 68 [102528/221852 (46%)]\tLoss: 0.190290\tAcc: 76.00\n",
      "train epoch: 68 [115328/221852 (52%)]\tLoss: 0.160884\tAcc: 81.00\n",
      "train epoch: 68 [128128/221852 (58%)]\tLoss: 0.250281\tAcc: 77.00\n",
      "train epoch: 68 [140928/221852 (64%)]\tLoss: 0.258487\tAcc: 74.00\n",
      "train epoch: 68 [153728/221852 (69%)]\tLoss: 0.230369\tAcc: 79.00\n",
      "train epoch: 68 [166528/221852 (75%)]\tLoss: 0.134552\tAcc: 80.00\n",
      "train epoch: 68 [179328/221852 (81%)]\tLoss: 0.575763\tAcc: 67.00\n",
      "train epoch: 68 [192128/221852 (87%)]\tLoss: 0.269390\tAcc: 70.00\n",
      "val epoch: 68 [128/221852 (0%)]\tLoss: 0.192616\tAcc: 80.00\n",
      "val epoch: 68 [12928/221852 (6%)]\tLoss: 0.206116\tAcc: 72.00\n",
      "train epoch: 69 [128/221852 (0%)]\tLoss: 0.227564\tAcc: 73.00\n",
      "train epoch: 69 [12928/221852 (6%)]\tLoss: 0.215650\tAcc: 71.00\n",
      "train epoch: 69 [25728/221852 (12%)]\tLoss: 0.218320\tAcc: 72.00\n",
      "train epoch: 69 [38528/221852 (17%)]\tLoss: 0.214190\tAcc: 76.00\n",
      "train epoch: 69 [51328/221852 (23%)]\tLoss: 0.082061\tAcc: 80.00\n",
      "train epoch: 69 [64128/221852 (29%)]\tLoss: 0.290431\tAcc: 66.00\n",
      "train epoch: 69 [76928/221852 (35%)]\tLoss: 0.210488\tAcc: 73.00\n",
      "train epoch: 69 [89728/221852 (40%)]\tLoss: 0.241526\tAcc: 69.00\n",
      "train epoch: 69 [102528/221852 (46%)]\tLoss: 0.283887\tAcc: 73.00\n",
      "train epoch: 69 [115328/221852 (52%)]\tLoss: 0.282646\tAcc: 73.00\n",
      "train epoch: 69 [128128/221852 (58%)]\tLoss: 0.203163\tAcc: 74.00\n",
      "train epoch: 69 [140928/221852 (64%)]\tLoss: 0.214131\tAcc: 75.00\n",
      "train epoch: 69 [153728/221852 (69%)]\tLoss: 0.195455\tAcc: 78.00\n",
      "train epoch: 69 [166528/221852 (75%)]\tLoss: 0.197741\tAcc: 78.00\n",
      "train epoch: 69 [179328/221852 (81%)]\tLoss: 0.283463\tAcc: 75.00\n",
      "train epoch: 69 [192128/221852 (87%)]\tLoss: 0.252343\tAcc: 74.00\n",
      "val epoch: 69 [128/221852 (0%)]\tLoss: 0.187857\tAcc: 74.00\n",
      "val epoch: 69 [12928/221852 (6%)]\tLoss: 0.225640\tAcc: 74.00\n",
      "train epoch: 70 [128/221852 (0%)]\tLoss: 0.199871\tAcc: 78.00\n",
      "train epoch: 70 [12928/221852 (6%)]\tLoss: 0.204518\tAcc: 77.00\n",
      "train epoch: 70 [25728/221852 (12%)]\tLoss: 0.215240\tAcc: 77.00\n",
      "train epoch: 70 [38528/221852 (17%)]\tLoss: 0.169857\tAcc: 77.00\n",
      "train epoch: 70 [51328/221852 (23%)]\tLoss: 0.174672\tAcc: 77.00\n",
      "train epoch: 70 [64128/221852 (29%)]\tLoss: 0.135687\tAcc: 73.00\n",
      "train epoch: 70 [76928/221852 (35%)]\tLoss: 0.222902\tAcc: 77.00\n",
      "train epoch: 70 [89728/221852 (40%)]\tLoss: 0.597822\tAcc: 70.00\n",
      "train epoch: 70 [102528/221852 (46%)]\tLoss: 0.335557\tAcc: 67.00\n",
      "train epoch: 70 [115328/221852 (52%)]\tLoss: 0.324291\tAcc: 66.00\n",
      "train epoch: 70 [128128/221852 (58%)]\tLoss: 0.233138\tAcc: 62.00\n",
      "train epoch: 70 [140928/221852 (64%)]\tLoss: 0.202880\tAcc: 70.00\n",
      "train epoch: 70 [153728/221852 (69%)]\tLoss: 0.240279\tAcc: 70.00\n",
      "train epoch: 70 [166528/221852 (75%)]\tLoss: 0.262934\tAcc: 70.00\n",
      "train epoch: 70 [179328/221852 (81%)]\tLoss: 0.168144\tAcc: 80.00\n",
      "train epoch: 70 [192128/221852 (87%)]\tLoss: 0.204848\tAcc: 80.00\n",
      "val epoch: 70 [128/221852 (0%)]\tLoss: 0.179281\tAcc: 77.00\n",
      "val epoch: 70 [12928/221852 (6%)]\tLoss: 0.187010\tAcc: 80.00\n",
      "train epoch: 71 [128/221852 (0%)]\tLoss: 0.212225\tAcc: 70.00\n",
      "train epoch: 71 [12928/221852 (6%)]\tLoss: 0.256007\tAcc: 77.00\n",
      "train epoch: 71 [25728/221852 (12%)]\tLoss: 0.158945\tAcc: 82.00\n",
      "train epoch: 71 [38528/221852 (17%)]\tLoss: 0.210935\tAcc: 72.00\n",
      "train epoch: 71 [51328/221852 (23%)]\tLoss: 0.255532\tAcc: 77.00\n",
      "train epoch: 71 [64128/221852 (29%)]\tLoss: 0.196520\tAcc: 72.00\n",
      "train epoch: 71 [76928/221852 (35%)]\tLoss: 0.207642\tAcc: 77.00\n",
      "train epoch: 71 [89728/221852 (40%)]\tLoss: 0.248253\tAcc: 80.00\n",
      "train epoch: 71 [102528/221852 (46%)]\tLoss: 0.231619\tAcc: 83.00\n",
      "train epoch: 71 [115328/221852 (52%)]\tLoss: 0.178644\tAcc: 80.00\n",
      "train epoch: 71 [128128/221852 (58%)]\tLoss: 0.203525\tAcc: 82.00\n",
      "train epoch: 71 [140928/221852 (64%)]\tLoss: 0.242286\tAcc: 80.00\n",
      "train epoch: 71 [153728/221852 (69%)]\tLoss: 0.168178\tAcc: 80.00\n",
      "train epoch: 71 [166528/221852 (75%)]\tLoss: 0.199509\tAcc: 80.00\n",
      "train epoch: 71 [179328/221852 (81%)]\tLoss: 0.288821\tAcc: 64.00\n",
      "train epoch: 71 [192128/221852 (87%)]\tLoss: 0.181325\tAcc: 80.00\n",
      "val epoch: 71 [128/221852 (0%)]\tLoss: 0.201513\tAcc: 81.00\n",
      "val epoch: 71 [12928/221852 (6%)]\tLoss: 0.118610\tAcc: 87.00\n",
      "train epoch: 72 [128/221852 (0%)]\tLoss: 0.182031\tAcc: 77.00\n",
      "train epoch: 72 [12928/221852 (6%)]\tLoss: 0.198445\tAcc: 78.00\n",
      "train epoch: 72 [25728/221852 (12%)]\tLoss: 0.182366\tAcc: 70.00\n",
      "train epoch: 72 [38528/221852 (17%)]\tLoss: 0.157302\tAcc: 78.00\n",
      "train epoch: 72 [51328/221852 (23%)]\tLoss: 0.198486\tAcc: 74.00\n",
      "train epoch: 72 [64128/221852 (29%)]\tLoss: 0.273867\tAcc: 76.00\n",
      "train epoch: 72 [76928/221852 (35%)]\tLoss: 0.224335\tAcc: 81.00\n",
      "train epoch: 72 [89728/221852 (40%)]\tLoss: 0.213220\tAcc: 83.00\n",
      "train epoch: 72 [102528/221852 (46%)]\tLoss: 0.169781\tAcc: 79.00\n",
      "train epoch: 72 [115328/221852 (52%)]\tLoss: 0.229085\tAcc: 81.00\n",
      "train epoch: 72 [128128/221852 (58%)]\tLoss: 0.234746\tAcc: 76.00\n",
      "train epoch: 72 [140928/221852 (64%)]\tLoss: 0.197424\tAcc: 80.00\n",
      "train epoch: 72 [153728/221852 (69%)]\tLoss: 0.402151\tAcc: 83.00\n",
      "train epoch: 72 [166528/221852 (75%)]\tLoss: 0.117257\tAcc: 82.00\n",
      "train epoch: 72 [179328/221852 (81%)]\tLoss: 0.145377\tAcc: 80.00\n",
      "train epoch: 72 [192128/221852 (87%)]\tLoss: 0.185828\tAcc: 76.00\n",
      "val epoch: 72 [128/221852 (0%)]\tLoss: 0.108992\tAcc: 79.00\n",
      "val epoch: 72 [12928/221852 (6%)]\tLoss: 0.237363\tAcc: 79.00\n",
      "train epoch: 73 [128/221852 (0%)]\tLoss: 0.190896\tAcc: 77.00\n",
      "train epoch: 73 [12928/221852 (6%)]\tLoss: 0.178524\tAcc: 82.00\n",
      "train epoch: 73 [25728/221852 (12%)]\tLoss: 0.244467\tAcc: 78.00\n",
      "train epoch: 73 [38528/221852 (17%)]\tLoss: 0.197029\tAcc: 69.00\n",
      "train epoch: 73 [51328/221852 (23%)]\tLoss: 0.169024\tAcc: 77.00\n",
      "train epoch: 73 [64128/221852 (29%)]\tLoss: 0.213881\tAcc: 85.00\n",
      "train epoch: 73 [76928/221852 (35%)]\tLoss: 0.257490\tAcc: 72.00\n",
      "train epoch: 73 [89728/221852 (40%)]\tLoss: 0.137001\tAcc: 73.00\n",
      "train epoch: 73 [102528/221852 (46%)]\tLoss: 0.211279\tAcc: 80.00\n",
      "train epoch: 73 [115328/221852 (52%)]\tLoss: 0.233705\tAcc: 76.00\n",
      "train epoch: 73 [128128/221852 (58%)]\tLoss: 0.248585\tAcc: 79.00\n",
      "train epoch: 73 [140928/221852 (64%)]\tLoss: 0.264583\tAcc: 77.00\n",
      "train epoch: 73 [153728/221852 (69%)]\tLoss: 0.230059\tAcc: 79.00\n",
      "train epoch: 73 [166528/221852 (75%)]\tLoss: 0.243795\tAcc: 77.00\n",
      "train epoch: 73 [179328/221852 (81%)]\tLoss: 0.194683\tAcc: 75.00\n",
      "train epoch: 73 [192128/221852 (87%)]\tLoss: 0.171126\tAcc: 75.00\n",
      "val epoch: 73 [128/221852 (0%)]\tLoss: 0.106173\tAcc: 80.00\n",
      "val epoch: 73 [12928/221852 (6%)]\tLoss: 0.145398\tAcc: 83.00\n",
      "train epoch: 74 [128/221852 (0%)]\tLoss: 0.121691\tAcc: 77.00\n",
      "train epoch: 74 [12928/221852 (6%)]\tLoss: 0.267908\tAcc: 77.00\n",
      "train epoch: 74 [25728/221852 (12%)]\tLoss: 0.279127\tAcc: 69.00\n",
      "train epoch: 74 [38528/221852 (17%)]\tLoss: 0.177345\tAcc: 73.00\n",
      "train epoch: 74 [51328/221852 (23%)]\tLoss: 0.176637\tAcc: 71.00\n",
      "train epoch: 74 [64128/221852 (29%)]\tLoss: 0.181642\tAcc: 74.00\n",
      "train epoch: 74 [76928/221852 (35%)]\tLoss: 0.174768\tAcc: 78.00\n",
      "train epoch: 74 [89728/221852 (40%)]\tLoss: 0.155740\tAcc: 81.00\n",
      "train epoch: 74 [102528/221852 (46%)]\tLoss: 0.188353\tAcc: 80.00\n",
      "train epoch: 74 [115328/221852 (52%)]\tLoss: 0.189810\tAcc: 77.00\n",
      "train epoch: 74 [128128/221852 (58%)]\tLoss: 0.142723\tAcc: 84.00\n",
      "train epoch: 74 [140928/221852 (64%)]\tLoss: 0.220684\tAcc: 80.00\n",
      "train epoch: 74 [153728/221852 (69%)]\tLoss: 0.282895\tAcc: 70.00\n",
      "train epoch: 74 [166528/221852 (75%)]\tLoss: 0.240601\tAcc: 78.00\n",
      "train epoch: 74 [179328/221852 (81%)]\tLoss: 0.213669\tAcc: 77.00\n",
      "train epoch: 74 [192128/221852 (87%)]\tLoss: 0.184488\tAcc: 77.00\n",
      "val epoch: 74 [128/221852 (0%)]\tLoss: 0.294995\tAcc: 75.00\n",
      "val epoch: 74 [12928/221852 (6%)]\tLoss: 0.520707\tAcc: 74.00\n",
      "train epoch: 75 [128/221852 (0%)]\tLoss: 0.323398\tAcc: 77.00\n",
      "train epoch: 75 [12928/221852 (6%)]\tLoss: 0.286136\tAcc: 76.00\n",
      "train epoch: 75 [25728/221852 (12%)]\tLoss: 0.229097\tAcc: 80.00\n",
      "train epoch: 75 [38528/221852 (17%)]\tLoss: 0.273982\tAcc: 75.00\n",
      "train epoch: 75 [51328/221852 (23%)]\tLoss: 0.219912\tAcc: 73.00\n",
      "train epoch: 75 [64128/221852 (29%)]\tLoss: 0.230884\tAcc: 73.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 75 [76928/221852 (35%)]\tLoss: 0.173486\tAcc: 83.00\n",
      "train epoch: 75 [89728/221852 (40%)]\tLoss: 0.122015\tAcc: 81.00\n",
      "train epoch: 75 [102528/221852 (46%)]\tLoss: 0.195469\tAcc: 79.00\n",
      "train epoch: 75 [115328/221852 (52%)]\tLoss: 0.170830\tAcc: 80.00\n",
      "train epoch: 75 [128128/221852 (58%)]\tLoss: 0.151246\tAcc: 80.00\n",
      "train epoch: 75 [140928/221852 (64%)]\tLoss: 0.238484\tAcc: 73.00\n",
      "train epoch: 75 [153728/221852 (69%)]\tLoss: 0.189446\tAcc: 82.00\n",
      "train epoch: 75 [166528/221852 (75%)]\tLoss: 0.189802\tAcc: 77.00\n",
      "train epoch: 75 [179328/221852 (81%)]\tLoss: 0.212432\tAcc: 72.00\n",
      "train epoch: 75 [192128/221852 (87%)]\tLoss: 0.221378\tAcc: 80.00\n",
      "val epoch: 75 [128/221852 (0%)]\tLoss: 0.217045\tAcc: 77.00\n",
      "val epoch: 75 [12928/221852 (6%)]\tLoss: 0.287253\tAcc: 76.00\n",
      "train epoch: 76 [128/221852 (0%)]\tLoss: 0.259182\tAcc: 78.00\n",
      "train epoch: 76 [12928/221852 (6%)]\tLoss: 0.256059\tAcc: 77.00\n",
      "train epoch: 76 [25728/221852 (12%)]\tLoss: 0.221232\tAcc: 80.00\n",
      "train epoch: 76 [38528/221852 (17%)]\tLoss: 0.223051\tAcc: 72.00\n",
      "train epoch: 76 [51328/221852 (23%)]\tLoss: 0.169041\tAcc: 77.00\n",
      "train epoch: 76 [64128/221852 (29%)]\tLoss: 0.223531\tAcc: 77.00\n",
      "train epoch: 76 [76928/221852 (35%)]\tLoss: 0.232527\tAcc: 71.00\n",
      "train epoch: 76 [89728/221852 (40%)]\tLoss: 0.261722\tAcc: 79.00\n",
      "train epoch: 76 [102528/221852 (46%)]\tLoss: 0.165679\tAcc: 73.00\n",
      "train epoch: 76 [115328/221852 (52%)]\tLoss: 0.169886\tAcc: 74.00\n",
      "train epoch: 76 [128128/221852 (58%)]\tLoss: 0.107300\tAcc: 80.00\n",
      "train epoch: 76 [140928/221852 (64%)]\tLoss: 0.319643\tAcc: 77.00\n",
      "train epoch: 76 [153728/221852 (69%)]\tLoss: 0.180626\tAcc: 80.00\n",
      "train epoch: 76 [166528/221852 (75%)]\tLoss: 0.249970\tAcc: 72.00\n",
      "train epoch: 76 [179328/221852 (81%)]\tLoss: 0.190042\tAcc: 78.00\n",
      "train epoch: 76 [192128/221852 (87%)]\tLoss: 0.270508\tAcc: 77.00\n",
      "val epoch: 76 [128/221852 (0%)]\tLoss: 0.179654\tAcc: 80.00\n",
      "val epoch: 76 [12928/221852 (6%)]\tLoss: 0.135005\tAcc: 76.00\n",
      "train epoch: 77 [128/221852 (0%)]\tLoss: 0.193980\tAcc: 75.00\n",
      "train epoch: 77 [12928/221852 (6%)]\tLoss: 0.248021\tAcc: 79.00\n",
      "train epoch: 77 [25728/221852 (12%)]\tLoss: 0.186912\tAcc: 79.00\n",
      "train epoch: 77 [38528/221852 (17%)]\tLoss: 0.264149\tAcc: 77.00\n",
      "train epoch: 77 [51328/221852 (23%)]\tLoss: 0.232739\tAcc: 80.00\n",
      "train epoch: 77 [64128/221852 (29%)]\tLoss: 0.193240\tAcc: 77.00\n",
      "train epoch: 77 [76928/221852 (35%)]\tLoss: 0.106867\tAcc: 77.00\n",
      "train epoch: 77 [89728/221852 (40%)]\tLoss: 0.270777\tAcc: 73.00\n",
      "train epoch: 77 [102528/221852 (46%)]\tLoss: 0.211174\tAcc: 81.00\n",
      "train epoch: 77 [115328/221852 (52%)]\tLoss: 0.200181\tAcc: 78.00\n",
      "train epoch: 77 [128128/221852 (58%)]\tLoss: 0.173986\tAcc: 80.00\n",
      "train epoch: 77 [140928/221852 (64%)]\tLoss: 0.241008\tAcc: 82.00\n",
      "train epoch: 77 [153728/221852 (69%)]\tLoss: 0.162223\tAcc: 79.00\n",
      "train epoch: 77 [166528/221852 (75%)]\tLoss: 0.204787\tAcc: 80.00\n",
      "train epoch: 77 [179328/221852 (81%)]\tLoss: 0.184921\tAcc: 80.00\n",
      "train epoch: 77 [192128/221852 (87%)]\tLoss: 0.194618\tAcc: 77.00\n",
      "val epoch: 77 [128/221852 (0%)]\tLoss: 0.125672\tAcc: 84.00\n",
      "val epoch: 77 [12928/221852 (6%)]\tLoss: 0.210689\tAcc: 78.00\n",
      "train epoch: 78 [128/221852 (0%)]\tLoss: 0.195033\tAcc: 75.00\n",
      "train epoch: 78 [12928/221852 (6%)]\tLoss: 0.235770\tAcc: 77.00\n",
      "train epoch: 78 [25728/221852 (12%)]\tLoss: 0.263456\tAcc: 82.00\n",
      "train epoch: 78 [38528/221852 (17%)]\tLoss: 0.209543\tAcc: 82.00\n",
      "train epoch: 78 [51328/221852 (23%)]\tLoss: 0.175188\tAcc: 82.00\n",
      "train epoch: 78 [64128/221852 (29%)]\tLoss: 0.302430\tAcc: 78.00\n",
      "train epoch: 78 [76928/221852 (35%)]\tLoss: 0.132760\tAcc: 76.00\n",
      "train epoch: 78 [89728/221852 (40%)]\tLoss: 0.223724\tAcc: 76.00\n",
      "train epoch: 78 [102528/221852 (46%)]\tLoss: 0.215635\tAcc: 81.00\n",
      "train epoch: 78 [115328/221852 (52%)]\tLoss: 0.248387\tAcc: 69.00\n",
      "train epoch: 78 [128128/221852 (58%)]\tLoss: 0.153088\tAcc: 77.00\n",
      "train epoch: 78 [140928/221852 (64%)]\tLoss: 0.331875\tAcc: 73.00\n",
      "train epoch: 78 [153728/221852 (69%)]\tLoss: 0.160726\tAcc: 79.00\n",
      "train epoch: 78 [166528/221852 (75%)]\tLoss: 0.256937\tAcc: 84.00\n",
      "train epoch: 78 [179328/221852 (81%)]\tLoss: 0.224199\tAcc: 74.00\n",
      "train epoch: 78 [192128/221852 (87%)]\tLoss: 0.320101\tAcc: 81.00\n",
      "val epoch: 78 [128/221852 (0%)]\tLoss: 0.157756\tAcc: 85.00\n",
      "val epoch: 78 [12928/221852 (6%)]\tLoss: 0.213407\tAcc: 73.00\n",
      "train epoch: 79 [128/221852 (0%)]\tLoss: 0.270016\tAcc: 75.00\n",
      "train epoch: 79 [12928/221852 (6%)]\tLoss: 0.132565\tAcc: 78.00\n",
      "train epoch: 79 [25728/221852 (12%)]\tLoss: 0.166989\tAcc: 83.00\n",
      "train epoch: 79 [38528/221852 (17%)]\tLoss: 0.243359\tAcc: 75.00\n",
      "train epoch: 79 [51328/221852 (23%)]\tLoss: 0.165510\tAcc: 78.00\n",
      "train epoch: 79 [64128/221852 (29%)]\tLoss: 0.160137\tAcc: 80.00\n",
      "train epoch: 79 [76928/221852 (35%)]\tLoss: 0.198800\tAcc: 77.00\n",
      "train epoch: 79 [89728/221852 (40%)]\tLoss: 0.170726\tAcc: 80.00\n",
      "train epoch: 79 [102528/221852 (46%)]\tLoss: 0.226124\tAcc: 81.00\n",
      "train epoch: 79 [115328/221852 (52%)]\tLoss: 0.262821\tAcc: 79.00\n",
      "train epoch: 79 [128128/221852 (58%)]\tLoss: 0.162516\tAcc: 78.00\n",
      "train epoch: 79 [140928/221852 (64%)]\tLoss: 0.170135\tAcc: 78.00\n",
      "train epoch: 79 [153728/221852 (69%)]\tLoss: 0.277726\tAcc: 74.00\n",
      "train epoch: 79 [166528/221852 (75%)]\tLoss: 0.269424\tAcc: 77.00\n",
      "train epoch: 79 [179328/221852 (81%)]\tLoss: 0.352233\tAcc: 73.00\n",
      "train epoch: 79 [192128/221852 (87%)]\tLoss: 0.258000\tAcc: 75.00\n",
      "val epoch: 79 [128/221852 (0%)]\tLoss: 0.194284\tAcc: 78.00\n",
      "val epoch: 79 [12928/221852 (6%)]\tLoss: 0.177837\tAcc: 81.00\n",
      "train epoch: 80 [128/221852 (0%)]\tLoss: 0.219213\tAcc: 78.00\n",
      "train epoch: 80 [12928/221852 (6%)]\tLoss: 0.195963\tAcc: 82.00\n",
      "train epoch: 80 [25728/221852 (12%)]\tLoss: 0.261386\tAcc: 78.00\n",
      "train epoch: 80 [38528/221852 (17%)]\tLoss: 0.193605\tAcc: 79.00\n",
      "train epoch: 80 [51328/221852 (23%)]\tLoss: 0.268207\tAcc: 76.00\n",
      "train epoch: 80 [64128/221852 (29%)]\tLoss: 0.232365\tAcc: 80.00\n",
      "train epoch: 80 [76928/221852 (35%)]\tLoss: 0.202109\tAcc: 83.00\n",
      "train epoch: 80 [89728/221852 (40%)]\tLoss: 0.335863\tAcc: 80.00\n",
      "train epoch: 80 [102528/221852 (46%)]\tLoss: 0.274614\tAcc: 78.00\n",
      "train epoch: 80 [115328/221852 (52%)]\tLoss: 0.183313\tAcc: 81.00\n",
      "train epoch: 80 [128128/221852 (58%)]\tLoss: 0.134116\tAcc: 80.00\n",
      "train epoch: 80 [140928/221852 (64%)]\tLoss: 0.117557\tAcc: 79.00\n",
      "train epoch: 80 [153728/221852 (69%)]\tLoss: 0.384280\tAcc: 77.00\n",
      "train epoch: 80 [166528/221852 (75%)]\tLoss: 0.212415\tAcc: 84.00\n",
      "train epoch: 80 [179328/221852 (81%)]\tLoss: 0.131951\tAcc: 70.00\n",
      "train epoch: 80 [192128/221852 (87%)]\tLoss: 0.271678\tAcc: 72.00\n",
      "val epoch: 80 [128/221852 (0%)]\tLoss: 0.234863\tAcc: 80.00\n",
      "val epoch: 80 [12928/221852 (6%)]\tLoss: 0.314433\tAcc: 74.00\n",
      "train epoch: 81 [128/221852 (0%)]\tLoss: 0.216897\tAcc: 80.00\n",
      "train epoch: 81 [12928/221852 (6%)]\tLoss: 0.153747\tAcc: 81.00\n",
      "train epoch: 81 [25728/221852 (12%)]\tLoss: 0.192957\tAcc: 81.00\n",
      "train epoch: 81 [38528/221852 (17%)]\tLoss: 0.130214\tAcc: 80.00\n",
      "train epoch: 81 [51328/221852 (23%)]\tLoss: 0.204900\tAcc: 73.00\n",
      "train epoch: 81 [64128/221852 (29%)]\tLoss: 0.224845\tAcc: 80.00\n",
      "train epoch: 81 [76928/221852 (35%)]\tLoss: 0.181834\tAcc: 77.00\n",
      "train epoch: 81 [89728/221852 (40%)]\tLoss: 0.195437\tAcc: 84.00\n",
      "train epoch: 81 [102528/221852 (46%)]\tLoss: 0.296942\tAcc: 75.00\n",
      "train epoch: 81 [115328/221852 (52%)]\tLoss: 0.238212\tAcc: 73.00\n",
      "train epoch: 81 [128128/221852 (58%)]\tLoss: 0.229822\tAcc: 76.00\n",
      "train epoch: 81 [140928/221852 (64%)]\tLoss: 0.132842\tAcc: 81.00\n",
      "train epoch: 81 [153728/221852 (69%)]\tLoss: 0.163869\tAcc: 79.00\n",
      "train epoch: 81 [166528/221852 (75%)]\tLoss: 0.157890\tAcc: 83.00\n",
      "train epoch: 81 [179328/221852 (81%)]\tLoss: 0.157018\tAcc: 82.00\n",
      "train epoch: 81 [192128/221852 (87%)]\tLoss: 0.307904\tAcc: 78.00\n",
      "val epoch: 81 [128/221852 (0%)]\tLoss: 0.162095\tAcc: 78.00\n",
      "val epoch: 81 [12928/221852 (6%)]\tLoss: 0.224687\tAcc: 77.00\n",
      "train epoch: 82 [128/221852 (0%)]\tLoss: 0.228744\tAcc: 78.00\n",
      "train epoch: 82 [12928/221852 (6%)]\tLoss: 0.215363\tAcc: 80.00\n",
      "train epoch: 82 [25728/221852 (12%)]\tLoss: 0.180250\tAcc: 79.00\n",
      "train epoch: 82 [38528/221852 (17%)]\tLoss: 0.219444\tAcc: 81.00\n",
      "train epoch: 82 [51328/221852 (23%)]\tLoss: 0.259292\tAcc: 73.00\n",
      "train epoch: 82 [64128/221852 (29%)]\tLoss: 0.289319\tAcc: 74.00\n",
      "train epoch: 82 [76928/221852 (35%)]\tLoss: 0.176143\tAcc: 80.00\n",
      "train epoch: 82 [89728/221852 (40%)]\tLoss: 0.171177\tAcc: 81.00\n",
      "train epoch: 82 [102528/221852 (46%)]\tLoss: 0.224911\tAcc: 77.00\n",
      "train epoch: 82 [115328/221852 (52%)]\tLoss: 0.165747\tAcc: 79.00\n",
      "train epoch: 82 [128128/221852 (58%)]\tLoss: 0.099638\tAcc: 88.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 82 [140928/221852 (64%)]\tLoss: 0.163562\tAcc: 77.00\n",
      "train epoch: 82 [153728/221852 (69%)]\tLoss: 0.205314\tAcc: 82.00\n",
      "train epoch: 82 [166528/221852 (75%)]\tLoss: 0.180962\tAcc: 77.00\n",
      "train epoch: 82 [179328/221852 (81%)]\tLoss: 0.230772\tAcc: 77.00\n",
      "train epoch: 82 [192128/221852 (87%)]\tLoss: 0.152927\tAcc: 77.00\n",
      "val epoch: 82 [128/221852 (0%)]\tLoss: 0.273091\tAcc: 80.00\n",
      "val epoch: 82 [12928/221852 (6%)]\tLoss: 0.155355\tAcc: 81.00\n",
      "train epoch: 83 [128/221852 (0%)]\tLoss: 0.211449\tAcc: 76.00\n",
      "train epoch: 83 [12928/221852 (6%)]\tLoss: 0.179642\tAcc: 75.00\n",
      "train epoch: 83 [25728/221852 (12%)]\tLoss: 0.179271\tAcc: 80.00\n",
      "train epoch: 83 [38528/221852 (17%)]\tLoss: 0.162968\tAcc: 80.00\n",
      "train epoch: 83 [51328/221852 (23%)]\tLoss: 0.227475\tAcc: 75.00\n",
      "train epoch: 83 [64128/221852 (29%)]\tLoss: 0.182525\tAcc: 83.00\n",
      "train epoch: 83 [76928/221852 (35%)]\tLoss: 0.199462\tAcc: 80.00\n",
      "train epoch: 83 [89728/221852 (40%)]\tLoss: 0.229045\tAcc: 77.00\n",
      "train epoch: 83 [102528/221852 (46%)]\tLoss: 0.321383\tAcc: 77.00\n",
      "train epoch: 83 [115328/221852 (52%)]\tLoss: 0.137086\tAcc: 77.00\n",
      "train epoch: 83 [128128/221852 (58%)]\tLoss: 0.211927\tAcc: 80.00\n",
      "train epoch: 83 [140928/221852 (64%)]\tLoss: 0.249100\tAcc: 68.00\n",
      "train epoch: 83 [153728/221852 (69%)]\tLoss: 0.201497\tAcc: 84.00\n",
      "train epoch: 83 [166528/221852 (75%)]\tLoss: 0.175487\tAcc: 84.00\n",
      "train epoch: 83 [179328/221852 (81%)]\tLoss: 0.391622\tAcc: 79.00\n",
      "train epoch: 83 [192128/221852 (87%)]\tLoss: 0.264858\tAcc: 80.00\n",
      "val epoch: 83 [128/221852 (0%)]\tLoss: 0.275841\tAcc: 75.00\n",
      "val epoch: 83 [12928/221852 (6%)]\tLoss: 0.177177\tAcc: 74.00\n",
      "train epoch: 84 [128/221852 (0%)]\tLoss: 0.202115\tAcc: 77.00\n",
      "train epoch: 84 [12928/221852 (6%)]\tLoss: 0.183497\tAcc: 76.00\n",
      "train epoch: 84 [25728/221852 (12%)]\tLoss: 0.144190\tAcc: 80.00\n",
      "train epoch: 84 [38528/221852 (17%)]\tLoss: 0.166727\tAcc: 82.00\n",
      "train epoch: 84 [51328/221852 (23%)]\tLoss: 0.192420\tAcc: 82.00\n",
      "train epoch: 84 [64128/221852 (29%)]\tLoss: 0.143720\tAcc: 81.00\n",
      "train epoch: 84 [76928/221852 (35%)]\tLoss: 0.199603\tAcc: 84.00\n",
      "train epoch: 84 [89728/221852 (40%)]\tLoss: 0.223569\tAcc: 76.00\n",
      "train epoch: 84 [102528/221852 (46%)]\tLoss: 0.241734\tAcc: 78.00\n",
      "train epoch: 84 [115328/221852 (52%)]\tLoss: 0.149025\tAcc: 84.00\n",
      "train epoch: 84 [128128/221852 (58%)]\tLoss: 0.156487\tAcc: 79.00\n",
      "train epoch: 84 [140928/221852 (64%)]\tLoss: 0.170306\tAcc: 79.00\n",
      "train epoch: 84 [153728/221852 (69%)]\tLoss: 0.178553\tAcc: 77.00\n",
      "train epoch: 84 [166528/221852 (75%)]\tLoss: 0.182160\tAcc: 80.00\n",
      "train epoch: 84 [179328/221852 (81%)]\tLoss: 0.176370\tAcc: 80.00\n",
      "train epoch: 84 [192128/221852 (87%)]\tLoss: 0.173230\tAcc: 84.00\n",
      "val epoch: 84 [128/221852 (0%)]\tLoss: 0.177530\tAcc: 83.00\n",
      "val epoch: 84 [12928/221852 (6%)]\tLoss: 0.191299\tAcc: 88.00\n",
      "train epoch: 85 [128/221852 (0%)]\tLoss: 0.148229\tAcc: 84.00\n",
      "train epoch: 85 [12928/221852 (6%)]\tLoss: 0.204124\tAcc: 79.00\n",
      "train epoch: 85 [25728/221852 (12%)]\tLoss: 0.199529\tAcc: 77.00\n",
      "train epoch: 85 [38528/221852 (17%)]\tLoss: 0.209237\tAcc: 77.00\n",
      "train epoch: 85 [51328/221852 (23%)]\tLoss: 0.186204\tAcc: 86.00\n",
      "train epoch: 85 [64128/221852 (29%)]\tLoss: 0.112015\tAcc: 80.00\n",
      "train epoch: 85 [76928/221852 (35%)]\tLoss: 0.865047\tAcc: 79.00\n",
      "train epoch: 85 [89728/221852 (40%)]\tLoss: 0.262159\tAcc: 80.00\n",
      "train epoch: 85 [102528/221852 (46%)]\tLoss: 0.200642\tAcc: 74.00\n",
      "train epoch: 85 [115328/221852 (52%)]\tLoss: 0.196124\tAcc: 79.00\n",
      "train epoch: 85 [128128/221852 (58%)]\tLoss: 0.165265\tAcc: 77.00\n",
      "train epoch: 85 [140928/221852 (64%)]\tLoss: 0.178727\tAcc: 83.00\n",
      "train epoch: 85 [153728/221852 (69%)]\tLoss: 0.205818\tAcc: 73.00\n",
      "train epoch: 85 [166528/221852 (75%)]\tLoss: 0.272959\tAcc: 77.00\n",
      "train epoch: 85 [179328/221852 (81%)]\tLoss: 0.233006\tAcc: 76.00\n",
      "train epoch: 85 [192128/221852 (87%)]\tLoss: 0.276411\tAcc: 72.00\n",
      "val epoch: 85 [128/221852 (0%)]\tLoss: 0.226709\tAcc: 77.00\n",
      "val epoch: 85 [12928/221852 (6%)]\tLoss: 0.229495\tAcc: 70.00\n",
      "train epoch: 86 [128/221852 (0%)]\tLoss: 0.207637\tAcc: 74.00\n",
      "train epoch: 86 [12928/221852 (6%)]\tLoss: 0.202347\tAcc: 74.00\n",
      "train epoch: 86 [25728/221852 (12%)]\tLoss: 0.230121\tAcc: 77.00\n",
      "train epoch: 86 [38528/221852 (17%)]\tLoss: 0.239807\tAcc: 73.00\n",
      "train epoch: 86 [51328/221852 (23%)]\tLoss: 0.208153\tAcc: 77.00\n",
      "train epoch: 86 [64128/221852 (29%)]\tLoss: 0.214294\tAcc: 81.00\n",
      "train epoch: 86 [76928/221852 (35%)]\tLoss: 0.190096\tAcc: 88.00\n",
      "train epoch: 86 [89728/221852 (40%)]\tLoss: 0.165520\tAcc: 82.00\n",
      "train epoch: 86 [102528/221852 (46%)]\tLoss: 0.239314\tAcc: 81.00\n",
      "train epoch: 86 [115328/221852 (52%)]\tLoss: 0.181134\tAcc: 81.00\n",
      "train epoch: 86 [128128/221852 (58%)]\tLoss: 0.250820\tAcc: 75.00\n",
      "train epoch: 86 [140928/221852 (64%)]\tLoss: 0.108658\tAcc: 77.00\n",
      "train epoch: 86 [153728/221852 (69%)]\tLoss: 0.172738\tAcc: 86.00\n",
      "train epoch: 86 [166528/221852 (75%)]\tLoss: 0.235799\tAcc: 75.00\n",
      "train epoch: 86 [179328/221852 (81%)]\tLoss: 0.270873\tAcc: 82.00\n",
      "train epoch: 86 [192128/221852 (87%)]\tLoss: 0.252893\tAcc: 73.00\n",
      "val epoch: 86 [128/221852 (0%)]\tLoss: 0.230567\tAcc: 77.00\n",
      "val epoch: 86 [12928/221852 (6%)]\tLoss: 0.278572\tAcc: 73.00\n",
      "train epoch: 87 [128/221852 (0%)]\tLoss: 0.185543\tAcc: 79.00\n",
      "train epoch: 87 [12928/221852 (6%)]\tLoss: 0.184521\tAcc: 79.00\n",
      "train epoch: 87 [25728/221852 (12%)]\tLoss: 0.164057\tAcc: 77.00\n",
      "train epoch: 87 [38528/221852 (17%)]\tLoss: 0.421873\tAcc: 81.00\n",
      "train epoch: 87 [51328/221852 (23%)]\tLoss: 0.187565\tAcc: 83.00\n",
      "train epoch: 87 [64128/221852 (29%)]\tLoss: 0.203976\tAcc: 82.00\n",
      "train epoch: 87 [76928/221852 (35%)]\tLoss: 0.224076\tAcc: 85.00\n",
      "train epoch: 87 [89728/221852 (40%)]\tLoss: 0.238658\tAcc: 78.00\n",
      "train epoch: 87 [102528/221852 (46%)]\tLoss: 0.142829\tAcc: 76.00\n",
      "train epoch: 87 [115328/221852 (52%)]\tLoss: 0.211914\tAcc: 71.00\n",
      "train epoch: 87 [128128/221852 (58%)]\tLoss: 0.207125\tAcc: 82.00\n",
      "train epoch: 87 [140928/221852 (64%)]\tLoss: 0.295962\tAcc: 79.00\n",
      "train epoch: 87 [153728/221852 (69%)]\tLoss: 0.159612\tAcc: 85.00\n",
      "train epoch: 87 [166528/221852 (75%)]\tLoss: 0.320064\tAcc: 70.00\n",
      "train epoch: 87 [179328/221852 (81%)]\tLoss: 0.351533\tAcc: 68.00\n",
      "train epoch: 87 [192128/221852 (87%)]\tLoss: 0.214030\tAcc: 74.00\n",
      "val epoch: 87 [128/221852 (0%)]\tLoss: 0.323164\tAcc: 75.00\n",
      "val epoch: 87 [12928/221852 (6%)]\tLoss: 0.390166\tAcc: 69.00\n",
      "train epoch: 88 [128/221852 (0%)]\tLoss: 0.242431\tAcc: 77.00\n",
      "train epoch: 88 [12928/221852 (6%)]\tLoss: 0.197383\tAcc: 80.00\n",
      "train epoch: 88 [25728/221852 (12%)]\tLoss: 0.171090\tAcc: 81.00\n",
      "train epoch: 88 [38528/221852 (17%)]\tLoss: 0.328177\tAcc: 84.00\n",
      "train epoch: 88 [51328/221852 (23%)]\tLoss: 0.188057\tAcc: 80.00\n",
      "train epoch: 88 [64128/221852 (29%)]\tLoss: 0.197774\tAcc: 82.00\n",
      "train epoch: 88 [76928/221852 (35%)]\tLoss: 0.298167\tAcc: 74.00\n",
      "train epoch: 88 [89728/221852 (40%)]\tLoss: 0.186982\tAcc: 83.00\n",
      "train epoch: 88 [102528/221852 (46%)]\tLoss: 0.158110\tAcc: 87.00\n",
      "train epoch: 88 [115328/221852 (52%)]\tLoss: 0.194289\tAcc: 79.00\n",
      "train epoch: 88 [128128/221852 (58%)]\tLoss: 0.380750\tAcc: 79.00\n",
      "train epoch: 88 [140928/221852 (64%)]\tLoss: 0.215750\tAcc: 80.00\n",
      "train epoch: 88 [153728/221852 (69%)]\tLoss: 0.214654\tAcc: 72.00\n",
      "train epoch: 88 [166528/221852 (75%)]\tLoss: 0.179501\tAcc: 73.00\n",
      "train epoch: 88 [179328/221852 (81%)]\tLoss: 0.241000\tAcc: 77.00\n",
      "train epoch: 88 [192128/221852 (87%)]\tLoss: 0.228652\tAcc: 77.00\n",
      "val epoch: 88 [128/221852 (0%)]\tLoss: 0.194609\tAcc: 83.00\n",
      "val epoch: 88 [12928/221852 (6%)]\tLoss: 0.243828\tAcc: 72.00\n",
      "train epoch: 89 [128/221852 (0%)]\tLoss: 0.184973\tAcc: 79.00\n",
      "train epoch: 89 [12928/221852 (6%)]\tLoss: 0.163682\tAcc: 84.00\n",
      "train epoch: 89 [25728/221852 (12%)]\tLoss: 0.156550\tAcc: 81.00\n",
      "train epoch: 89 [38528/221852 (17%)]\tLoss: 0.369941\tAcc: 71.00\n",
      "train epoch: 89 [51328/221852 (23%)]\tLoss: 0.171161\tAcc: 84.00\n",
      "train epoch: 89 [64128/221852 (29%)]\tLoss: 0.207118\tAcc: 88.00\n",
      "train epoch: 89 [76928/221852 (35%)]\tLoss: 0.247491\tAcc: 79.00\n",
      "train epoch: 89 [89728/221852 (40%)]\tLoss: 0.233620\tAcc: 72.00\n",
      "train epoch: 89 [102528/221852 (46%)]\tLoss: 0.383429\tAcc: 66.00\n",
      "train epoch: 89 [115328/221852 (52%)]\tLoss: 0.224410\tAcc: 73.00\n",
      "train epoch: 89 [128128/221852 (58%)]\tLoss: 0.203903\tAcc: 74.00\n",
      "train epoch: 89 [140928/221852 (64%)]\tLoss: 0.188249\tAcc: 77.00\n",
      "train epoch: 89 [153728/221852 (69%)]\tLoss: 0.302051\tAcc: 84.00\n",
      "train epoch: 89 [166528/221852 (75%)]\tLoss: 0.178459\tAcc: 81.00\n",
      "train epoch: 89 [179328/221852 (81%)]\tLoss: 0.368245\tAcc: 73.00\n",
      "train epoch: 89 [192128/221852 (87%)]\tLoss: 0.155142\tAcc: 76.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 89 [128/221852 (0%)]\tLoss: 0.207448\tAcc: 80.00\n",
      "val epoch: 89 [12928/221852 (6%)]\tLoss: 0.139313\tAcc: 81.00\n",
      "train epoch: 90 [128/221852 (0%)]\tLoss: 0.162844\tAcc: 80.00\n",
      "train epoch: 90 [12928/221852 (6%)]\tLoss: 0.191430\tAcc: 88.00\n",
      "train epoch: 90 [25728/221852 (12%)]\tLoss: 0.209970\tAcc: 82.00\n",
      "train epoch: 90 [38528/221852 (17%)]\tLoss: 0.199357\tAcc: 77.00\n",
      "train epoch: 90 [51328/221852 (23%)]\tLoss: 0.171221\tAcc: 81.00\n",
      "train epoch: 90 [64128/221852 (29%)]\tLoss: 0.236278\tAcc: 80.00\n",
      "train epoch: 90 [76928/221852 (35%)]\tLoss: 0.204605\tAcc: 73.00\n",
      "train epoch: 90 [89728/221852 (40%)]\tLoss: 0.198119\tAcc: 80.00\n",
      "train epoch: 90 [102528/221852 (46%)]\tLoss: 0.213576\tAcc: 80.00\n",
      "train epoch: 90 [115328/221852 (52%)]\tLoss: 0.165266\tAcc: 77.00\n",
      "train epoch: 90 [128128/221852 (58%)]\tLoss: 0.257135\tAcc: 75.00\n",
      "train epoch: 90 [140928/221852 (64%)]\tLoss: 0.204489\tAcc: 77.00\n",
      "train epoch: 90 [153728/221852 (69%)]\tLoss: 0.135798\tAcc: 80.00\n",
      "train epoch: 90 [166528/221852 (75%)]\tLoss: 0.248700\tAcc: 77.00\n",
      "train epoch: 90 [179328/221852 (81%)]\tLoss: 0.211186\tAcc: 81.00\n",
      "train epoch: 90 [192128/221852 (87%)]\tLoss: 0.186297\tAcc: 77.00\n",
      "val epoch: 90 [128/221852 (0%)]\tLoss: 0.270611\tAcc: 80.00\n",
      "val epoch: 90 [12928/221852 (6%)]\tLoss: 0.308571\tAcc: 80.00\n",
      "train epoch: 91 [128/221852 (0%)]\tLoss: 0.216652\tAcc: 80.00\n",
      "train epoch: 91 [12928/221852 (6%)]\tLoss: 0.191442\tAcc: 75.00\n",
      "train epoch: 91 [25728/221852 (12%)]\tLoss: 0.177523\tAcc: 82.00\n",
      "train epoch: 91 [38528/221852 (17%)]\tLoss: 0.176221\tAcc: 77.00\n",
      "train epoch: 91 [51328/221852 (23%)]\tLoss: 0.250064\tAcc: 83.00\n",
      "train epoch: 91 [64128/221852 (29%)]\tLoss: 0.183311\tAcc: 78.00\n",
      "train epoch: 91 [76928/221852 (35%)]\tLoss: 0.302073\tAcc: 74.00\n",
      "train epoch: 91 [89728/221852 (40%)]\tLoss: 0.206999\tAcc: 84.00\n",
      "train epoch: 91 [102528/221852 (46%)]\tLoss: 0.171445\tAcc: 81.00\n",
      "train epoch: 91 [115328/221852 (52%)]\tLoss: 0.193592\tAcc: 78.00\n",
      "train epoch: 91 [128128/221852 (58%)]\tLoss: 0.388837\tAcc: 78.00\n",
      "train epoch: 91 [140928/221852 (64%)]\tLoss: 0.228272\tAcc: 84.00\n",
      "train epoch: 91 [153728/221852 (69%)]\tLoss: 0.179889\tAcc: 80.00\n",
      "train epoch: 91 [166528/221852 (75%)]\tLoss: 0.165802\tAcc: 81.00\n",
      "train epoch: 91 [179328/221852 (81%)]\tLoss: 0.209780\tAcc: 77.00\n",
      "train epoch: 91 [192128/221852 (87%)]\tLoss: 0.245615\tAcc: 75.00\n",
      "val epoch: 91 [128/221852 (0%)]\tLoss: 0.185708\tAcc: 80.00\n",
      "val epoch: 91 [12928/221852 (6%)]\tLoss: 0.166556\tAcc: 76.00\n",
      "train epoch: 92 [128/221852 (0%)]\tLoss: 0.132268\tAcc: 79.00\n",
      "train epoch: 92 [12928/221852 (6%)]\tLoss: 0.129256\tAcc: 80.00\n",
      "train epoch: 92 [25728/221852 (12%)]\tLoss: 0.177563\tAcc: 80.00\n",
      "train epoch: 92 [38528/221852 (17%)]\tLoss: 0.205273\tAcc: 78.00\n",
      "train epoch: 92 [51328/221852 (23%)]\tLoss: 0.143123\tAcc: 79.00\n",
      "train epoch: 92 [64128/221852 (29%)]\tLoss: 0.223062\tAcc: 84.00\n",
      "train epoch: 92 [76928/221852 (35%)]\tLoss: 0.161442\tAcc: 82.00\n",
      "train epoch: 92 [89728/221852 (40%)]\tLoss: 0.161524\tAcc: 77.00\n",
      "train epoch: 92 [102528/221852 (46%)]\tLoss: 0.253300\tAcc: 83.00\n",
      "train epoch: 92 [115328/221852 (52%)]\tLoss: 0.217802\tAcc: 75.00\n",
      "train epoch: 92 [128128/221852 (58%)]\tLoss: 0.161290\tAcc: 83.00\n",
      "train epoch: 92 [140928/221852 (64%)]\tLoss: 0.150074\tAcc: 84.00\n",
      "train epoch: 92 [153728/221852 (69%)]\tLoss: 0.262168\tAcc: 80.00\n",
      "train epoch: 92 [166528/221852 (75%)]\tLoss: 0.194802\tAcc: 70.00\n",
      "train epoch: 92 [179328/221852 (81%)]\tLoss: 0.172377\tAcc: 81.00\n",
      "train epoch: 92 [192128/221852 (87%)]\tLoss: 0.176490\tAcc: 77.00\n",
      "val epoch: 92 [128/221852 (0%)]\tLoss: 0.227791\tAcc: 80.00\n",
      "val epoch: 92 [12928/221852 (6%)]\tLoss: 0.139274\tAcc: 83.00\n",
      "train epoch: 93 [128/221852 (0%)]\tLoss: 0.152444\tAcc: 82.00\n",
      "train epoch: 93 [12928/221852 (6%)]\tLoss: 0.297738\tAcc: 74.00\n",
      "train epoch: 93 [25728/221852 (12%)]\tLoss: 0.191302\tAcc: 81.00\n",
      "train epoch: 93 [38528/221852 (17%)]\tLoss: 0.261649\tAcc: 76.00\n",
      "train epoch: 93 [51328/221852 (23%)]\tLoss: 0.177435\tAcc: 82.00\n",
      "train epoch: 93 [64128/221852 (29%)]\tLoss: 1.311001\tAcc: 77.00\n",
      "train epoch: 93 [76928/221852 (35%)]\tLoss: 0.262715\tAcc: 70.00\n",
      "train epoch: 93 [89728/221852 (40%)]\tLoss: 0.219337\tAcc: 81.00\n",
      "train epoch: 93 [102528/221852 (46%)]\tLoss: 0.212014\tAcc: 83.00\n",
      "train epoch: 93 [115328/221852 (52%)]\tLoss: 0.221166\tAcc: 81.00\n",
      "train epoch: 93 [128128/221852 (58%)]\tLoss: 0.223966\tAcc: 82.00\n",
      "train epoch: 93 [140928/221852 (64%)]\tLoss: 0.259430\tAcc: 74.00\n",
      "train epoch: 93 [153728/221852 (69%)]\tLoss: 0.227975\tAcc: 77.00\n",
      "train epoch: 93 [166528/221852 (75%)]\tLoss: 0.205750\tAcc: 80.00\n",
      "train epoch: 93 [179328/221852 (81%)]\tLoss: 0.493209\tAcc: 74.00\n",
      "train epoch: 93 [192128/221852 (87%)]\tLoss: 0.248616\tAcc: 70.00\n",
      "val epoch: 93 [128/221852 (0%)]\tLoss: 0.184916\tAcc: 78.00\n",
      "val epoch: 93 [12928/221852 (6%)]\tLoss: 0.173799\tAcc: 84.00\n",
      "train epoch: 94 [128/221852 (0%)]\tLoss: 0.233382\tAcc: 77.00\n",
      "train epoch: 94 [12928/221852 (6%)]\tLoss: 0.182195\tAcc: 74.00\n",
      "train epoch: 94 [25728/221852 (12%)]\tLoss: 0.165280\tAcc: 80.00\n",
      "train epoch: 94 [38528/221852 (17%)]\tLoss: 0.197485\tAcc: 73.00\n",
      "train epoch: 94 [51328/221852 (23%)]\tLoss: 0.222888\tAcc: 77.00\n",
      "train epoch: 94 [64128/221852 (29%)]\tLoss: 0.104490\tAcc: 91.00\n",
      "train epoch: 94 [76928/221852 (35%)]\tLoss: 0.257028\tAcc: 69.00\n",
      "train epoch: 94 [89728/221852 (40%)]\tLoss: 0.205634\tAcc: 80.00\n",
      "train epoch: 94 [102528/221852 (46%)]\tLoss: 0.264281\tAcc: 74.00\n",
      "train epoch: 94 [115328/221852 (52%)]\tLoss: 0.229647\tAcc: 78.00\n",
      "train epoch: 94 [128128/221852 (58%)]\tLoss: 0.123601\tAcc: 83.00\n",
      "train epoch: 94 [140928/221852 (64%)]\tLoss: 0.121749\tAcc: 80.00\n",
      "train epoch: 94 [153728/221852 (69%)]\tLoss: 0.430372\tAcc: 78.00\n",
      "train epoch: 94 [166528/221852 (75%)]\tLoss: 0.219624\tAcc: 78.00\n",
      "train epoch: 94 [179328/221852 (81%)]\tLoss: 0.282129\tAcc: 70.00\n",
      "train epoch: 94 [192128/221852 (87%)]\tLoss: 0.246522\tAcc: 81.00\n",
      "val epoch: 94 [128/221852 (0%)]\tLoss: 0.141457\tAcc: 83.00\n",
      "val epoch: 94 [12928/221852 (6%)]\tLoss: 0.225119\tAcc: 77.00\n",
      "train epoch: 95 [128/221852 (0%)]\tLoss: 0.138722\tAcc: 80.00\n",
      "train epoch: 95 [12928/221852 (6%)]\tLoss: 0.160596\tAcc: 82.00\n",
      "train epoch: 95 [25728/221852 (12%)]\tLoss: 0.280757\tAcc: 78.00\n",
      "train epoch: 95 [38528/221852 (17%)]\tLoss: 0.270922\tAcc: 78.00\n",
      "train epoch: 95 [51328/221852 (23%)]\tLoss: 0.175479\tAcc: 78.00\n",
      "train epoch: 95 [64128/221852 (29%)]\tLoss: 0.192726\tAcc: 84.00\n",
      "train epoch: 95 [76928/221852 (35%)]\tLoss: 0.193678\tAcc: 81.00\n",
      "train epoch: 95 [89728/221852 (40%)]\tLoss: 0.157950\tAcc: 79.00\n",
      "train epoch: 95 [102528/221852 (46%)]\tLoss: 0.169681\tAcc: 78.00\n",
      "train epoch: 95 [115328/221852 (52%)]\tLoss: 0.116914\tAcc: 82.00\n",
      "train epoch: 95 [128128/221852 (58%)]\tLoss: 0.193119\tAcc: 80.00\n",
      "train epoch: 95 [140928/221852 (64%)]\tLoss: 0.093405\tAcc: 86.00\n",
      "train epoch: 95 [153728/221852 (69%)]\tLoss: 0.082431\tAcc: 82.00\n",
      "train epoch: 95 [166528/221852 (75%)]\tLoss: 0.168839\tAcc: 77.00\n",
      "train epoch: 95 [179328/221852 (81%)]\tLoss: 0.223704\tAcc: 81.00\n",
      "train epoch: 95 [192128/221852 (87%)]\tLoss: 0.220949\tAcc: 78.00\n",
      "val epoch: 95 [128/221852 (0%)]\tLoss: 0.157916\tAcc: 84.00\n",
      "val epoch: 95 [12928/221852 (6%)]\tLoss: 0.135158\tAcc: 84.00\n",
      "train epoch: 96 [128/221852 (0%)]\tLoss: 0.162820\tAcc: 84.00\n",
      "train epoch: 96 [12928/221852 (6%)]\tLoss: 0.161687\tAcc: 76.00\n",
      "train epoch: 96 [25728/221852 (12%)]\tLoss: 0.211749\tAcc: 79.00\n",
      "train epoch: 96 [38528/221852 (17%)]\tLoss: 0.306776\tAcc: 70.00\n",
      "train epoch: 96 [51328/221852 (23%)]\tLoss: 0.151609\tAcc: 82.00\n",
      "train epoch: 96 [64128/221852 (29%)]\tLoss: 0.224304\tAcc: 79.00\n",
      "train epoch: 96 [76928/221852 (35%)]\tLoss: 0.188212\tAcc: 80.00\n",
      "train epoch: 96 [89728/221852 (40%)]\tLoss: 0.215431\tAcc: 80.00\n",
      "train epoch: 96 [102528/221852 (46%)]\tLoss: 0.205688\tAcc: 83.00\n",
      "train epoch: 96 [115328/221852 (52%)]\tLoss: 0.219224\tAcc: 75.00\n",
      "train epoch: 96 [128128/221852 (58%)]\tLoss: 0.254631\tAcc: 84.00\n",
      "train epoch: 96 [140928/221852 (64%)]\tLoss: 0.291994\tAcc: 78.00\n",
      "train epoch: 96 [153728/221852 (69%)]\tLoss: 0.174612\tAcc: 83.00\n",
      "train epoch: 96 [166528/221852 (75%)]\tLoss: 0.203611\tAcc: 78.00\n",
      "train epoch: 96 [179328/221852 (81%)]\tLoss: 0.157013\tAcc: 87.00\n",
      "train epoch: 96 [192128/221852 (87%)]\tLoss: 0.211257\tAcc: 80.00\n",
      "val epoch: 96 [128/221852 (0%)]\tLoss: 0.220330\tAcc: 78.00\n",
      "val epoch: 96 [12928/221852 (6%)]\tLoss: 0.203419\tAcc: 77.00\n",
      "train epoch: 97 [128/221852 (0%)]\tLoss: 0.237902\tAcc: 87.00\n",
      "train epoch: 97 [12928/221852 (6%)]\tLoss: 0.142902\tAcc: 84.00\n",
      "train epoch: 97 [25728/221852 (12%)]\tLoss: 0.192184\tAcc: 79.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 97 [38528/221852 (17%)]\tLoss: 0.261993\tAcc: 83.00\n",
      "train epoch: 97 [51328/221852 (23%)]\tLoss: 0.228257\tAcc: 78.00\n",
      "train epoch: 97 [64128/221852 (29%)]\tLoss: 0.180741\tAcc: 79.00\n",
      "train epoch: 97 [76928/221852 (35%)]\tLoss: 0.174188\tAcc: 84.00\n",
      "train epoch: 97 [89728/221852 (40%)]\tLoss: 0.150243\tAcc: 81.00\n",
      "train epoch: 97 [102528/221852 (46%)]\tLoss: 0.182968\tAcc: 86.00\n",
      "train epoch: 97 [115328/221852 (52%)]\tLoss: 0.271223\tAcc: 75.00\n",
      "train epoch: 97 [128128/221852 (58%)]\tLoss: 0.203935\tAcc: 75.00\n",
      "train epoch: 97 [140928/221852 (64%)]\tLoss: 0.176770\tAcc: 76.00\n",
      "train epoch: 97 [153728/221852 (69%)]\tLoss: 0.263547\tAcc: 74.00\n",
      "train epoch: 97 [166528/221852 (75%)]\tLoss: 0.195107\tAcc: 80.00\n",
      "train epoch: 97 [179328/221852 (81%)]\tLoss: 0.208604\tAcc: 84.00\n",
      "train epoch: 97 [192128/221852 (87%)]\tLoss: 0.199141\tAcc: 79.00\n",
      "val epoch: 97 [128/221852 (0%)]\tLoss: 0.148577\tAcc: 78.00\n",
      "val epoch: 97 [12928/221852 (6%)]\tLoss: 0.256788\tAcc: 79.00\n",
      "train epoch: 98 [128/221852 (0%)]\tLoss: 0.187790\tAcc: 86.00\n",
      "train epoch: 98 [12928/221852 (6%)]\tLoss: 0.139294\tAcc: 80.00\n",
      "train epoch: 98 [25728/221852 (12%)]\tLoss: 0.270417\tAcc: 79.00\n",
      "train epoch: 98 [38528/221852 (17%)]\tLoss: 0.287397\tAcc: 75.00\n",
      "train epoch: 98 [51328/221852 (23%)]\tLoss: 0.235557\tAcc: 78.00\n",
      "train epoch: 98 [64128/221852 (29%)]\tLoss: 0.216103\tAcc: 73.00\n",
      "train epoch: 98 [76928/221852 (35%)]\tLoss: 0.205714\tAcc: 86.00\n",
      "train epoch: 98 [89728/221852 (40%)]\tLoss: 0.215781\tAcc: 76.00\n",
      "train epoch: 98 [102528/221852 (46%)]\tLoss: 0.330673\tAcc: 70.00\n",
      "train epoch: 98 [115328/221852 (52%)]\tLoss: 0.207173\tAcc: 78.00\n",
      "train epoch: 98 [128128/221852 (58%)]\tLoss: 0.253810\tAcc: 74.00\n",
      "train epoch: 98 [140928/221852 (64%)]\tLoss: 0.249909\tAcc: 73.00\n",
      "train epoch: 98 [153728/221852 (69%)]\tLoss: 0.206248\tAcc: 77.00\n",
      "train epoch: 98 [166528/221852 (75%)]\tLoss: 0.120767\tAcc: 84.00\n",
      "train epoch: 98 [179328/221852 (81%)]\tLoss: 0.147052\tAcc: 80.00\n",
      "train epoch: 98 [192128/221852 (87%)]\tLoss: 0.144994\tAcc: 85.00\n",
      "val epoch: 98 [128/221852 (0%)]\tLoss: 0.160902\tAcc: 77.00\n",
      "val epoch: 98 [12928/221852 (6%)]\tLoss: 0.157162\tAcc: 78.00\n",
      "train epoch: 99 [128/221852 (0%)]\tLoss: 0.182251\tAcc: 76.00\n",
      "train epoch: 99 [12928/221852 (6%)]\tLoss: 0.208515\tAcc: 80.00\n",
      "train epoch: 99 [25728/221852 (12%)]\tLoss: 0.386596\tAcc: 73.00\n",
      "train epoch: 99 [38528/221852 (17%)]\tLoss: 0.189556\tAcc: 73.00\n",
      "train epoch: 99 [51328/221852 (23%)]\tLoss: 0.275020\tAcc: 74.00\n",
      "train epoch: 99 [64128/221852 (29%)]\tLoss: 0.240091\tAcc: 80.00\n",
      "train epoch: 99 [76928/221852 (35%)]\tLoss: 0.177818\tAcc: 80.00\n",
      "train epoch: 99 [89728/221852 (40%)]\tLoss: 0.181640\tAcc: 82.00\n",
      "train epoch: 99 [102528/221852 (46%)]\tLoss: 0.146447\tAcc: 84.00\n",
      "train epoch: 99 [115328/221852 (52%)]\tLoss: 0.221948\tAcc: 74.00\n",
      "train epoch: 99 [128128/221852 (58%)]\tLoss: 0.229585\tAcc: 75.00\n",
      "train epoch: 99 [140928/221852 (64%)]\tLoss: 0.139211\tAcc: 76.00\n",
      "train epoch: 99 [153728/221852 (69%)]\tLoss: 0.156198\tAcc: 84.00\n",
      "train epoch: 99 [166528/221852 (75%)]\tLoss: 0.157165\tAcc: 81.00\n",
      "train epoch: 99 [179328/221852 (81%)]\tLoss: 0.263175\tAcc: 81.00\n",
      "train epoch: 99 [192128/221852 (87%)]\tLoss: 0.208735\tAcc: 78.00\n",
      "val epoch: 99 [128/221852 (0%)]\tLoss: 0.187426\tAcc: 80.00\n",
      "val epoch: 99 [12928/221852 (6%)]\tLoss: 0.151048\tAcc: 84.00\n",
      "train epoch: 100 [128/221852 (0%)]\tLoss: 0.106082\tAcc: 84.00\n",
      "train epoch: 100 [12928/221852 (6%)]\tLoss: 0.217241\tAcc: 77.00\n",
      "train epoch: 100 [25728/221852 (12%)]\tLoss: 0.156630\tAcc: 82.00\n",
      "train epoch: 100 [38528/221852 (17%)]\tLoss: 0.240510\tAcc: 80.00\n",
      "train epoch: 100 [51328/221852 (23%)]\tLoss: 0.198962\tAcc: 85.00\n",
      "train epoch: 100 [64128/221852 (29%)]\tLoss: 0.137828\tAcc: 84.00\n",
      "train epoch: 100 [76928/221852 (35%)]\tLoss: 0.236475\tAcc: 77.00\n",
      "train epoch: 100 [89728/221852 (40%)]\tLoss: 0.242542\tAcc: 84.00\n",
      "train epoch: 100 [102528/221852 (46%)]\tLoss: 0.220873\tAcc: 71.00\n",
      "train epoch: 100 [115328/221852 (52%)]\tLoss: 0.220122\tAcc: 80.00\n",
      "train epoch: 100 [128128/221852 (58%)]\tLoss: 0.219815\tAcc: 76.00\n",
      "train epoch: 100 [140928/221852 (64%)]\tLoss: 0.181737\tAcc: 73.00\n",
      "train epoch: 100 [153728/221852 (69%)]\tLoss: 0.180804\tAcc: 78.00\n",
      "train epoch: 100 [166528/221852 (75%)]\tLoss: 0.207807\tAcc: 77.00\n",
      "train epoch: 100 [179328/221852 (81%)]\tLoss: 0.217042\tAcc: 80.00\n",
      "train epoch: 100 [192128/221852 (87%)]\tLoss: 0.169242\tAcc: 78.00\n",
      "val epoch: 100 [128/221852 (0%)]\tLoss: 0.095742\tAcc: 86.00\n",
      "val epoch: 100 [12928/221852 (6%)]\tLoss: 0.200452\tAcc: 84.00\n",
      "train epoch: 101 [128/221852 (0%)]\tLoss: 0.176474\tAcc: 78.00\n",
      "train epoch: 101 [12928/221852 (6%)]\tLoss: 0.080070\tAcc: 84.00\n",
      "train epoch: 101 [25728/221852 (12%)]\tLoss: 0.196360\tAcc: 77.00\n",
      "train epoch: 101 [38528/221852 (17%)]\tLoss: 0.248448\tAcc: 81.00\n",
      "train epoch: 101 [51328/221852 (23%)]\tLoss: 0.136398\tAcc: 84.00\n",
      "train epoch: 101 [64128/221852 (29%)]\tLoss: 0.188352\tAcc: 75.00\n",
      "train epoch: 101 [76928/221852 (35%)]\tLoss: 0.210693\tAcc: 81.00\n",
      "train epoch: 101 [89728/221852 (40%)]\tLoss: 0.224299\tAcc: 77.00\n",
      "train epoch: 101 [102528/221852 (46%)]\tLoss: 0.200935\tAcc: 83.00\n",
      "train epoch: 101 [115328/221852 (52%)]\tLoss: 0.353866\tAcc: 75.00\n",
      "train epoch: 101 [128128/221852 (58%)]\tLoss: 0.198331\tAcc: 75.00\n",
      "train epoch: 101 [140928/221852 (64%)]\tLoss: 0.149339\tAcc: 83.00\n",
      "train epoch: 101 [153728/221852 (69%)]\tLoss: 0.151378\tAcc: 84.00\n",
      "train epoch: 101 [166528/221852 (75%)]\tLoss: 0.301095\tAcc: 74.00\n",
      "train epoch: 101 [179328/221852 (81%)]\tLoss: 0.129376\tAcc: 84.00\n",
      "train epoch: 101 [192128/221852 (87%)]\tLoss: 0.221425\tAcc: 81.00\n",
      "val epoch: 101 [128/221852 (0%)]\tLoss: 0.251705\tAcc: 76.00\n",
      "val epoch: 101 [12928/221852 (6%)]\tLoss: 0.213967\tAcc: 76.00\n",
      "train epoch: 102 [128/221852 (0%)]\tLoss: 0.290123\tAcc: 76.00\n",
      "train epoch: 102 [12928/221852 (6%)]\tLoss: 0.144122\tAcc: 78.00\n",
      "train epoch: 102 [25728/221852 (12%)]\tLoss: 0.240294\tAcc: 88.00\n",
      "train epoch: 102 [38528/221852 (17%)]\tLoss: 0.223535\tAcc: 76.00\n",
      "train epoch: 102 [51328/221852 (23%)]\tLoss: 0.186674\tAcc: 83.00\n",
      "train epoch: 102 [64128/221852 (29%)]\tLoss: 0.298552\tAcc: 80.00\n",
      "train epoch: 102 [76928/221852 (35%)]\tLoss: 0.161252\tAcc: 76.00\n",
      "train epoch: 102 [89728/221852 (40%)]\tLoss: 0.181938\tAcc: 78.00\n",
      "train epoch: 102 [102528/221852 (46%)]\tLoss: 0.185850\tAcc: 80.00\n",
      "train epoch: 102 [115328/221852 (52%)]\tLoss: 0.210224\tAcc: 79.00\n",
      "train epoch: 102 [128128/221852 (58%)]\tLoss: 0.225011\tAcc: 76.00\n",
      "train epoch: 102 [140928/221852 (64%)]\tLoss: 0.180856\tAcc: 80.00\n",
      "train epoch: 102 [153728/221852 (69%)]\tLoss: 0.198655\tAcc: 76.00\n",
      "train epoch: 102 [166528/221852 (75%)]\tLoss: 0.103158\tAcc: 83.00\n",
      "train epoch: 102 [179328/221852 (81%)]\tLoss: 0.197842\tAcc: 82.00\n",
      "train epoch: 102 [192128/221852 (87%)]\tLoss: 0.204762\tAcc: 80.00\n",
      "val epoch: 102 [128/221852 (0%)]\tLoss: 0.265200\tAcc: 80.00\n",
      "val epoch: 102 [12928/221852 (6%)]\tLoss: 0.132100\tAcc: 79.00\n",
      "train epoch: 103 [128/221852 (0%)]\tLoss: 0.196074\tAcc: 84.00\n",
      "train epoch: 103 [12928/221852 (6%)]\tLoss: 0.150703\tAcc: 83.00\n",
      "train epoch: 103 [25728/221852 (12%)]\tLoss: 0.170126\tAcc: 82.00\n",
      "train epoch: 103 [38528/221852 (17%)]\tLoss: 0.192839\tAcc: 82.00\n",
      "train epoch: 103 [51328/221852 (23%)]\tLoss: 0.251039\tAcc: 76.00\n",
      "train epoch: 103 [64128/221852 (29%)]\tLoss: 0.248513\tAcc: 80.00\n",
      "train epoch: 103 [76928/221852 (35%)]\tLoss: 0.180530\tAcc: 78.00\n",
      "train epoch: 103 [89728/221852 (40%)]\tLoss: 0.160796\tAcc: 82.00\n",
      "train epoch: 103 [102528/221852 (46%)]\tLoss: 0.184202\tAcc: 79.00\n",
      "train epoch: 103 [115328/221852 (52%)]\tLoss: 0.332801\tAcc: 76.00\n",
      "train epoch: 103 [128128/221852 (58%)]\tLoss: 0.181449\tAcc: 80.00\n",
      "train epoch: 103 [140928/221852 (64%)]\tLoss: 0.179566\tAcc: 75.00\n",
      "train epoch: 103 [153728/221852 (69%)]\tLoss: 0.115417\tAcc: 88.00\n",
      "train epoch: 103 [166528/221852 (75%)]\tLoss: 0.192309\tAcc: 83.00\n",
      "train epoch: 103 [179328/221852 (81%)]\tLoss: 0.152038\tAcc: 83.00\n",
      "train epoch: 103 [192128/221852 (87%)]\tLoss: 0.198546\tAcc: 83.00\n",
      "val epoch: 103 [128/221852 (0%)]\tLoss: 0.129411\tAcc: 88.00\n",
      "val epoch: 103 [12928/221852 (6%)]\tLoss: 0.153732\tAcc: 81.00\n",
      "train epoch: 104 [128/221852 (0%)]\tLoss: 0.226483\tAcc: 77.00\n",
      "train epoch: 104 [12928/221852 (6%)]\tLoss: 0.251704\tAcc: 82.00\n",
      "train epoch: 104 [25728/221852 (12%)]\tLoss: 0.217554\tAcc: 80.00\n",
      "train epoch: 104 [38528/221852 (17%)]\tLoss: 0.156310\tAcc: 84.00\n",
      "train epoch: 104 [51328/221852 (23%)]\tLoss: 0.286065\tAcc: 76.00\n",
      "train epoch: 104 [64128/221852 (29%)]\tLoss: 0.319884\tAcc: 70.00\n",
      "train epoch: 104 [76928/221852 (35%)]\tLoss: 0.232782\tAcc: 72.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 104 [89728/221852 (40%)]\tLoss: 0.252322\tAcc: 84.00\n",
      "train epoch: 104 [102528/221852 (46%)]\tLoss: 0.278771\tAcc: 81.00\n",
      "train epoch: 104 [115328/221852 (52%)]\tLoss: 0.146287\tAcc: 83.00\n",
      "train epoch: 104 [128128/221852 (58%)]\tLoss: 0.204209\tAcc: 80.00\n",
      "train epoch: 104 [140928/221852 (64%)]\tLoss: 0.228869\tAcc: 77.00\n",
      "train epoch: 104 [153728/221852 (69%)]\tLoss: 0.186756\tAcc: 82.00\n",
      "train epoch: 104 [166528/221852 (75%)]\tLoss: 0.236334\tAcc: 80.00\n",
      "train epoch: 104 [179328/221852 (81%)]\tLoss: 0.213685\tAcc: 80.00\n",
      "train epoch: 104 [192128/221852 (87%)]\tLoss: 0.082218\tAcc: 85.00\n",
      "val epoch: 104 [128/221852 (0%)]\tLoss: 0.191822\tAcc: 84.00\n",
      "val epoch: 104 [12928/221852 (6%)]\tLoss: 0.144298\tAcc: 77.00\n",
      "train epoch: 105 [128/221852 (0%)]\tLoss: 0.234501\tAcc: 77.00\n",
      "train epoch: 105 [12928/221852 (6%)]\tLoss: 0.150723\tAcc: 80.00\n",
      "train epoch: 105 [25728/221852 (12%)]\tLoss: 0.232185\tAcc: 79.00\n",
      "train epoch: 105 [38528/221852 (17%)]\tLoss: 0.207915\tAcc: 74.00\n",
      "train epoch: 105 [51328/221852 (23%)]\tLoss: 0.288758\tAcc: 73.00\n",
      "train epoch: 105 [64128/221852 (29%)]\tLoss: 0.188469\tAcc: 78.00\n",
      "train epoch: 105 [76928/221852 (35%)]\tLoss: 0.145283\tAcc: 77.00\n",
      "train epoch: 105 [89728/221852 (40%)]\tLoss: 0.173582\tAcc: 84.00\n",
      "train epoch: 105 [102528/221852 (46%)]\tLoss: 0.096876\tAcc: 84.00\n",
      "train epoch: 105 [115328/221852 (52%)]\tLoss: 0.149228\tAcc: 78.00\n",
      "train epoch: 105 [128128/221852 (58%)]\tLoss: 0.951078\tAcc: 85.00\n",
      "train epoch: 105 [140928/221852 (64%)]\tLoss: 0.187114\tAcc: 71.00\n",
      "train epoch: 105 [153728/221852 (69%)]\tLoss: 0.168628\tAcc: 83.00\n",
      "train epoch: 105 [166528/221852 (75%)]\tLoss: 0.282762\tAcc: 79.00\n",
      "train epoch: 105 [179328/221852 (81%)]\tLoss: 0.231998\tAcc: 77.00\n",
      "train epoch: 105 [192128/221852 (87%)]\tLoss: 0.271256\tAcc: 70.00\n",
      "val epoch: 105 [128/221852 (0%)]\tLoss: 0.250678\tAcc: 73.00\n",
      "val epoch: 105 [12928/221852 (6%)]\tLoss: 0.206808\tAcc: 77.00\n",
      "train epoch: 106 [128/221852 (0%)]\tLoss: 0.193837\tAcc: 79.00\n",
      "train epoch: 106 [12928/221852 (6%)]\tLoss: 0.233998\tAcc: 75.00\n",
      "train epoch: 106 [25728/221852 (12%)]\tLoss: 0.217576\tAcc: 84.00\n",
      "train epoch: 106 [38528/221852 (17%)]\tLoss: 0.247282\tAcc: 74.00\n",
      "train epoch: 106 [51328/221852 (23%)]\tLoss: 0.218635\tAcc: 83.00\n",
      "train epoch: 106 [64128/221852 (29%)]\tLoss: 0.159591\tAcc: 79.00\n",
      "train epoch: 106 [76928/221852 (35%)]\tLoss: 0.184966\tAcc: 73.00\n",
      "train epoch: 106 [89728/221852 (40%)]\tLoss: 0.229687\tAcc: 77.00\n",
      "train epoch: 106 [102528/221852 (46%)]\tLoss: 0.236683\tAcc: 80.00\n",
      "train epoch: 106 [115328/221852 (52%)]\tLoss: 0.190005\tAcc: 83.00\n",
      "train epoch: 106 [128128/221852 (58%)]\tLoss: 0.159745\tAcc: 79.00\n",
      "train epoch: 106 [140928/221852 (64%)]\tLoss: 0.232004\tAcc: 76.00\n",
      "train epoch: 106 [153728/221852 (69%)]\tLoss: 0.135224\tAcc: 82.00\n",
      "train epoch: 106 [166528/221852 (75%)]\tLoss: 0.251347\tAcc: 75.00\n",
      "train epoch: 106 [179328/221852 (81%)]\tLoss: 0.229223\tAcc: 78.00\n",
      "train epoch: 106 [192128/221852 (87%)]\tLoss: 0.188520\tAcc: 86.00\n",
      "val epoch: 106 [128/221852 (0%)]\tLoss: 0.165017\tAcc: 79.00\n",
      "val epoch: 106 [12928/221852 (6%)]\tLoss: 0.171193\tAcc: 84.00\n",
      "train epoch: 107 [128/221852 (0%)]\tLoss: 0.136379\tAcc: 83.00\n",
      "train epoch: 107 [12928/221852 (6%)]\tLoss: 0.129992\tAcc: 80.00\n",
      "train epoch: 107 [25728/221852 (12%)]\tLoss: 0.121839\tAcc: 80.00\n",
      "train epoch: 107 [38528/221852 (17%)]\tLoss: 0.221929\tAcc: 77.00\n",
      "train epoch: 107 [51328/221852 (23%)]\tLoss: 0.132599\tAcc: 89.00\n",
      "train epoch: 107 [64128/221852 (29%)]\tLoss: 0.225749\tAcc: 83.00\n",
      "train epoch: 107 [76928/221852 (35%)]\tLoss: 0.209050\tAcc: 72.00\n",
      "train epoch: 107 [89728/221852 (40%)]\tLoss: 0.183126\tAcc: 77.00\n",
      "train epoch: 107 [102528/221852 (46%)]\tLoss: 0.206812\tAcc: 83.00\n",
      "train epoch: 107 [115328/221852 (52%)]\tLoss: 0.192667\tAcc: 78.00\n",
      "train epoch: 107 [128128/221852 (58%)]\tLoss: 0.213063\tAcc: 79.00\n",
      "train epoch: 107 [140928/221852 (64%)]\tLoss: 0.279660\tAcc: 73.00\n",
      "train epoch: 107 [153728/221852 (69%)]\tLoss: 0.220005\tAcc: 76.00\n",
      "train epoch: 107 [166528/221852 (75%)]\tLoss: 0.255381\tAcc: 84.00\n",
      "train epoch: 107 [179328/221852 (81%)]\tLoss: 0.230127\tAcc: 76.00\n",
      "train epoch: 107 [192128/221852 (87%)]\tLoss: 0.157489\tAcc: 80.00\n",
      "val epoch: 107 [128/221852 (0%)]\tLoss: 0.135903\tAcc: 81.00\n",
      "val epoch: 107 [12928/221852 (6%)]\tLoss: 0.206959\tAcc: 79.00\n",
      "train epoch: 108 [128/221852 (0%)]\tLoss: 0.206961\tAcc: 75.00\n",
      "train epoch: 108 [12928/221852 (6%)]\tLoss: 0.154753\tAcc: 82.00\n",
      "train epoch: 108 [25728/221852 (12%)]\tLoss: 0.143161\tAcc: 84.00\n",
      "train epoch: 108 [38528/221852 (17%)]\tLoss: 0.130925\tAcc: 82.00\n",
      "train epoch: 108 [51328/221852 (23%)]\tLoss: 0.111380\tAcc: 84.00\n",
      "train epoch: 108 [64128/221852 (29%)]\tLoss: 0.205271\tAcc: 75.00\n",
      "train epoch: 108 [76928/221852 (35%)]\tLoss: 0.174487\tAcc: 81.00\n",
      "train epoch: 108 [89728/221852 (40%)]\tLoss: 0.172565\tAcc: 78.00\n",
      "train epoch: 108 [102528/221852 (46%)]\tLoss: 0.155877\tAcc: 85.00\n",
      "train epoch: 108 [115328/221852 (52%)]\tLoss: 0.175839\tAcc: 76.00\n",
      "train epoch: 108 [128128/221852 (58%)]\tLoss: 0.163227\tAcc: 77.00\n",
      "train epoch: 108 [140928/221852 (64%)]\tLoss: 0.118990\tAcc: 77.00\n",
      "train epoch: 108 [153728/221852 (69%)]\tLoss: 0.167615\tAcc: 83.00\n",
      "train epoch: 108 [166528/221852 (75%)]\tLoss: 0.223346\tAcc: 74.00\n",
      "train epoch: 108 [179328/221852 (81%)]\tLoss: 0.198906\tAcc: 79.00\n",
      "train epoch: 108 [192128/221852 (87%)]\tLoss: 0.118552\tAcc: 81.00\n",
      "val epoch: 108 [128/221852 (0%)]\tLoss: 0.214156\tAcc: 75.00\n",
      "val epoch: 108 [12928/221852 (6%)]\tLoss: 0.173010\tAcc: 80.00\n",
      "train epoch: 109 [128/221852 (0%)]\tLoss: 0.178675\tAcc: 84.00\n",
      "train epoch: 109 [12928/221852 (6%)]\tLoss: 0.257890\tAcc: 77.00\n",
      "train epoch: 109 [25728/221852 (12%)]\tLoss: 0.169678\tAcc: 88.00\n",
      "train epoch: 109 [38528/221852 (17%)]\tLoss: 0.241427\tAcc: 80.00\n",
      "train epoch: 109 [51328/221852 (23%)]\tLoss: 0.166476\tAcc: 80.00\n",
      "train epoch: 109 [64128/221852 (29%)]\tLoss: 0.212147\tAcc: 80.00\n",
      "train epoch: 109 [76928/221852 (35%)]\tLoss: 0.137155\tAcc: 80.00\n",
      "train epoch: 109 [89728/221852 (40%)]\tLoss: 0.181829\tAcc: 80.00\n",
      "train epoch: 109 [102528/221852 (46%)]\tLoss: 0.173051\tAcc: 81.00\n",
      "train epoch: 109 [115328/221852 (52%)]\tLoss: 0.192700\tAcc: 81.00\n",
      "train epoch: 109 [128128/221852 (58%)]\tLoss: 0.181638\tAcc: 84.00\n",
      "train epoch: 109 [140928/221852 (64%)]\tLoss: 0.165868\tAcc: 76.00\n",
      "train epoch: 109 [153728/221852 (69%)]\tLoss: 0.185485\tAcc: 80.00\n",
      "train epoch: 109 [166528/221852 (75%)]\tLoss: 0.219556\tAcc: 81.00\n",
      "train epoch: 109 [179328/221852 (81%)]\tLoss: 0.187392\tAcc: 83.00\n",
      "train epoch: 109 [192128/221852 (87%)]\tLoss: 0.168498\tAcc: 79.00\n",
      "val epoch: 109 [128/221852 (0%)]\tLoss: 0.253869\tAcc: 79.00\n",
      "val epoch: 109 [12928/221852 (6%)]\tLoss: 0.269907\tAcc: 76.00\n",
      "train epoch: 110 [128/221852 (0%)]\tLoss: 0.194720\tAcc: 75.00\n",
      "train epoch: 110 [12928/221852 (6%)]\tLoss: 0.197456\tAcc: 83.00\n",
      "train epoch: 110 [25728/221852 (12%)]\tLoss: 0.154783\tAcc: 77.00\n",
      "train epoch: 110 [38528/221852 (17%)]\tLoss: 0.152679\tAcc: 73.00\n",
      "train epoch: 110 [51328/221852 (23%)]\tLoss: 0.195566\tAcc: 77.00\n",
      "train epoch: 110 [64128/221852 (29%)]\tLoss: 0.176343\tAcc: 79.00\n",
      "train epoch: 110 [76928/221852 (35%)]\tLoss: 0.275081\tAcc: 80.00\n",
      "train epoch: 110 [89728/221852 (40%)]\tLoss: 0.199580\tAcc: 77.00\n",
      "train epoch: 110 [102528/221852 (46%)]\tLoss: 0.126003\tAcc: 84.00\n",
      "train epoch: 110 [115328/221852 (52%)]\tLoss: 0.167940\tAcc: 84.00\n",
      "train epoch: 110 [128128/221852 (58%)]\tLoss: 0.261974\tAcc: 77.00\n",
      "train epoch: 110 [140928/221852 (64%)]\tLoss: 0.198013\tAcc: 80.00\n",
      "train epoch: 110 [153728/221852 (69%)]\tLoss: 0.191320\tAcc: 83.00\n",
      "train epoch: 110 [166528/221852 (75%)]\tLoss: 0.204760\tAcc: 77.00\n",
      "train epoch: 110 [179328/221852 (81%)]\tLoss: 0.174738\tAcc: 84.00\n",
      "train epoch: 110 [192128/221852 (87%)]\tLoss: 0.196872\tAcc: 78.00\n",
      "val epoch: 110 [128/221852 (0%)]\tLoss: 0.121686\tAcc: 91.00\n",
      "val epoch: 110 [12928/221852 (6%)]\tLoss: 0.152571\tAcc: 80.00\n",
      "train epoch: 111 [128/221852 (0%)]\tLoss: 0.215343\tAcc: 77.00\n",
      "train epoch: 111 [12928/221852 (6%)]\tLoss: 0.118083\tAcc: 83.00\n",
      "train epoch: 111 [25728/221852 (12%)]\tLoss: 0.161409\tAcc: 80.00\n",
      "train epoch: 111 [38528/221852 (17%)]\tLoss: 0.163454\tAcc: 82.00\n",
      "train epoch: 111 [51328/221852 (23%)]\tLoss: 0.147663\tAcc: 79.00\n",
      "train epoch: 111 [64128/221852 (29%)]\tLoss: 0.223835\tAcc: 80.00\n",
      "train epoch: 111 [76928/221852 (35%)]\tLoss: 0.149893\tAcc: 89.00\n",
      "train epoch: 111 [89728/221852 (40%)]\tLoss: 0.269054\tAcc: 83.00\n",
      "train epoch: 111 [102528/221852 (46%)]\tLoss: 0.164317\tAcc: 85.00\n",
      "train epoch: 111 [115328/221852 (52%)]\tLoss: 0.160131\tAcc: 83.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 111 [128128/221852 (58%)]\tLoss: 0.212811\tAcc: 85.00\n",
      "train epoch: 111 [140928/221852 (64%)]\tLoss: 0.135193\tAcc: 79.00\n",
      "train epoch: 111 [153728/221852 (69%)]\tLoss: 0.186038\tAcc: 77.00\n",
      "train epoch: 111 [166528/221852 (75%)]\tLoss: 0.185582\tAcc: 84.00\n",
      "train epoch: 111 [179328/221852 (81%)]\tLoss: 0.201986\tAcc: 81.00\n",
      "train epoch: 111 [192128/221852 (87%)]\tLoss: 0.178419\tAcc: 82.00\n",
      "val epoch: 111 [128/221852 (0%)]\tLoss: 0.293297\tAcc: 73.00\n",
      "val epoch: 111 [12928/221852 (6%)]\tLoss: 0.211155\tAcc: 77.00\n",
      "train epoch: 112 [128/221852 (0%)]\tLoss: 0.237248\tAcc: 80.00\n",
      "train epoch: 112 [12928/221852 (6%)]\tLoss: 0.198766\tAcc: 80.00\n",
      "train epoch: 112 [25728/221852 (12%)]\tLoss: 0.273033\tAcc: 79.00\n",
      "train epoch: 112 [38528/221852 (17%)]\tLoss: 0.217711\tAcc: 75.00\n",
      "train epoch: 112 [51328/221852 (23%)]\tLoss: 0.195999\tAcc: 75.00\n",
      "train epoch: 112 [64128/221852 (29%)]\tLoss: 0.133720\tAcc: 84.00\n",
      "train epoch: 112 [76928/221852 (35%)]\tLoss: 0.156141\tAcc: 81.00\n",
      "train epoch: 112 [89728/221852 (40%)]\tLoss: 0.197262\tAcc: 84.00\n",
      "train epoch: 112 [102528/221852 (46%)]\tLoss: 0.126432\tAcc: 83.00\n",
      "train epoch: 112 [115328/221852 (52%)]\tLoss: 0.206350\tAcc: 84.00\n",
      "train epoch: 112 [128128/221852 (58%)]\tLoss: 0.145195\tAcc: 88.00\n",
      "train epoch: 112 [140928/221852 (64%)]\tLoss: 0.238891\tAcc: 74.00\n",
      "train epoch: 112 [153728/221852 (69%)]\tLoss: 0.151202\tAcc: 81.00\n",
      "train epoch: 112 [166528/221852 (75%)]\tLoss: 0.160534\tAcc: 75.00\n",
      "train epoch: 112 [179328/221852 (81%)]\tLoss: 0.176029\tAcc: 79.00\n",
      "train epoch: 112 [192128/221852 (87%)]\tLoss: 0.191325\tAcc: 74.00\n",
      "val epoch: 112 [128/221852 (0%)]\tLoss: 0.136523\tAcc: 80.00\n",
      "val epoch: 112 [12928/221852 (6%)]\tLoss: 0.216065\tAcc: 77.00\n",
      "train epoch: 113 [128/221852 (0%)]\tLoss: 0.168640\tAcc: 83.00\n",
      "train epoch: 113 [12928/221852 (6%)]\tLoss: 0.160921\tAcc: 82.00\n",
      "train epoch: 113 [25728/221852 (12%)]\tLoss: 0.229196\tAcc: 81.00\n",
      "train epoch: 113 [38528/221852 (17%)]\tLoss: 0.184544\tAcc: 77.00\n",
      "train epoch: 113 [51328/221852 (23%)]\tLoss: 0.172847\tAcc: 84.00\n",
      "train epoch: 113 [64128/221852 (29%)]\tLoss: 0.145420\tAcc: 78.00\n",
      "train epoch: 113 [76928/221852 (35%)]\tLoss: 0.248630\tAcc: 77.00\n",
      "train epoch: 113 [89728/221852 (40%)]\tLoss: 0.258851\tAcc: 76.00\n",
      "train epoch: 113 [102528/221852 (46%)]\tLoss: 0.119811\tAcc: 84.00\n",
      "train epoch: 113 [115328/221852 (52%)]\tLoss: 0.189253\tAcc: 81.00\n",
      "train epoch: 113 [128128/221852 (58%)]\tLoss: 0.263589\tAcc: 73.00\n",
      "train epoch: 113 [140928/221852 (64%)]\tLoss: 0.173418\tAcc: 73.00\n",
      "train epoch: 113 [153728/221852 (69%)]\tLoss: 0.206152\tAcc: 81.00\n",
      "train epoch: 113 [166528/221852 (75%)]\tLoss: 0.277116\tAcc: 73.00\n",
      "train epoch: 113 [179328/221852 (81%)]\tLoss: 0.165802\tAcc: 84.00\n",
      "train epoch: 113 [192128/221852 (87%)]\tLoss: 0.177065\tAcc: 81.00\n",
      "val epoch: 113 [128/221852 (0%)]\tLoss: 0.287948\tAcc: 73.00\n",
      "val epoch: 113 [12928/221852 (6%)]\tLoss: 0.232232\tAcc: 80.00\n",
      "train epoch: 114 [128/221852 (0%)]\tLoss: 0.158176\tAcc: 87.00\n",
      "train epoch: 114 [12928/221852 (6%)]\tLoss: 0.175235\tAcc: 78.00\n",
      "train epoch: 114 [25728/221852 (12%)]\tLoss: 0.232380\tAcc: 79.00\n",
      "train epoch: 114 [38528/221852 (17%)]\tLoss: 0.200456\tAcc: 80.00\n",
      "train epoch: 114 [51328/221852 (23%)]\tLoss: 0.191263\tAcc: 81.00\n",
      "train epoch: 114 [64128/221852 (29%)]\tLoss: 0.178691\tAcc: 80.00\n",
      "train epoch: 114 [76928/221852 (35%)]\tLoss: 0.214001\tAcc: 83.00\n",
      "train epoch: 114 [89728/221852 (40%)]\tLoss: 0.126195\tAcc: 83.00\n",
      "train epoch: 114 [102528/221852 (46%)]\tLoss: 0.195805\tAcc: 80.00\n",
      "train epoch: 114 [115328/221852 (52%)]\tLoss: 0.221680\tAcc: 77.00\n",
      "train epoch: 114 [128128/221852 (58%)]\tLoss: 0.182736\tAcc: 82.00\n",
      "train epoch: 114 [140928/221852 (64%)]\tLoss: 0.252433\tAcc: 73.00\n",
      "train epoch: 114 [153728/221852 (69%)]\tLoss: 0.175690\tAcc: 76.00\n",
      "train epoch: 114 [166528/221852 (75%)]\tLoss: 0.140596\tAcc: 81.00\n",
      "train epoch: 114 [179328/221852 (81%)]\tLoss: 0.283626\tAcc: 79.00\n",
      "train epoch: 114 [192128/221852 (87%)]\tLoss: 0.248102\tAcc: 83.00\n",
      "val epoch: 114 [128/221852 (0%)]\tLoss: 0.244233\tAcc: 79.00\n",
      "val epoch: 114 [12928/221852 (6%)]\tLoss: 0.192935\tAcc: 75.00\n",
      "train epoch: 115 [128/221852 (0%)]\tLoss: 0.217056\tAcc: 71.00\n",
      "train epoch: 115 [12928/221852 (6%)]\tLoss: 0.163191\tAcc: 84.00\n",
      "train epoch: 115 [25728/221852 (12%)]\tLoss: 0.205399\tAcc: 84.00\n",
      "train epoch: 115 [38528/221852 (17%)]\tLoss: 0.200287\tAcc: 81.00\n",
      "train epoch: 115 [51328/221852 (23%)]\tLoss: 0.207424\tAcc: 83.00\n",
      "train epoch: 115 [64128/221852 (29%)]\tLoss: 0.137586\tAcc: 80.00\n",
      "train epoch: 115 [76928/221852 (35%)]\tLoss: 0.268284\tAcc: 73.00\n",
      "train epoch: 115 [89728/221852 (40%)]\tLoss: 0.178046\tAcc: 77.00\n",
      "train epoch: 115 [102528/221852 (46%)]\tLoss: 0.116246\tAcc: 84.00\n",
      "train epoch: 115 [115328/221852 (52%)]\tLoss: 0.135141\tAcc: 84.00\n",
      "train epoch: 115 [128128/221852 (58%)]\tLoss: 0.168473\tAcc: 77.00\n",
      "train epoch: 115 [140928/221852 (64%)]\tLoss: 0.170102\tAcc: 78.00\n",
      "train epoch: 115 [153728/221852 (69%)]\tLoss: 0.239360\tAcc: 83.00\n",
      "train epoch: 115 [166528/221852 (75%)]\tLoss: 0.137868\tAcc: 81.00\n",
      "train epoch: 115 [179328/221852 (81%)]\tLoss: 0.182204\tAcc: 77.00\n",
      "train epoch: 115 [192128/221852 (87%)]\tLoss: 0.166580\tAcc: 78.00\n",
      "val epoch: 115 [128/221852 (0%)]\tLoss: 0.155873\tAcc: 88.00\n",
      "val epoch: 115 [12928/221852 (6%)]\tLoss: 0.175335\tAcc: 79.00\n",
      "train epoch: 116 [128/221852 (0%)]\tLoss: 0.161500\tAcc: 77.00\n",
      "train epoch: 116 [12928/221852 (6%)]\tLoss: 0.148545\tAcc: 82.00\n",
      "train epoch: 116 [25728/221852 (12%)]\tLoss: 0.175580\tAcc: 76.00\n",
      "train epoch: 116 [38528/221852 (17%)]\tLoss: 0.246834\tAcc: 76.00\n",
      "train epoch: 116 [51328/221852 (23%)]\tLoss: 0.190840\tAcc: 81.00\n",
      "train epoch: 116 [64128/221852 (29%)]\tLoss: 0.119430\tAcc: 82.00\n",
      "train epoch: 116 [76928/221852 (35%)]\tLoss: 0.173563\tAcc: 88.00\n",
      "train epoch: 116 [89728/221852 (40%)]\tLoss: 0.340308\tAcc: 80.00\n",
      "train epoch: 116 [102528/221852 (46%)]\tLoss: 0.180584\tAcc: 77.00\n",
      "train epoch: 116 [115328/221852 (52%)]\tLoss: 0.146341\tAcc: 80.00\n",
      "train epoch: 116 [128128/221852 (58%)]\tLoss: 0.172678\tAcc: 83.00\n",
      "train epoch: 116 [140928/221852 (64%)]\tLoss: 0.234738\tAcc: 81.00\n",
      "train epoch: 116 [153728/221852 (69%)]\tLoss: 0.143644\tAcc: 80.00\n",
      "train epoch: 116 [166528/221852 (75%)]\tLoss: 0.230874\tAcc: 81.00\n",
      "train epoch: 116 [179328/221852 (81%)]\tLoss: 0.186098\tAcc: 76.00\n",
      "train epoch: 116 [192128/221852 (87%)]\tLoss: 0.167503\tAcc: 80.00\n",
      "val epoch: 116 [128/221852 (0%)]\tLoss: 0.161239\tAcc: 78.00\n",
      "val epoch: 116 [12928/221852 (6%)]\tLoss: 0.180032\tAcc: 90.00\n",
      "train epoch: 117 [128/221852 (0%)]\tLoss: 0.166164\tAcc: 77.00\n",
      "train epoch: 117 [12928/221852 (6%)]\tLoss: 0.117221\tAcc: 79.00\n",
      "train epoch: 117 [25728/221852 (12%)]\tLoss: 0.152532\tAcc: 84.00\n",
      "train epoch: 117 [38528/221852 (17%)]\tLoss: 0.155961\tAcc: 78.00\n",
      "train epoch: 117 [51328/221852 (23%)]\tLoss: 0.155795\tAcc: 77.00\n",
      "train epoch: 117 [64128/221852 (29%)]\tLoss: 0.215435\tAcc: 77.00\n",
      "train epoch: 117 [76928/221852 (35%)]\tLoss: 0.214778\tAcc: 80.00\n",
      "train epoch: 117 [89728/221852 (40%)]\tLoss: 0.214979\tAcc: 73.00\n",
      "train epoch: 117 [102528/221852 (46%)]\tLoss: 0.172400\tAcc: 83.00\n",
      "train epoch: 117 [115328/221852 (52%)]\tLoss: 0.201217\tAcc: 75.00\n",
      "train epoch: 117 [128128/221852 (58%)]\tLoss: 0.172179\tAcc: 84.00\n",
      "train epoch: 117 [140928/221852 (64%)]\tLoss: 0.218178\tAcc: 76.00\n",
      "train epoch: 117 [153728/221852 (69%)]\tLoss: 0.224164\tAcc: 73.00\n",
      "train epoch: 117 [166528/221852 (75%)]\tLoss: 0.267093\tAcc: 83.00\n",
      "train epoch: 117 [179328/221852 (81%)]\tLoss: 0.238755\tAcc: 69.00\n",
      "train epoch: 117 [192128/221852 (87%)]\tLoss: 0.169644\tAcc: 80.00\n",
      "val epoch: 117 [128/221852 (0%)]\tLoss: 0.171182\tAcc: 84.00\n",
      "val epoch: 117 [12928/221852 (6%)]\tLoss: 0.153737\tAcc: 86.00\n",
      "train epoch: 118 [128/221852 (0%)]\tLoss: 0.128813\tAcc: 86.00\n",
      "train epoch: 118 [12928/221852 (6%)]\tLoss: 0.201036\tAcc: 75.00\n",
      "train epoch: 118 [25728/221852 (12%)]\tLoss: 0.150451\tAcc: 79.00\n",
      "train epoch: 118 [38528/221852 (17%)]\tLoss: 0.127458\tAcc: 76.00\n",
      "train epoch: 118 [51328/221852 (23%)]\tLoss: 0.167712\tAcc: 79.00\n",
      "train epoch: 118 [64128/221852 (29%)]\tLoss: 0.213784\tAcc: 80.00\n",
      "train epoch: 118 [76928/221852 (35%)]\tLoss: 0.189128\tAcc: 80.00\n",
      "train epoch: 118 [89728/221852 (40%)]\tLoss: 0.203785\tAcc: 77.00\n",
      "train epoch: 118 [102528/221852 (46%)]\tLoss: 0.208379\tAcc: 78.00\n",
      "train epoch: 118 [115328/221852 (52%)]\tLoss: 0.275312\tAcc: 77.00\n",
      "train epoch: 118 [128128/221852 (58%)]\tLoss: 0.162237\tAcc: 87.00\n",
      "train epoch: 118 [140928/221852 (64%)]\tLoss: 0.165238\tAcc: 80.00\n",
      "train epoch: 118 [153728/221852 (69%)]\tLoss: 0.118727\tAcc: 83.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 118 [166528/221852 (75%)]\tLoss: 0.210953\tAcc: 78.00\n",
      "train epoch: 118 [179328/221852 (81%)]\tLoss: 0.186748\tAcc: 77.00\n",
      "train epoch: 118 [192128/221852 (87%)]\tLoss: 0.224717\tAcc: 83.00\n",
      "val epoch: 118 [128/221852 (0%)]\tLoss: 0.237853\tAcc: 76.00\n",
      "val epoch: 118 [12928/221852 (6%)]\tLoss: 0.192497\tAcc: 81.00\n",
      "train epoch: 119 [128/221852 (0%)]\tLoss: 0.175084\tAcc: 83.00\n",
      "train epoch: 119 [12928/221852 (6%)]\tLoss: 0.119283\tAcc: 86.00\n",
      "train epoch: 119 [25728/221852 (12%)]\tLoss: 0.211432\tAcc: 76.00\n",
      "train epoch: 119 [38528/221852 (17%)]\tLoss: 0.260863\tAcc: 71.00\n",
      "train epoch: 119 [51328/221852 (23%)]\tLoss: 0.166389\tAcc: 79.00\n",
      "train epoch: 119 [64128/221852 (29%)]\tLoss: 0.149985\tAcc: 80.00\n",
      "train epoch: 119 [76928/221852 (35%)]\tLoss: 0.187077\tAcc: 80.00\n",
      "train epoch: 119 [89728/221852 (40%)]\tLoss: 0.241555\tAcc: 83.00\n",
      "train epoch: 119 [102528/221852 (46%)]\tLoss: 0.240726\tAcc: 82.00\n",
      "train epoch: 119 [115328/221852 (52%)]\tLoss: 0.193805\tAcc: 80.00\n",
      "train epoch: 119 [128128/221852 (58%)]\tLoss: 0.182236\tAcc: 87.00\n",
      "train epoch: 119 [140928/221852 (64%)]\tLoss: 0.190199\tAcc: 88.00\n",
      "train epoch: 119 [153728/221852 (69%)]\tLoss: 0.229356\tAcc: 82.00\n",
      "train epoch: 119 [166528/221852 (75%)]\tLoss: 0.158378\tAcc: 86.00\n",
      "train epoch: 119 [179328/221852 (81%)]\tLoss: 0.247183\tAcc: 73.00\n",
      "train epoch: 119 [192128/221852 (87%)]\tLoss: 0.167185\tAcc: 84.00\n",
      "val epoch: 119 [128/221852 (0%)]\tLoss: 0.261502\tAcc: 81.00\n",
      "val epoch: 119 [12928/221852 (6%)]\tLoss: 0.181070\tAcc: 77.00\n",
      "train epoch: 120 [128/221852 (0%)]\tLoss: 0.171442\tAcc: 86.00\n",
      "train epoch: 120 [12928/221852 (6%)]\tLoss: 0.124334\tAcc: 83.00\n",
      "train epoch: 120 [25728/221852 (12%)]\tLoss: 0.162057\tAcc: 82.00\n",
      "train epoch: 120 [38528/221852 (17%)]\tLoss: 0.254117\tAcc: 80.00\n",
      "train epoch: 120 [51328/221852 (23%)]\tLoss: 0.162918\tAcc: 74.00\n",
      "train epoch: 120 [64128/221852 (29%)]\tLoss: 0.115958\tAcc: 81.00\n",
      "train epoch: 120 [76928/221852 (35%)]\tLoss: 0.181797\tAcc: 78.00\n",
      "train epoch: 120 [89728/221852 (40%)]\tLoss: 0.303406\tAcc: 80.00\n",
      "train epoch: 120 [102528/221852 (46%)]\tLoss: 0.237783\tAcc: 77.00\n",
      "train epoch: 120 [115328/221852 (52%)]\tLoss: 0.182610\tAcc: 84.00\n",
      "train epoch: 120 [128128/221852 (58%)]\tLoss: 0.289213\tAcc: 80.00\n",
      "train epoch: 120 [140928/221852 (64%)]\tLoss: 0.154439\tAcc: 84.00\n",
      "train epoch: 120 [153728/221852 (69%)]\tLoss: 0.220266\tAcc: 80.00\n",
      "train epoch: 120 [166528/221852 (75%)]\tLoss: 0.148918\tAcc: 76.00\n",
      "train epoch: 120 [179328/221852 (81%)]\tLoss: 0.195362\tAcc: 86.00\n",
      "train epoch: 120 [192128/221852 (87%)]\tLoss: 0.111151\tAcc: 80.00\n",
      "val epoch: 120 [128/221852 (0%)]\tLoss: 0.208779\tAcc: 79.00\n",
      "val epoch: 120 [12928/221852 (6%)]\tLoss: 0.157787\tAcc: 79.00\n",
      "train epoch: 121 [128/221852 (0%)]\tLoss: 0.168057\tAcc: 85.00\n",
      "train epoch: 121 [12928/221852 (6%)]\tLoss: 0.113297\tAcc: 90.00\n",
      "train epoch: 121 [25728/221852 (12%)]\tLoss: 0.090049\tAcc: 78.00\n",
      "train epoch: 121 [38528/221852 (17%)]\tLoss: 0.135048\tAcc: 84.00\n",
      "train epoch: 121 [51328/221852 (23%)]\tLoss: 0.196004\tAcc: 80.00\n",
      "train epoch: 121 [64128/221852 (29%)]\tLoss: 0.161077\tAcc: 83.00\n",
      "train epoch: 121 [76928/221852 (35%)]\tLoss: 0.211388\tAcc: 81.00\n",
      "train epoch: 121 [89728/221852 (40%)]\tLoss: 0.143887\tAcc: 83.00\n",
      "train epoch: 121 [102528/221852 (46%)]\tLoss: 0.203449\tAcc: 83.00\n",
      "train epoch: 121 [115328/221852 (52%)]\tLoss: 0.220705\tAcc: 81.00\n",
      "train epoch: 121 [128128/221852 (58%)]\tLoss: 0.166401\tAcc: 81.00\n",
      "train epoch: 121 [140928/221852 (64%)]\tLoss: 0.162878\tAcc: 85.00\n",
      "train epoch: 121 [153728/221852 (69%)]\tLoss: 0.212102\tAcc: 77.00\n",
      "train epoch: 121 [166528/221852 (75%)]\tLoss: 0.256643\tAcc: 84.00\n",
      "train epoch: 121 [179328/221852 (81%)]\tLoss: 0.232712\tAcc: 77.00\n",
      "train epoch: 121 [192128/221852 (87%)]\tLoss: 0.222630\tAcc: 77.00\n",
      "val epoch: 121 [128/221852 (0%)]\tLoss: 0.241530\tAcc: 77.00\n",
      "val epoch: 121 [12928/221852 (6%)]\tLoss: 0.166121\tAcc: 80.00\n",
      "train epoch: 122 [128/221852 (0%)]\tLoss: 0.244125\tAcc: 77.00\n",
      "train epoch: 122 [12928/221852 (6%)]\tLoss: 0.259830\tAcc: 80.00\n",
      "train epoch: 122 [25728/221852 (12%)]\tLoss: 0.111628\tAcc: 74.00\n",
      "train epoch: 122 [38528/221852 (17%)]\tLoss: 0.194371\tAcc: 77.00\n",
      "train epoch: 122 [51328/221852 (23%)]\tLoss: 0.215601\tAcc: 83.00\n",
      "train epoch: 122 [64128/221852 (29%)]\tLoss: 0.192308\tAcc: 73.00\n",
      "train epoch: 122 [76928/221852 (35%)]\tLoss: 0.212882\tAcc: 75.00\n",
      "train epoch: 122 [89728/221852 (40%)]\tLoss: 0.293334\tAcc: 77.00\n",
      "train epoch: 122 [102528/221852 (46%)]\tLoss: 0.126925\tAcc: 79.00\n",
      "train epoch: 122 [115328/221852 (52%)]\tLoss: 0.081462\tAcc: 82.00\n",
      "train epoch: 122 [128128/221852 (58%)]\tLoss: 0.217890\tAcc: 77.00\n",
      "train epoch: 122 [140928/221852 (64%)]\tLoss: 0.147934\tAcc: 86.00\n",
      "train epoch: 122 [153728/221852 (69%)]\tLoss: 0.312641\tAcc: 75.00\n",
      "train epoch: 122 [166528/221852 (75%)]\tLoss: 0.244737\tAcc: 77.00\n",
      "train epoch: 122 [179328/221852 (81%)]\tLoss: 0.231881\tAcc: 76.00\n",
      "train epoch: 122 [192128/221852 (87%)]\tLoss: 0.157264\tAcc: 82.00\n",
      "val epoch: 122 [128/221852 (0%)]\tLoss: 0.216482\tAcc: 80.00\n",
      "val epoch: 122 [12928/221852 (6%)]\tLoss: 0.119813\tAcc: 86.00\n",
      "train epoch: 123 [128/221852 (0%)]\tLoss: 0.126573\tAcc: 79.00\n",
      "train epoch: 123 [12928/221852 (6%)]\tLoss: 0.215549\tAcc: 81.00\n",
      "train epoch: 123 [25728/221852 (12%)]\tLoss: 0.178841\tAcc: 82.00\n",
      "train epoch: 123 [38528/221852 (17%)]\tLoss: 0.194311\tAcc: 77.00\n",
      "train epoch: 123 [51328/221852 (23%)]\tLoss: 0.175246\tAcc: 85.00\n",
      "train epoch: 123 [64128/221852 (29%)]\tLoss: 0.241756\tAcc: 80.00\n",
      "train epoch: 123 [76928/221852 (35%)]\tLoss: 0.141501\tAcc: 84.00\n",
      "train epoch: 123 [89728/221852 (40%)]\tLoss: 0.164144\tAcc: 82.00\n",
      "train epoch: 123 [102528/221852 (46%)]\tLoss: 0.094737\tAcc: 86.00\n",
      "train epoch: 123 [115328/221852 (52%)]\tLoss: 0.124682\tAcc: 77.00\n",
      "train epoch: 123 [128128/221852 (58%)]\tLoss: 0.146359\tAcc: 85.00\n",
      "train epoch: 123 [140928/221852 (64%)]\tLoss: 0.153295\tAcc: 90.00\n",
      "train epoch: 123 [153728/221852 (69%)]\tLoss: 0.204446\tAcc: 80.00\n",
      "train epoch: 123 [166528/221852 (75%)]\tLoss: 0.165081\tAcc: 81.00\n",
      "train epoch: 123 [179328/221852 (81%)]\tLoss: 0.158921\tAcc: 82.00\n",
      "train epoch: 123 [192128/221852 (87%)]\tLoss: 0.109357\tAcc: 85.00\n",
      "val epoch: 123 [128/221852 (0%)]\tLoss: 0.205513\tAcc: 81.00\n",
      "val epoch: 123 [12928/221852 (6%)]\tLoss: 0.277970\tAcc: 75.00\n",
      "train epoch: 124 [128/221852 (0%)]\tLoss: 0.111633\tAcc: 87.00\n",
      "train epoch: 124 [12928/221852 (6%)]\tLoss: 0.262991\tAcc: 74.00\n",
      "train epoch: 124 [25728/221852 (12%)]\tLoss: 0.138972\tAcc: 85.00\n",
      "train epoch: 124 [38528/221852 (17%)]\tLoss: 0.150204\tAcc: 87.00\n",
      "train epoch: 124 [51328/221852 (23%)]\tLoss: 0.174578\tAcc: 80.00\n",
      "train epoch: 124 [64128/221852 (29%)]\tLoss: 0.171432\tAcc: 80.00\n",
      "train epoch: 124 [76928/221852 (35%)]\tLoss: 0.177609\tAcc: 80.00\n",
      "train epoch: 124 [89728/221852 (40%)]\tLoss: 0.177176\tAcc: 84.00\n",
      "train epoch: 124 [102528/221852 (46%)]\tLoss: 0.157506\tAcc: 77.00\n",
      "train epoch: 124 [115328/221852 (52%)]\tLoss: 0.281361\tAcc: 79.00\n",
      "train epoch: 124 [128128/221852 (58%)]\tLoss: 0.195478\tAcc: 84.00\n",
      "train epoch: 124 [140928/221852 (64%)]\tLoss: 0.260467\tAcc: 79.00\n",
      "train epoch: 124 [153728/221852 (69%)]\tLoss: 0.361356\tAcc: 80.00\n",
      "train epoch: 124 [166528/221852 (75%)]\tLoss: 0.204712\tAcc: 76.00\n",
      "train epoch: 124 [179328/221852 (81%)]\tLoss: 0.134350\tAcc: 75.00\n",
      "train epoch: 124 [192128/221852 (87%)]\tLoss: 0.163811\tAcc: 82.00\n",
      "val epoch: 124 [128/221852 (0%)]\tLoss: 0.178357\tAcc: 85.00\n",
      "val epoch: 124 [12928/221852 (6%)]\tLoss: 0.175784\tAcc: 83.00\n",
      "train epoch: 125 [128/221852 (0%)]\tLoss: 0.220831\tAcc: 84.00\n",
      "train epoch: 125 [12928/221852 (6%)]\tLoss: 0.169969\tAcc: 80.00\n",
      "train epoch: 125 [25728/221852 (12%)]\tLoss: 0.234899\tAcc: 77.00\n",
      "train epoch: 125 [38528/221852 (17%)]\tLoss: 0.198860\tAcc: 80.00\n",
      "train epoch: 125 [51328/221852 (23%)]\tLoss: 0.186594\tAcc: 83.00\n",
      "train epoch: 125 [64128/221852 (29%)]\tLoss: 0.162605\tAcc: 84.00\n",
      "train epoch: 125 [76928/221852 (35%)]\tLoss: 0.165631\tAcc: 77.00\n",
      "train epoch: 125 [89728/221852 (40%)]\tLoss: 0.205071\tAcc: 80.00\n",
      "train epoch: 125 [102528/221852 (46%)]\tLoss: 0.208840\tAcc: 77.00\n",
      "train epoch: 125 [115328/221852 (52%)]\tLoss: 0.162272\tAcc: 79.00\n",
      "train epoch: 125 [128128/221852 (58%)]\tLoss: 0.247958\tAcc: 84.00\n",
      "train epoch: 125 [140928/221852 (64%)]\tLoss: 0.170259\tAcc: 80.00\n",
      "train epoch: 125 [153728/221852 (69%)]\tLoss: 0.178457\tAcc: 85.00\n",
      "train epoch: 125 [166528/221852 (75%)]\tLoss: 0.192085\tAcc: 80.00\n",
      "train epoch: 125 [179328/221852 (81%)]\tLoss: 0.325570\tAcc: 78.00\n",
      "train epoch: 125 [192128/221852 (87%)]\tLoss: 0.242902\tAcc: 83.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 125 [128/221852 (0%)]\tLoss: 0.182633\tAcc: 77.00\n",
      "val epoch: 125 [12928/221852 (6%)]\tLoss: 0.132047\tAcc: 90.00\n",
      "train epoch: 126 [128/221852 (0%)]\tLoss: 0.265560\tAcc: 80.00\n",
      "train epoch: 126 [12928/221852 (6%)]\tLoss: 0.119698\tAcc: 83.00\n",
      "train epoch: 126 [25728/221852 (12%)]\tLoss: 0.202674\tAcc: 78.00\n",
      "train epoch: 126 [38528/221852 (17%)]\tLoss: 0.168686\tAcc: 79.00\n",
      "train epoch: 126 [51328/221852 (23%)]\tLoss: 0.210487\tAcc: 79.00\n",
      "train epoch: 126 [64128/221852 (29%)]\tLoss: 0.233092\tAcc: 79.00\n",
      "train epoch: 126 [76928/221852 (35%)]\tLoss: 0.232280\tAcc: 78.00\n",
      "train epoch: 126 [89728/221852 (40%)]\tLoss: 0.267678\tAcc: 77.00\n",
      "train epoch: 126 [102528/221852 (46%)]\tLoss: 0.151565\tAcc: 78.00\n",
      "train epoch: 126 [115328/221852 (52%)]\tLoss: 0.231883\tAcc: 78.00\n",
      "train epoch: 126 [128128/221852 (58%)]\tLoss: 0.191498\tAcc: 85.00\n",
      "train epoch: 126 [140928/221852 (64%)]\tLoss: 0.182596\tAcc: 81.00\n",
      "train epoch: 126 [153728/221852 (69%)]\tLoss: 0.212052\tAcc: 77.00\n",
      "train epoch: 126 [166528/221852 (75%)]\tLoss: 0.159183\tAcc: 84.00\n",
      "train epoch: 126 [179328/221852 (81%)]\tLoss: 0.247245\tAcc: 75.00\n",
      "train epoch: 126 [192128/221852 (87%)]\tLoss: 0.131661\tAcc: 86.00\n",
      "val epoch: 126 [128/221852 (0%)]\tLoss: 0.148953\tAcc: 84.00\n",
      "val epoch: 126 [12928/221852 (6%)]\tLoss: 0.165466\tAcc: 82.00\n",
      "train epoch: 127 [128/221852 (0%)]\tLoss: 0.157766\tAcc: 88.00\n",
      "train epoch: 127 [12928/221852 (6%)]\tLoss: 0.128823\tAcc: 88.00\n",
      "train epoch: 127 [25728/221852 (12%)]\tLoss: 0.116722\tAcc: 76.00\n",
      "train epoch: 127 [38528/221852 (17%)]\tLoss: 0.184523\tAcc: 83.00\n",
      "train epoch: 127 [51328/221852 (23%)]\tLoss: 0.199054\tAcc: 75.00\n",
      "train epoch: 127 [64128/221852 (29%)]\tLoss: 0.178452\tAcc: 74.00\n",
      "train epoch: 127 [76928/221852 (35%)]\tLoss: 0.137714\tAcc: 82.00\n",
      "train epoch: 127 [89728/221852 (40%)]\tLoss: 0.216808\tAcc: 83.00\n",
      "train epoch: 127 [102528/221852 (46%)]\tLoss: 0.133316\tAcc: 79.00\n",
      "train epoch: 127 [115328/221852 (52%)]\tLoss: 0.188345\tAcc: 77.00\n",
      "train epoch: 127 [128128/221852 (58%)]\tLoss: 0.208908\tAcc: 83.00\n",
      "train epoch: 127 [140928/221852 (64%)]\tLoss: 0.230434\tAcc: 80.00\n",
      "train epoch: 127 [153728/221852 (69%)]\tLoss: 0.249414\tAcc: 78.00\n",
      "train epoch: 127 [166528/221852 (75%)]\tLoss: 0.134288\tAcc: 82.00\n",
      "train epoch: 127 [179328/221852 (81%)]\tLoss: 0.196040\tAcc: 79.00\n",
      "train epoch: 127 [192128/221852 (87%)]\tLoss: 0.162214\tAcc: 78.00\n",
      "val epoch: 127 [128/221852 (0%)]\tLoss: 0.106770\tAcc: 78.00\n",
      "val epoch: 127 [12928/221852 (6%)]\tLoss: 0.228118\tAcc: 77.00\n",
      "train epoch: 128 [128/221852 (0%)]\tLoss: 0.124284\tAcc: 87.00\n",
      "train epoch: 128 [12928/221852 (6%)]\tLoss: 0.216014\tAcc: 79.00\n",
      "train epoch: 128 [25728/221852 (12%)]\tLoss: 0.237402\tAcc: 75.00\n",
      "train epoch: 128 [38528/221852 (17%)]\tLoss: 0.199344\tAcc: 80.00\n",
      "train epoch: 128 [51328/221852 (23%)]\tLoss: 0.235434\tAcc: 85.00\n",
      "train epoch: 128 [64128/221852 (29%)]\tLoss: 0.258845\tAcc: 80.00\n",
      "train epoch: 128 [76928/221852 (35%)]\tLoss: 0.243822\tAcc: 76.00\n",
      "train epoch: 128 [89728/221852 (40%)]\tLoss: 0.224807\tAcc: 76.00\n",
      "train epoch: 128 [102528/221852 (46%)]\tLoss: 0.203038\tAcc: 78.00\n",
      "train epoch: 128 [115328/221852 (52%)]\tLoss: 0.121111\tAcc: 78.00\n",
      "train epoch: 128 [128128/221852 (58%)]\tLoss: 0.226693\tAcc: 73.00\n",
      "train epoch: 128 [140928/221852 (64%)]\tLoss: 0.180059\tAcc: 80.00\n",
      "train epoch: 128 [153728/221852 (69%)]\tLoss: 0.264760\tAcc: 84.00\n",
      "train epoch: 128 [166528/221852 (75%)]\tLoss: 0.209842\tAcc: 80.00\n",
      "train epoch: 128 [179328/221852 (81%)]\tLoss: 0.154973\tAcc: 84.00\n",
      "train epoch: 128 [192128/221852 (87%)]\tLoss: 0.130792\tAcc: 86.00\n",
      "val epoch: 128 [128/221852 (0%)]\tLoss: 0.171447\tAcc: 80.00\n",
      "val epoch: 128 [12928/221852 (6%)]\tLoss: 0.227900\tAcc: 77.00\n",
      "train epoch: 129 [128/221852 (0%)]\tLoss: 0.209895\tAcc: 85.00\n",
      "train epoch: 129 [12928/221852 (6%)]\tLoss: 0.120527\tAcc: 88.00\n",
      "train epoch: 129 [25728/221852 (12%)]\tLoss: 0.266137\tAcc: 78.00\n",
      "train epoch: 129 [38528/221852 (17%)]\tLoss: 0.238157\tAcc: 80.00\n",
      "train epoch: 129 [51328/221852 (23%)]\tLoss: 0.153220\tAcc: 86.00\n",
      "train epoch: 129 [64128/221852 (29%)]\tLoss: 0.152449\tAcc: 78.00\n",
      "train epoch: 129 [76928/221852 (35%)]\tLoss: 0.235601\tAcc: 83.00\n",
      "train epoch: 129 [89728/221852 (40%)]\tLoss: 0.140930\tAcc: 80.00\n",
      "train epoch: 129 [102528/221852 (46%)]\tLoss: 0.133676\tAcc: 80.00\n",
      "train epoch: 129 [115328/221852 (52%)]\tLoss: 0.143424\tAcc: 83.00\n",
      "train epoch: 129 [128128/221852 (58%)]\tLoss: 0.145086\tAcc: 84.00\n",
      "train epoch: 129 [140928/221852 (64%)]\tLoss: 0.258114\tAcc: 71.00\n",
      "train epoch: 129 [153728/221852 (69%)]\tLoss: 0.284796\tAcc: 71.00\n",
      "train epoch: 129 [166528/221852 (75%)]\tLoss: 0.256236\tAcc: 79.00\n",
      "train epoch: 129 [179328/221852 (81%)]\tLoss: 0.232772\tAcc: 75.00\n",
      "train epoch: 129 [192128/221852 (87%)]\tLoss: 0.128525\tAcc: 87.00\n",
      "val epoch: 129 [128/221852 (0%)]\tLoss: 0.290148\tAcc: 79.00\n",
      "val epoch: 129 [12928/221852 (6%)]\tLoss: 0.180840\tAcc: 74.00\n",
      "train epoch: 130 [128/221852 (0%)]\tLoss: 0.188406\tAcc: 77.00\n",
      "train epoch: 130 [12928/221852 (6%)]\tLoss: 0.211147\tAcc: 83.00\n",
      "train epoch: 130 [25728/221852 (12%)]\tLoss: 0.173145\tAcc: 80.00\n",
      "train epoch: 130 [38528/221852 (17%)]\tLoss: 0.159443\tAcc: 78.00\n",
      "train epoch: 130 [51328/221852 (23%)]\tLoss: 0.158277\tAcc: 80.00\n",
      "train epoch: 130 [64128/221852 (29%)]\tLoss: 0.166061\tAcc: 84.00\n",
      "train epoch: 130 [76928/221852 (35%)]\tLoss: 0.183601\tAcc: 83.00\n",
      "train epoch: 130 [89728/221852 (40%)]\tLoss: 0.098646\tAcc: 89.00\n",
      "train epoch: 130 [102528/221852 (46%)]\tLoss: 0.150033\tAcc: 81.00\n",
      "train epoch: 130 [115328/221852 (52%)]\tLoss: 0.153967\tAcc: 83.00\n",
      "train epoch: 130 [128128/221852 (58%)]\tLoss: 0.156097\tAcc: 85.00\n",
      "train epoch: 130 [140928/221852 (64%)]\tLoss: 0.170335\tAcc: 84.00\n",
      "train epoch: 130 [153728/221852 (69%)]\tLoss: 0.185903\tAcc: 79.00\n",
      "train epoch: 130 [166528/221852 (75%)]\tLoss: 0.183921\tAcc: 80.00\n",
      "train epoch: 130 [179328/221852 (81%)]\tLoss: 0.295420\tAcc: 78.00\n",
      "train epoch: 130 [192128/221852 (87%)]\tLoss: 0.184964\tAcc: 82.00\n",
      "val epoch: 130 [128/221852 (0%)]\tLoss: 0.128878\tAcc: 78.00\n",
      "val epoch: 130 [12928/221852 (6%)]\tLoss: 0.189405\tAcc: 80.00\n",
      "train epoch: 131 [128/221852 (0%)]\tLoss: 0.218904\tAcc: 85.00\n",
      "train epoch: 131 [12928/221852 (6%)]\tLoss: 0.271514\tAcc: 76.00\n",
      "train epoch: 131 [25728/221852 (12%)]\tLoss: 0.197051\tAcc: 82.00\n",
      "train epoch: 131 [38528/221852 (17%)]\tLoss: 0.167538\tAcc: 84.00\n",
      "train epoch: 131 [51328/221852 (23%)]\tLoss: 0.172399\tAcc: 83.00\n",
      "train epoch: 131 [64128/221852 (29%)]\tLoss: 0.219626\tAcc: 75.00\n",
      "train epoch: 131 [76928/221852 (35%)]\tLoss: 0.168786\tAcc: 85.00\n",
      "train epoch: 131 [89728/221852 (40%)]\tLoss: 0.233637\tAcc: 75.00\n",
      "train epoch: 131 [102528/221852 (46%)]\tLoss: 0.125656\tAcc: 84.00\n",
      "train epoch: 131 [115328/221852 (52%)]\tLoss: 0.227573\tAcc: 76.00\n",
      "train epoch: 131 [128128/221852 (58%)]\tLoss: 0.168805\tAcc: 80.00\n",
      "train epoch: 131 [140928/221852 (64%)]\tLoss: 0.152136\tAcc: 85.00\n",
      "train epoch: 131 [153728/221852 (69%)]\tLoss: 0.154814\tAcc: 86.00\n",
      "train epoch: 131 [166528/221852 (75%)]\tLoss: 0.152746\tAcc: 80.00\n",
      "train epoch: 131 [179328/221852 (81%)]\tLoss: 0.269997\tAcc: 82.00\n",
      "train epoch: 131 [192128/221852 (87%)]\tLoss: 0.258076\tAcc: 77.00\n",
      "val epoch: 131 [128/221852 (0%)]\tLoss: 0.161927\tAcc: 84.00\n",
      "val epoch: 131 [12928/221852 (6%)]\tLoss: 0.174861\tAcc: 76.00\n",
      "train epoch: 132 [128/221852 (0%)]\tLoss: 0.199391\tAcc: 84.00\n",
      "train epoch: 132 [12928/221852 (6%)]\tLoss: 0.160047\tAcc: 78.00\n",
      "train epoch: 132 [25728/221852 (12%)]\tLoss: 0.225127\tAcc: 77.00\n",
      "train epoch: 132 [38528/221852 (17%)]\tLoss: 0.210631\tAcc: 80.00\n",
      "train epoch: 132 [51328/221852 (23%)]\tLoss: 0.129497\tAcc: 88.00\n",
      "train epoch: 132 [64128/221852 (29%)]\tLoss: 0.144554\tAcc: 81.00\n",
      "train epoch: 132 [76928/221852 (35%)]\tLoss: 0.211103\tAcc: 78.00\n",
      "train epoch: 132 [89728/221852 (40%)]\tLoss: 0.226026\tAcc: 81.00\n",
      "train epoch: 132 [102528/221852 (46%)]\tLoss: 0.270595\tAcc: 82.00\n",
      "train epoch: 132 [115328/221852 (52%)]\tLoss: 0.248234\tAcc: 77.00\n",
      "train epoch: 132 [128128/221852 (58%)]\tLoss: 0.205054\tAcc: 77.00\n",
      "train epoch: 132 [140928/221852 (64%)]\tLoss: 0.151474\tAcc: 82.00\n",
      "train epoch: 132 [153728/221852 (69%)]\tLoss: 0.126878\tAcc: 82.00\n",
      "train epoch: 132 [166528/221852 (75%)]\tLoss: 0.290199\tAcc: 81.00\n",
      "train epoch: 132 [179328/221852 (81%)]\tLoss: 0.155404\tAcc: 83.00\n",
      "train epoch: 132 [192128/221852 (87%)]\tLoss: 0.174839\tAcc: 84.00\n",
      "val epoch: 132 [128/221852 (0%)]\tLoss: 0.147519\tAcc: 79.00\n",
      "val epoch: 132 [12928/221852 (6%)]\tLoss: 0.157005\tAcc: 81.00\n",
      "train epoch: 133 [128/221852 (0%)]\tLoss: 0.174304\tAcc: 80.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 133 [12928/221852 (6%)]\tLoss: 0.163273\tAcc: 83.00\n",
      "train epoch: 133 [25728/221852 (12%)]\tLoss: 0.182643\tAcc: 81.00\n",
      "train epoch: 133 [38528/221852 (17%)]\tLoss: 0.160901\tAcc: 84.00\n",
      "train epoch: 133 [51328/221852 (23%)]\tLoss: 0.202833\tAcc: 77.00\n",
      "train epoch: 133 [64128/221852 (29%)]\tLoss: 0.161661\tAcc: 82.00\n",
      "train epoch: 133 [76928/221852 (35%)]\tLoss: 0.129087\tAcc: 84.00\n",
      "train epoch: 133 [89728/221852 (40%)]\tLoss: 0.146834\tAcc: 85.00\n",
      "train epoch: 133 [102528/221852 (46%)]\tLoss: 0.099366\tAcc: 89.00\n",
      "train epoch: 133 [115328/221852 (52%)]\tLoss: 0.180168\tAcc: 81.00\n",
      "train epoch: 133 [128128/221852 (58%)]\tLoss: 0.188800\tAcc: 74.00\n",
      "train epoch: 133 [140928/221852 (64%)]\tLoss: 0.334368\tAcc: 70.00\n",
      "train epoch: 133 [153728/221852 (69%)]\tLoss: 0.211283\tAcc: 80.00\n",
      "train epoch: 133 [166528/221852 (75%)]\tLoss: 0.232790\tAcc: 81.00\n",
      "train epoch: 133 [179328/221852 (81%)]\tLoss: 0.306194\tAcc: 78.00\n",
      "train epoch: 133 [192128/221852 (87%)]\tLoss: 0.114481\tAcc: 87.00\n",
      "val epoch: 133 [128/221852 (0%)]\tLoss: 0.237570\tAcc: 76.00\n",
      "val epoch: 133 [12928/221852 (6%)]\tLoss: 0.218607\tAcc: 80.00\n",
      "train epoch: 134 [128/221852 (0%)]\tLoss: 0.183421\tAcc: 82.00\n",
      "train epoch: 134 [12928/221852 (6%)]\tLoss: 0.215758\tAcc: 80.00\n",
      "train epoch: 134 [25728/221852 (12%)]\tLoss: 0.162969\tAcc: 84.00\n",
      "train epoch: 134 [38528/221852 (17%)]\tLoss: 0.171597\tAcc: 81.00\n",
      "train epoch: 134 [51328/221852 (23%)]\tLoss: 0.220425\tAcc: 82.00\n",
      "train epoch: 134 [64128/221852 (29%)]\tLoss: 0.120178\tAcc: 90.00\n",
      "train epoch: 134 [76928/221852 (35%)]\tLoss: 0.203655\tAcc: 80.00\n",
      "train epoch: 134 [89728/221852 (40%)]\tLoss: 0.535227\tAcc: 77.00\n",
      "train epoch: 134 [102528/221852 (46%)]\tLoss: 0.202295\tAcc: 84.00\n",
      "train epoch: 134 [115328/221852 (52%)]\tLoss: 0.248533\tAcc: 80.00\n",
      "train epoch: 134 [128128/221852 (58%)]\tLoss: 0.200223\tAcc: 83.00\n",
      "train epoch: 134 [140928/221852 (64%)]\tLoss: 0.222754\tAcc: 77.00\n",
      "train epoch: 134 [153728/221852 (69%)]\tLoss: 0.166288\tAcc: 78.00\n",
      "train epoch: 134 [166528/221852 (75%)]\tLoss: 0.149204\tAcc: 83.00\n",
      "train epoch: 134 [179328/221852 (81%)]\tLoss: 0.225819\tAcc: 78.00\n",
      "train epoch: 134 [192128/221852 (87%)]\tLoss: 0.159631\tAcc: 77.00\n",
      "val epoch: 134 [128/221852 (0%)]\tLoss: 0.150084\tAcc: 84.00\n",
      "val epoch: 134 [12928/221852 (6%)]\tLoss: 0.185523\tAcc: 80.00\n",
      "train epoch: 135 [128/221852 (0%)]\tLoss: 0.128333\tAcc: 77.00\n",
      "train epoch: 135 [12928/221852 (6%)]\tLoss: 0.199421\tAcc: 83.00\n",
      "train epoch: 135 [25728/221852 (12%)]\tLoss: 0.160020\tAcc: 79.00\n",
      "train epoch: 135 [38528/221852 (17%)]\tLoss: 0.281501\tAcc: 78.00\n",
      "train epoch: 135 [51328/221852 (23%)]\tLoss: 0.130274\tAcc: 91.00\n",
      "train epoch: 135 [64128/221852 (29%)]\tLoss: 0.119545\tAcc: 88.00\n",
      "train epoch: 135 [76928/221852 (35%)]\tLoss: 0.330370\tAcc: 73.00\n",
      "train epoch: 135 [89728/221852 (40%)]\tLoss: 0.118299\tAcc: 82.00\n",
      "train epoch: 135 [102528/221852 (46%)]\tLoss: 0.094924\tAcc: 85.00\n",
      "train epoch: 135 [115328/221852 (52%)]\tLoss: 0.179850\tAcc: 80.00\n",
      "train epoch: 135 [128128/221852 (58%)]\tLoss: 0.207572\tAcc: 83.00\n",
      "train epoch: 135 [140928/221852 (64%)]\tLoss: 0.130576\tAcc: 85.00\n",
      "train epoch: 135 [153728/221852 (69%)]\tLoss: 0.165439\tAcc: 81.00\n",
      "train epoch: 135 [166528/221852 (75%)]\tLoss: 0.132510\tAcc: 82.00\n",
      "train epoch: 135 [179328/221852 (81%)]\tLoss: 0.187820\tAcc: 82.00\n",
      "train epoch: 135 [192128/221852 (87%)]\tLoss: 0.155189\tAcc: 79.00\n",
      "val epoch: 135 [128/221852 (0%)]\tLoss: 0.204533\tAcc: 80.00\n",
      "val epoch: 135 [12928/221852 (6%)]\tLoss: 0.226506\tAcc: 80.00\n",
      "train epoch: 136 [128/221852 (0%)]\tLoss: 0.177095\tAcc: 80.00\n",
      "train epoch: 136 [12928/221852 (6%)]\tLoss: 0.085444\tAcc: 90.00\n",
      "train epoch: 136 [25728/221852 (12%)]\tLoss: 0.167238\tAcc: 80.00\n",
      "train epoch: 136 [38528/221852 (17%)]\tLoss: 0.232962\tAcc: 75.00\n",
      "train epoch: 136 [51328/221852 (23%)]\tLoss: 0.185271\tAcc: 77.00\n",
      "train epoch: 136 [64128/221852 (29%)]\tLoss: 0.174428\tAcc: 78.00\n",
      "train epoch: 136 [76928/221852 (35%)]\tLoss: 0.176881\tAcc: 80.00\n",
      "train epoch: 136 [89728/221852 (40%)]\tLoss: 0.174761\tAcc: 85.00\n",
      "train epoch: 136 [102528/221852 (46%)]\tLoss: 0.127553\tAcc: 84.00\n",
      "train epoch: 136 [115328/221852 (52%)]\tLoss: 0.173777\tAcc: 82.00\n",
      "train epoch: 136 [128128/221852 (58%)]\tLoss: 0.190783\tAcc: 81.00\n",
      "train epoch: 136 [140928/221852 (64%)]\tLoss: 0.195125\tAcc: 87.00\n",
      "train epoch: 136 [153728/221852 (69%)]\tLoss: 0.164361\tAcc: 84.00\n",
      "train epoch: 136 [166528/221852 (75%)]\tLoss: 0.214443\tAcc: 77.00\n",
      "train epoch: 136 [179328/221852 (81%)]\tLoss: 0.209101\tAcc: 71.00\n",
      "train epoch: 136 [192128/221852 (87%)]\tLoss: 0.138716\tAcc: 89.00\n",
      "val epoch: 136 [128/221852 (0%)]\tLoss: 0.125587\tAcc: 80.00\n",
      "val epoch: 136 [12928/221852 (6%)]\tLoss: 0.174849\tAcc: 85.00\n",
      "train epoch: 137 [128/221852 (0%)]\tLoss: 0.170730\tAcc: 80.00\n",
      "train epoch: 137 [12928/221852 (6%)]\tLoss: 0.196239\tAcc: 81.00\n",
      "train epoch: 137 [25728/221852 (12%)]\tLoss: 0.146849\tAcc: 85.00\n",
      "train epoch: 137 [38528/221852 (17%)]\tLoss: 0.237348\tAcc: 75.00\n",
      "train epoch: 137 [51328/221852 (23%)]\tLoss: 0.142040\tAcc: 88.00\n",
      "train epoch: 137 [64128/221852 (29%)]\tLoss: 0.206478\tAcc: 88.00\n",
      "train epoch: 137 [76928/221852 (35%)]\tLoss: 0.135768\tAcc: 82.00\n",
      "train epoch: 137 [89728/221852 (40%)]\tLoss: 0.134343\tAcc: 80.00\n",
      "train epoch: 137 [102528/221852 (46%)]\tLoss: 0.200593\tAcc: 85.00\n",
      "train epoch: 137 [115328/221852 (52%)]\tLoss: 0.181912\tAcc: 82.00\n",
      "train epoch: 137 [128128/221852 (58%)]\tLoss: 0.125644\tAcc: 82.00\n",
      "train epoch: 137 [140928/221852 (64%)]\tLoss: 0.143536\tAcc: 85.00\n",
      "train epoch: 137 [153728/221852 (69%)]\tLoss: 0.207001\tAcc: 88.00\n",
      "train epoch: 137 [166528/221852 (75%)]\tLoss: 0.154735\tAcc: 83.00\n",
      "train epoch: 137 [179328/221852 (81%)]\tLoss: 0.125362\tAcc: 79.00\n",
      "train epoch: 137 [192128/221852 (87%)]\tLoss: 0.223398\tAcc: 85.00\n",
      "val epoch: 137 [128/221852 (0%)]\tLoss: 0.181721\tAcc: 77.00\n",
      "val epoch: 137 [12928/221852 (6%)]\tLoss: 0.109935\tAcc: 82.00\n",
      "train epoch: 138 [128/221852 (0%)]\tLoss: 0.131277\tAcc: 86.00\n",
      "train epoch: 138 [12928/221852 (6%)]\tLoss: 0.121182\tAcc: 84.00\n",
      "train epoch: 138 [25728/221852 (12%)]\tLoss: 0.151281\tAcc: 77.00\n",
      "train epoch: 138 [38528/221852 (17%)]\tLoss: 0.213223\tAcc: 76.00\n",
      "train epoch: 138 [51328/221852 (23%)]\tLoss: 0.226537\tAcc: 76.00\n",
      "train epoch: 138 [64128/221852 (29%)]\tLoss: 0.135114\tAcc: 81.00\n",
      "train epoch: 138 [76928/221852 (35%)]\tLoss: 0.238259\tAcc: 84.00\n",
      "train epoch: 138 [89728/221852 (40%)]\tLoss: 0.236240\tAcc: 84.00\n",
      "train epoch: 138 [102528/221852 (46%)]\tLoss: 0.197716\tAcc: 74.00\n",
      "train epoch: 138 [115328/221852 (52%)]\tLoss: 0.128406\tAcc: 86.00\n",
      "train epoch: 138 [128128/221852 (58%)]\tLoss: 0.354126\tAcc: 74.00\n",
      "train epoch: 138 [140928/221852 (64%)]\tLoss: 0.130643\tAcc: 86.00\n",
      "train epoch: 138 [153728/221852 (69%)]\tLoss: 0.225389\tAcc: 78.00\n",
      "train epoch: 138 [166528/221852 (75%)]\tLoss: 0.255121\tAcc: 80.00\n",
      "train epoch: 138 [179328/221852 (81%)]\tLoss: 0.131420\tAcc: 80.00\n",
      "train epoch: 138 [192128/221852 (87%)]\tLoss: 0.144313\tAcc: 87.00\n",
      "val epoch: 138 [128/221852 (0%)]\tLoss: 0.196917\tAcc: 80.00\n",
      "val epoch: 138 [12928/221852 (6%)]\tLoss: 0.152682\tAcc: 82.00\n",
      "train epoch: 139 [128/221852 (0%)]\tLoss: 0.223272\tAcc: 74.00\n",
      "train epoch: 139 [12928/221852 (6%)]\tLoss: 0.222130\tAcc: 79.00\n",
      "train epoch: 139 [25728/221852 (12%)]\tLoss: 0.112982\tAcc: 88.00\n",
      "train epoch: 139 [38528/221852 (17%)]\tLoss: 0.093473\tAcc: 85.00\n",
      "train epoch: 139 [51328/221852 (23%)]\tLoss: 0.169998\tAcc: 79.00\n",
      "train epoch: 139 [64128/221852 (29%)]\tLoss: 0.191827\tAcc: 85.00\n",
      "train epoch: 139 [76928/221852 (35%)]\tLoss: 0.142585\tAcc: 80.00\n",
      "train epoch: 139 [89728/221852 (40%)]\tLoss: 0.170294\tAcc: 81.00\n",
      "train epoch: 139 [102528/221852 (46%)]\tLoss: 0.126779\tAcc: 82.00\n",
      "train epoch: 139 [115328/221852 (52%)]\tLoss: 0.279891\tAcc: 84.00\n",
      "train epoch: 139 [128128/221852 (58%)]\tLoss: 0.117253\tAcc: 78.00\n",
      "train epoch: 139 [140928/221852 (64%)]\tLoss: 0.196857\tAcc: 83.00\n",
      "train epoch: 139 [153728/221852 (69%)]\tLoss: 0.196392\tAcc: 82.00\n",
      "train epoch: 139 [166528/221852 (75%)]\tLoss: 0.190356\tAcc: 82.00\n",
      "train epoch: 139 [179328/221852 (81%)]\tLoss: 0.157132\tAcc: 86.00\n",
      "train epoch: 139 [192128/221852 (87%)]\tLoss: 0.207007\tAcc: 78.00\n",
      "val epoch: 139 [128/221852 (0%)]\tLoss: 0.215284\tAcc: 82.00\n",
      "val epoch: 139 [12928/221852 (6%)]\tLoss: 0.203097\tAcc: 80.00\n",
      "train epoch: 140 [128/221852 (0%)]\tLoss: 0.179661\tAcc: 88.00\n",
      "train epoch: 140 [12928/221852 (6%)]\tLoss: 0.183727\tAcc: 80.00\n",
      "train epoch: 140 [25728/221852 (12%)]\tLoss: 0.286074\tAcc: 81.00\n",
      "train epoch: 140 [38528/221852 (17%)]\tLoss: 0.236209\tAcc: 78.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 140 [51328/221852 (23%)]\tLoss: 0.195883\tAcc: 75.00\n",
      "train epoch: 140 [64128/221852 (29%)]\tLoss: 0.160429\tAcc: 84.00\n",
      "train epoch: 140 [76928/221852 (35%)]\tLoss: 0.202506\tAcc: 78.00\n",
      "train epoch: 140 [89728/221852 (40%)]\tLoss: 0.220109\tAcc: 74.00\n",
      "train epoch: 140 [102528/221852 (46%)]\tLoss: 0.194056\tAcc: 80.00\n",
      "train epoch: 140 [115328/221852 (52%)]\tLoss: 0.164191\tAcc: 82.00\n",
      "train epoch: 140 [128128/221852 (58%)]\tLoss: 0.214678\tAcc: 87.00\n",
      "train epoch: 140 [140928/221852 (64%)]\tLoss: 0.167215\tAcc: 83.00\n",
      "train epoch: 140 [153728/221852 (69%)]\tLoss: 0.142569\tAcc: 82.00\n",
      "train epoch: 140 [166528/221852 (75%)]\tLoss: 0.307920\tAcc: 78.00\n",
      "train epoch: 140 [179328/221852 (81%)]\tLoss: 0.140229\tAcc: 80.00\n",
      "train epoch: 140 [192128/221852 (87%)]\tLoss: 0.188295\tAcc: 81.00\n",
      "val epoch: 140 [128/221852 (0%)]\tLoss: 0.162946\tAcc: 82.00\n",
      "val epoch: 140 [12928/221852 (6%)]\tLoss: 0.238633\tAcc: 76.00\n",
      "train epoch: 141 [128/221852 (0%)]\tLoss: 0.160643\tAcc: 84.00\n",
      "train epoch: 141 [12928/221852 (6%)]\tLoss: 0.196459\tAcc: 81.00\n",
      "train epoch: 141 [25728/221852 (12%)]\tLoss: 0.217411\tAcc: 77.00\n",
      "train epoch: 141 [38528/221852 (17%)]\tLoss: 0.154695\tAcc: 83.00\n",
      "train epoch: 141 [51328/221852 (23%)]\tLoss: 0.137566\tAcc: 85.00\n",
      "train epoch: 141 [64128/221852 (29%)]\tLoss: 0.217853\tAcc: 80.00\n",
      "train epoch: 141 [76928/221852 (35%)]\tLoss: 0.109986\tAcc: 83.00\n",
      "train epoch: 141 [89728/221852 (40%)]\tLoss: 0.201010\tAcc: 78.00\n",
      "train epoch: 141 [102528/221852 (46%)]\tLoss: 0.245347\tAcc: 76.00\n",
      "train epoch: 141 [115328/221852 (52%)]\tLoss: 0.293814\tAcc: 83.00\n",
      "train epoch: 141 [128128/221852 (58%)]\tLoss: 0.132258\tAcc: 83.00\n",
      "train epoch: 141 [140928/221852 (64%)]\tLoss: 0.148334\tAcc: 84.00\n",
      "train epoch: 141 [153728/221852 (69%)]\tLoss: 0.231830\tAcc: 76.00\n",
      "train epoch: 141 [166528/221852 (75%)]\tLoss: 0.215242\tAcc: 80.00\n",
      "train epoch: 141 [179328/221852 (81%)]\tLoss: 0.252054\tAcc: 78.00\n",
      "train epoch: 141 [192128/221852 (87%)]\tLoss: 0.190543\tAcc: 80.00\n",
      "val epoch: 141 [128/221852 (0%)]\tLoss: 0.352907\tAcc: 82.00\n",
      "val epoch: 141 [12928/221852 (6%)]\tLoss: 0.427292\tAcc: 84.00\n",
      "train epoch: 142 [128/221852 (0%)]\tLoss: 0.505877\tAcc: 83.00\n",
      "train epoch: 142 [12928/221852 (6%)]\tLoss: 0.115316\tAcc: 79.00\n",
      "train epoch: 142 [25728/221852 (12%)]\tLoss: 0.253651\tAcc: 77.00\n",
      "train epoch: 142 [38528/221852 (17%)]\tLoss: 0.220205\tAcc: 83.00\n",
      "train epoch: 142 [51328/221852 (23%)]\tLoss: 0.122432\tAcc: 85.00\n",
      "train epoch: 142 [64128/221852 (29%)]\tLoss: 0.121104\tAcc: 85.00\n",
      "train epoch: 142 [76928/221852 (35%)]\tLoss: 0.141230\tAcc: 89.00\n",
      "train epoch: 142 [89728/221852 (40%)]\tLoss: 0.173379\tAcc: 86.00\n",
      "train epoch: 142 [102528/221852 (46%)]\tLoss: 0.304741\tAcc: 70.00\n",
      "train epoch: 142 [115328/221852 (52%)]\tLoss: 0.259280\tAcc: 81.00\n",
      "train epoch: 142 [128128/221852 (58%)]\tLoss: 0.182433\tAcc: 80.00\n",
      "train epoch: 142 [140928/221852 (64%)]\tLoss: 0.141701\tAcc: 85.00\n",
      "train epoch: 142 [153728/221852 (69%)]\tLoss: 0.152915\tAcc: 80.00\n",
      "train epoch: 142 [166528/221852 (75%)]\tLoss: 0.142815\tAcc: 88.00\n",
      "train epoch: 142 [179328/221852 (81%)]\tLoss: 0.283733\tAcc: 84.00\n",
      "train epoch: 142 [192128/221852 (87%)]\tLoss: 0.146933\tAcc: 80.00\n",
      "val epoch: 142 [128/221852 (0%)]\tLoss: 0.117591\tAcc: 88.00\n",
      "val epoch: 142 [12928/221852 (6%)]\tLoss: 0.107600\tAcc: 84.00\n",
      "train epoch: 143 [128/221852 (0%)]\tLoss: 0.146821\tAcc: 87.00\n",
      "train epoch: 143 [12928/221852 (6%)]\tLoss: 0.130720\tAcc: 83.00\n",
      "train epoch: 143 [25728/221852 (12%)]\tLoss: 0.204182\tAcc: 80.00\n",
      "train epoch: 143 [38528/221852 (17%)]\tLoss: 0.267686\tAcc: 78.00\n",
      "train epoch: 143 [51328/221852 (23%)]\tLoss: 0.160425\tAcc: 80.00\n",
      "train epoch: 143 [64128/221852 (29%)]\tLoss: 0.130437\tAcc: 84.00\n",
      "train epoch: 143 [76928/221852 (35%)]\tLoss: 0.168615\tAcc: 82.00\n",
      "train epoch: 143 [89728/221852 (40%)]\tLoss: 0.209098\tAcc: 80.00\n",
      "train epoch: 143 [102528/221852 (46%)]\tLoss: 0.143833\tAcc: 79.00\n",
      "train epoch: 143 [115328/221852 (52%)]\tLoss: 0.163033\tAcc: 80.00\n",
      "train epoch: 143 [128128/221852 (58%)]\tLoss: 0.186448\tAcc: 83.00\n",
      "train epoch: 143 [140928/221852 (64%)]\tLoss: 0.104457\tAcc: 81.00\n",
      "train epoch: 143 [153728/221852 (69%)]\tLoss: 0.154828\tAcc: 77.00\n",
      "train epoch: 143 [166528/221852 (75%)]\tLoss: 0.231712\tAcc: 74.00\n",
      "train epoch: 143 [179328/221852 (81%)]\tLoss: 0.205141\tAcc: 84.00\n",
      "train epoch: 143 [192128/221852 (87%)]\tLoss: 0.188970\tAcc: 77.00\n",
      "val epoch: 143 [128/221852 (0%)]\tLoss: 0.154165\tAcc: 87.00\n",
      "val epoch: 143 [12928/221852 (6%)]\tLoss: 0.095787\tAcc: 83.00\n",
      "train epoch: 144 [128/221852 (0%)]\tLoss: 0.195224\tAcc: 77.00\n",
      "train epoch: 144 [12928/221852 (6%)]\tLoss: 0.240497\tAcc: 80.00\n",
      "train epoch: 144 [25728/221852 (12%)]\tLoss: 0.207656\tAcc: 84.00\n",
      "train epoch: 144 [38528/221852 (17%)]\tLoss: 0.117989\tAcc: 78.00\n",
      "train epoch: 144 [51328/221852 (23%)]\tLoss: 0.191156\tAcc: 79.00\n",
      "train epoch: 144 [64128/221852 (29%)]\tLoss: 0.157029\tAcc: 84.00\n",
      "train epoch: 144 [76928/221852 (35%)]\tLoss: 0.244829\tAcc: 80.00\n",
      "train epoch: 144 [89728/221852 (40%)]\tLoss: 0.351713\tAcc: 83.00\n",
      "train epoch: 144 [102528/221852 (46%)]\tLoss: 0.194231\tAcc: 83.00\n",
      "train epoch: 144 [115328/221852 (52%)]\tLoss: 0.157683\tAcc: 84.00\n",
      "train epoch: 144 [128128/221852 (58%)]\tLoss: 0.237162\tAcc: 71.00\n",
      "train epoch: 144 [140928/221852 (64%)]\tLoss: 0.111132\tAcc: 84.00\n",
      "train epoch: 144 [153728/221852 (69%)]\tLoss: 0.132982\tAcc: 79.00\n",
      "train epoch: 144 [166528/221852 (75%)]\tLoss: 0.217334\tAcc: 77.00\n",
      "train epoch: 144 [179328/221852 (81%)]\tLoss: 0.257064\tAcc: 78.00\n",
      "train epoch: 144 [192128/221852 (87%)]\tLoss: 0.141448\tAcc: 84.00\n",
      "val epoch: 144 [128/221852 (0%)]\tLoss: 0.179110\tAcc: 83.00\n",
      "val epoch: 144 [12928/221852 (6%)]\tLoss: 0.136223\tAcc: 89.00\n",
      "train epoch: 145 [128/221852 (0%)]\tLoss: 0.225658\tAcc: 79.00\n",
      "train epoch: 145 [12928/221852 (6%)]\tLoss: 0.190041\tAcc: 78.00\n",
      "train epoch: 145 [25728/221852 (12%)]\tLoss: 0.111948\tAcc: 84.00\n",
      "train epoch: 145 [38528/221852 (17%)]\tLoss: 0.225837\tAcc: 78.00\n",
      "train epoch: 145 [51328/221852 (23%)]\tLoss: 0.227838\tAcc: 84.00\n",
      "train epoch: 145 [64128/221852 (29%)]\tLoss: 0.195350\tAcc: 76.00\n",
      "train epoch: 145 [76928/221852 (35%)]\tLoss: 0.227736\tAcc: 82.00\n",
      "train epoch: 145 [89728/221852 (40%)]\tLoss: 0.211453\tAcc: 80.00\n",
      "train epoch: 145 [102528/221852 (46%)]\tLoss: 0.180385\tAcc: 79.00\n",
      "train epoch: 145 [115328/221852 (52%)]\tLoss: 0.138405\tAcc: 84.00\n",
      "train epoch: 145 [128128/221852 (58%)]\tLoss: 0.257518\tAcc: 78.00\n",
      "train epoch: 145 [140928/221852 (64%)]\tLoss: 0.156890\tAcc: 86.00\n",
      "train epoch: 145 [153728/221852 (69%)]\tLoss: 0.237514\tAcc: 81.00\n",
      "train epoch: 145 [166528/221852 (75%)]\tLoss: 0.269162\tAcc: 80.00\n",
      "train epoch: 145 [179328/221852 (81%)]\tLoss: 0.158371\tAcc: 84.00\n",
      "train epoch: 145 [192128/221852 (87%)]\tLoss: 0.284524\tAcc: 77.00\n",
      "val epoch: 145 [128/221852 (0%)]\tLoss: 0.238664\tAcc: 80.00\n",
      "val epoch: 145 [12928/221852 (6%)]\tLoss: 0.138451\tAcc: 79.00\n",
      "train epoch: 146 [128/221852 (0%)]\tLoss: 0.164255\tAcc: 81.00\n",
      "train epoch: 146 [12928/221852 (6%)]\tLoss: 0.220429\tAcc: 77.00\n",
      "train epoch: 146 [25728/221852 (12%)]\tLoss: 0.168064\tAcc: 86.00\n",
      "train epoch: 146 [38528/221852 (17%)]\tLoss: 0.171665\tAcc: 80.00\n",
      "train epoch: 146 [51328/221852 (23%)]\tLoss: 0.162083\tAcc: 84.00\n",
      "train epoch: 146 [64128/221852 (29%)]\tLoss: 0.191263\tAcc: 80.00\n",
      "train epoch: 146 [76928/221852 (35%)]\tLoss: 0.167075\tAcc: 84.00\n",
      "train epoch: 146 [89728/221852 (40%)]\tLoss: 0.111024\tAcc: 81.00\n",
      "train epoch: 146 [102528/221852 (46%)]\tLoss: 0.196075\tAcc: 80.00\n",
      "train epoch: 146 [115328/221852 (52%)]\tLoss: 0.128960\tAcc: 79.00\n",
      "train epoch: 146 [128128/221852 (58%)]\tLoss: 0.148305\tAcc: 80.00\n",
      "train epoch: 146 [140928/221852 (64%)]\tLoss: 0.116312\tAcc: 81.00\n",
      "train epoch: 146 [153728/221852 (69%)]\tLoss: 0.268540\tAcc: 72.00\n",
      "train epoch: 146 [166528/221852 (75%)]\tLoss: 0.165728\tAcc: 84.00\n",
      "train epoch: 146 [179328/221852 (81%)]\tLoss: 0.221204\tAcc: 84.00\n",
      "train epoch: 146 [192128/221852 (87%)]\tLoss: 0.113857\tAcc: 86.00\n",
      "val epoch: 146 [128/221852 (0%)]\tLoss: 0.142373\tAcc: 84.00\n",
      "val epoch: 146 [12928/221852 (6%)]\tLoss: 0.154943\tAcc: 84.00\n",
      "train epoch: 147 [128/221852 (0%)]\tLoss: 0.324226\tAcc: 80.00\n",
      "train epoch: 147 [12928/221852 (6%)]\tLoss: 0.132971\tAcc: 84.00\n",
      "train epoch: 147 [25728/221852 (12%)]\tLoss: 0.292298\tAcc: 80.00\n",
      "train epoch: 147 [38528/221852 (17%)]\tLoss: 0.088846\tAcc: 88.00\n",
      "train epoch: 147 [51328/221852 (23%)]\tLoss: 0.078056\tAcc: 89.00\n",
      "train epoch: 147 [64128/221852 (29%)]\tLoss: 0.236416\tAcc: 80.00\n",
      "train epoch: 147 [76928/221852 (35%)]\tLoss: 0.141275\tAcc: 86.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 147 [89728/221852 (40%)]\tLoss: 0.197919\tAcc: 79.00\n",
      "train epoch: 147 [102528/221852 (46%)]\tLoss: 0.223142\tAcc: 87.00\n",
      "train epoch: 147 [115328/221852 (52%)]\tLoss: 0.270634\tAcc: 74.00\n",
      "train epoch: 147 [128128/221852 (58%)]\tLoss: 0.214714\tAcc: 83.00\n",
      "train epoch: 147 [140928/221852 (64%)]\tLoss: 0.238469\tAcc: 77.00\n",
      "train epoch: 147 [153728/221852 (69%)]\tLoss: 0.160215\tAcc: 79.00\n",
      "train epoch: 147 [166528/221852 (75%)]\tLoss: 0.201192\tAcc: 80.00\n",
      "train epoch: 147 [179328/221852 (81%)]\tLoss: 0.234528\tAcc: 80.00\n",
      "train epoch: 147 [192128/221852 (87%)]\tLoss: 0.191145\tAcc: 80.00\n",
      "val epoch: 147 [128/221852 (0%)]\tLoss: 0.224541\tAcc: 77.00\n",
      "val epoch: 147 [12928/221852 (6%)]\tLoss: 0.153122\tAcc: 85.00\n",
      "train epoch: 148 [128/221852 (0%)]\tLoss: 0.184075\tAcc: 79.00\n",
      "train epoch: 148 [12928/221852 (6%)]\tLoss: 0.161798\tAcc: 74.00\n",
      "train epoch: 148 [25728/221852 (12%)]\tLoss: 0.190772\tAcc: 77.00\n",
      "train epoch: 148 [38528/221852 (17%)]\tLoss: 0.210454\tAcc: 77.00\n",
      "train epoch: 148 [51328/221852 (23%)]\tLoss: 0.250211\tAcc: 77.00\n",
      "train epoch: 148 [64128/221852 (29%)]\tLoss: 0.179503\tAcc: 82.00\n",
      "train epoch: 148 [76928/221852 (35%)]\tLoss: 0.192143\tAcc: 87.00\n",
      "train epoch: 148 [89728/221852 (40%)]\tLoss: 0.268684\tAcc: 78.00\n",
      "train epoch: 148 [102528/221852 (46%)]\tLoss: 0.326095\tAcc: 78.00\n",
      "train epoch: 148 [115328/221852 (52%)]\tLoss: 0.141590\tAcc: 83.00\n",
      "train epoch: 148 [128128/221852 (58%)]\tLoss: 0.173889\tAcc: 83.00\n",
      "train epoch: 148 [140928/221852 (64%)]\tLoss: 0.174639\tAcc: 81.00\n",
      "train epoch: 148 [153728/221852 (69%)]\tLoss: 0.260202\tAcc: 82.00\n",
      "train epoch: 148 [166528/221852 (75%)]\tLoss: 0.135998\tAcc: 87.00\n",
      "train epoch: 148 [179328/221852 (81%)]\tLoss: 0.143510\tAcc: 85.00\n",
      "train epoch: 148 [192128/221852 (87%)]\tLoss: 0.269894\tAcc: 77.00\n",
      "val epoch: 148 [128/221852 (0%)]\tLoss: 0.134041\tAcc: 87.00\n",
      "val epoch: 148 [12928/221852 (6%)]\tLoss: 0.188410\tAcc: 80.00\n",
      "train epoch: 149 [128/221852 (0%)]\tLoss: 0.241187\tAcc: 80.00\n",
      "train epoch: 149 [12928/221852 (6%)]\tLoss: 0.243733\tAcc: 76.00\n",
      "train epoch: 149 [25728/221852 (12%)]\tLoss: 0.215946\tAcc: 83.00\n",
      "train epoch: 149 [38528/221852 (17%)]\tLoss: 0.147376\tAcc: 86.00\n",
      "train epoch: 149 [51328/221852 (23%)]\tLoss: 0.211066\tAcc: 82.00\n",
      "train epoch: 149 [64128/221852 (29%)]\tLoss: 0.211588\tAcc: 84.00\n",
      "train epoch: 149 [76928/221852 (35%)]\tLoss: 0.205038\tAcc: 81.00\n",
      "train epoch: 149 [89728/221852 (40%)]\tLoss: 0.250531\tAcc: 80.00\n",
      "train epoch: 149 [102528/221852 (46%)]\tLoss: 0.148819\tAcc: 80.00\n",
      "train epoch: 149 [115328/221852 (52%)]\tLoss: 0.131726\tAcc: 82.00\n",
      "train epoch: 149 [128128/221852 (58%)]\tLoss: 0.244250\tAcc: 77.00\n",
      "train epoch: 149 [140928/221852 (64%)]\tLoss: 0.169618\tAcc: 86.00\n",
      "train epoch: 149 [153728/221852 (69%)]\tLoss: 0.198313\tAcc: 86.00\n",
      "train epoch: 149 [166528/221852 (75%)]\tLoss: 0.177666\tAcc: 83.00\n",
      "train epoch: 149 [179328/221852 (81%)]\tLoss: 0.219753\tAcc: 77.00\n",
      "train epoch: 149 [192128/221852 (87%)]\tLoss: 0.152314\tAcc: 86.00\n",
      "val epoch: 149 [128/221852 (0%)]\tLoss: 0.200756\tAcc: 83.00\n",
      "val epoch: 149 [12928/221852 (6%)]\tLoss: 0.208203\tAcc: 79.00\n",
      "train epoch: 150 [128/221852 (0%)]\tLoss: 0.263138\tAcc: 77.00\n",
      "train epoch: 150 [12928/221852 (6%)]\tLoss: 0.173296\tAcc: 83.00\n",
      "train epoch: 150 [25728/221852 (12%)]\tLoss: 0.194903\tAcc: 80.00\n",
      "train epoch: 150 [38528/221852 (17%)]\tLoss: 0.182544\tAcc: 80.00\n",
      "train epoch: 150 [51328/221852 (23%)]\tLoss: 0.252552\tAcc: 80.00\n",
      "train epoch: 150 [64128/221852 (29%)]\tLoss: 0.138590\tAcc: 82.00\n",
      "train epoch: 150 [76928/221852 (35%)]\tLoss: 0.192659\tAcc: 83.00\n",
      "train epoch: 150 [89728/221852 (40%)]\tLoss: 0.158807\tAcc: 80.00\n",
      "train epoch: 150 [102528/221852 (46%)]\tLoss: 0.137546\tAcc: 77.00\n",
      "train epoch: 150 [115328/221852 (52%)]\tLoss: 0.130298\tAcc: 81.00\n",
      "train epoch: 150 [128128/221852 (58%)]\tLoss: 0.177501\tAcc: 85.00\n",
      "train epoch: 150 [140928/221852 (64%)]\tLoss: 0.143820\tAcc: 82.00\n",
      "train epoch: 150 [153728/221852 (69%)]\tLoss: 0.234909\tAcc: 79.00\n",
      "train epoch: 150 [166528/221852 (75%)]\tLoss: 0.234955\tAcc: 82.00\n",
      "train epoch: 150 [179328/221852 (81%)]\tLoss: 0.122943\tAcc: 87.00\n",
      "train epoch: 150 [192128/221852 (87%)]\tLoss: 0.198314\tAcc: 84.00\n",
      "val epoch: 150 [128/221852 (0%)]\tLoss: 0.131613\tAcc: 85.00\n",
      "val epoch: 150 [12928/221852 (6%)]\tLoss: 0.224638\tAcc: 73.00\n",
      "train epoch: 151 [128/221852 (0%)]\tLoss: 0.171796\tAcc: 86.00\n",
      "train epoch: 151 [12928/221852 (6%)]\tLoss: 0.208901\tAcc: 83.00\n",
      "train epoch: 151 [25728/221852 (12%)]\tLoss: 0.223014\tAcc: 81.00\n",
      "train epoch: 151 [38528/221852 (17%)]\tLoss: 0.174372\tAcc: 77.00\n",
      "train epoch: 151 [51328/221852 (23%)]\tLoss: 0.182098\tAcc: 87.00\n",
      "train epoch: 151 [64128/221852 (29%)]\tLoss: 0.229607\tAcc: 77.00\n",
      "train epoch: 151 [76928/221852 (35%)]\tLoss: 0.119050\tAcc: 82.00\n",
      "train epoch: 151 [89728/221852 (40%)]\tLoss: 0.161127\tAcc: 81.00\n",
      "train epoch: 151 [102528/221852 (46%)]\tLoss: 0.118437\tAcc: 87.00\n",
      "train epoch: 151 [115328/221852 (52%)]\tLoss: 0.185637\tAcc: 83.00\n",
      "train epoch: 151 [128128/221852 (58%)]\tLoss: 0.129060\tAcc: 86.00\n",
      "train epoch: 151 [140928/221852 (64%)]\tLoss: 0.250702\tAcc: 76.00\n",
      "train epoch: 151 [153728/221852 (69%)]\tLoss: 0.179811\tAcc: 83.00\n",
      "train epoch: 151 [166528/221852 (75%)]\tLoss: 0.193106\tAcc: 88.00\n",
      "train epoch: 151 [179328/221852 (81%)]\tLoss: 0.127791\tAcc: 88.00\n",
      "train epoch: 151 [192128/221852 (87%)]\tLoss: 0.159715\tAcc: 85.00\n",
      "val epoch: 151 [128/221852 (0%)]\tLoss: 0.146178\tAcc: 84.00\n",
      "val epoch: 151 [12928/221852 (6%)]\tLoss: 0.173763\tAcc: 82.00\n",
      "train epoch: 152 [128/221852 (0%)]\tLoss: 0.143980\tAcc: 86.00\n",
      "train epoch: 152 [12928/221852 (6%)]\tLoss: 0.154897\tAcc: 83.00\n",
      "train epoch: 152 [25728/221852 (12%)]\tLoss: 0.153157\tAcc: 84.00\n",
      "train epoch: 152 [38528/221852 (17%)]\tLoss: 0.129087\tAcc: 80.00\n",
      "train epoch: 152 [51328/221852 (23%)]\tLoss: 0.151611\tAcc: 77.00\n",
      "train epoch: 152 [64128/221852 (29%)]\tLoss: 0.217124\tAcc: 81.00\n",
      "train epoch: 152 [76928/221852 (35%)]\tLoss: 0.126952\tAcc: 83.00\n",
      "train epoch: 152 [89728/221852 (40%)]\tLoss: 0.165817\tAcc: 84.00\n",
      "train epoch: 152 [102528/221852 (46%)]\tLoss: 0.204936\tAcc: 83.00\n",
      "train epoch: 152 [115328/221852 (52%)]\tLoss: 0.165997\tAcc: 84.00\n",
      "train epoch: 152 [128128/221852 (58%)]\tLoss: 0.210342\tAcc: 79.00\n",
      "train epoch: 152 [140928/221852 (64%)]\tLoss: 0.120110\tAcc: 88.00\n",
      "train epoch: 152 [153728/221852 (69%)]\tLoss: 0.204630\tAcc: 84.00\n",
      "train epoch: 152 [166528/221852 (75%)]\tLoss: 0.220740\tAcc: 84.00\n",
      "train epoch: 152 [179328/221852 (81%)]\tLoss: 0.183831\tAcc: 83.00\n",
      "train epoch: 152 [192128/221852 (87%)]\tLoss: 0.143186\tAcc: 77.00\n",
      "val epoch: 152 [128/221852 (0%)]\tLoss: 0.261259\tAcc: 73.00\n",
      "val epoch: 152 [12928/221852 (6%)]\tLoss: 0.137644\tAcc: 86.00\n",
      "train epoch: 153 [128/221852 (0%)]\tLoss: 0.204602\tAcc: 77.00\n",
      "train epoch: 153 [12928/221852 (6%)]\tLoss: 0.253138\tAcc: 78.00\n",
      "train epoch: 153 [25728/221852 (12%)]\tLoss: 0.201155\tAcc: 73.00\n",
      "train epoch: 153 [38528/221852 (17%)]\tLoss: 0.151846\tAcc: 82.00\n",
      "train epoch: 153 [51328/221852 (23%)]\tLoss: 0.229602\tAcc: 79.00\n",
      "train epoch: 153 [64128/221852 (29%)]\tLoss: 0.121212\tAcc: 85.00\n",
      "train epoch: 153 [76928/221852 (35%)]\tLoss: 0.140000\tAcc: 84.00\n",
      "train epoch: 153 [89728/221852 (40%)]\tLoss: 0.117774\tAcc: 87.00\n",
      "train epoch: 153 [102528/221852 (46%)]\tLoss: 0.139708\tAcc: 88.00\n",
      "train epoch: 153 [115328/221852 (52%)]\tLoss: 0.177260\tAcc: 80.00\n",
      "train epoch: 153 [128128/221852 (58%)]\tLoss: 0.282441\tAcc: 80.00\n",
      "train epoch: 153 [140928/221852 (64%)]\tLoss: 0.178797\tAcc: 85.00\n",
      "train epoch: 153 [153728/221852 (69%)]\tLoss: 0.134640\tAcc: 85.00\n",
      "train epoch: 153 [166528/221852 (75%)]\tLoss: 0.260869\tAcc: 80.00\n",
      "train epoch: 153 [179328/221852 (81%)]\tLoss: 0.164005\tAcc: 84.00\n",
      "train epoch: 153 [192128/221852 (87%)]\tLoss: 0.132375\tAcc: 88.00\n",
      "val epoch: 153 [128/221852 (0%)]\tLoss: 0.197875\tAcc: 85.00\n",
      "val epoch: 153 [12928/221852 (6%)]\tLoss: 0.126104\tAcc: 83.00\n",
      "train epoch: 154 [128/221852 (0%)]\tLoss: 0.208915\tAcc: 84.00\n",
      "train epoch: 154 [12928/221852 (6%)]\tLoss: 0.278728\tAcc: 78.00\n",
      "train epoch: 154 [25728/221852 (12%)]\tLoss: 0.205335\tAcc: 86.00\n",
      "train epoch: 154 [38528/221852 (17%)]\tLoss: 0.198632\tAcc: 79.00\n",
      "train epoch: 154 [51328/221852 (23%)]\tLoss: 0.242183\tAcc: 79.00\n",
      "train epoch: 154 [64128/221852 (29%)]\tLoss: 0.161135\tAcc: 81.00\n",
      "train epoch: 154 [76928/221852 (35%)]\tLoss: 0.225599\tAcc: 80.00\n",
      "train epoch: 154 [89728/221852 (40%)]\tLoss: 0.165018\tAcc: 77.00\n",
      "train epoch: 154 [102528/221852 (46%)]\tLoss: 0.110048\tAcc: 85.00\n",
      "train epoch: 154 [115328/221852 (52%)]\tLoss: 0.187145\tAcc: 82.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 154 [128128/221852 (58%)]\tLoss: 0.162629\tAcc: 84.00\n",
      "train epoch: 154 [140928/221852 (64%)]\tLoss: 0.179385\tAcc: 79.00\n",
      "train epoch: 154 [153728/221852 (69%)]\tLoss: 0.304175\tAcc: 78.00\n",
      "train epoch: 154 [166528/221852 (75%)]\tLoss: 0.183790\tAcc: 82.00\n",
      "train epoch: 154 [179328/221852 (81%)]\tLoss: 0.167638\tAcc: 79.00\n",
      "train epoch: 154 [192128/221852 (87%)]\tLoss: 0.267644\tAcc: 82.00\n",
      "val epoch: 154 [128/221852 (0%)]\tLoss: 0.196314\tAcc: 78.00\n",
      "val epoch: 154 [12928/221852 (6%)]\tLoss: 0.189577\tAcc: 86.00\n",
      "train epoch: 155 [128/221852 (0%)]\tLoss: 0.165491\tAcc: 81.00\n",
      "train epoch: 155 [12928/221852 (6%)]\tLoss: 0.197898\tAcc: 74.00\n",
      "train epoch: 155 [25728/221852 (12%)]\tLoss: 0.132909\tAcc: 87.00\n",
      "train epoch: 155 [38528/221852 (17%)]\tLoss: 0.180489\tAcc: 85.00\n",
      "train epoch: 155 [51328/221852 (23%)]\tLoss: 0.167010\tAcc: 84.00\n",
      "train epoch: 155 [64128/221852 (29%)]\tLoss: 0.154173\tAcc: 84.00\n",
      "train epoch: 155 [76928/221852 (35%)]\tLoss: 0.194792\tAcc: 84.00\n",
      "train epoch: 155 [89728/221852 (40%)]\tLoss: 0.282517\tAcc: 77.00\n",
      "train epoch: 155 [102528/221852 (46%)]\tLoss: 0.139362\tAcc: 85.00\n",
      "train epoch: 155 [115328/221852 (52%)]\tLoss: 0.123442\tAcc: 84.00\n",
      "train epoch: 155 [128128/221852 (58%)]\tLoss: 0.205326\tAcc: 79.00\n",
      "train epoch: 155 [140928/221852 (64%)]\tLoss: 0.156544\tAcc: 80.00\n",
      "train epoch: 155 [153728/221852 (69%)]\tLoss: 0.134987\tAcc: 84.00\n",
      "train epoch: 155 [166528/221852 (75%)]\tLoss: 0.113095\tAcc: 85.00\n",
      "train epoch: 155 [179328/221852 (81%)]\tLoss: 0.125741\tAcc: 84.00\n",
      "train epoch: 155 [192128/221852 (87%)]\tLoss: 0.181103\tAcc: 76.00\n",
      "val epoch: 155 [128/221852 (0%)]\tLoss: 0.234346\tAcc: 78.00\n",
      "val epoch: 155 [12928/221852 (6%)]\tLoss: 0.160605\tAcc: 88.00\n",
      "train epoch: 156 [128/221852 (0%)]\tLoss: 0.204036\tAcc: 84.00\n",
      "train epoch: 156 [12928/221852 (6%)]\tLoss: 0.119250\tAcc: 84.00\n",
      "train epoch: 156 [25728/221852 (12%)]\tLoss: 0.171238\tAcc: 83.00\n",
      "train epoch: 156 [38528/221852 (17%)]\tLoss: 0.158226\tAcc: 85.00\n",
      "train epoch: 156 [51328/221852 (23%)]\tLoss: 0.138365\tAcc: 84.00\n",
      "train epoch: 156 [64128/221852 (29%)]\tLoss: 0.131745\tAcc: 82.00\n",
      "train epoch: 156 [76928/221852 (35%)]\tLoss: 0.163699\tAcc: 86.00\n",
      "train epoch: 156 [89728/221852 (40%)]\tLoss: 0.140551\tAcc: 88.00\n",
      "train epoch: 156 [102528/221852 (46%)]\tLoss: 0.198541\tAcc: 85.00\n",
      "train epoch: 156 [115328/221852 (52%)]\tLoss: 0.105906\tAcc: 85.00\n",
      "train epoch: 156 [128128/221852 (58%)]\tLoss: 0.177880\tAcc: 83.00\n",
      "train epoch: 156 [140928/221852 (64%)]\tLoss: 0.258304\tAcc: 82.00\n",
      "train epoch: 156 [153728/221852 (69%)]\tLoss: 0.153312\tAcc: 89.00\n",
      "train epoch: 156 [166528/221852 (75%)]\tLoss: 0.188556\tAcc: 88.00\n",
      "train epoch: 156 [179328/221852 (81%)]\tLoss: 0.190087\tAcc: 79.00\n",
      "train epoch: 156 [192128/221852 (87%)]\tLoss: 0.135567\tAcc: 84.00\n",
      "val epoch: 156 [128/221852 (0%)]\tLoss: 0.198181\tAcc: 81.00\n",
      "val epoch: 156 [12928/221852 (6%)]\tLoss: 0.127583\tAcc: 84.00\n",
      "train epoch: 157 [128/221852 (0%)]\tLoss: 0.110018\tAcc: 81.00\n",
      "train epoch: 157 [12928/221852 (6%)]\tLoss: 0.111285\tAcc: 85.00\n",
      "train epoch: 157 [25728/221852 (12%)]\tLoss: 0.163420\tAcc: 82.00\n",
      "train epoch: 157 [38528/221852 (17%)]\tLoss: 0.269432\tAcc: 77.00\n",
      "train epoch: 157 [51328/221852 (23%)]\tLoss: 0.209575\tAcc: 82.00\n",
      "train epoch: 157 [64128/221852 (29%)]\tLoss: 0.137639\tAcc: 81.00\n",
      "train epoch: 157 [76928/221852 (35%)]\tLoss: 0.180061\tAcc: 74.00\n",
      "train epoch: 157 [89728/221852 (40%)]\tLoss: 0.192964\tAcc: 80.00\n",
      "train epoch: 157 [102528/221852 (46%)]\tLoss: 0.208853\tAcc: 81.00\n",
      "train epoch: 157 [115328/221852 (52%)]\tLoss: 0.321051\tAcc: 80.00\n",
      "train epoch: 157 [128128/221852 (58%)]\tLoss: 0.151652\tAcc: 79.00\n",
      "train epoch: 157 [140928/221852 (64%)]\tLoss: 0.403026\tAcc: 86.00\n",
      "train epoch: 157 [153728/221852 (69%)]\tLoss: 0.162302\tAcc: 88.00\n",
      "train epoch: 157 [166528/221852 (75%)]\tLoss: 0.202372\tAcc: 83.00\n",
      "train epoch: 157 [179328/221852 (81%)]\tLoss: 0.142694\tAcc: 81.00\n",
      "train epoch: 157 [192128/221852 (87%)]\tLoss: 0.145999\tAcc: 81.00\n",
      "val epoch: 157 [128/221852 (0%)]\tLoss: 0.176613\tAcc: 84.00\n",
      "val epoch: 157 [12928/221852 (6%)]\tLoss: 0.337219\tAcc: 80.00\n",
      "train epoch: 158 [128/221852 (0%)]\tLoss: 0.236697\tAcc: 81.00\n",
      "train epoch: 158 [12928/221852 (6%)]\tLoss: 0.090569\tAcc: 88.00\n",
      "train epoch: 158 [25728/221852 (12%)]\tLoss: 0.109778\tAcc: 85.00\n",
      "train epoch: 158 [38528/221852 (17%)]\tLoss: 0.275717\tAcc: 82.00\n",
      "train epoch: 158 [51328/221852 (23%)]\tLoss: 0.163503\tAcc: 80.00\n",
      "train epoch: 158 [64128/221852 (29%)]\tLoss: 0.184209\tAcc: 82.00\n",
      "train epoch: 158 [76928/221852 (35%)]\tLoss: 0.245546\tAcc: 77.00\n",
      "train epoch: 158 [89728/221852 (40%)]\tLoss: 0.272136\tAcc: 77.00\n",
      "train epoch: 158 [102528/221852 (46%)]\tLoss: 0.221018\tAcc: 80.00\n",
      "train epoch: 158 [115328/221852 (52%)]\tLoss: 0.226012\tAcc: 81.00\n",
      "train epoch: 158 [128128/221852 (58%)]\tLoss: 0.226763\tAcc: 84.00\n",
      "train epoch: 158 [140928/221852 (64%)]\tLoss: 0.159074\tAcc: 80.00\n",
      "train epoch: 158 [153728/221852 (69%)]\tLoss: 0.263911\tAcc: 77.00\n",
      "train epoch: 158 [166528/221852 (75%)]\tLoss: 0.225494\tAcc: 82.00\n",
      "train epoch: 158 [179328/221852 (81%)]\tLoss: 0.088756\tAcc: 88.00\n",
      "train epoch: 158 [192128/221852 (87%)]\tLoss: 0.134436\tAcc: 80.00\n",
      "val epoch: 158 [128/221852 (0%)]\tLoss: 0.218462\tAcc: 81.00\n",
      "val epoch: 158 [12928/221852 (6%)]\tLoss: 0.140275\tAcc: 85.00\n",
      "train epoch: 159 [128/221852 (0%)]\tLoss: 0.160529\tAcc: 80.00\n",
      "train epoch: 159 [12928/221852 (6%)]\tLoss: 0.176364\tAcc: 83.00\n",
      "train epoch: 159 [25728/221852 (12%)]\tLoss: 0.148194\tAcc: 85.00\n",
      "train epoch: 159 [38528/221852 (17%)]\tLoss: 0.199515\tAcc: 82.00\n",
      "train epoch: 159 [51328/221852 (23%)]\tLoss: 0.398176\tAcc: 83.00\n",
      "train epoch: 159 [64128/221852 (29%)]\tLoss: 0.108003\tAcc: 83.00\n",
      "train epoch: 159 [76928/221852 (35%)]\tLoss: 0.206650\tAcc: 88.00\n",
      "train epoch: 159 [89728/221852 (40%)]\tLoss: 0.151250\tAcc: 80.00\n",
      "train epoch: 159 [102528/221852 (46%)]\tLoss: 0.165188\tAcc: 89.00\n",
      "train epoch: 159 [115328/221852 (52%)]\tLoss: 0.142185\tAcc: 80.00\n",
      "train epoch: 159 [128128/221852 (58%)]\tLoss: 0.279326\tAcc: 87.00\n",
      "train epoch: 159 [140928/221852 (64%)]\tLoss: 0.201714\tAcc: 82.00\n",
      "train epoch: 159 [153728/221852 (69%)]\tLoss: 0.169203\tAcc: 81.00\n",
      "train epoch: 159 [166528/221852 (75%)]\tLoss: 0.209067\tAcc: 84.00\n",
      "train epoch: 159 [179328/221852 (81%)]\tLoss: 0.159589\tAcc: 86.00\n",
      "train epoch: 159 [192128/221852 (87%)]\tLoss: 0.111208\tAcc: 84.00\n",
      "val epoch: 159 [128/221852 (0%)]\tLoss: 0.169123\tAcc: 83.00\n",
      "val epoch: 159 [12928/221852 (6%)]\tLoss: 0.207991\tAcc: 80.00\n",
      "train epoch: 160 [128/221852 (0%)]\tLoss: 0.126158\tAcc: 89.00\n",
      "train epoch: 160 [12928/221852 (6%)]\tLoss: 0.132081\tAcc: 83.00\n",
      "train epoch: 160 [25728/221852 (12%)]\tLoss: 0.213604\tAcc: 84.00\n",
      "train epoch: 160 [38528/221852 (17%)]\tLoss: 0.229458\tAcc: 84.00\n",
      "train epoch: 160 [51328/221852 (23%)]\tLoss: 0.204335\tAcc: 80.00\n",
      "train epoch: 160 [64128/221852 (29%)]\tLoss: 0.185573\tAcc: 78.00\n",
      "train epoch: 160 [76928/221852 (35%)]\tLoss: 0.232590\tAcc: 81.00\n",
      "train epoch: 160 [89728/221852 (40%)]\tLoss: 0.130009\tAcc: 84.00\n",
      "train epoch: 160 [102528/221852 (46%)]\tLoss: 0.219253\tAcc: 77.00\n",
      "train epoch: 160 [115328/221852 (52%)]\tLoss: 0.188667\tAcc: 82.00\n",
      "train epoch: 160 [128128/221852 (58%)]\tLoss: 0.163401\tAcc: 80.00\n",
      "train epoch: 160 [140928/221852 (64%)]\tLoss: 0.248582\tAcc: 80.00\n",
      "train epoch: 160 [153728/221852 (69%)]\tLoss: 0.226314\tAcc: 77.00\n",
      "train epoch: 160 [166528/221852 (75%)]\tLoss: 0.169138\tAcc: 83.00\n",
      "train epoch: 160 [179328/221852 (81%)]\tLoss: 0.172295\tAcc: 88.00\n",
      "train epoch: 160 [192128/221852 (87%)]\tLoss: 0.098644\tAcc: 79.00\n",
      "val epoch: 160 [128/221852 (0%)]\tLoss: 0.189184\tAcc: 78.00\n",
      "val epoch: 160 [12928/221852 (6%)]\tLoss: 0.225210\tAcc: 75.00\n",
      "train epoch: 161 [128/221852 (0%)]\tLoss: 0.241287\tAcc: 79.00\n",
      "train epoch: 161 [12928/221852 (6%)]\tLoss: 0.285148\tAcc: 82.00\n",
      "train epoch: 161 [25728/221852 (12%)]\tLoss: 0.178245\tAcc: 84.00\n",
      "train epoch: 161 [38528/221852 (17%)]\tLoss: 0.213133\tAcc: 80.00\n",
      "train epoch: 161 [51328/221852 (23%)]\tLoss: 0.162130\tAcc: 82.00\n",
      "train epoch: 161 [64128/221852 (29%)]\tLoss: 0.249265\tAcc: 88.00\n",
      "train epoch: 161 [76928/221852 (35%)]\tLoss: 0.227755\tAcc: 80.00\n",
      "train epoch: 161 [89728/221852 (40%)]\tLoss: 0.245428\tAcc: 80.00\n",
      "train epoch: 161 [102528/221852 (46%)]\tLoss: 0.237841\tAcc: 76.00\n",
      "train epoch: 161 [115328/221852 (52%)]\tLoss: 0.135536\tAcc: 85.00\n",
      "train epoch: 161 [128128/221852 (58%)]\tLoss: 0.260177\tAcc: 82.00\n",
      "train epoch: 161 [140928/221852 (64%)]\tLoss: 0.172637\tAcc: 84.00\n",
      "train epoch: 161 [153728/221852 (69%)]\tLoss: 0.237622\tAcc: 80.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 161 [166528/221852 (75%)]\tLoss: 0.092094\tAcc: 88.00\n",
      "train epoch: 161 [179328/221852 (81%)]\tLoss: 0.229502\tAcc: 78.00\n",
      "train epoch: 161 [192128/221852 (87%)]\tLoss: 0.344448\tAcc: 80.00\n",
      "val epoch: 161 [128/221852 (0%)]\tLoss: 0.229838\tAcc: 81.00\n",
      "val epoch: 161 [12928/221852 (6%)]\tLoss: 0.291770\tAcc: 75.00\n",
      "train epoch: 162 [128/221852 (0%)]\tLoss: 0.314760\tAcc: 77.00\n",
      "train epoch: 162 [12928/221852 (6%)]\tLoss: 0.177851\tAcc: 82.00\n",
      "train epoch: 162 [25728/221852 (12%)]\tLoss: 0.174838\tAcc: 82.00\n",
      "train epoch: 162 [38528/221852 (17%)]\tLoss: 0.180604\tAcc: 80.00\n",
      "train epoch: 162 [51328/221852 (23%)]\tLoss: 0.173160\tAcc: 80.00\n",
      "train epoch: 162 [64128/221852 (29%)]\tLoss: 0.176511\tAcc: 80.00\n",
      "train epoch: 162 [76928/221852 (35%)]\tLoss: 0.191384\tAcc: 87.00\n",
      "train epoch: 162 [89728/221852 (40%)]\tLoss: 0.178579\tAcc: 88.00\n",
      "train epoch: 162 [102528/221852 (46%)]\tLoss: 0.208897\tAcc: 79.00\n",
      "train epoch: 162 [115328/221852 (52%)]\tLoss: 0.180919\tAcc: 80.00\n",
      "train epoch: 162 [128128/221852 (58%)]\tLoss: 0.297011\tAcc: 87.00\n",
      "train epoch: 162 [140928/221852 (64%)]\tLoss: 0.125126\tAcc: 84.00\n",
      "train epoch: 162 [153728/221852 (69%)]\tLoss: 0.108960\tAcc: 83.00\n",
      "train epoch: 162 [166528/221852 (75%)]\tLoss: 0.212301\tAcc: 83.00\n",
      "train epoch: 162 [179328/221852 (81%)]\tLoss: 0.127231\tAcc: 87.00\n",
      "train epoch: 162 [192128/221852 (87%)]\tLoss: 0.291527\tAcc: 74.00\n",
      "val epoch: 162 [128/221852 (0%)]\tLoss: 0.228871\tAcc: 74.00\n",
      "val epoch: 162 [12928/221852 (6%)]\tLoss: 0.276136\tAcc: 82.00\n",
      "train epoch: 163 [128/221852 (0%)]\tLoss: 0.290121\tAcc: 80.00\n",
      "train epoch: 163 [12928/221852 (6%)]\tLoss: 0.186561\tAcc: 80.00\n",
      "train epoch: 163 [25728/221852 (12%)]\tLoss: 0.135773\tAcc: 84.00\n",
      "train epoch: 163 [38528/221852 (17%)]\tLoss: 0.164790\tAcc: 84.00\n",
      "train epoch: 163 [51328/221852 (23%)]\tLoss: 0.210847\tAcc: 82.00\n",
      "train epoch: 163 [64128/221852 (29%)]\tLoss: 0.157442\tAcc: 84.00\n",
      "train epoch: 163 [76928/221852 (35%)]\tLoss: 0.230920\tAcc: 78.00\n",
      "train epoch: 163 [89728/221852 (40%)]\tLoss: 0.203527\tAcc: 79.00\n",
      "train epoch: 163 [102528/221852 (46%)]\tLoss: 0.204268\tAcc: 80.00\n",
      "train epoch: 163 [115328/221852 (52%)]\tLoss: 0.217390\tAcc: 84.00\n",
      "train epoch: 163 [128128/221852 (58%)]\tLoss: 0.182600\tAcc: 81.00\n",
      "train epoch: 163 [140928/221852 (64%)]\tLoss: 0.186832\tAcc: 82.00\n",
      "train epoch: 163 [153728/221852 (69%)]\tLoss: 0.136168\tAcc: 78.00\n",
      "train epoch: 163 [166528/221852 (75%)]\tLoss: 0.145760\tAcc: 80.00\n",
      "train epoch: 163 [179328/221852 (81%)]\tLoss: 0.208103\tAcc: 80.00\n",
      "train epoch: 163 [192128/221852 (87%)]\tLoss: 0.104016\tAcc: 83.00\n",
      "val epoch: 163 [128/221852 (0%)]\tLoss: 0.097523\tAcc: 89.00\n",
      "val epoch: 163 [12928/221852 (6%)]\tLoss: 0.245406\tAcc: 77.00\n",
      "train epoch: 164 [128/221852 (0%)]\tLoss: 0.150307\tAcc: 78.00\n",
      "train epoch: 164 [12928/221852 (6%)]\tLoss: 0.192102\tAcc: 80.00\n",
      "train epoch: 164 [25728/221852 (12%)]\tLoss: 0.172013\tAcc: 83.00\n",
      "train epoch: 164 [38528/221852 (17%)]\tLoss: 0.201015\tAcc: 86.00\n",
      "train epoch: 164 [51328/221852 (23%)]\tLoss: 0.187964\tAcc: 85.00\n",
      "train epoch: 164 [64128/221852 (29%)]\tLoss: 0.139238\tAcc: 84.00\n",
      "train epoch: 164 [76928/221852 (35%)]\tLoss: 0.191210\tAcc: 78.00\n",
      "train epoch: 164 [89728/221852 (40%)]\tLoss: 0.144004\tAcc: 84.00\n",
      "train epoch: 164 [102528/221852 (46%)]\tLoss: 0.153799\tAcc: 81.00\n",
      "train epoch: 164 [115328/221852 (52%)]\tLoss: 0.132312\tAcc: 84.00\n",
      "train epoch: 164 [128128/221852 (58%)]\tLoss: 0.215257\tAcc: 80.00\n",
      "train epoch: 164 [140928/221852 (64%)]\tLoss: 0.209327\tAcc: 81.00\n",
      "train epoch: 164 [153728/221852 (69%)]\tLoss: 0.172808\tAcc: 81.00\n",
      "train epoch: 164 [166528/221852 (75%)]\tLoss: 0.138501\tAcc: 86.00\n",
      "train epoch: 164 [179328/221852 (81%)]\tLoss: 0.137333\tAcc: 77.00\n",
      "train epoch: 164 [192128/221852 (87%)]\tLoss: 0.201481\tAcc: 80.00\n",
      "val epoch: 164 [128/221852 (0%)]\tLoss: 0.147895\tAcc: 85.00\n",
      "val epoch: 164 [12928/221852 (6%)]\tLoss: 0.180910\tAcc: 76.00\n",
      "train epoch: 165 [128/221852 (0%)]\tLoss: 0.180489\tAcc: 85.00\n",
      "train epoch: 165 [12928/221852 (6%)]\tLoss: 0.150401\tAcc: 85.00\n",
      "train epoch: 165 [25728/221852 (12%)]\tLoss: 0.196197\tAcc: 80.00\n",
      "train epoch: 165 [38528/221852 (17%)]\tLoss: 0.125127\tAcc: 80.00\n",
      "train epoch: 165 [51328/221852 (23%)]\tLoss: 0.148516\tAcc: 91.00\n",
      "train epoch: 165 [64128/221852 (29%)]\tLoss: 0.165413\tAcc: 82.00\n",
      "train epoch: 165 [76928/221852 (35%)]\tLoss: 0.092239\tAcc: 87.00\n",
      "train epoch: 165 [89728/221852 (40%)]\tLoss: 0.180542\tAcc: 84.00\n",
      "train epoch: 165 [102528/221852 (46%)]\tLoss: 0.134823\tAcc: 88.00\n",
      "train epoch: 165 [115328/221852 (52%)]\tLoss: 0.206564\tAcc: 79.00\n",
      "train epoch: 165 [128128/221852 (58%)]\tLoss: 0.315063\tAcc: 80.00\n",
      "train epoch: 165 [140928/221852 (64%)]\tLoss: 0.245881\tAcc: 81.00\n",
      "train epoch: 165 [153728/221852 (69%)]\tLoss: 0.152884\tAcc: 84.00\n",
      "train epoch: 165 [166528/221852 (75%)]\tLoss: 0.135438\tAcc: 77.00\n",
      "train epoch: 165 [179328/221852 (81%)]\tLoss: 0.186399\tAcc: 84.00\n",
      "train epoch: 165 [192128/221852 (87%)]\tLoss: 0.128907\tAcc: 87.00\n",
      "val epoch: 165 [128/221852 (0%)]\tLoss: 0.193016\tAcc: 84.00\n",
      "val epoch: 165 [12928/221852 (6%)]\tLoss: 0.126813\tAcc: 84.00\n",
      "train epoch: 166 [128/221852 (0%)]\tLoss: 0.111607\tAcc: 89.00\n",
      "train epoch: 166 [12928/221852 (6%)]\tLoss: 0.350930\tAcc: 80.00\n",
      "train epoch: 166 [25728/221852 (12%)]\tLoss: 0.186261\tAcc: 75.00\n",
      "train epoch: 166 [38528/221852 (17%)]\tLoss: 0.150913\tAcc: 80.00\n",
      "train epoch: 166 [51328/221852 (23%)]\tLoss: 0.165874\tAcc: 82.00\n",
      "train epoch: 166 [64128/221852 (29%)]\tLoss: 0.227292\tAcc: 86.00\n",
      "train epoch: 166 [76928/221852 (35%)]\tLoss: 0.159750\tAcc: 84.00\n",
      "train epoch: 166 [89728/221852 (40%)]\tLoss: 0.157776\tAcc: 85.00\n",
      "train epoch: 166 [102528/221852 (46%)]\tLoss: 0.174925\tAcc: 83.00\n",
      "train epoch: 166 [115328/221852 (52%)]\tLoss: 0.124675\tAcc: 87.00\n",
      "train epoch: 166 [128128/221852 (58%)]\tLoss: 0.146763\tAcc: 77.00\n",
      "train epoch: 166 [140928/221852 (64%)]\tLoss: 0.126179\tAcc: 80.00\n",
      "train epoch: 166 [153728/221852 (69%)]\tLoss: 0.085549\tAcc: 88.00\n",
      "train epoch: 166 [166528/221852 (75%)]\tLoss: 0.165671\tAcc: 81.00\n",
      "train epoch: 166 [179328/221852 (81%)]\tLoss: 0.190951\tAcc: 82.00\n",
      "train epoch: 166 [192128/221852 (87%)]\tLoss: 0.203853\tAcc: 75.00\n",
      "val epoch: 166 [128/221852 (0%)]\tLoss: 0.189388\tAcc: 81.00\n",
      "val epoch: 166 [12928/221852 (6%)]\tLoss: 0.202484\tAcc: 85.00\n",
      "train epoch: 167 [128/221852 (0%)]\tLoss: 0.211013\tAcc: 85.00\n",
      "train epoch: 167 [12928/221852 (6%)]\tLoss: 0.153638\tAcc: 82.00\n",
      "train epoch: 167 [25728/221852 (12%)]\tLoss: 0.422074\tAcc: 80.00\n",
      "train epoch: 167 [38528/221852 (17%)]\tLoss: 0.211276\tAcc: 80.00\n",
      "train epoch: 167 [51328/221852 (23%)]\tLoss: 0.241912\tAcc: 82.00\n",
      "train epoch: 167 [64128/221852 (29%)]\tLoss: 0.145159\tAcc: 87.00\n",
      "train epoch: 167 [76928/221852 (35%)]\tLoss: 0.187800\tAcc: 85.00\n",
      "train epoch: 167 [89728/221852 (40%)]\tLoss: 0.140628\tAcc: 86.00\n",
      "train epoch: 167 [102528/221852 (46%)]\tLoss: 0.162746\tAcc: 79.00\n",
      "train epoch: 167 [115328/221852 (52%)]\tLoss: 0.214813\tAcc: 85.00\n",
      "train epoch: 167 [128128/221852 (58%)]\tLoss: 0.251961\tAcc: 80.00\n",
      "train epoch: 167 [140928/221852 (64%)]\tLoss: 0.230919\tAcc: 89.00\n",
      "train epoch: 167 [153728/221852 (69%)]\tLoss: 0.173131\tAcc: 84.00\n",
      "train epoch: 167 [166528/221852 (75%)]\tLoss: 0.281404\tAcc: 81.00\n",
      "train epoch: 167 [179328/221852 (81%)]\tLoss: 0.233289\tAcc: 77.00\n",
      "train epoch: 167 [192128/221852 (87%)]\tLoss: 0.148672\tAcc: 79.00\n",
      "val epoch: 167 [128/221852 (0%)]\tLoss: 0.263261\tAcc: 80.00\n",
      "val epoch: 167 [12928/221852 (6%)]\tLoss: 0.238034\tAcc: 80.00\n",
      "train epoch: 168 [128/221852 (0%)]\tLoss: 0.228087\tAcc: 78.00\n",
      "train epoch: 168 [12928/221852 (6%)]\tLoss: 0.178395\tAcc: 80.00\n",
      "train epoch: 168 [25728/221852 (12%)]\tLoss: 0.105541\tAcc: 83.00\n",
      "train epoch: 168 [38528/221852 (17%)]\tLoss: 0.267532\tAcc: 80.00\n",
      "train epoch: 168 [51328/221852 (23%)]\tLoss: 0.358828\tAcc: 73.00\n",
      "train epoch: 168 [64128/221852 (29%)]\tLoss: 0.163617\tAcc: 88.00\n",
      "train epoch: 168 [76928/221852 (35%)]\tLoss: 0.193731\tAcc: 80.00\n",
      "train epoch: 168 [89728/221852 (40%)]\tLoss: 0.119156\tAcc: 78.00\n",
      "train epoch: 168 [102528/221852 (46%)]\tLoss: 0.207118\tAcc: 84.00\n",
      "train epoch: 168 [115328/221852 (52%)]\tLoss: 0.150240\tAcc: 80.00\n",
      "train epoch: 168 [128128/221852 (58%)]\tLoss: 0.159883\tAcc: 84.00\n",
      "train epoch: 168 [140928/221852 (64%)]\tLoss: 0.145954\tAcc: 89.00\n",
      "train epoch: 168 [153728/221852 (69%)]\tLoss: 0.249497\tAcc: 87.00\n",
      "train epoch: 168 [166528/221852 (75%)]\tLoss: 0.164287\tAcc: 84.00\n",
      "train epoch: 168 [179328/221852 (81%)]\tLoss: 0.137934\tAcc: 84.00\n",
      "train epoch: 168 [192128/221852 (87%)]\tLoss: 0.109086\tAcc: 85.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 168 [128/221852 (0%)]\tLoss: 0.160448\tAcc: 82.00\n",
      "val epoch: 168 [12928/221852 (6%)]\tLoss: 0.198469\tAcc: 87.00\n",
      "train epoch: 169 [128/221852 (0%)]\tLoss: 0.300676\tAcc: 81.00\n",
      "train epoch: 169 [12928/221852 (6%)]\tLoss: 0.209253\tAcc: 80.00\n",
      "train epoch: 169 [25728/221852 (12%)]\tLoss: 0.148475\tAcc: 79.00\n",
      "train epoch: 169 [38528/221852 (17%)]\tLoss: 0.214218\tAcc: 80.00\n",
      "train epoch: 169 [51328/221852 (23%)]\tLoss: 0.314400\tAcc: 78.00\n",
      "train epoch: 169 [64128/221852 (29%)]\tLoss: 0.163871\tAcc: 86.00\n",
      "train epoch: 169 [76928/221852 (35%)]\tLoss: 0.182859\tAcc: 84.00\n",
      "train epoch: 169 [89728/221852 (40%)]\tLoss: 0.265366\tAcc: 72.00\n",
      "train epoch: 169 [102528/221852 (46%)]\tLoss: 0.205402\tAcc: 82.00\n",
      "train epoch: 169 [115328/221852 (52%)]\tLoss: 0.144941\tAcc: 84.00\n",
      "train epoch: 169 [128128/221852 (58%)]\tLoss: 0.127886\tAcc: 86.00\n",
      "train epoch: 169 [140928/221852 (64%)]\tLoss: 0.128084\tAcc: 86.00\n",
      "train epoch: 169 [153728/221852 (69%)]\tLoss: 0.207099\tAcc: 76.00\n",
      "train epoch: 169 [166528/221852 (75%)]\tLoss: 0.098671\tAcc: 88.00\n",
      "train epoch: 169 [179328/221852 (81%)]\tLoss: 0.218865\tAcc: 83.00\n",
      "train epoch: 169 [192128/221852 (87%)]\tLoss: 0.164756\tAcc: 82.00\n",
      "val epoch: 169 [128/221852 (0%)]\tLoss: 0.163302\tAcc: 83.00\n",
      "val epoch: 169 [12928/221852 (6%)]\tLoss: 0.185802\tAcc: 77.00\n",
      "train epoch: 170 [128/221852 (0%)]\tLoss: 0.168600\tAcc: 88.00\n",
      "train epoch: 170 [12928/221852 (6%)]\tLoss: 0.220449\tAcc: 84.00\n",
      "train epoch: 170 [25728/221852 (12%)]\tLoss: 0.160240\tAcc: 87.00\n",
      "train epoch: 170 [38528/221852 (17%)]\tLoss: 0.181787\tAcc: 80.00\n",
      "train epoch: 170 [51328/221852 (23%)]\tLoss: 0.166253\tAcc: 88.00\n",
      "train epoch: 170 [64128/221852 (29%)]\tLoss: 0.146998\tAcc: 85.00\n",
      "train epoch: 170 [76928/221852 (35%)]\tLoss: 0.224171\tAcc: 80.00\n",
      "train epoch: 170 [89728/221852 (40%)]\tLoss: 0.211531\tAcc: 82.00\n",
      "train epoch: 170 [102528/221852 (46%)]\tLoss: 0.192911\tAcc: 81.00\n",
      "train epoch: 170 [115328/221852 (52%)]\tLoss: 0.245052\tAcc: 81.00\n",
      "train epoch: 170 [128128/221852 (58%)]\tLoss: 0.210269\tAcc: 80.00\n",
      "train epoch: 170 [140928/221852 (64%)]\tLoss: 0.144811\tAcc: 88.00\n",
      "train epoch: 170 [153728/221852 (69%)]\tLoss: 0.221331\tAcc: 79.00\n",
      "train epoch: 170 [166528/221852 (75%)]\tLoss: 0.157539\tAcc: 84.00\n",
      "train epoch: 170 [179328/221852 (81%)]\tLoss: 0.138240\tAcc: 84.00\n",
      "train epoch: 170 [192128/221852 (87%)]\tLoss: 0.149102\tAcc: 83.00\n",
      "val epoch: 170 [128/221852 (0%)]\tLoss: 0.165816\tAcc: 78.00\n",
      "val epoch: 170 [12928/221852 (6%)]\tLoss: 0.091476\tAcc: 87.00\n",
      "train epoch: 171 [128/221852 (0%)]\tLoss: 0.201601\tAcc: 88.00\n",
      "train epoch: 171 [12928/221852 (6%)]\tLoss: 0.126930\tAcc: 85.00\n",
      "train epoch: 171 [25728/221852 (12%)]\tLoss: 0.106598\tAcc: 88.00\n",
      "train epoch: 171 [38528/221852 (17%)]\tLoss: 0.117986\tAcc: 88.00\n",
      "train epoch: 171 [51328/221852 (23%)]\tLoss: 0.157533\tAcc: 87.00\n",
      "train epoch: 171 [64128/221852 (29%)]\tLoss: 0.244952\tAcc: 82.00\n",
      "train epoch: 171 [76928/221852 (35%)]\tLoss: 0.135465\tAcc: 88.00\n",
      "train epoch: 171 [89728/221852 (40%)]\tLoss: 0.099115\tAcc: 84.00\n",
      "train epoch: 171 [102528/221852 (46%)]\tLoss: 0.244655\tAcc: 85.00\n",
      "train epoch: 171 [115328/221852 (52%)]\tLoss: 0.121663\tAcc: 84.00\n",
      "train epoch: 171 [128128/221852 (58%)]\tLoss: 0.114385\tAcc: 87.00\n",
      "train epoch: 171 [140928/221852 (64%)]\tLoss: 0.151800\tAcc: 84.00\n",
      "train epoch: 171 [153728/221852 (69%)]\tLoss: 0.137280\tAcc: 84.00\n",
      "train epoch: 171 [166528/221852 (75%)]\tLoss: 0.210039\tAcc: 80.00\n",
      "train epoch: 171 [179328/221852 (81%)]\tLoss: 0.134334\tAcc: 88.00\n",
      "train epoch: 171 [192128/221852 (87%)]\tLoss: 0.249313\tAcc: 73.00\n",
      "val epoch: 171 [128/221852 (0%)]\tLoss: 0.385081\tAcc: 89.00\n",
      "val epoch: 171 [12928/221852 (6%)]\tLoss: 0.550284\tAcc: 84.00\n",
      "train epoch: 172 [128/221852 (0%)]\tLoss: 0.514683\tAcc: 80.00\n",
      "train epoch: 172 [12928/221852 (6%)]\tLoss: 0.156424\tAcc: 87.00\n",
      "train epoch: 172 [25728/221852 (12%)]\tLoss: 1.343592\tAcc: 82.00\n",
      "train epoch: 172 [38528/221852 (17%)]\tLoss: 0.238524\tAcc: 77.00\n",
      "train epoch: 172 [51328/221852 (23%)]\tLoss: 0.133065\tAcc: 80.00\n",
      "train epoch: 172 [64128/221852 (29%)]\tLoss: 0.216053\tAcc: 76.00\n",
      "train epoch: 172 [76928/221852 (35%)]\tLoss: 0.232969\tAcc: 75.00\n",
      "train epoch: 172 [89728/221852 (40%)]\tLoss: 0.201873\tAcc: 84.00\n",
      "train epoch: 172 [102528/221852 (46%)]\tLoss: 0.222958\tAcc: 88.00\n",
      "train epoch: 172 [115328/221852 (52%)]\tLoss: 0.175844\tAcc: 82.00\n",
      "train epoch: 172 [128128/221852 (58%)]\tLoss: 0.198416\tAcc: 88.00\n",
      "train epoch: 172 [140928/221852 (64%)]\tLoss: 0.119003\tAcc: 82.00\n",
      "train epoch: 172 [153728/221852 (69%)]\tLoss: 0.154016\tAcc: 83.00\n",
      "train epoch: 172 [166528/221852 (75%)]\tLoss: 0.150770\tAcc: 88.00\n",
      "train epoch: 172 [179328/221852 (81%)]\tLoss: 0.196561\tAcc: 84.00\n",
      "train epoch: 172 [192128/221852 (87%)]\tLoss: 0.155046\tAcc: 80.00\n",
      "val epoch: 172 [128/221852 (0%)]\tLoss: 0.149166\tAcc: 88.00\n",
      "val epoch: 172 [12928/221852 (6%)]\tLoss: 0.149185\tAcc: 79.00\n",
      "train epoch: 173 [128/221852 (0%)]\tLoss: 0.094493\tAcc: 86.00\n",
      "train epoch: 173 [12928/221852 (6%)]\tLoss: 0.180950\tAcc: 84.00\n",
      "train epoch: 173 [25728/221852 (12%)]\tLoss: 0.155571\tAcc: 80.00\n",
      "train epoch: 173 [38528/221852 (17%)]\tLoss: 0.245785\tAcc: 76.00\n",
      "train epoch: 173 [51328/221852 (23%)]\tLoss: 0.137565\tAcc: 88.00\n",
      "train epoch: 173 [64128/221852 (29%)]\tLoss: 0.216697\tAcc: 82.00\n",
      "train epoch: 173 [76928/221852 (35%)]\tLoss: 0.212988\tAcc: 85.00\n",
      "train epoch: 173 [89728/221852 (40%)]\tLoss: 0.238136\tAcc: 84.00\n",
      "train epoch: 173 [102528/221852 (46%)]\tLoss: 0.209545\tAcc: 79.00\n",
      "train epoch: 173 [115328/221852 (52%)]\tLoss: 0.209762\tAcc: 80.00\n",
      "train epoch: 173 [128128/221852 (58%)]\tLoss: 0.114458\tAcc: 89.00\n",
      "train epoch: 173 [140928/221852 (64%)]\tLoss: 0.126333\tAcc: 81.00\n",
      "train epoch: 173 [153728/221852 (69%)]\tLoss: 0.139083\tAcc: 84.00\n",
      "train epoch: 173 [166528/221852 (75%)]\tLoss: 0.165687\tAcc: 86.00\n",
      "train epoch: 173 [179328/221852 (81%)]\tLoss: 0.164996\tAcc: 77.00\n",
      "train epoch: 173 [192128/221852 (87%)]\tLoss: 0.226159\tAcc: 81.00\n",
      "val epoch: 173 [128/221852 (0%)]\tLoss: 0.200691\tAcc: 83.00\n",
      "val epoch: 173 [12928/221852 (6%)]\tLoss: 0.221643\tAcc: 86.00\n",
      "train epoch: 174 [128/221852 (0%)]\tLoss: 0.166509\tAcc: 84.00\n",
      "train epoch: 174 [12928/221852 (6%)]\tLoss: 0.144960\tAcc: 83.00\n",
      "train epoch: 174 [25728/221852 (12%)]\tLoss: 0.157670\tAcc: 80.00\n",
      "train epoch: 174 [38528/221852 (17%)]\tLoss: 0.237913\tAcc: 78.00\n",
      "train epoch: 174 [51328/221852 (23%)]\tLoss: 0.137897\tAcc: 86.00\n",
      "train epoch: 174 [64128/221852 (29%)]\tLoss: 0.161964\tAcc: 83.00\n",
      "train epoch: 174 [76928/221852 (35%)]\tLoss: 0.162676\tAcc: 74.00\n",
      "train epoch: 174 [89728/221852 (40%)]\tLoss: 0.140069\tAcc: 80.00\n",
      "train epoch: 174 [102528/221852 (46%)]\tLoss: 0.249177\tAcc: 79.00\n",
      "train epoch: 174 [115328/221852 (52%)]\tLoss: 0.268145\tAcc: 83.00\n",
      "train epoch: 174 [128128/221852 (58%)]\tLoss: 0.084531\tAcc: 84.00\n",
      "train epoch: 174 [140928/221852 (64%)]\tLoss: 0.135984\tAcc: 88.00\n",
      "train epoch: 174 [153728/221852 (69%)]\tLoss: 0.243890\tAcc: 81.00\n",
      "train epoch: 174 [166528/221852 (75%)]\tLoss: 0.204701\tAcc: 79.00\n",
      "train epoch: 174 [179328/221852 (81%)]\tLoss: 0.156307\tAcc: 88.00\n",
      "train epoch: 174 [192128/221852 (87%)]\tLoss: 0.169400\tAcc: 84.00\n",
      "val epoch: 174 [128/221852 (0%)]\tLoss: 0.124657\tAcc: 82.00\n",
      "val epoch: 174 [12928/221852 (6%)]\tLoss: 0.128508\tAcc: 81.00\n",
      "train epoch: 175 [128/221852 (0%)]\tLoss: 0.133654\tAcc: 83.00\n",
      "train epoch: 175 [12928/221852 (6%)]\tLoss: 0.198164\tAcc: 82.00\n",
      "train epoch: 175 [25728/221852 (12%)]\tLoss: 0.126807\tAcc: 88.00\n",
      "train epoch: 175 [38528/221852 (17%)]\tLoss: 0.186820\tAcc: 89.00\n",
      "train epoch: 175 [51328/221852 (23%)]\tLoss: 0.217516\tAcc: 81.00\n",
      "train epoch: 175 [64128/221852 (29%)]\tLoss: 0.431633\tAcc: 82.00\n",
      "train epoch: 175 [76928/221852 (35%)]\tLoss: 0.267323\tAcc: 73.00\n",
      "train epoch: 175 [89728/221852 (40%)]\tLoss: 0.220269\tAcc: 80.00\n",
      "train epoch: 175 [102528/221852 (46%)]\tLoss: 0.165655\tAcc: 82.00\n",
      "train epoch: 175 [115328/221852 (52%)]\tLoss: 0.194031\tAcc: 84.00\n",
      "train epoch: 175 [128128/221852 (58%)]\tLoss: 0.141953\tAcc: 82.00\n",
      "train epoch: 175 [140928/221852 (64%)]\tLoss: 0.269274\tAcc: 76.00\n",
      "train epoch: 175 [153728/221852 (69%)]\tLoss: 0.187259\tAcc: 73.00\n",
      "train epoch: 175 [166528/221852 (75%)]\tLoss: 0.190732\tAcc: 76.00\n",
      "train epoch: 175 [179328/221852 (81%)]\tLoss: 0.163197\tAcc: 84.00\n",
      "train epoch: 175 [192128/221852 (87%)]\tLoss: 0.171506\tAcc: 81.00\n",
      "val epoch: 175 [128/221852 (0%)]\tLoss: 0.167784\tAcc: 88.00\n",
      "val epoch: 175 [12928/221852 (6%)]\tLoss: 0.205230\tAcc: 77.00\n",
      "train epoch: 176 [128/221852 (0%)]\tLoss: 0.135499\tAcc: 86.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 176 [12928/221852 (6%)]\tLoss: 0.113751\tAcc: 86.00\n",
      "train epoch: 176 [25728/221852 (12%)]\tLoss: 0.183285\tAcc: 84.00\n",
      "train epoch: 176 [38528/221852 (17%)]\tLoss: 0.245389\tAcc: 81.00\n",
      "train epoch: 176 [51328/221852 (23%)]\tLoss: 0.218629\tAcc: 88.00\n",
      "train epoch: 176 [64128/221852 (29%)]\tLoss: 0.216464\tAcc: 89.00\n",
      "train epoch: 176 [76928/221852 (35%)]\tLoss: 0.107584\tAcc: 80.00\n",
      "train epoch: 176 [89728/221852 (40%)]\tLoss: 0.171725\tAcc: 82.00\n",
      "train epoch: 176 [102528/221852 (46%)]\tLoss: 0.194186\tAcc: 73.00\n",
      "train epoch: 176 [115328/221852 (52%)]\tLoss: 0.118839\tAcc: 83.00\n",
      "train epoch: 176 [128128/221852 (58%)]\tLoss: 0.142474\tAcc: 81.00\n",
      "train epoch: 176 [140928/221852 (64%)]\tLoss: 0.187663\tAcc: 81.00\n",
      "train epoch: 176 [153728/221852 (69%)]\tLoss: 0.148720\tAcc: 86.00\n",
      "train epoch: 176 [166528/221852 (75%)]\tLoss: 0.181462\tAcc: 80.00\n",
      "train epoch: 176 [179328/221852 (81%)]\tLoss: 0.148628\tAcc: 84.00\n",
      "train epoch: 176 [192128/221852 (87%)]\tLoss: 0.245722\tAcc: 80.00\n",
      "val epoch: 176 [128/221852 (0%)]\tLoss: 0.255048\tAcc: 83.00\n",
      "val epoch: 176 [12928/221852 (6%)]\tLoss: 0.295924\tAcc: 76.00\n",
      "train epoch: 177 [128/221852 (0%)]\tLoss: 0.151336\tAcc: 83.00\n",
      "train epoch: 177 [12928/221852 (6%)]\tLoss: 0.128379\tAcc: 87.00\n",
      "train epoch: 177 [25728/221852 (12%)]\tLoss: 0.263555\tAcc: 80.00\n",
      "train epoch: 177 [38528/221852 (17%)]\tLoss: 0.187671\tAcc: 83.00\n",
      "train epoch: 177 [51328/221852 (23%)]\tLoss: 0.146136\tAcc: 85.00\n",
      "train epoch: 177 [64128/221852 (29%)]\tLoss: 0.139850\tAcc: 77.00\n",
      "train epoch: 177 [76928/221852 (35%)]\tLoss: 0.269550\tAcc: 84.00\n",
      "train epoch: 177 [89728/221852 (40%)]\tLoss: 0.110156\tAcc: 88.00\n",
      "train epoch: 177 [102528/221852 (46%)]\tLoss: 0.193352\tAcc: 86.00\n",
      "train epoch: 177 [115328/221852 (52%)]\tLoss: 0.138195\tAcc: 87.00\n",
      "train epoch: 177 [128128/221852 (58%)]\tLoss: 0.193979\tAcc: 83.00\n",
      "train epoch: 177 [140928/221852 (64%)]\tLoss: 0.173805\tAcc: 88.00\n",
      "train epoch: 177 [153728/221852 (69%)]\tLoss: 0.130612\tAcc: 85.00\n",
      "train epoch: 177 [166528/221852 (75%)]\tLoss: 0.179108\tAcc: 82.00\n",
      "train epoch: 177 [179328/221852 (81%)]\tLoss: 0.125720\tAcc: 85.00\n",
      "train epoch: 177 [192128/221852 (87%)]\tLoss: 0.277737\tAcc: 76.00\n",
      "val epoch: 177 [128/221852 (0%)]\tLoss: 0.161675\tAcc: 80.00\n",
      "val epoch: 177 [12928/221852 (6%)]\tLoss: 0.176325\tAcc: 81.00\n",
      "train epoch: 178 [128/221852 (0%)]\tLoss: 0.114709\tAcc: 80.00\n",
      "train epoch: 178 [12928/221852 (6%)]\tLoss: 0.116268\tAcc: 81.00\n",
      "train epoch: 178 [25728/221852 (12%)]\tLoss: 0.145062\tAcc: 86.00\n",
      "train epoch: 178 [38528/221852 (17%)]\tLoss: 0.160925\tAcc: 81.00\n",
      "train epoch: 178 [51328/221852 (23%)]\tLoss: 0.230382\tAcc: 84.00\n",
      "train epoch: 178 [64128/221852 (29%)]\tLoss: 0.217760\tAcc: 75.00\n",
      "train epoch: 178 [76928/221852 (35%)]\tLoss: 0.242990\tAcc: 85.00\n",
      "train epoch: 178 [89728/221852 (40%)]\tLoss: 0.170750\tAcc: 87.00\n",
      "train epoch: 178 [102528/221852 (46%)]\tLoss: 0.162417\tAcc: 84.00\n",
      "train epoch: 178 [115328/221852 (52%)]\tLoss: 0.209931\tAcc: 78.00\n",
      "train epoch: 178 [128128/221852 (58%)]\tLoss: 0.177577\tAcc: 84.00\n",
      "train epoch: 178 [140928/221852 (64%)]\tLoss: 0.181319\tAcc: 87.00\n",
      "train epoch: 178 [153728/221852 (69%)]\tLoss: 0.194045\tAcc: 82.00\n",
      "train epoch: 178 [166528/221852 (75%)]\tLoss: 0.233832\tAcc: 79.00\n",
      "train epoch: 178 [179328/221852 (81%)]\tLoss: 0.168398\tAcc: 79.00\n",
      "train epoch: 178 [192128/221852 (87%)]\tLoss: 0.185037\tAcc: 84.00\n",
      "val epoch: 178 [128/221852 (0%)]\tLoss: 0.153658\tAcc: 81.00\n",
      "val epoch: 178 [12928/221852 (6%)]\tLoss: 0.193712\tAcc: 81.00\n",
      "train epoch: 179 [128/221852 (0%)]\tLoss: 0.175299\tAcc: 85.00\n",
      "train epoch: 179 [12928/221852 (6%)]\tLoss: 0.200574\tAcc: 86.00\n",
      "train epoch: 179 [25728/221852 (12%)]\tLoss: 0.117315\tAcc: 80.00\n",
      "train epoch: 179 [38528/221852 (17%)]\tLoss: 0.144034\tAcc: 82.00\n",
      "train epoch: 179 [51328/221852 (23%)]\tLoss: 0.153852\tAcc: 89.00\n",
      "train epoch: 179 [64128/221852 (29%)]\tLoss: 0.174888\tAcc: 77.00\n",
      "train epoch: 179 [76928/221852 (35%)]\tLoss: 0.227878\tAcc: 80.00\n",
      "train epoch: 179 [89728/221852 (40%)]\tLoss: 0.169479\tAcc: 84.00\n",
      "train epoch: 179 [102528/221852 (46%)]\tLoss: 0.205014\tAcc: 80.00\n",
      "train epoch: 179 [115328/221852 (52%)]\tLoss: 0.201926\tAcc: 81.00\n",
      "train epoch: 179 [128128/221852 (58%)]\tLoss: 0.129897\tAcc: 83.00\n",
      "train epoch: 179 [140928/221852 (64%)]\tLoss: 0.129672\tAcc: 85.00\n",
      "train epoch: 179 [153728/221852 (69%)]\tLoss: 0.275109\tAcc: 82.00\n",
      "train epoch: 179 [166528/221852 (75%)]\tLoss: 0.157928\tAcc: 81.00\n",
      "train epoch: 179 [179328/221852 (81%)]\tLoss: 0.142818\tAcc: 81.00\n",
      "train epoch: 179 [192128/221852 (87%)]\tLoss: 0.153041\tAcc: 86.00\n",
      "val epoch: 179 [128/221852 (0%)]\tLoss: 0.301387\tAcc: 80.00\n",
      "val epoch: 179 [12928/221852 (6%)]\tLoss: 0.088271\tAcc: 85.00\n",
      "train epoch: 180 [128/221852 (0%)]\tLoss: 0.190022\tAcc: 79.00\n",
      "train epoch: 180 [12928/221852 (6%)]\tLoss: 0.208628\tAcc: 80.00\n",
      "train epoch: 180 [25728/221852 (12%)]\tLoss: 0.165825\tAcc: 88.00\n",
      "train epoch: 180 [38528/221852 (17%)]\tLoss: 0.180062\tAcc: 77.00\n",
      "train epoch: 180 [51328/221852 (23%)]\tLoss: 0.130612\tAcc: 86.00\n",
      "train epoch: 180 [64128/221852 (29%)]\tLoss: 0.242280\tAcc: 78.00\n",
      "train epoch: 180 [76928/221852 (35%)]\tLoss: 0.092471\tAcc: 88.00\n",
      "train epoch: 180 [89728/221852 (40%)]\tLoss: 0.170935\tAcc: 83.00\n",
      "train epoch: 180 [102528/221852 (46%)]\tLoss: 0.174944\tAcc: 81.00\n",
      "train epoch: 180 [115328/221852 (52%)]\tLoss: 0.147014\tAcc: 91.00\n",
      "train epoch: 180 [128128/221852 (58%)]\tLoss: 0.134511\tAcc: 82.00\n",
      "train epoch: 180 [140928/221852 (64%)]\tLoss: 0.136368\tAcc: 81.00\n",
      "train epoch: 180 [153728/221852 (69%)]\tLoss: 0.085442\tAcc: 88.00\n",
      "train epoch: 180 [166528/221852 (75%)]\tLoss: 0.116832\tAcc: 88.00\n",
      "train epoch: 180 [179328/221852 (81%)]\tLoss: 0.249604\tAcc: 80.00\n",
      "train epoch: 180 [192128/221852 (87%)]\tLoss: 0.120066\tAcc: 88.00\n",
      "val epoch: 180 [128/221852 (0%)]\tLoss: 0.158929\tAcc: 77.00\n",
      "val epoch: 180 [12928/221852 (6%)]\tLoss: 0.143580\tAcc: 83.00\n",
      "train epoch: 181 [128/221852 (0%)]\tLoss: 0.130952\tAcc: 89.00\n",
      "train epoch: 181 [12928/221852 (6%)]\tLoss: 0.136471\tAcc: 84.00\n",
      "train epoch: 181 [25728/221852 (12%)]\tLoss: 0.135437\tAcc: 88.00\n",
      "train epoch: 181 [38528/221852 (17%)]\tLoss: 0.254659\tAcc: 77.00\n",
      "train epoch: 181 [51328/221852 (23%)]\tLoss: 0.201134\tAcc: 79.00\n",
      "train epoch: 181 [64128/221852 (29%)]\tLoss: 0.171084\tAcc: 81.00\n",
      "train epoch: 181 [76928/221852 (35%)]\tLoss: 0.189196\tAcc: 83.00\n",
      "train epoch: 181 [89728/221852 (40%)]\tLoss: 0.171381\tAcc: 80.00\n",
      "train epoch: 181 [102528/221852 (46%)]\tLoss: 0.098723\tAcc: 80.00\n",
      "train epoch: 181 [115328/221852 (52%)]\tLoss: 0.139833\tAcc: 81.00\n",
      "train epoch: 181 [128128/221852 (58%)]\tLoss: 0.186762\tAcc: 84.00\n",
      "train epoch: 181 [140928/221852 (64%)]\tLoss: 0.220343\tAcc: 81.00\n",
      "train epoch: 181 [153728/221852 (69%)]\tLoss: 0.164277\tAcc: 80.00\n",
      "train epoch: 181 [166528/221852 (75%)]\tLoss: 0.144169\tAcc: 81.00\n",
      "train epoch: 181 [179328/221852 (81%)]\tLoss: 0.135275\tAcc: 85.00\n",
      "train epoch: 181 [192128/221852 (87%)]\tLoss: 0.167378\tAcc: 88.00\n",
      "val epoch: 181 [128/221852 (0%)]\tLoss: 0.137206\tAcc: 88.00\n",
      "val epoch: 181 [12928/221852 (6%)]\tLoss: 0.313245\tAcc: 78.00\n",
      "train epoch: 182 [128/221852 (0%)]\tLoss: 0.186498\tAcc: 86.00\n",
      "train epoch: 182 [12928/221852 (6%)]\tLoss: 0.271114\tAcc: 81.00\n",
      "train epoch: 182 [25728/221852 (12%)]\tLoss: 0.186964\tAcc: 80.00\n",
      "train epoch: 182 [38528/221852 (17%)]\tLoss: 0.185979\tAcc: 84.00\n",
      "train epoch: 182 [51328/221852 (23%)]\tLoss: 0.170149\tAcc: 80.00\n",
      "train epoch: 182 [64128/221852 (29%)]\tLoss: 0.178661\tAcc: 80.00\n",
      "train epoch: 182 [76928/221852 (35%)]\tLoss: 0.155022\tAcc: 83.00\n",
      "train epoch: 182 [89728/221852 (40%)]\tLoss: 0.147376\tAcc: 81.00\n",
      "train epoch: 182 [102528/221852 (46%)]\tLoss: 0.098903\tAcc: 84.00\n",
      "train epoch: 182 [115328/221852 (52%)]\tLoss: 0.114121\tAcc: 82.00\n",
      "train epoch: 182 [128128/221852 (58%)]\tLoss: 0.125124\tAcc: 88.00\n",
      "train epoch: 182 [140928/221852 (64%)]\tLoss: 0.272320\tAcc: 79.00\n",
      "train epoch: 182 [153728/221852 (69%)]\tLoss: 0.265669\tAcc: 82.00\n",
      "train epoch: 182 [166528/221852 (75%)]\tLoss: 0.177309\tAcc: 81.00\n",
      "train epoch: 182 [179328/221852 (81%)]\tLoss: 0.193576\tAcc: 84.00\n",
      "train epoch: 182 [192128/221852 (87%)]\tLoss: 0.197475\tAcc: 77.00\n",
      "val epoch: 182 [128/221852 (0%)]\tLoss: 0.216244\tAcc: 88.00\n",
      "val epoch: 182 [12928/221852 (6%)]\tLoss: 0.232331\tAcc: 79.00\n",
      "train epoch: 183 [128/221852 (0%)]\tLoss: 0.162449\tAcc: 78.00\n",
      "train epoch: 183 [12928/221852 (6%)]\tLoss: 0.256172\tAcc: 79.00\n",
      "train epoch: 183 [25728/221852 (12%)]\tLoss: 0.163140\tAcc: 78.00\n",
      "train epoch: 183 [38528/221852 (17%)]\tLoss: 0.108195\tAcc: 88.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 183 [51328/221852 (23%)]\tLoss: 0.106245\tAcc: 91.00\n",
      "train epoch: 183 [64128/221852 (29%)]\tLoss: 0.145090\tAcc: 86.00\n",
      "train epoch: 183 [76928/221852 (35%)]\tLoss: 0.264729\tAcc: 80.00\n",
      "train epoch: 183 [89728/221852 (40%)]\tLoss: 0.154780\tAcc: 81.00\n",
      "train epoch: 183 [102528/221852 (46%)]\tLoss: 0.614591\tAcc: 77.00\n",
      "train epoch: 183 [115328/221852 (52%)]\tLoss: 0.201025\tAcc: 82.00\n",
      "train epoch: 183 [128128/221852 (58%)]\tLoss: 0.233788\tAcc: 79.00\n",
      "train epoch: 183 [140928/221852 (64%)]\tLoss: 0.280425\tAcc: 82.00\n",
      "train epoch: 183 [153728/221852 (69%)]\tLoss: 0.219367\tAcc: 76.00\n",
      "train epoch: 183 [166528/221852 (75%)]\tLoss: 0.243970\tAcc: 81.00\n",
      "train epoch: 183 [179328/221852 (81%)]\tLoss: 0.168632\tAcc: 85.00\n",
      "train epoch: 183 [192128/221852 (87%)]\tLoss: 0.139385\tAcc: 83.00\n",
      "val epoch: 183 [128/221852 (0%)]\tLoss: 0.132211\tAcc: 84.00\n",
      "val epoch: 183 [12928/221852 (6%)]\tLoss: 0.288303\tAcc: 77.00\n",
      "train epoch: 184 [128/221852 (0%)]\tLoss: 0.119449\tAcc: 85.00\n",
      "train epoch: 184 [12928/221852 (6%)]\tLoss: 0.258133\tAcc: 81.00\n",
      "train epoch: 184 [25728/221852 (12%)]\tLoss: 0.143024\tAcc: 84.00\n",
      "train epoch: 184 [38528/221852 (17%)]\tLoss: 0.220888\tAcc: 86.00\n",
      "train epoch: 184 [51328/221852 (23%)]\tLoss: 0.211097\tAcc: 80.00\n",
      "train epoch: 184 [64128/221852 (29%)]\tLoss: 0.138503\tAcc: 80.00\n",
      "train epoch: 184 [76928/221852 (35%)]\tLoss: 0.156276\tAcc: 86.00\n",
      "train epoch: 184 [89728/221852 (40%)]\tLoss: 0.137302\tAcc: 88.00\n",
      "train epoch: 184 [102528/221852 (46%)]\tLoss: 0.130276\tAcc: 82.00\n",
      "train epoch: 184 [115328/221852 (52%)]\tLoss: 0.214505\tAcc: 78.00\n",
      "train epoch: 184 [128128/221852 (58%)]\tLoss: 0.207617\tAcc: 82.00\n",
      "train epoch: 184 [140928/221852 (64%)]\tLoss: 0.253478\tAcc: 77.00\n",
      "train epoch: 184 [153728/221852 (69%)]\tLoss: 0.158107\tAcc: 85.00\n",
      "train epoch: 184 [166528/221852 (75%)]\tLoss: 0.110434\tAcc: 84.00\n",
      "train epoch: 184 [179328/221852 (81%)]\tLoss: 0.114501\tAcc: 83.00\n",
      "train epoch: 184 [192128/221852 (87%)]\tLoss: 0.223798\tAcc: 80.00\n",
      "val epoch: 184 [128/221852 (0%)]\tLoss: 0.103350\tAcc: 83.00\n",
      "val epoch: 184 [12928/221852 (6%)]\tLoss: 0.181228\tAcc: 76.00\n",
      "train epoch: 185 [128/221852 (0%)]\tLoss: 0.158027\tAcc: 82.00\n",
      "train epoch: 185 [12928/221852 (6%)]\tLoss: 0.177675\tAcc: 86.00\n",
      "train epoch: 185 [25728/221852 (12%)]\tLoss: 0.196612\tAcc: 83.00\n",
      "train epoch: 185 [38528/221852 (17%)]\tLoss: 0.154864\tAcc: 84.00\n",
      "train epoch: 185 [51328/221852 (23%)]\tLoss: 0.140869\tAcc: 83.00\n",
      "train epoch: 185 [64128/221852 (29%)]\tLoss: 0.225930\tAcc: 87.00\n",
      "train epoch: 185 [76928/221852 (35%)]\tLoss: 0.091086\tAcc: 85.00\n",
      "train epoch: 185 [89728/221852 (40%)]\tLoss: 0.172090\tAcc: 80.00\n",
      "train epoch: 185 [102528/221852 (46%)]\tLoss: 0.118084\tAcc: 80.00\n",
      "train epoch: 185 [115328/221852 (52%)]\tLoss: 0.162735\tAcc: 84.00\n",
      "train epoch: 185 [128128/221852 (58%)]\tLoss: 0.167718\tAcc: 85.00\n",
      "train epoch: 185 [140928/221852 (64%)]\tLoss: 0.125014\tAcc: 91.00\n",
      "train epoch: 185 [153728/221852 (69%)]\tLoss: 0.221803\tAcc: 84.00\n",
      "train epoch: 185 [166528/221852 (75%)]\tLoss: 0.203588\tAcc: 82.00\n",
      "train epoch: 185 [179328/221852 (81%)]\tLoss: 0.169923\tAcc: 83.00\n",
      "train epoch: 185 [192128/221852 (87%)]\tLoss: 0.199409\tAcc: 81.00\n",
      "val epoch: 185 [128/221852 (0%)]\tLoss: 0.151504\tAcc: 82.00\n",
      "val epoch: 185 [12928/221852 (6%)]\tLoss: 0.142281\tAcc: 85.00\n",
      "train epoch: 186 [128/221852 (0%)]\tLoss: 0.216861\tAcc: 82.00\n",
      "train epoch: 186 [12928/221852 (6%)]\tLoss: 0.316237\tAcc: 84.00\n",
      "train epoch: 186 [25728/221852 (12%)]\tLoss: 0.219156\tAcc: 80.00\n",
      "train epoch: 186 [38528/221852 (17%)]\tLoss: 0.186685\tAcc: 85.00\n",
      "train epoch: 186 [51328/221852 (23%)]\tLoss: 0.148115\tAcc: 88.00\n",
      "train epoch: 186 [64128/221852 (29%)]\tLoss: 0.193285\tAcc: 88.00\n",
      "train epoch: 186 [76928/221852 (35%)]\tLoss: 0.175468\tAcc: 84.00\n",
      "train epoch: 186 [89728/221852 (40%)]\tLoss: 0.226432\tAcc: 81.00\n",
      "train epoch: 186 [102528/221852 (46%)]\tLoss: 0.121375\tAcc: 84.00\n",
      "train epoch: 186 [115328/221852 (52%)]\tLoss: 0.233729\tAcc: 77.00\n",
      "train epoch: 186 [128128/221852 (58%)]\tLoss: 0.198914\tAcc: 80.00\n",
      "train epoch: 186 [140928/221852 (64%)]\tLoss: 0.183524\tAcc: 84.00\n",
      "train epoch: 186 [153728/221852 (69%)]\tLoss: 0.196743\tAcc: 81.00\n",
      "train epoch: 186 [166528/221852 (75%)]\tLoss: 0.338846\tAcc: 81.00\n",
      "train epoch: 186 [179328/221852 (81%)]\tLoss: 0.108554\tAcc: 82.00\n",
      "train epoch: 186 [192128/221852 (87%)]\tLoss: 0.360520\tAcc: 76.00\n",
      "val epoch: 186 [128/221852 (0%)]\tLoss: 0.174968\tAcc: 87.00\n",
      "val epoch: 186 [12928/221852 (6%)]\tLoss: 0.171526\tAcc: 84.00\n",
      "train epoch: 187 [128/221852 (0%)]\tLoss: 0.190309\tAcc: 84.00\n",
      "train epoch: 187 [12928/221852 (6%)]\tLoss: 0.187841\tAcc: 86.00\n",
      "train epoch: 187 [25728/221852 (12%)]\tLoss: 0.175121\tAcc: 83.00\n",
      "train epoch: 187 [38528/221852 (17%)]\tLoss: 0.126557\tAcc: 77.00\n",
      "train epoch: 187 [51328/221852 (23%)]\tLoss: 0.141032\tAcc: 88.00\n",
      "train epoch: 187 [64128/221852 (29%)]\tLoss: 0.173626\tAcc: 87.00\n",
      "train epoch: 187 [76928/221852 (35%)]\tLoss: 0.191176\tAcc: 83.00\n",
      "train epoch: 187 [89728/221852 (40%)]\tLoss: 0.182749\tAcc: 80.00\n",
      "train epoch: 187 [102528/221852 (46%)]\tLoss: 0.174379\tAcc: 87.00\n",
      "train epoch: 187 [115328/221852 (52%)]\tLoss: 0.277340\tAcc: 86.00\n",
      "train epoch: 187 [128128/221852 (58%)]\tLoss: 0.156602\tAcc: 87.00\n",
      "train epoch: 187 [140928/221852 (64%)]\tLoss: 0.145111\tAcc: 85.00\n",
      "train epoch: 187 [153728/221852 (69%)]\tLoss: 0.147536\tAcc: 85.00\n",
      "train epoch: 187 [166528/221852 (75%)]\tLoss: 0.158555\tAcc: 88.00\n",
      "train epoch: 187 [179328/221852 (81%)]\tLoss: 0.145878\tAcc: 85.00\n",
      "train epoch: 187 [192128/221852 (87%)]\tLoss: 0.141818\tAcc: 81.00\n",
      "val epoch: 187 [128/221852 (0%)]\tLoss: 0.237343\tAcc: 80.00\n",
      "val epoch: 187 [12928/221852 (6%)]\tLoss: 0.208850\tAcc: 81.00\n",
      "train epoch: 188 [128/221852 (0%)]\tLoss: 0.114379\tAcc: 91.00\n",
      "train epoch: 188 [12928/221852 (6%)]\tLoss: 0.133267\tAcc: 84.00\n",
      "train epoch: 188 [25728/221852 (12%)]\tLoss: 0.194833\tAcc: 86.00\n",
      "train epoch: 188 [38528/221852 (17%)]\tLoss: 0.191157\tAcc: 78.00\n",
      "train epoch: 188 [51328/221852 (23%)]\tLoss: 0.153564\tAcc: 83.00\n",
      "train epoch: 188 [64128/221852 (29%)]\tLoss: 0.169290\tAcc: 80.00\n",
      "train epoch: 188 [76928/221852 (35%)]\tLoss: 0.124031\tAcc: 84.00\n",
      "train epoch: 188 [89728/221852 (40%)]\tLoss: 0.115603\tAcc: 84.00\n",
      "train epoch: 188 [102528/221852 (46%)]\tLoss: 0.094155\tAcc: 89.00\n",
      "train epoch: 188 [115328/221852 (52%)]\tLoss: 0.177379\tAcc: 79.00\n",
      "train epoch: 188 [128128/221852 (58%)]\tLoss: 0.212966\tAcc: 81.00\n",
      "train epoch: 188 [140928/221852 (64%)]\tLoss: 0.200701\tAcc: 83.00\n",
      "train epoch: 188 [153728/221852 (69%)]\tLoss: 0.239053\tAcc: 85.00\n",
      "train epoch: 188 [166528/221852 (75%)]\tLoss: 0.131258\tAcc: 86.00\n",
      "train epoch: 188 [179328/221852 (81%)]\tLoss: 0.183418\tAcc: 83.00\n",
      "train epoch: 188 [192128/221852 (87%)]\tLoss: 0.248991\tAcc: 80.00\n",
      "val epoch: 188 [128/221852 (0%)]\tLoss: 0.116496\tAcc: 92.00\n",
      "val epoch: 188 [12928/221852 (6%)]\tLoss: 0.256855\tAcc: 81.00\n",
      "train epoch: 189 [128/221852 (0%)]\tLoss: 0.167635\tAcc: 82.00\n",
      "train epoch: 189 [12928/221852 (6%)]\tLoss: 0.296563\tAcc: 78.00\n",
      "train epoch: 189 [25728/221852 (12%)]\tLoss: 0.217929\tAcc: 87.00\n",
      "train epoch: 189 [38528/221852 (17%)]\tLoss: 0.191582\tAcc: 80.00\n",
      "train epoch: 189 [51328/221852 (23%)]\tLoss: 0.153643\tAcc: 84.00\n",
      "train epoch: 189 [64128/221852 (29%)]\tLoss: 0.187720\tAcc: 80.00\n",
      "train epoch: 189 [76928/221852 (35%)]\tLoss: 0.114582\tAcc: 85.00\n",
      "train epoch: 189 [89728/221852 (40%)]\tLoss: 0.176070\tAcc: 84.00\n",
      "train epoch: 189 [102528/221852 (46%)]\tLoss: 0.149394\tAcc: 84.00\n",
      "train epoch: 189 [115328/221852 (52%)]\tLoss: 0.179171\tAcc: 84.00\n",
      "train epoch: 189 [128128/221852 (58%)]\tLoss: 0.155804\tAcc: 86.00\n",
      "train epoch: 189 [140928/221852 (64%)]\tLoss: 0.224883\tAcc: 83.00\n",
      "train epoch: 189 [153728/221852 (69%)]\tLoss: 0.175254\tAcc: 82.00\n",
      "train epoch: 189 [166528/221852 (75%)]\tLoss: 0.211630\tAcc: 80.00\n",
      "train epoch: 189 [179328/221852 (81%)]\tLoss: 0.370104\tAcc: 78.00\n",
      "train epoch: 189 [192128/221852 (87%)]\tLoss: 0.166397\tAcc: 84.00\n",
      "val epoch: 189 [128/221852 (0%)]\tLoss: 0.254872\tAcc: 83.00\n",
      "val epoch: 189 [12928/221852 (6%)]\tLoss: 0.133868\tAcc: 88.00\n",
      "train epoch: 190 [128/221852 (0%)]\tLoss: 0.122829\tAcc: 80.00\n",
      "train epoch: 190 [12928/221852 (6%)]\tLoss: 0.113185\tAcc: 83.00\n",
      "train epoch: 190 [25728/221852 (12%)]\tLoss: 0.127822\tAcc: 88.00\n",
      "train epoch: 190 [38528/221852 (17%)]\tLoss: 0.195504\tAcc: 80.00\n",
      "train epoch: 190 [51328/221852 (23%)]\tLoss: 0.145681\tAcc: 84.00\n",
      "train epoch: 190 [64128/221852 (29%)]\tLoss: 0.119435\tAcc: 87.00\n",
      "train epoch: 190 [76928/221852 (35%)]\tLoss: 0.151522\tAcc: 83.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 190 [89728/221852 (40%)]\tLoss: 0.126131\tAcc: 78.00\n",
      "train epoch: 190 [102528/221852 (46%)]\tLoss: 0.238297\tAcc: 80.00\n",
      "train epoch: 190 [115328/221852 (52%)]\tLoss: 0.239017\tAcc: 74.00\n",
      "train epoch: 190 [128128/221852 (58%)]\tLoss: 0.172098\tAcc: 88.00\n",
      "train epoch: 190 [140928/221852 (64%)]\tLoss: 0.101653\tAcc: 83.00\n",
      "train epoch: 190 [153728/221852 (69%)]\tLoss: 0.167293\tAcc: 84.00\n",
      "train epoch: 190 [166528/221852 (75%)]\tLoss: 0.117508\tAcc: 80.00\n",
      "train epoch: 190 [179328/221852 (81%)]\tLoss: 0.171248\tAcc: 80.00\n",
      "train epoch: 190 [192128/221852 (87%)]\tLoss: 0.145595\tAcc: 83.00\n",
      "val epoch: 190 [128/221852 (0%)]\tLoss: 0.185953\tAcc: 89.00\n",
      "val epoch: 190 [12928/221852 (6%)]\tLoss: 0.201516\tAcc: 91.00\n",
      "train epoch: 191 [128/221852 (0%)]\tLoss: 0.177580\tAcc: 85.00\n",
      "train epoch: 191 [12928/221852 (6%)]\tLoss: 0.164335\tAcc: 85.00\n",
      "train epoch: 191 [25728/221852 (12%)]\tLoss: 0.111854\tAcc: 89.00\n",
      "train epoch: 191 [38528/221852 (17%)]\tLoss: 0.224771\tAcc: 78.00\n",
      "train epoch: 191 [51328/221852 (23%)]\tLoss: 0.216685\tAcc: 84.00\n",
      "train epoch: 191 [64128/221852 (29%)]\tLoss: 0.105771\tAcc: 87.00\n",
      "train epoch: 191 [76928/221852 (35%)]\tLoss: 0.439794\tAcc: 80.00\n",
      "train epoch: 191 [89728/221852 (40%)]\tLoss: 0.169748\tAcc: 85.00\n",
      "train epoch: 191 [102528/221852 (46%)]\tLoss: 0.183761\tAcc: 84.00\n",
      "train epoch: 191 [115328/221852 (52%)]\tLoss: 0.130579\tAcc: 90.00\n",
      "train epoch: 191 [128128/221852 (58%)]\tLoss: 0.198548\tAcc: 88.00\n",
      "train epoch: 191 [140928/221852 (64%)]\tLoss: 0.158759\tAcc: 81.00\n",
      "train epoch: 191 [153728/221852 (69%)]\tLoss: 0.138979\tAcc: 87.00\n",
      "train epoch: 191 [166528/221852 (75%)]\tLoss: 0.136799\tAcc: 85.00\n",
      "train epoch: 191 [179328/221852 (81%)]\tLoss: 0.142072\tAcc: 82.00\n",
      "train epoch: 191 [192128/221852 (87%)]\tLoss: 0.221595\tAcc: 84.00\n",
      "val epoch: 191 [128/221852 (0%)]\tLoss: 0.150513\tAcc: 88.00\n",
      "val epoch: 191 [12928/221852 (6%)]\tLoss: 0.151890\tAcc: 83.00\n",
      "train epoch: 192 [128/221852 (0%)]\tLoss: 0.200521\tAcc: 80.00\n",
      "train epoch: 192 [12928/221852 (6%)]\tLoss: 0.327656\tAcc: 77.00\n",
      "train epoch: 192 [25728/221852 (12%)]\tLoss: 0.140329\tAcc: 79.00\n",
      "train epoch: 192 [38528/221852 (17%)]\tLoss: 0.073819\tAcc: 87.00\n",
      "train epoch: 192 [51328/221852 (23%)]\tLoss: 0.277674\tAcc: 83.00\n",
      "train epoch: 192 [64128/221852 (29%)]\tLoss: 0.212336\tAcc: 82.00\n",
      "train epoch: 192 [76928/221852 (35%)]\tLoss: 0.091295\tAcc: 88.00\n",
      "train epoch: 192 [89728/221852 (40%)]\tLoss: 0.188280\tAcc: 80.00\n",
      "train epoch: 192 [102528/221852 (46%)]\tLoss: 0.201997\tAcc: 77.00\n",
      "train epoch: 192 [115328/221852 (52%)]\tLoss: 0.167763\tAcc: 83.00\n",
      "train epoch: 192 [128128/221852 (58%)]\tLoss: 0.222675\tAcc: 79.00\n",
      "train epoch: 192 [140928/221852 (64%)]\tLoss: 0.151761\tAcc: 85.00\n",
      "train epoch: 192 [153728/221852 (69%)]\tLoss: 0.155284\tAcc: 81.00\n",
      "train epoch: 192 [166528/221852 (75%)]\tLoss: 0.147420\tAcc: 88.00\n",
      "train epoch: 192 [179328/221852 (81%)]\tLoss: 0.182878\tAcc: 85.00\n",
      "train epoch: 192 [192128/221852 (87%)]\tLoss: 0.153348\tAcc: 85.00\n",
      "val epoch: 192 [128/221852 (0%)]\tLoss: 0.185757\tAcc: 82.00\n",
      "val epoch: 192 [12928/221852 (6%)]\tLoss: 0.181980\tAcc: 87.00\n",
      "train epoch: 193 [128/221852 (0%)]\tLoss: 0.153418\tAcc: 86.00\n",
      "train epoch: 193 [12928/221852 (6%)]\tLoss: 0.180950\tAcc: 88.00\n",
      "train epoch: 193 [25728/221852 (12%)]\tLoss: 0.284000\tAcc: 78.00\n",
      "train epoch: 193 [38528/221852 (17%)]\tLoss: 0.201729\tAcc: 82.00\n",
      "train epoch: 193 [51328/221852 (23%)]\tLoss: 0.191122\tAcc: 84.00\n",
      "train epoch: 193 [64128/221852 (29%)]\tLoss: 0.220429\tAcc: 80.00\n",
      "train epoch: 193 [76928/221852 (35%)]\tLoss: 0.194895\tAcc: 80.00\n",
      "train epoch: 193 [89728/221852 (40%)]\tLoss: 0.155765\tAcc: 83.00\n",
      "train epoch: 193 [102528/221852 (46%)]\tLoss: 0.145528\tAcc: 86.00\n",
      "train epoch: 193 [115328/221852 (52%)]\tLoss: 0.170354\tAcc: 84.00\n",
      "train epoch: 193 [128128/221852 (58%)]\tLoss: 0.223001\tAcc: 73.00\n",
      "train epoch: 193 [140928/221852 (64%)]\tLoss: 0.148168\tAcc: 88.00\n",
      "train epoch: 193 [153728/221852 (69%)]\tLoss: 0.236346\tAcc: 87.00\n",
      "train epoch: 193 [166528/221852 (75%)]\tLoss: 0.114476\tAcc: 84.00\n",
      "train epoch: 193 [179328/221852 (81%)]\tLoss: 0.107840\tAcc: 88.00\n",
      "train epoch: 193 [192128/221852 (87%)]\tLoss: 0.224205\tAcc: 78.00\n",
      "val epoch: 193 [128/221852 (0%)]\tLoss: 0.225687\tAcc: 82.00\n",
      "val epoch: 193 [12928/221852 (6%)]\tLoss: 0.180266\tAcc: 84.00\n",
      "train epoch: 194 [128/221852 (0%)]\tLoss: 0.155525\tAcc: 86.00\n",
      "train epoch: 194 [12928/221852 (6%)]\tLoss: 0.205672\tAcc: 84.00\n",
      "train epoch: 194 [25728/221852 (12%)]\tLoss: 0.157274\tAcc: 82.00\n",
      "train epoch: 194 [38528/221852 (17%)]\tLoss: 0.133295\tAcc: 84.00\n",
      "train epoch: 194 [51328/221852 (23%)]\tLoss: 0.142974\tAcc: 84.00\n",
      "train epoch: 194 [64128/221852 (29%)]\tLoss: 0.079774\tAcc: 92.00\n",
      "train epoch: 194 [76928/221852 (35%)]\tLoss: 0.147077\tAcc: 88.00\n",
      "train epoch: 194 [89728/221852 (40%)]\tLoss: 0.246398\tAcc: 84.00\n",
      "train epoch: 194 [102528/221852 (46%)]\tLoss: 0.213157\tAcc: 86.00\n",
      "train epoch: 194 [115328/221852 (52%)]\tLoss: 0.115448\tAcc: 89.00\n",
      "train epoch: 194 [128128/221852 (58%)]\tLoss: 0.223782\tAcc: 81.00\n",
      "train epoch: 194 [140928/221852 (64%)]\tLoss: 0.183747\tAcc: 90.00\n",
      "train epoch: 194 [153728/221852 (69%)]\tLoss: 0.176420\tAcc: 77.00\n",
      "train epoch: 194 [166528/221852 (75%)]\tLoss: 0.091148\tAcc: 93.00\n",
      "train epoch: 194 [179328/221852 (81%)]\tLoss: 0.230413\tAcc: 80.00\n",
      "train epoch: 194 [192128/221852 (87%)]\tLoss: 0.204823\tAcc: 77.00\n",
      "val epoch: 194 [128/221852 (0%)]\tLoss: 0.207824\tAcc: 84.00\n",
      "val epoch: 194 [12928/221852 (6%)]\tLoss: 0.164757\tAcc: 84.00\n",
      "train epoch: 195 [128/221852 (0%)]\tLoss: 0.172746\tAcc: 88.00\n",
      "train epoch: 195 [12928/221852 (6%)]\tLoss: 0.184856\tAcc: 83.00\n",
      "train epoch: 195 [25728/221852 (12%)]\tLoss: 0.249000\tAcc: 81.00\n",
      "train epoch: 195 [38528/221852 (17%)]\tLoss: 0.306893\tAcc: 80.00\n",
      "train epoch: 195 [51328/221852 (23%)]\tLoss: 0.253976\tAcc: 80.00\n",
      "train epoch: 195 [64128/221852 (29%)]\tLoss: 0.285789\tAcc: 79.00\n",
      "train epoch: 195 [76928/221852 (35%)]\tLoss: 0.165034\tAcc: 77.00\n",
      "train epoch: 195 [89728/221852 (40%)]\tLoss: 0.135029\tAcc: 82.00\n",
      "train epoch: 195 [102528/221852 (46%)]\tLoss: 0.156164\tAcc: 85.00\n",
      "train epoch: 195 [115328/221852 (52%)]\tLoss: 0.110761\tAcc: 80.00\n",
      "train epoch: 195 [128128/221852 (58%)]\tLoss: 0.157917\tAcc: 84.00\n",
      "train epoch: 195 [140928/221852 (64%)]\tLoss: 0.174531\tAcc: 83.00\n",
      "train epoch: 195 [153728/221852 (69%)]\tLoss: 0.183937\tAcc: 85.00\n",
      "train epoch: 195 [166528/221852 (75%)]\tLoss: 0.126471\tAcc: 88.00\n",
      "train epoch: 195 [179328/221852 (81%)]\tLoss: 0.132678\tAcc: 86.00\n",
      "train epoch: 195 [192128/221852 (87%)]\tLoss: 0.140521\tAcc: 85.00\n",
      "val epoch: 195 [128/221852 (0%)]\tLoss: 0.180951\tAcc: 84.00\n",
      "val epoch: 195 [12928/221852 (6%)]\tLoss: 0.148506\tAcc: 82.00\n",
      "train epoch: 196 [128/221852 (0%)]\tLoss: 0.149424\tAcc: 84.00\n",
      "train epoch: 196 [12928/221852 (6%)]\tLoss: 0.179740\tAcc: 86.00\n",
      "train epoch: 196 [25728/221852 (12%)]\tLoss: 0.172024\tAcc: 85.00\n",
      "train epoch: 196 [38528/221852 (17%)]\tLoss: 0.204696\tAcc: 75.00\n",
      "train epoch: 196 [51328/221852 (23%)]\tLoss: 0.175251\tAcc: 86.00\n",
      "train epoch: 196 [64128/221852 (29%)]\tLoss: 0.202112\tAcc: 81.00\n",
      "train epoch: 196 [76928/221852 (35%)]\tLoss: 0.128155\tAcc: 84.00\n",
      "train epoch: 196 [89728/221852 (40%)]\tLoss: 0.248706\tAcc: 84.00\n",
      "train epoch: 196 [102528/221852 (46%)]\tLoss: 0.182854\tAcc: 82.00\n",
      "train epoch: 196 [115328/221852 (52%)]\tLoss: 0.159046\tAcc: 82.00\n",
      "train epoch: 196 [128128/221852 (58%)]\tLoss: 0.220934\tAcc: 80.00\n",
      "train epoch: 196 [140928/221852 (64%)]\tLoss: 0.118703\tAcc: 88.00\n",
      "train epoch: 196 [153728/221852 (69%)]\tLoss: 0.161217\tAcc: 88.00\n",
      "train epoch: 196 [166528/221852 (75%)]\tLoss: 0.219925\tAcc: 84.00\n",
      "train epoch: 196 [179328/221852 (81%)]\tLoss: 0.184098\tAcc: 82.00\n",
      "train epoch: 196 [192128/221852 (87%)]\tLoss: 0.184063\tAcc: 78.00\n",
      "val epoch: 196 [128/221852 (0%)]\tLoss: 0.195960\tAcc: 86.00\n",
      "val epoch: 196 [12928/221852 (6%)]\tLoss: 0.193064\tAcc: 86.00\n",
      "train epoch: 197 [128/221852 (0%)]\tLoss: 0.207535\tAcc: 88.00\n",
      "train epoch: 197 [12928/221852 (6%)]\tLoss: 0.155963\tAcc: 80.00\n",
      "train epoch: 197 [25728/221852 (12%)]\tLoss: 0.279816\tAcc: 83.00\n",
      "train epoch: 197 [38528/221852 (17%)]\tLoss: 0.130691\tAcc: 84.00\n",
      "train epoch: 197 [51328/221852 (23%)]\tLoss: 0.216526\tAcc: 78.00\n",
      "train epoch: 197 [64128/221852 (29%)]\tLoss: 0.212057\tAcc: 80.00\n",
      "train epoch: 197 [76928/221852 (35%)]\tLoss: 0.091983\tAcc: 88.00\n",
      "train epoch: 197 [89728/221852 (40%)]\tLoss: 0.174519\tAcc: 84.00\n",
      "train epoch: 197 [102528/221852 (46%)]\tLoss: 0.165274\tAcc: 80.00\n",
      "train epoch: 197 [115328/221852 (52%)]\tLoss: 0.132380\tAcc: 83.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 197 [128128/221852 (58%)]\tLoss: 0.217860\tAcc: 85.00\n",
      "train epoch: 197 [140928/221852 (64%)]\tLoss: 0.253096\tAcc: 83.00\n",
      "train epoch: 197 [153728/221852 (69%)]\tLoss: 0.215555\tAcc: 82.00\n",
      "train epoch: 197 [166528/221852 (75%)]\tLoss: 0.200925\tAcc: 88.00\n",
      "train epoch: 197 [179328/221852 (81%)]\tLoss: 0.148933\tAcc: 88.00\n",
      "train epoch: 197 [192128/221852 (87%)]\tLoss: 0.172182\tAcc: 86.00\n",
      "val epoch: 197 [128/221852 (0%)]\tLoss: 0.202704\tAcc: 79.00\n",
      "val epoch: 197 [12928/221852 (6%)]\tLoss: 0.112688\tAcc: 84.00\n",
      "train epoch: 198 [128/221852 (0%)]\tLoss: 0.173571\tAcc: 80.00\n",
      "train epoch: 198 [12928/221852 (6%)]\tLoss: 0.177735\tAcc: 80.00\n",
      "train epoch: 198 [25728/221852 (12%)]\tLoss: 0.260077\tAcc: 80.00\n",
      "train epoch: 198 [38528/221852 (17%)]\tLoss: 0.087084\tAcc: 87.00\n",
      "train epoch: 198 [51328/221852 (23%)]\tLoss: 0.217533\tAcc: 80.00\n",
      "train epoch: 198 [64128/221852 (29%)]\tLoss: 0.166201\tAcc: 84.00\n",
      "train epoch: 198 [76928/221852 (35%)]\tLoss: 0.236984\tAcc: 81.00\n",
      "train epoch: 198 [89728/221852 (40%)]\tLoss: 0.167448\tAcc: 80.00\n",
      "train epoch: 198 [102528/221852 (46%)]\tLoss: 0.173024\tAcc: 86.00\n",
      "train epoch: 198 [115328/221852 (52%)]\tLoss: 0.149388\tAcc: 84.00\n",
      "train epoch: 198 [128128/221852 (58%)]\tLoss: 0.099900\tAcc: 88.00\n",
      "train epoch: 198 [140928/221852 (64%)]\tLoss: 0.274248\tAcc: 82.00\n",
      "train epoch: 198 [153728/221852 (69%)]\tLoss: 0.100401\tAcc: 88.00\n",
      "train epoch: 198 [166528/221852 (75%)]\tLoss: 0.237380\tAcc: 73.00\n",
      "train epoch: 198 [179328/221852 (81%)]\tLoss: 0.295357\tAcc: 87.00\n",
      "train epoch: 198 [192128/221852 (87%)]\tLoss: 0.177452\tAcc: 86.00\n",
      "val epoch: 198 [128/221852 (0%)]\tLoss: 0.131873\tAcc: 89.00\n",
      "val epoch: 198 [12928/221852 (6%)]\tLoss: 0.190070\tAcc: 80.00\n",
      "train epoch: 199 [128/221852 (0%)]\tLoss: 0.186059\tAcc: 81.00\n",
      "train epoch: 199 [12928/221852 (6%)]\tLoss: 0.186611\tAcc: 81.00\n",
      "train epoch: 199 [25728/221852 (12%)]\tLoss: 0.267515\tAcc: 82.00\n",
      "train epoch: 199 [38528/221852 (17%)]\tLoss: 0.128348\tAcc: 86.00\n",
      "train epoch: 199 [51328/221852 (23%)]\tLoss: 0.145449\tAcc: 80.00\n",
      "train epoch: 199 [64128/221852 (29%)]\tLoss: 0.137737\tAcc: 88.00\n",
      "train epoch: 199 [76928/221852 (35%)]\tLoss: 0.132973\tAcc: 84.00\n",
      "train epoch: 199 [89728/221852 (40%)]\tLoss: 0.188787\tAcc: 84.00\n",
      "train epoch: 199 [102528/221852 (46%)]\tLoss: 0.159886\tAcc: 80.00\n",
      "train epoch: 199 [115328/221852 (52%)]\tLoss: 0.178241\tAcc: 84.00\n",
      "train epoch: 199 [128128/221852 (58%)]\tLoss: 0.131126\tAcc: 88.00\n",
      "train epoch: 199 [140928/221852 (64%)]\tLoss: 0.083994\tAcc: 87.00\n",
      "train epoch: 199 [153728/221852 (69%)]\tLoss: 0.187784\tAcc: 82.00\n",
      "train epoch: 199 [166528/221852 (75%)]\tLoss: 0.487234\tAcc: 74.00\n",
      "train epoch: 199 [179328/221852 (81%)]\tLoss: 0.180691\tAcc: 82.00\n",
      "train epoch: 199 [192128/221852 (87%)]\tLoss: 0.105182\tAcc: 84.00\n",
      "val epoch: 199 [128/221852 (0%)]\tLoss: 0.198711\tAcc: 79.00\n",
      "val epoch: 199 [12928/221852 (6%)]\tLoss: 0.201054\tAcc: 84.00\n",
      "saving\n",
      "train epoch: 0 [128/221852 (0%)]\tLoss: 0.697440\tAcc: 49.00\n",
      "train epoch: 0 [12928/221852 (6%)]\tLoss: 0.692462\tAcc: 45.00\n",
      "train epoch: 0 [25728/221852 (12%)]\tLoss: 0.689421\tAcc: 46.00\n",
      "train epoch: 0 [38528/221852 (17%)]\tLoss: 0.692668\tAcc: 49.00\n",
      "train epoch: 0 [51328/221852 (23%)]\tLoss: 0.692913\tAcc: 57.00\n",
      "train epoch: 0 [64128/221852 (29%)]\tLoss: 0.680977\tAcc: 52.00\n",
      "train epoch: 0 [76928/221852 (35%)]\tLoss: 0.582743\tAcc: 51.00\n",
      "train epoch: 0 [89728/221852 (40%)]\tLoss: 0.570789\tAcc: 48.00\n",
      "train epoch: 0 [102528/221852 (46%)]\tLoss: 0.552887\tAcc: 50.00\n",
      "train epoch: 0 [115328/221852 (52%)]\tLoss: 0.518791\tAcc: 56.00\n",
      "train epoch: 0 [128128/221852 (58%)]\tLoss: 0.589139\tAcc: 47.00\n",
      "train epoch: 0 [140928/221852 (64%)]\tLoss: 0.567039\tAcc: 59.00\n",
      "train epoch: 0 [153728/221852 (69%)]\tLoss: 0.649793\tAcc: 59.00\n",
      "train epoch: 0 [166528/221852 (75%)]\tLoss: 0.416451\tAcc: 55.00\n",
      "train epoch: 0 [179328/221852 (81%)]\tLoss: 0.439256\tAcc: 60.00\n",
      "train epoch: 0 [192128/221852 (87%)]\tLoss: 0.497049\tAcc: 55.00\n",
      "val epoch: 0 [128/221852 (0%)]\tLoss: 0.552699\tAcc: 58.00\n",
      "val epoch: 0 [12928/221852 (6%)]\tLoss: 0.643944\tAcc: 57.00\n",
      "train epoch: 1 [128/221852 (0%)]\tLoss: 0.680275\tAcc: 45.00\n",
      "train epoch: 1 [12928/221852 (6%)]\tLoss: 0.501273\tAcc: 59.00\n",
      "train epoch: 1 [25728/221852 (12%)]\tLoss: 0.503693\tAcc: 58.00\n",
      "train epoch: 1 [38528/221852 (17%)]\tLoss: 0.365441\tAcc: 60.00\n",
      "train epoch: 1 [51328/221852 (23%)]\tLoss: 0.729264\tAcc: 52.00\n",
      "train epoch: 1 [64128/221852 (29%)]\tLoss: 0.505209\tAcc: 55.00\n",
      "train epoch: 1 [76928/221852 (35%)]\tLoss: 0.391181\tAcc: 55.00\n",
      "train epoch: 1 [89728/221852 (40%)]\tLoss: 0.470404\tAcc: 61.00\n",
      "train epoch: 1 [102528/221852 (46%)]\tLoss: 0.435290\tAcc: 61.00\n",
      "train epoch: 1 [115328/221852 (52%)]\tLoss: 0.357897\tAcc: 50.00\n",
      "train epoch: 1 [128128/221852 (58%)]\tLoss: 0.303611\tAcc: 67.00\n",
      "train epoch: 1 [140928/221852 (64%)]\tLoss: 0.483049\tAcc: 60.00\n",
      "train epoch: 1 [153728/221852 (69%)]\tLoss: 0.400055\tAcc: 66.00\n",
      "train epoch: 1 [166528/221852 (75%)]\tLoss: 0.449246\tAcc: 60.00\n",
      "train epoch: 1 [179328/221852 (81%)]\tLoss: 0.379562\tAcc: 62.00\n",
      "train epoch: 1 [192128/221852 (87%)]\tLoss: 0.412478\tAcc: 66.00\n",
      "val epoch: 1 [128/221852 (0%)]\tLoss: 0.378568\tAcc: 58.00\n",
      "val epoch: 1 [12928/221852 (6%)]\tLoss: 0.385984\tAcc: 55.00\n",
      "train epoch: 2 [128/221852 (0%)]\tLoss: 0.352631\tAcc: 70.00\n",
      "train epoch: 2 [12928/221852 (6%)]\tLoss: 0.538187\tAcc: 59.00\n",
      "train epoch: 2 [25728/221852 (12%)]\tLoss: 0.388998\tAcc: 67.00\n",
      "train epoch: 2 [38528/221852 (17%)]\tLoss: 0.332509\tAcc: 62.00\n",
      "train epoch: 2 [51328/221852 (23%)]\tLoss: 0.295604\tAcc: 67.00\n",
      "train epoch: 2 [64128/221852 (29%)]\tLoss: 0.518776\tAcc: 58.00\n",
      "train epoch: 2 [76928/221852 (35%)]\tLoss: 0.411056\tAcc: 55.00\n",
      "train epoch: 2 [89728/221852 (40%)]\tLoss: 0.655920\tAcc: 58.00\n",
      "train epoch: 2 [102528/221852 (46%)]\tLoss: 0.436920\tAcc: 59.00\n",
      "train epoch: 2 [115328/221852 (52%)]\tLoss: 0.371492\tAcc: 61.00\n",
      "train epoch: 2 [128128/221852 (58%)]\tLoss: 0.512470\tAcc: 62.00\n",
      "train epoch: 2 [140928/221852 (64%)]\tLoss: 0.341095\tAcc: 65.00\n",
      "train epoch: 2 [153728/221852 (69%)]\tLoss: 0.381024\tAcc: 69.00\n",
      "train epoch: 2 [166528/221852 (75%)]\tLoss: 0.386177\tAcc: 59.00\n",
      "train epoch: 2 [179328/221852 (81%)]\tLoss: 0.416474\tAcc: 56.00\n",
      "train epoch: 2 [192128/221852 (87%)]\tLoss: 0.370590\tAcc: 59.00\n",
      "val epoch: 2 [128/221852 (0%)]\tLoss: 0.326802\tAcc: 65.00\n",
      "val epoch: 2 [12928/221852 (6%)]\tLoss: 0.275034\tAcc: 65.00\n",
      "train epoch: 3 [128/221852 (0%)]\tLoss: 0.339632\tAcc: 59.00\n",
      "train epoch: 3 [12928/221852 (6%)]\tLoss: 0.441597\tAcc: 62.00\n",
      "train epoch: 3 [25728/221852 (12%)]\tLoss: 0.406251\tAcc: 59.00\n",
      "train epoch: 3 [38528/221852 (17%)]\tLoss: 0.380947\tAcc: 59.00\n",
      "train epoch: 3 [51328/221852 (23%)]\tLoss: 0.458231\tAcc: 62.00\n",
      "train epoch: 3 [64128/221852 (29%)]\tLoss: 0.395016\tAcc: 66.00\n",
      "train epoch: 3 [76928/221852 (35%)]\tLoss: 0.256210\tAcc: 63.00\n",
      "train epoch: 3 [89728/221852 (40%)]\tLoss: 0.308882\tAcc: 67.00\n",
      "train epoch: 3 [102528/221852 (46%)]\tLoss: 0.419219\tAcc: 60.00\n",
      "train epoch: 3 [115328/221852 (52%)]\tLoss: 0.401814\tAcc: 65.00\n",
      "train epoch: 3 [128128/221852 (58%)]\tLoss: 0.359994\tAcc: 63.00\n",
      "train epoch: 3 [140928/221852 (64%)]\tLoss: 0.477882\tAcc: 59.00\n",
      "train epoch: 3 [153728/221852 (69%)]\tLoss: 0.348286\tAcc: 67.00\n",
      "train epoch: 3 [166528/221852 (75%)]\tLoss: 0.418261\tAcc: 62.00\n",
      "train epoch: 3 [179328/221852 (81%)]\tLoss: 0.417897\tAcc: 60.00\n",
      "train epoch: 3 [192128/221852 (87%)]\tLoss: 0.351191\tAcc: 61.00\n",
      "val epoch: 3 [128/221852 (0%)]\tLoss: 0.393235\tAcc: 69.00\n",
      "val epoch: 3 [12928/221852 (6%)]\tLoss: 0.310003\tAcc: 64.00\n",
      "train epoch: 4 [128/221852 (0%)]\tLoss: 0.401038\tAcc: 61.00\n",
      "train epoch: 4 [12928/221852 (6%)]\tLoss: 0.352313\tAcc: 63.00\n",
      "train epoch: 4 [25728/221852 (12%)]\tLoss: 0.491782\tAcc: 57.00\n",
      "train epoch: 4 [38528/221852 (17%)]\tLoss: 0.376389\tAcc: 52.00\n",
      "train epoch: 4 [51328/221852 (23%)]\tLoss: 0.414427\tAcc: 59.00\n",
      "train epoch: 4 [64128/221852 (29%)]\tLoss: 0.360392\tAcc: 66.00\n",
      "train epoch: 4 [76928/221852 (35%)]\tLoss: 0.272914\tAcc: 70.00\n",
      "train epoch: 4 [89728/221852 (40%)]\tLoss: 0.443105\tAcc: 62.00\n",
      "train epoch: 4 [102528/221852 (46%)]\tLoss: 0.394537\tAcc: 66.00\n",
      "train epoch: 4 [115328/221852 (52%)]\tLoss: 0.364442\tAcc: 62.00\n",
      "train epoch: 4 [128128/221852 (58%)]\tLoss: 0.453135\tAcc: 57.00\n",
      "train epoch: 4 [140928/221852 (64%)]\tLoss: 0.316856\tAcc: 70.00\n",
      "train epoch: 4 [153728/221852 (69%)]\tLoss: 0.383079\tAcc: 67.00\n",
      "train epoch: 4 [166528/221852 (75%)]\tLoss: 0.332664\tAcc: 70.00\n",
      "train epoch: 4 [179328/221852 (81%)]\tLoss: 0.318809\tAcc: 63.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 4 [192128/221852 (87%)]\tLoss: 0.368702\tAcc: 59.00\n",
      "val epoch: 4 [128/221852 (0%)]\tLoss: 0.335925\tAcc: 61.00\n",
      "val epoch: 4 [12928/221852 (6%)]\tLoss: 0.314826\tAcc: 70.00\n",
      "train epoch: 5 [128/221852 (0%)]\tLoss: 0.388696\tAcc: 66.00\n",
      "train epoch: 5 [12928/221852 (6%)]\tLoss: 0.448740\tAcc: 67.00\n",
      "train epoch: 5 [25728/221852 (12%)]\tLoss: 0.297406\tAcc: 63.00\n",
      "train epoch: 5 [38528/221852 (17%)]\tLoss: 0.361564\tAcc: 65.00\n",
      "train epoch: 5 [51328/221852 (23%)]\tLoss: 0.372958\tAcc: 58.00\n",
      "train epoch: 5 [64128/221852 (29%)]\tLoss: 0.321933\tAcc: 66.00\n",
      "train epoch: 5 [76928/221852 (35%)]\tLoss: 0.356320\tAcc: 63.00\n",
      "train epoch: 5 [89728/221852 (40%)]\tLoss: 0.408879\tAcc: 62.00\n",
      "train epoch: 5 [102528/221852 (46%)]\tLoss: 0.366199\tAcc: 58.00\n",
      "train epoch: 5 [115328/221852 (52%)]\tLoss: 0.564489\tAcc: 63.00\n",
      "train epoch: 5 [128128/221852 (58%)]\tLoss: 0.400517\tAcc: 65.00\n",
      "train epoch: 5 [140928/221852 (64%)]\tLoss: 0.358541\tAcc: 64.00\n",
      "train epoch: 5 [153728/221852 (69%)]\tLoss: 0.468492\tAcc: 62.00\n",
      "train epoch: 5 [166528/221852 (75%)]\tLoss: 0.403692\tAcc: 63.00\n",
      "train epoch: 5 [179328/221852 (81%)]\tLoss: 0.344527\tAcc: 68.00\n",
      "train epoch: 5 [192128/221852 (87%)]\tLoss: 0.291418\tAcc: 69.00\n",
      "val epoch: 5 [128/221852 (0%)]\tLoss: 0.376847\tAcc: 66.00\n",
      "val epoch: 5 [12928/221852 (6%)]\tLoss: 0.411968\tAcc: 64.00\n",
      "train epoch: 6 [128/221852 (0%)]\tLoss: 0.457442\tAcc: 66.00\n",
      "train epoch: 6 [12928/221852 (6%)]\tLoss: 0.289275\tAcc: 62.00\n",
      "train epoch: 6 [25728/221852 (12%)]\tLoss: 0.425566\tAcc: 64.00\n",
      "train epoch: 6 [38528/221852 (17%)]\tLoss: 0.328789\tAcc: 61.00\n",
      "train epoch: 6 [51328/221852 (23%)]\tLoss: 0.410131\tAcc: 59.00\n",
      "train epoch: 6 [64128/221852 (29%)]\tLoss: 0.377573\tAcc: 62.00\n",
      "train epoch: 6 [76928/221852 (35%)]\tLoss: 0.439134\tAcc: 65.00\n",
      "train epoch: 6 [89728/221852 (40%)]\tLoss: 0.304767\tAcc: 69.00\n",
      "train epoch: 6 [102528/221852 (46%)]\tLoss: 0.279451\tAcc: 63.00\n",
      "train epoch: 6 [115328/221852 (52%)]\tLoss: 0.317728\tAcc: 70.00\n",
      "train epoch: 6 [128128/221852 (58%)]\tLoss: 0.371751\tAcc: 62.00\n",
      "train epoch: 6 [140928/221852 (64%)]\tLoss: 0.267733\tAcc: 66.00\n",
      "train epoch: 6 [153728/221852 (69%)]\tLoss: 0.255861\tAcc: 64.00\n",
      "train epoch: 6 [166528/221852 (75%)]\tLoss: 0.298119\tAcc: 63.00\n",
      "train epoch: 6 [179328/221852 (81%)]\tLoss: 0.500620\tAcc: 67.00\n",
      "train epoch: 6 [192128/221852 (87%)]\tLoss: 0.292098\tAcc: 61.00\n",
      "val epoch: 6 [128/221852 (0%)]\tLoss: 0.432266\tAcc: 67.00\n",
      "val epoch: 6 [12928/221852 (6%)]\tLoss: 0.417814\tAcc: 62.00\n",
      "train epoch: 7 [128/221852 (0%)]\tLoss: 0.394057\tAcc: 61.00\n",
      "train epoch: 7 [12928/221852 (6%)]\tLoss: 0.249899\tAcc: 69.00\n",
      "train epoch: 7 [25728/221852 (12%)]\tLoss: 0.439650\tAcc: 68.00\n",
      "train epoch: 7 [38528/221852 (17%)]\tLoss: 0.415364\tAcc: 66.00\n",
      "train epoch: 7 [51328/221852 (23%)]\tLoss: 0.336123\tAcc: 65.00\n",
      "train epoch: 7 [64128/221852 (29%)]\tLoss: 0.262758\tAcc: 62.00\n",
      "train epoch: 7 [76928/221852 (35%)]\tLoss: 0.462080\tAcc: 61.00\n",
      "train epoch: 7 [89728/221852 (40%)]\tLoss: 0.354380\tAcc: 62.00\n",
      "train epoch: 7 [102528/221852 (46%)]\tLoss: 0.313133\tAcc: 59.00\n",
      "train epoch: 7 [115328/221852 (52%)]\tLoss: 0.359542\tAcc: 68.00\n",
      "train epoch: 7 [128128/221852 (58%)]\tLoss: 0.358515\tAcc: 59.00\n",
      "train epoch: 7 [140928/221852 (64%)]\tLoss: 0.423406\tAcc: 68.00\n",
      "train epoch: 7 [153728/221852 (69%)]\tLoss: 0.406071\tAcc: 62.00\n",
      "train epoch: 7 [166528/221852 (75%)]\tLoss: 0.300206\tAcc: 72.00\n",
      "train epoch: 7 [179328/221852 (81%)]\tLoss: 0.270260\tAcc: 71.00\n",
      "train epoch: 7 [192128/221852 (87%)]\tLoss: 0.276178\tAcc: 69.00\n",
      "val epoch: 7 [128/221852 (0%)]\tLoss: 0.287810\tAcc: 70.00\n",
      "val epoch: 7 [12928/221852 (6%)]\tLoss: 0.281673\tAcc: 65.00\n",
      "train epoch: 8 [128/221852 (0%)]\tLoss: 0.324929\tAcc: 61.00\n",
      "train epoch: 8 [12928/221852 (6%)]\tLoss: 0.444395\tAcc: 67.00\n",
      "train epoch: 8 [25728/221852 (12%)]\tLoss: 0.343136\tAcc: 66.00\n",
      "train epoch: 8 [38528/221852 (17%)]\tLoss: 0.354640\tAcc: 63.00\n",
      "train epoch: 8 [51328/221852 (23%)]\tLoss: 0.335131\tAcc: 62.00\n",
      "train epoch: 8 [64128/221852 (29%)]\tLoss: 0.347812\tAcc: 61.00\n",
      "train epoch: 8 [76928/221852 (35%)]\tLoss: 0.430478\tAcc: 59.00\n",
      "train epoch: 8 [89728/221852 (40%)]\tLoss: 0.334130\tAcc: 60.00\n",
      "train epoch: 8 [102528/221852 (46%)]\tLoss: 0.278020\tAcc: 64.00\n",
      "train epoch: 8 [115328/221852 (52%)]\tLoss: 0.345849\tAcc: 67.00\n",
      "train epoch: 8 [128128/221852 (58%)]\tLoss: 0.486959\tAcc: 68.00\n",
      "train epoch: 8 [140928/221852 (64%)]\tLoss: 0.249839\tAcc: 70.00\n",
      "train epoch: 8 [153728/221852 (69%)]\tLoss: 0.359256\tAcc: 67.00\n",
      "train epoch: 8 [166528/221852 (75%)]\tLoss: 0.389611\tAcc: 65.00\n",
      "train epoch: 8 [179328/221852 (81%)]\tLoss: 0.312325\tAcc: 65.00\n",
      "train epoch: 8 [192128/221852 (87%)]\tLoss: 0.354755\tAcc: 62.00\n",
      "val epoch: 8 [128/221852 (0%)]\tLoss: 0.372977\tAcc: 69.00\n",
      "val epoch: 8 [12928/221852 (6%)]\tLoss: 0.467954\tAcc: 63.00\n",
      "train epoch: 9 [128/221852 (0%)]\tLoss: 0.418787\tAcc: 55.00\n",
      "train epoch: 9 [12928/221852 (6%)]\tLoss: 0.386842\tAcc: 66.00\n",
      "train epoch: 9 [25728/221852 (12%)]\tLoss: 0.260022\tAcc: 72.00\n",
      "train epoch: 9 [38528/221852 (17%)]\tLoss: 0.324957\tAcc: 75.00\n",
      "train epoch: 9 [51328/221852 (23%)]\tLoss: 0.256922\tAcc: 57.00\n",
      "train epoch: 9 [64128/221852 (29%)]\tLoss: 0.237395\tAcc: 73.00\n",
      "train epoch: 9 [76928/221852 (35%)]\tLoss: 0.294819\tAcc: 66.00\n",
      "train epoch: 9 [89728/221852 (40%)]\tLoss: 0.247595\tAcc: 69.00\n",
      "train epoch: 9 [102528/221852 (46%)]\tLoss: 0.336820\tAcc: 68.00\n",
      "train epoch: 9 [115328/221852 (52%)]\tLoss: 0.333884\tAcc: 65.00\n",
      "train epoch: 9 [128128/221852 (58%)]\tLoss: 0.332412\tAcc: 68.00\n",
      "train epoch: 9 [140928/221852 (64%)]\tLoss: 0.329692\tAcc: 71.00\n",
      "train epoch: 9 [153728/221852 (69%)]\tLoss: 0.330942\tAcc: 59.00\n",
      "train epoch: 9 [166528/221852 (75%)]\tLoss: 0.327489\tAcc: 62.00\n",
      "train epoch: 9 [179328/221852 (81%)]\tLoss: 0.357938\tAcc: 61.00\n",
      "train epoch: 9 [192128/221852 (87%)]\tLoss: 0.359052\tAcc: 67.00\n",
      "val epoch: 9 [128/221852 (0%)]\tLoss: 0.208385\tAcc: 77.00\n",
      "val epoch: 9 [12928/221852 (6%)]\tLoss: 0.249744\tAcc: 59.00\n",
      "train epoch: 10 [128/221852 (0%)]\tLoss: 0.282197\tAcc: 65.00\n",
      "train epoch: 10 [12928/221852 (6%)]\tLoss: 0.391813\tAcc: 61.00\n",
      "train epoch: 10 [25728/221852 (12%)]\tLoss: 0.234676\tAcc: 63.00\n",
      "train epoch: 10 [38528/221852 (17%)]\tLoss: 0.341709\tAcc: 64.00\n",
      "train epoch: 10 [51328/221852 (23%)]\tLoss: 0.323617\tAcc: 57.00\n",
      "train epoch: 10 [64128/221852 (29%)]\tLoss: 0.342021\tAcc: 62.00\n",
      "train epoch: 10 [76928/221852 (35%)]\tLoss: 0.285370\tAcc: 68.00\n",
      "train epoch: 10 [89728/221852 (40%)]\tLoss: 0.305259\tAcc: 66.00\n",
      "train epoch: 10 [102528/221852 (46%)]\tLoss: 0.315319\tAcc: 65.00\n",
      "train epoch: 10 [115328/221852 (52%)]\tLoss: 0.282377\tAcc: 68.00\n",
      "train epoch: 10 [128128/221852 (58%)]\tLoss: 0.314335\tAcc: 66.00\n",
      "train epoch: 10 [140928/221852 (64%)]\tLoss: 0.294962\tAcc: 70.00\n",
      "train epoch: 10 [153728/221852 (69%)]\tLoss: 0.352945\tAcc: 65.00\n",
      "train epoch: 10 [166528/221852 (75%)]\tLoss: 0.277677\tAcc: 67.00\n",
      "train epoch: 10 [179328/221852 (81%)]\tLoss: 0.303568\tAcc: 65.00\n",
      "train epoch: 10 [192128/221852 (87%)]\tLoss: 0.224944\tAcc: 72.00\n",
      "val epoch: 10 [128/221852 (0%)]\tLoss: 0.251986\tAcc: 70.00\n",
      "val epoch: 10 [12928/221852 (6%)]\tLoss: 0.320455\tAcc: 70.00\n",
      "train epoch: 11 [128/221852 (0%)]\tLoss: 0.383501\tAcc: 65.00\n",
      "train epoch: 11 [12928/221852 (6%)]\tLoss: 0.213026\tAcc: 64.00\n",
      "train epoch: 11 [25728/221852 (12%)]\tLoss: 0.333062\tAcc: 61.00\n",
      "train epoch: 11 [38528/221852 (17%)]\tLoss: 0.364523\tAcc: 67.00\n",
      "train epoch: 11 [51328/221852 (23%)]\tLoss: 0.310613\tAcc: 59.00\n",
      "train epoch: 11 [64128/221852 (29%)]\tLoss: 0.302245\tAcc: 69.00\n",
      "train epoch: 11 [76928/221852 (35%)]\tLoss: 0.261796\tAcc: 66.00\n",
      "train epoch: 11 [89728/221852 (40%)]\tLoss: 0.296763\tAcc: 73.00\n",
      "train epoch: 11 [102528/221852 (46%)]\tLoss: 0.428554\tAcc: 62.00\n",
      "train epoch: 11 [115328/221852 (52%)]\tLoss: 0.440211\tAcc: 66.00\n",
      "train epoch: 11 [128128/221852 (58%)]\tLoss: 0.368860\tAcc: 62.00\n",
      "train epoch: 11 [140928/221852 (64%)]\tLoss: 0.294750\tAcc: 72.00\n",
      "train epoch: 11 [153728/221852 (69%)]\tLoss: 0.315564\tAcc: 69.00\n",
      "train epoch: 11 [166528/221852 (75%)]\tLoss: 0.341072\tAcc: 62.00\n",
      "train epoch: 11 [179328/221852 (81%)]\tLoss: 0.270368\tAcc: 66.00\n",
      "train epoch: 11 [192128/221852 (87%)]\tLoss: 0.301044\tAcc: 62.00\n",
      "val epoch: 11 [128/221852 (0%)]\tLoss: 0.334853\tAcc: 66.00\n",
      "val epoch: 11 [12928/221852 (6%)]\tLoss: 0.365885\tAcc: 61.00\n",
      "train epoch: 12 [128/221852 (0%)]\tLoss: 0.274640\tAcc: 66.00\n",
      "train epoch: 12 [12928/221852 (6%)]\tLoss: 0.277860\tAcc: 67.00\n",
      "train epoch: 12 [25728/221852 (12%)]\tLoss: 0.303476\tAcc: 66.00\n",
      "train epoch: 12 [38528/221852 (17%)]\tLoss: 0.346661\tAcc: 66.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 12 [51328/221852 (23%)]\tLoss: 0.381505\tAcc: 67.00\n",
      "train epoch: 12 [64128/221852 (29%)]\tLoss: 0.228821\tAcc: 74.00\n",
      "train epoch: 12 [76928/221852 (35%)]\tLoss: 0.308238\tAcc: 68.00\n",
      "train epoch: 12 [89728/221852 (40%)]\tLoss: 0.311344\tAcc: 66.00\n",
      "train epoch: 12 [102528/221852 (46%)]\tLoss: 0.273400\tAcc: 68.00\n",
      "train epoch: 12 [115328/221852 (52%)]\tLoss: 0.309818\tAcc: 62.00\n",
      "train epoch: 12 [128128/221852 (58%)]\tLoss: 0.387981\tAcc: 63.00\n",
      "train epoch: 12 [140928/221852 (64%)]\tLoss: 0.209747\tAcc: 65.00\n",
      "train epoch: 12 [153728/221852 (69%)]\tLoss: 0.249707\tAcc: 66.00\n",
      "train epoch: 12 [166528/221852 (75%)]\tLoss: 0.259926\tAcc: 66.00\n",
      "train epoch: 12 [179328/221852 (81%)]\tLoss: 0.351321\tAcc: 60.00\n",
      "train epoch: 12 [192128/221852 (87%)]\tLoss: 0.284071\tAcc: 61.00\n",
      "val epoch: 12 [128/221852 (0%)]\tLoss: 0.354601\tAcc: 69.00\n",
      "val epoch: 12 [12928/221852 (6%)]\tLoss: 0.372634\tAcc: 67.00\n",
      "train epoch: 13 [128/221852 (0%)]\tLoss: 0.394498\tAcc: 65.00\n",
      "train epoch: 13 [12928/221852 (6%)]\tLoss: 0.301019\tAcc: 66.00\n",
      "train epoch: 13 [25728/221852 (12%)]\tLoss: 0.370576\tAcc: 62.00\n",
      "train epoch: 13 [38528/221852 (17%)]\tLoss: 0.333728\tAcc: 68.00\n",
      "train epoch: 13 [51328/221852 (23%)]\tLoss: 0.251527\tAcc: 70.00\n",
      "train epoch: 13 [64128/221852 (29%)]\tLoss: 0.369647\tAcc: 67.00\n",
      "train epoch: 13 [76928/221852 (35%)]\tLoss: 0.290491\tAcc: 62.00\n",
      "train epoch: 13 [89728/221852 (40%)]\tLoss: 0.267817\tAcc: 69.00\n",
      "train epoch: 13 [102528/221852 (46%)]\tLoss: 0.338992\tAcc: 66.00\n",
      "train epoch: 13 [115328/221852 (52%)]\tLoss: 0.279983\tAcc: 67.00\n",
      "train epoch: 13 [128128/221852 (58%)]\tLoss: 0.298365\tAcc: 69.00\n",
      "train epoch: 13 [140928/221852 (64%)]\tLoss: 0.249484\tAcc: 69.00\n",
      "train epoch: 13 [153728/221852 (69%)]\tLoss: 0.227575\tAcc: 69.00\n",
      "train epoch: 13 [166528/221852 (75%)]\tLoss: 0.265153\tAcc: 73.00\n",
      "train epoch: 13 [179328/221852 (81%)]\tLoss: 0.231269\tAcc: 66.00\n",
      "train epoch: 13 [192128/221852 (87%)]\tLoss: 0.491528\tAcc: 63.00\n",
      "val epoch: 13 [128/221852 (0%)]\tLoss: 0.283725\tAcc: 79.00\n",
      "val epoch: 13 [12928/221852 (6%)]\tLoss: 0.336277\tAcc: 73.00\n",
      "train epoch: 14 [128/221852 (0%)]\tLoss: 0.372896\tAcc: 72.00\n",
      "train epoch: 14 [12928/221852 (6%)]\tLoss: 0.360297\tAcc: 68.00\n",
      "train epoch: 14 [25728/221852 (12%)]\tLoss: 0.305049\tAcc: 67.00\n",
      "train epoch: 14 [38528/221852 (17%)]\tLoss: 0.298181\tAcc: 70.00\n",
      "train epoch: 14 [51328/221852 (23%)]\tLoss: 0.291450\tAcc: 76.00\n",
      "train epoch: 14 [64128/221852 (29%)]\tLoss: 0.348421\tAcc: 68.00\n",
      "train epoch: 14 [76928/221852 (35%)]\tLoss: 0.284708\tAcc: 70.00\n",
      "train epoch: 14 [89728/221852 (40%)]\tLoss: 0.275349\tAcc: 65.00\n",
      "train epoch: 14 [102528/221852 (46%)]\tLoss: 0.269958\tAcc: 60.00\n",
      "train epoch: 14 [115328/221852 (52%)]\tLoss: 0.516468\tAcc: 64.00\n",
      "train epoch: 14 [128128/221852 (58%)]\tLoss: 0.358885\tAcc: 55.00\n",
      "train epoch: 14 [140928/221852 (64%)]\tLoss: 0.322502\tAcc: 66.00\n",
      "train epoch: 14 [153728/221852 (69%)]\tLoss: 0.356211\tAcc: 62.00\n",
      "train epoch: 14 [166528/221852 (75%)]\tLoss: 0.272553\tAcc: 73.00\n",
      "train epoch: 14 [179328/221852 (81%)]\tLoss: 0.339359\tAcc: 70.00\n",
      "train epoch: 14 [192128/221852 (87%)]\tLoss: 0.303714\tAcc: 66.00\n",
      "val epoch: 14 [128/221852 (0%)]\tLoss: 0.220169\tAcc: 70.00\n",
      "val epoch: 14 [12928/221852 (6%)]\tLoss: 0.319807\tAcc: 64.00\n",
      "train epoch: 15 [128/221852 (0%)]\tLoss: 0.233459\tAcc: 71.00\n",
      "train epoch: 15 [12928/221852 (6%)]\tLoss: 0.254664\tAcc: 66.00\n",
      "train epoch: 15 [25728/221852 (12%)]\tLoss: 0.554626\tAcc: 62.00\n",
      "train epoch: 15 [38528/221852 (17%)]\tLoss: 0.341034\tAcc: 63.00\n",
      "train epoch: 15 [51328/221852 (23%)]\tLoss: 0.250110\tAcc: 71.00\n",
      "train epoch: 15 [64128/221852 (29%)]\tLoss: 0.293285\tAcc: 62.00\n",
      "train epoch: 15 [76928/221852 (35%)]\tLoss: 0.279986\tAcc: 66.00\n",
      "train epoch: 15 [89728/221852 (40%)]\tLoss: 0.288548\tAcc: 74.00\n",
      "train epoch: 15 [102528/221852 (46%)]\tLoss: 0.256066\tAcc: 65.00\n",
      "train epoch: 15 [115328/221852 (52%)]\tLoss: 0.341147\tAcc: 70.00\n",
      "train epoch: 15 [128128/221852 (58%)]\tLoss: 0.173162\tAcc: 68.00\n",
      "train epoch: 15 [140928/221852 (64%)]\tLoss: 0.284914\tAcc: 66.00\n",
      "train epoch: 15 [153728/221852 (69%)]\tLoss: 0.310661\tAcc: 70.00\n",
      "train epoch: 15 [166528/221852 (75%)]\tLoss: 0.277339\tAcc: 70.00\n",
      "train epoch: 15 [179328/221852 (81%)]\tLoss: 0.295194\tAcc: 74.00\n",
      "train epoch: 15 [192128/221852 (87%)]\tLoss: 0.356238\tAcc: 65.00\n",
      "val epoch: 15 [128/221852 (0%)]\tLoss: 0.289681\tAcc: 67.00\n",
      "val epoch: 15 [12928/221852 (6%)]\tLoss: 0.339912\tAcc: 69.00\n",
      "train epoch: 16 [128/221852 (0%)]\tLoss: 0.293291\tAcc: 59.00\n",
      "train epoch: 16 [12928/221852 (6%)]\tLoss: 0.248596\tAcc: 72.00\n",
      "train epoch: 16 [25728/221852 (12%)]\tLoss: 0.252073\tAcc: 65.00\n",
      "train epoch: 16 [38528/221852 (17%)]\tLoss: 0.297046\tAcc: 67.00\n",
      "train epoch: 16 [51328/221852 (23%)]\tLoss: 0.328887\tAcc: 61.00\n",
      "train epoch: 16 [64128/221852 (29%)]\tLoss: 0.236193\tAcc: 66.00\n",
      "train epoch: 16 [76928/221852 (35%)]\tLoss: 0.325902\tAcc: 62.00\n",
      "train epoch: 16 [89728/221852 (40%)]\tLoss: 0.307701\tAcc: 66.00\n",
      "train epoch: 16 [102528/221852 (46%)]\tLoss: 0.288874\tAcc: 72.00\n",
      "train epoch: 16 [115328/221852 (52%)]\tLoss: 0.381671\tAcc: 62.00\n",
      "train epoch: 16 [128128/221852 (58%)]\tLoss: 0.251602\tAcc: 69.00\n",
      "train epoch: 16 [140928/221852 (64%)]\tLoss: 0.313581\tAcc: 64.00\n",
      "train epoch: 16 [153728/221852 (69%)]\tLoss: 0.290724\tAcc: 73.00\n",
      "train epoch: 16 [166528/221852 (75%)]\tLoss: 0.249306\tAcc: 70.00\n",
      "train epoch: 16 [179328/221852 (81%)]\tLoss: 0.307359\tAcc: 67.00\n",
      "train epoch: 16 [192128/221852 (87%)]\tLoss: 0.401937\tAcc: 69.00\n",
      "val epoch: 16 [128/221852 (0%)]\tLoss: 0.300156\tAcc: 70.00\n",
      "val epoch: 16 [12928/221852 (6%)]\tLoss: 0.313078\tAcc: 59.00\n",
      "train epoch: 17 [128/221852 (0%)]\tLoss: 0.245767\tAcc: 70.00\n",
      "train epoch: 17 [12928/221852 (6%)]\tLoss: 0.329879\tAcc: 71.00\n",
      "train epoch: 17 [25728/221852 (12%)]\tLoss: 0.303231\tAcc: 62.00\n",
      "train epoch: 17 [38528/221852 (17%)]\tLoss: 0.266724\tAcc: 75.00\n",
      "train epoch: 17 [51328/221852 (23%)]\tLoss: 0.293807\tAcc: 70.00\n",
      "train epoch: 17 [64128/221852 (29%)]\tLoss: 0.340844\tAcc: 69.00\n",
      "train epoch: 17 [76928/221852 (35%)]\tLoss: 0.288022\tAcc: 72.00\n",
      "train epoch: 17 [89728/221852 (40%)]\tLoss: 0.251796\tAcc: 72.00\n",
      "train epoch: 17 [102528/221852 (46%)]\tLoss: 0.163997\tAcc: 77.00\n",
      "train epoch: 17 [115328/221852 (52%)]\tLoss: 0.289164\tAcc: 73.00\n",
      "train epoch: 17 [128128/221852 (58%)]\tLoss: 0.249089\tAcc: 70.00\n",
      "train epoch: 17 [140928/221852 (64%)]\tLoss: 0.322917\tAcc: 67.00\n",
      "train epoch: 17 [153728/221852 (69%)]\tLoss: 0.327370\tAcc: 75.00\n",
      "train epoch: 17 [166528/221852 (75%)]\tLoss: 0.471962\tAcc: 59.00\n",
      "train epoch: 17 [179328/221852 (81%)]\tLoss: 0.313279\tAcc: 70.00\n",
      "train epoch: 17 [192128/221852 (87%)]\tLoss: 0.233703\tAcc: 65.00\n",
      "val epoch: 17 [128/221852 (0%)]\tLoss: 0.199308\tAcc: 70.00\n",
      "val epoch: 17 [12928/221852 (6%)]\tLoss: 0.225464\tAcc: 66.00\n",
      "train epoch: 18 [128/221852 (0%)]\tLoss: 0.185226\tAcc: 67.00\n",
      "train epoch: 18 [12928/221852 (6%)]\tLoss: 0.331212\tAcc: 66.00\n",
      "train epoch: 18 [25728/221852 (12%)]\tLoss: 0.186069\tAcc: 70.00\n",
      "train epoch: 18 [38528/221852 (17%)]\tLoss: 0.274248\tAcc: 71.00\n",
      "train epoch: 18 [51328/221852 (23%)]\tLoss: 0.323814\tAcc: 67.00\n",
      "train epoch: 18 [64128/221852 (29%)]\tLoss: 0.531451\tAcc: 55.00\n",
      "train epoch: 18 [76928/221852 (35%)]\tLoss: 0.365046\tAcc: 67.00\n",
      "train epoch: 18 [89728/221852 (40%)]\tLoss: 0.309864\tAcc: 70.00\n",
      "train epoch: 18 [102528/221852 (46%)]\tLoss: 0.378875\tAcc: 69.00\n",
      "train epoch: 18 [115328/221852 (52%)]\tLoss: 0.374433\tAcc: 69.00\n",
      "train epoch: 18 [128128/221852 (58%)]\tLoss: 0.323725\tAcc: 65.00\n",
      "train epoch: 18 [140928/221852 (64%)]\tLoss: 0.254527\tAcc: 63.00\n",
      "train epoch: 18 [153728/221852 (69%)]\tLoss: 0.340338\tAcc: 68.00\n",
      "train epoch: 18 [166528/221852 (75%)]\tLoss: 0.257776\tAcc: 77.00\n",
      "train epoch: 18 [179328/221852 (81%)]\tLoss: 0.213121\tAcc: 74.00\n",
      "train epoch: 18 [192128/221852 (87%)]\tLoss: 0.295147\tAcc: 69.00\n",
      "val epoch: 18 [128/221852 (0%)]\tLoss: 0.221973\tAcc: 69.00\n",
      "val epoch: 18 [12928/221852 (6%)]\tLoss: 0.189231\tAcc: 73.00\n",
      "train epoch: 19 [128/221852 (0%)]\tLoss: 0.321625\tAcc: 67.00\n",
      "train epoch: 19 [12928/221852 (6%)]\tLoss: 0.272190\tAcc: 70.00\n",
      "train epoch: 19 [25728/221852 (12%)]\tLoss: 0.206212\tAcc: 70.00\n",
      "train epoch: 19 [38528/221852 (17%)]\tLoss: 0.310308\tAcc: 65.00\n",
      "train epoch: 19 [51328/221852 (23%)]\tLoss: 0.311222\tAcc: 69.00\n",
      "train epoch: 19 [64128/221852 (29%)]\tLoss: 0.382981\tAcc: 66.00\n",
      "train epoch: 19 [76928/221852 (35%)]\tLoss: 0.448637\tAcc: 69.00\n",
      "train epoch: 19 [89728/221852 (40%)]\tLoss: 0.251697\tAcc: 67.00\n",
      "train epoch: 19 [102528/221852 (46%)]\tLoss: 0.316910\tAcc: 72.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 19 [115328/221852 (52%)]\tLoss: 0.252779\tAcc: 69.00\n",
      "train epoch: 19 [128128/221852 (58%)]\tLoss: 0.193424\tAcc: 73.00\n",
      "train epoch: 19 [140928/221852 (64%)]\tLoss: 0.363842\tAcc: 59.00\n",
      "train epoch: 19 [153728/221852 (69%)]\tLoss: 0.301901\tAcc: 72.00\n",
      "train epoch: 19 [166528/221852 (75%)]\tLoss: 0.216863\tAcc: 76.00\n",
      "train epoch: 19 [179328/221852 (81%)]\tLoss: 0.321868\tAcc: 66.00\n",
      "train epoch: 19 [192128/221852 (87%)]\tLoss: 0.333814\tAcc: 71.00\n",
      "val epoch: 19 [128/221852 (0%)]\tLoss: 0.296252\tAcc: 73.00\n",
      "val epoch: 19 [12928/221852 (6%)]\tLoss: 0.184476\tAcc: 70.00\n",
      "train epoch: 20 [128/221852 (0%)]\tLoss: 0.275658\tAcc: 66.00\n",
      "train epoch: 20 [12928/221852 (6%)]\tLoss: 0.307271\tAcc: 62.00\n",
      "train epoch: 20 [25728/221852 (12%)]\tLoss: 0.246582\tAcc: 66.00\n",
      "train epoch: 20 [38528/221852 (17%)]\tLoss: 0.224048\tAcc: 73.00\n",
      "train epoch: 20 [51328/221852 (23%)]\tLoss: 0.326784\tAcc: 71.00\n",
      "train epoch: 20 [64128/221852 (29%)]\tLoss: 0.425851\tAcc: 63.00\n",
      "train epoch: 20 [76928/221852 (35%)]\tLoss: 0.261218\tAcc: 68.00\n",
      "train epoch: 20 [89728/221852 (40%)]\tLoss: 0.268625\tAcc: 66.00\n",
      "train epoch: 20 [102528/221852 (46%)]\tLoss: 0.300364\tAcc: 69.00\n",
      "train epoch: 20 [115328/221852 (52%)]\tLoss: 0.302819\tAcc: 68.00\n",
      "train epoch: 20 [128128/221852 (58%)]\tLoss: 0.214167\tAcc: 66.00\n",
      "train epoch: 20 [140928/221852 (64%)]\tLoss: 0.230838\tAcc: 71.00\n",
      "train epoch: 20 [153728/221852 (69%)]\tLoss: 0.289855\tAcc: 75.00\n",
      "train epoch: 20 [166528/221852 (75%)]\tLoss: 0.291112\tAcc: 63.00\n",
      "train epoch: 20 [179328/221852 (81%)]\tLoss: 0.356231\tAcc: 69.00\n",
      "train epoch: 20 [192128/221852 (87%)]\tLoss: 0.297161\tAcc: 70.00\n",
      "val epoch: 20 [128/221852 (0%)]\tLoss: 0.202642\tAcc: 70.00\n",
      "val epoch: 20 [12928/221852 (6%)]\tLoss: 0.258144\tAcc: 72.00\n",
      "train epoch: 21 [128/221852 (0%)]\tLoss: 0.322530\tAcc: 71.00\n",
      "train epoch: 21 [12928/221852 (6%)]\tLoss: 0.355284\tAcc: 72.00\n",
      "train epoch: 21 [25728/221852 (12%)]\tLoss: 0.339862\tAcc: 72.00\n",
      "train epoch: 21 [38528/221852 (17%)]\tLoss: 0.333527\tAcc: 69.00\n",
      "train epoch: 21 [51328/221852 (23%)]\tLoss: 0.236893\tAcc: 77.00\n",
      "train epoch: 21 [64128/221852 (29%)]\tLoss: 0.162559\tAcc: 73.00\n",
      "train epoch: 21 [76928/221852 (35%)]\tLoss: 0.269753\tAcc: 76.00\n",
      "train epoch: 21 [89728/221852 (40%)]\tLoss: 0.313180\tAcc: 72.00\n",
      "train epoch: 21 [102528/221852 (46%)]\tLoss: 0.256495\tAcc: 70.00\n",
      "train epoch: 21 [115328/221852 (52%)]\tLoss: 0.276773\tAcc: 70.00\n",
      "train epoch: 21 [128128/221852 (58%)]\tLoss: 0.207643\tAcc: 71.00\n",
      "train epoch: 21 [140928/221852 (64%)]\tLoss: 0.216631\tAcc: 80.00\n",
      "train epoch: 21 [153728/221852 (69%)]\tLoss: 0.236048\tAcc: 79.00\n",
      "train epoch: 21 [166528/221852 (75%)]\tLoss: 0.218931\tAcc: 84.00\n",
      "train epoch: 21 [179328/221852 (81%)]\tLoss: 0.478115\tAcc: 69.00\n",
      "train epoch: 21 [192128/221852 (87%)]\tLoss: 0.244595\tAcc: 71.00\n",
      "val epoch: 21 [128/221852 (0%)]\tLoss: 0.301625\tAcc: 65.00\n",
      "val epoch: 21 [12928/221852 (6%)]\tLoss: 0.194378\tAcc: 79.00\n",
      "train epoch: 22 [128/221852 (0%)]\tLoss: 0.250157\tAcc: 70.00\n",
      "train epoch: 22 [12928/221852 (6%)]\tLoss: 0.517232\tAcc: 65.00\n",
      "train epoch: 22 [25728/221852 (12%)]\tLoss: 0.268599\tAcc: 69.00\n",
      "train epoch: 22 [38528/221852 (17%)]\tLoss: 0.286612\tAcc: 71.00\n",
      "train epoch: 22 [51328/221852 (23%)]\tLoss: 0.373590\tAcc: 67.00\n",
      "train epoch: 22 [64128/221852 (29%)]\tLoss: 0.267205\tAcc: 71.00\n",
      "train epoch: 22 [76928/221852 (35%)]\tLoss: 0.363359\tAcc: 60.00\n",
      "train epoch: 22 [89728/221852 (40%)]\tLoss: 0.304216\tAcc: 73.00\n",
      "train epoch: 22 [102528/221852 (46%)]\tLoss: 0.228552\tAcc: 77.00\n",
      "train epoch: 22 [115328/221852 (52%)]\tLoss: 0.352805\tAcc: 66.00\n",
      "train epoch: 22 [128128/221852 (58%)]\tLoss: 0.322184\tAcc: 70.00\n",
      "train epoch: 22 [140928/221852 (64%)]\tLoss: 0.265960\tAcc: 72.00\n",
      "train epoch: 22 [153728/221852 (69%)]\tLoss: 0.298219\tAcc: 73.00\n",
      "train epoch: 22 [166528/221852 (75%)]\tLoss: 0.287375\tAcc: 74.00\n",
      "train epoch: 22 [179328/221852 (81%)]\tLoss: 0.253228\tAcc: 74.00\n",
      "train epoch: 22 [192128/221852 (87%)]\tLoss: 0.321216\tAcc: 66.00\n",
      "val epoch: 22 [128/221852 (0%)]\tLoss: 0.262074\tAcc: 67.00\n",
      "val epoch: 22 [12928/221852 (6%)]\tLoss: 0.285987\tAcc: 67.00\n",
      "train epoch: 23 [128/221852 (0%)]\tLoss: 0.275978\tAcc: 68.00\n",
      "train epoch: 23 [12928/221852 (6%)]\tLoss: 0.231774\tAcc: 68.00\n",
      "train epoch: 23 [25728/221852 (12%)]\tLoss: 0.227162\tAcc: 72.00\n",
      "train epoch: 23 [38528/221852 (17%)]\tLoss: 0.361412\tAcc: 63.00\n",
      "train epoch: 23 [51328/221852 (23%)]\tLoss: 0.312528\tAcc: 74.00\n",
      "train epoch: 23 [64128/221852 (29%)]\tLoss: 0.180209\tAcc: 71.00\n",
      "train epoch: 23 [76928/221852 (35%)]\tLoss: 0.262641\tAcc: 63.00\n",
      "train epoch: 23 [89728/221852 (40%)]\tLoss: 0.291395\tAcc: 66.00\n",
      "train epoch: 23 [102528/221852 (46%)]\tLoss: 0.290774\tAcc: 68.00\n",
      "train epoch: 23 [115328/221852 (52%)]\tLoss: 0.242191\tAcc: 75.00\n",
      "train epoch: 23 [128128/221852 (58%)]\tLoss: 0.309366\tAcc: 74.00\n",
      "train epoch: 23 [140928/221852 (64%)]\tLoss: 0.274705\tAcc: 76.00\n",
      "train epoch: 23 [153728/221852 (69%)]\tLoss: 0.185925\tAcc: 76.00\n",
      "train epoch: 23 [166528/221852 (75%)]\tLoss: 0.235403\tAcc: 78.00\n",
      "train epoch: 23 [179328/221852 (81%)]\tLoss: 0.227566\tAcc: 75.00\n",
      "train epoch: 23 [192128/221852 (87%)]\tLoss: 0.236973\tAcc: 70.00\n",
      "val epoch: 23 [128/221852 (0%)]\tLoss: 0.284559\tAcc: 76.00\n",
      "val epoch: 23 [12928/221852 (6%)]\tLoss: 0.283243\tAcc: 70.00\n",
      "train epoch: 24 [128/221852 (0%)]\tLoss: 0.257782\tAcc: 77.00\n",
      "train epoch: 24 [12928/221852 (6%)]\tLoss: 0.599138\tAcc: 63.00\n",
      "train epoch: 24 [25728/221852 (12%)]\tLoss: 0.506008\tAcc: 69.00\n",
      "train epoch: 24 [38528/221852 (17%)]\tLoss: 0.396790\tAcc: 65.00\n",
      "train epoch: 24 [51328/221852 (23%)]\tLoss: 0.351845\tAcc: 64.00\n",
      "train epoch: 24 [64128/221852 (29%)]\tLoss: 0.362650\tAcc: 68.00\n",
      "train epoch: 24 [76928/221852 (35%)]\tLoss: 0.406901\tAcc: 70.00\n",
      "train epoch: 24 [89728/221852 (40%)]\tLoss: 0.276557\tAcc: 63.00\n",
      "train epoch: 24 [102528/221852 (46%)]\tLoss: 0.336600\tAcc: 66.00\n",
      "train epoch: 24 [115328/221852 (52%)]\tLoss: 0.213879\tAcc: 66.00\n",
      "train epoch: 24 [128128/221852 (58%)]\tLoss: 0.303269\tAcc: 70.00\n",
      "train epoch: 24 [140928/221852 (64%)]\tLoss: 0.426611\tAcc: 63.00\n",
      "train epoch: 24 [153728/221852 (69%)]\tLoss: 0.286293\tAcc: 73.00\n",
      "train epoch: 24 [166528/221852 (75%)]\tLoss: 0.358517\tAcc: 69.00\n",
      "train epoch: 24 [179328/221852 (81%)]\tLoss: 0.263239\tAcc: 68.00\n",
      "train epoch: 24 [192128/221852 (87%)]\tLoss: 0.232914\tAcc: 67.00\n",
      "val epoch: 24 [128/221852 (0%)]\tLoss: 0.338919\tAcc: 59.00\n",
      "val epoch: 24 [12928/221852 (6%)]\tLoss: 0.271674\tAcc: 62.00\n",
      "train epoch: 25 [128/221852 (0%)]\tLoss: 0.343577\tAcc: 65.00\n",
      "train epoch: 25 [12928/221852 (6%)]\tLoss: 0.301621\tAcc: 58.00\n",
      "train epoch: 25 [25728/221852 (12%)]\tLoss: 0.294789\tAcc: 77.00\n",
      "train epoch: 25 [38528/221852 (17%)]\tLoss: 0.284612\tAcc: 77.00\n",
      "train epoch: 25 [51328/221852 (23%)]\tLoss: 0.348175\tAcc: 66.00\n",
      "train epoch: 25 [64128/221852 (29%)]\tLoss: 0.268948\tAcc: 68.00\n",
      "train epoch: 25 [76928/221852 (35%)]\tLoss: 0.229732\tAcc: 60.00\n",
      "train epoch: 25 [89728/221852 (40%)]\tLoss: 0.257641\tAcc: 65.00\n",
      "train epoch: 25 [102528/221852 (46%)]\tLoss: 0.308658\tAcc: 62.00\n",
      "train epoch: 25 [115328/221852 (52%)]\tLoss: 0.243308\tAcc: 66.00\n",
      "train epoch: 25 [128128/221852 (58%)]\tLoss: 0.398817\tAcc: 58.00\n",
      "train epoch: 25 [140928/221852 (64%)]\tLoss: 0.222728\tAcc: 70.00\n",
      "train epoch: 25 [153728/221852 (69%)]\tLoss: 0.253172\tAcc: 70.00\n",
      "train epoch: 25 [166528/221852 (75%)]\tLoss: 0.315933\tAcc: 62.00\n",
      "train epoch: 25 [179328/221852 (81%)]\tLoss: 0.363117\tAcc: 62.00\n",
      "train epoch: 25 [192128/221852 (87%)]\tLoss: 0.232423\tAcc: 73.00\n",
      "val epoch: 25 [128/221852 (0%)]\tLoss: 0.330742\tAcc: 65.00\n",
      "val epoch: 25 [12928/221852 (6%)]\tLoss: 0.322032\tAcc: 63.00\n",
      "train epoch: 26 [128/221852 (0%)]\tLoss: 0.304606\tAcc: 63.00\n",
      "train epoch: 26 [12928/221852 (6%)]\tLoss: 0.391660\tAcc: 62.00\n",
      "train epoch: 26 [25728/221852 (12%)]\tLoss: 0.287268\tAcc: 72.00\n",
      "train epoch: 26 [38528/221852 (17%)]\tLoss: 0.300788\tAcc: 69.00\n",
      "train epoch: 26 [51328/221852 (23%)]\tLoss: 0.197642\tAcc: 66.00\n",
      "train epoch: 26 [64128/221852 (29%)]\tLoss: 0.300886\tAcc: 56.00\n",
      "train epoch: 26 [76928/221852 (35%)]\tLoss: 0.325253\tAcc: 66.00\n",
      "train epoch: 26 [89728/221852 (40%)]\tLoss: 0.223769\tAcc: 71.00\n",
      "train epoch: 26 [102528/221852 (46%)]\tLoss: 0.303462\tAcc: 65.00\n",
      "train epoch: 26 [115328/221852 (52%)]\tLoss: 0.341809\tAcc: 73.00\n",
      "train epoch: 26 [128128/221852 (58%)]\tLoss: 0.321926\tAcc: 59.00\n",
      "train epoch: 26 [140928/221852 (64%)]\tLoss: 0.346438\tAcc: 69.00\n",
      "train epoch: 26 [153728/221852 (69%)]\tLoss: 0.251401\tAcc: 63.00\n",
      "train epoch: 26 [166528/221852 (75%)]\tLoss: 0.534536\tAcc: 60.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 26 [179328/221852 (81%)]\tLoss: 0.472119\tAcc: 63.00\n",
      "train epoch: 26 [192128/221852 (87%)]\tLoss: 0.366472\tAcc: 68.00\n",
      "val epoch: 26 [128/221852 (0%)]\tLoss: 0.319396\tAcc: 66.00\n",
      "val epoch: 26 [12928/221852 (6%)]\tLoss: 0.303417\tAcc: 65.00\n",
      "train epoch: 27 [128/221852 (0%)]\tLoss: 0.251229\tAcc: 72.00\n",
      "train epoch: 27 [12928/221852 (6%)]\tLoss: 0.319002\tAcc: 66.00\n",
      "train epoch: 27 [25728/221852 (12%)]\tLoss: 0.304936\tAcc: 65.00\n",
      "train epoch: 27 [38528/221852 (17%)]\tLoss: 0.356903\tAcc: 62.00\n",
      "train epoch: 27 [51328/221852 (23%)]\tLoss: 0.288008\tAcc: 62.00\n",
      "train epoch: 27 [64128/221852 (29%)]\tLoss: 0.206201\tAcc: 73.00\n",
      "train epoch: 27 [76928/221852 (35%)]\tLoss: 0.262592\tAcc: 65.00\n",
      "train epoch: 27 [89728/221852 (40%)]\tLoss: 0.272442\tAcc: 62.00\n",
      "train epoch: 27 [102528/221852 (46%)]\tLoss: 0.230043\tAcc: 74.00\n",
      "train epoch: 27 [115328/221852 (52%)]\tLoss: 0.225871\tAcc: 73.00\n",
      "train epoch: 27 [128128/221852 (58%)]\tLoss: 0.270996\tAcc: 71.00\n",
      "train epoch: 27 [140928/221852 (64%)]\tLoss: 0.236021\tAcc: 66.00\n",
      "train epoch: 27 [153728/221852 (69%)]\tLoss: 0.340645\tAcc: 60.00\n",
      "train epoch: 27 [166528/221852 (75%)]\tLoss: 0.223327\tAcc: 70.00\n",
      "train epoch: 27 [179328/221852 (81%)]\tLoss: 0.301349\tAcc: 69.00\n",
      "train epoch: 27 [192128/221852 (87%)]\tLoss: 0.284213\tAcc: 66.00\n",
      "val epoch: 27 [128/221852 (0%)]\tLoss: 0.372475\tAcc: 63.00\n",
      "val epoch: 27 [12928/221852 (6%)]\tLoss: 0.318885\tAcc: 63.00\n",
      "train epoch: 28 [128/221852 (0%)]\tLoss: 0.261277\tAcc: 63.00\n",
      "train epoch: 28 [12928/221852 (6%)]\tLoss: 0.317384\tAcc: 63.00\n",
      "train epoch: 28 [25728/221852 (12%)]\tLoss: 0.197609\tAcc: 74.00\n",
      "train epoch: 28 [38528/221852 (17%)]\tLoss: 0.273853\tAcc: 68.00\n",
      "train epoch: 28 [51328/221852 (23%)]\tLoss: 0.482214\tAcc: 66.00\n",
      "train epoch: 28 [64128/221852 (29%)]\tLoss: 0.297245\tAcc: 69.00\n",
      "train epoch: 28 [76928/221852 (35%)]\tLoss: 0.297649\tAcc: 64.00\n",
      "train epoch: 28 [89728/221852 (40%)]\tLoss: 0.294730\tAcc: 66.00\n",
      "train epoch: 28 [102528/221852 (46%)]\tLoss: 0.314429\tAcc: 66.00\n",
      "train epoch: 28 [115328/221852 (52%)]\tLoss: 0.215905\tAcc: 66.00\n",
      "train epoch: 28 [128128/221852 (58%)]\tLoss: 0.279197\tAcc: 66.00\n",
      "train epoch: 28 [140928/221852 (64%)]\tLoss: 0.209345\tAcc: 70.00\n",
      "train epoch: 28 [153728/221852 (69%)]\tLoss: 0.266040\tAcc: 70.00\n",
      "train epoch: 28 [166528/221852 (75%)]\tLoss: 0.288110\tAcc: 73.00\n",
      "train epoch: 28 [179328/221852 (81%)]\tLoss: 0.242281\tAcc: 73.00\n",
      "train epoch: 28 [192128/221852 (87%)]\tLoss: 0.382075\tAcc: 60.00\n",
      "val epoch: 28 [128/221852 (0%)]\tLoss: 0.300152\tAcc: 70.00\n",
      "val epoch: 28 [12928/221852 (6%)]\tLoss: 0.211329\tAcc: 69.00\n",
      "train epoch: 29 [128/221852 (0%)]\tLoss: 0.266648\tAcc: 77.00\n",
      "train epoch: 29 [12928/221852 (6%)]\tLoss: 0.217456\tAcc: 75.00\n",
      "train epoch: 29 [25728/221852 (12%)]\tLoss: 0.274229\tAcc: 77.00\n",
      "train epoch: 29 [38528/221852 (17%)]\tLoss: 0.234394\tAcc: 76.00\n",
      "train epoch: 29 [51328/221852 (23%)]\tLoss: 0.361676\tAcc: 64.00\n",
      "train epoch: 29 [64128/221852 (29%)]\tLoss: 0.227556\tAcc: 64.00\n",
      "train epoch: 29 [76928/221852 (35%)]\tLoss: 0.230286\tAcc: 77.00\n",
      "train epoch: 29 [89728/221852 (40%)]\tLoss: 0.259876\tAcc: 75.00\n",
      "train epoch: 29 [102528/221852 (46%)]\tLoss: 0.305240\tAcc: 76.00\n",
      "train epoch: 29 [115328/221852 (52%)]\tLoss: 0.439217\tAcc: 69.00\n",
      "train epoch: 29 [128128/221852 (58%)]\tLoss: 0.359122\tAcc: 63.00\n",
      "train epoch: 29 [140928/221852 (64%)]\tLoss: 0.272203\tAcc: 65.00\n",
      "train epoch: 29 [153728/221852 (69%)]\tLoss: 0.280391\tAcc: 65.00\n",
      "train epoch: 29 [166528/221852 (75%)]\tLoss: 0.251893\tAcc: 71.00\n",
      "train epoch: 29 [179328/221852 (81%)]\tLoss: 0.222790\tAcc: 72.00\n",
      "train epoch: 29 [192128/221852 (87%)]\tLoss: 0.292299\tAcc: 65.00\n",
      "val epoch: 29 [128/221852 (0%)]\tLoss: 0.250524\tAcc: 67.00\n",
      "val epoch: 29 [12928/221852 (6%)]\tLoss: 0.246031\tAcc: 69.00\n",
      "train epoch: 30 [128/221852 (0%)]\tLoss: 0.197678\tAcc: 66.00\n",
      "train epoch: 30 [12928/221852 (6%)]\tLoss: 0.430329\tAcc: 66.00\n",
      "train epoch: 30 [25728/221852 (12%)]\tLoss: 0.342368\tAcc: 62.00\n",
      "train epoch: 30 [38528/221852 (17%)]\tLoss: 0.242661\tAcc: 66.00\n",
      "train epoch: 30 [51328/221852 (23%)]\tLoss: 0.199669\tAcc: 68.00\n",
      "train epoch: 30 [64128/221852 (29%)]\tLoss: 0.337264\tAcc: 69.00\n",
      "train epoch: 30 [76928/221852 (35%)]\tLoss: 0.318985\tAcc: 62.00\n",
      "train epoch: 30 [89728/221852 (40%)]\tLoss: 0.356273\tAcc: 64.00\n",
      "train epoch: 30 [102528/221852 (46%)]\tLoss: 0.203839\tAcc: 63.00\n",
      "train epoch: 30 [115328/221852 (52%)]\tLoss: 0.330041\tAcc: 57.00\n",
      "train epoch: 30 [128128/221852 (58%)]\tLoss: 0.303586\tAcc: 67.00\n",
      "train epoch: 30 [140928/221852 (64%)]\tLoss: 0.339600\tAcc: 70.00\n",
      "train epoch: 30 [153728/221852 (69%)]\tLoss: 0.323502\tAcc: 62.00\n",
      "train epoch: 30 [166528/221852 (75%)]\tLoss: 0.292618\tAcc: 73.00\n",
      "train epoch: 30 [179328/221852 (81%)]\tLoss: 0.230951\tAcc: 75.00\n",
      "train epoch: 30 [192128/221852 (87%)]\tLoss: 0.410225\tAcc: 73.00\n",
      "val epoch: 30 [128/221852 (0%)]\tLoss: 0.234756\tAcc: 66.00\n",
      "val epoch: 30 [12928/221852 (6%)]\tLoss: 0.242679\tAcc: 64.00\n",
      "train epoch: 31 [128/221852 (0%)]\tLoss: 0.233095\tAcc: 61.00\n",
      "train epoch: 31 [12928/221852 (6%)]\tLoss: 0.208402\tAcc: 78.00\n",
      "train epoch: 31 [25728/221852 (12%)]\tLoss: 0.315737\tAcc: 66.00\n",
      "train epoch: 31 [38528/221852 (17%)]\tLoss: 0.264512\tAcc: 66.00\n",
      "train epoch: 31 [51328/221852 (23%)]\tLoss: 0.357403\tAcc: 74.00\n",
      "train epoch: 31 [64128/221852 (29%)]\tLoss: 0.228359\tAcc: 77.00\n",
      "train epoch: 31 [76928/221852 (35%)]\tLoss: 0.363969\tAcc: 70.00\n",
      "train epoch: 31 [89728/221852 (40%)]\tLoss: 0.150741\tAcc: 76.00\n",
      "train epoch: 31 [102528/221852 (46%)]\tLoss: 0.268109\tAcc: 68.00\n",
      "train epoch: 31 [115328/221852 (52%)]\tLoss: 0.204039\tAcc: 73.00\n",
      "train epoch: 31 [128128/221852 (58%)]\tLoss: 0.300670\tAcc: 64.00\n",
      "train epoch: 31 [140928/221852 (64%)]\tLoss: 0.277316\tAcc: 73.00\n",
      "train epoch: 31 [153728/221852 (69%)]\tLoss: 0.346721\tAcc: 62.00\n",
      "train epoch: 31 [166528/221852 (75%)]\tLoss: 0.251921\tAcc: 70.00\n",
      "train epoch: 31 [179328/221852 (81%)]\tLoss: 0.247786\tAcc: 69.00\n",
      "train epoch: 31 [192128/221852 (87%)]\tLoss: 0.242097\tAcc: 79.00\n",
      "val epoch: 31 [128/221852 (0%)]\tLoss: 0.234670\tAcc: 75.00\n",
      "val epoch: 31 [12928/221852 (6%)]\tLoss: 0.208182\tAcc: 77.00\n",
      "train epoch: 32 [128/221852 (0%)]\tLoss: 0.257937\tAcc: 71.00\n",
      "train epoch: 32 [12928/221852 (6%)]\tLoss: 0.281765\tAcc: 73.00\n",
      "train epoch: 32 [25728/221852 (12%)]\tLoss: 0.181102\tAcc: 78.00\n",
      "train epoch: 32 [38528/221852 (17%)]\tLoss: 0.222397\tAcc: 74.00\n",
      "train epoch: 32 [51328/221852 (23%)]\tLoss: 0.289553\tAcc: 62.00\n",
      "train epoch: 32 [64128/221852 (29%)]\tLoss: 0.273385\tAcc: 75.00\n",
      "train epoch: 32 [76928/221852 (35%)]\tLoss: 0.281664\tAcc: 66.00\n",
      "train epoch: 32 [89728/221852 (40%)]\tLoss: 0.315323\tAcc: 74.00\n",
      "train epoch: 32 [102528/221852 (46%)]\tLoss: 0.190242\tAcc: 73.00\n",
      "train epoch: 32 [115328/221852 (52%)]\tLoss: 0.224579\tAcc: 73.00\n",
      "train epoch: 32 [128128/221852 (58%)]\tLoss: 0.308123\tAcc: 68.00\n",
      "train epoch: 32 [140928/221852 (64%)]\tLoss: 0.257354\tAcc: 69.00\n",
      "train epoch: 32 [153728/221852 (69%)]\tLoss: 0.236676\tAcc: 73.00\n",
      "train epoch: 32 [166528/221852 (75%)]\tLoss: 0.578196\tAcc: 62.00\n",
      "train epoch: 32 [179328/221852 (81%)]\tLoss: 0.212284\tAcc: 70.00\n",
      "train epoch: 32 [192128/221852 (87%)]\tLoss: 0.261710\tAcc: 66.00\n",
      "val epoch: 32 [128/221852 (0%)]\tLoss: 0.292907\tAcc: 74.00\n",
      "val epoch: 32 [12928/221852 (6%)]\tLoss: 0.293123\tAcc: 67.00\n",
      "train epoch: 33 [128/221852 (0%)]\tLoss: 0.246804\tAcc: 77.00\n",
      "train epoch: 33 [12928/221852 (6%)]\tLoss: 0.425999\tAcc: 65.00\n",
      "train epoch: 33 [25728/221852 (12%)]\tLoss: 0.319814\tAcc: 69.00\n",
      "train epoch: 33 [38528/221852 (17%)]\tLoss: 0.403697\tAcc: 63.00\n",
      "train epoch: 33 [51328/221852 (23%)]\tLoss: 0.437031\tAcc: 70.00\n",
      "train epoch: 33 [64128/221852 (29%)]\tLoss: 0.310405\tAcc: 67.00\n",
      "train epoch: 33 [76928/221852 (35%)]\tLoss: 0.265879\tAcc: 71.00\n",
      "train epoch: 33 [89728/221852 (40%)]\tLoss: 0.186081\tAcc: 70.00\n",
      "train epoch: 33 [102528/221852 (46%)]\tLoss: 0.250732\tAcc: 73.00\n",
      "train epoch: 33 [115328/221852 (52%)]\tLoss: 0.253562\tAcc: 70.00\n",
      "train epoch: 33 [128128/221852 (58%)]\tLoss: 0.246633\tAcc: 77.00\n",
      "train epoch: 33 [140928/221852 (64%)]\tLoss: 0.164924\tAcc: 73.00\n",
      "train epoch: 33 [153728/221852 (69%)]\tLoss: 0.253829\tAcc: 70.00\n",
      "train epoch: 33 [166528/221852 (75%)]\tLoss: 0.228902\tAcc: 74.00\n",
      "train epoch: 33 [179328/221852 (81%)]\tLoss: 0.284659\tAcc: 73.00\n",
      "train epoch: 33 [192128/221852 (87%)]\tLoss: 0.260062\tAcc: 71.00\n",
      "val epoch: 33 [128/221852 (0%)]\tLoss: 0.382758\tAcc: 62.00\n",
      "val epoch: 33 [12928/221852 (6%)]\tLoss: 0.407605\tAcc: 67.00\n",
      "train epoch: 34 [128/221852 (0%)]\tLoss: 0.323611\tAcc: 69.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 34 [12928/221852 (6%)]\tLoss: 0.211820\tAcc: 73.00\n",
      "train epoch: 34 [25728/221852 (12%)]\tLoss: 0.217166\tAcc: 80.00\n",
      "train epoch: 34 [38528/221852 (17%)]\tLoss: 0.228985\tAcc: 74.00\n",
      "train epoch: 34 [51328/221852 (23%)]\tLoss: 0.290963\tAcc: 72.00\n",
      "train epoch: 34 [64128/221852 (29%)]\tLoss: 0.270193\tAcc: 72.00\n",
      "train epoch: 34 [76928/221852 (35%)]\tLoss: 0.210695\tAcc: 73.00\n",
      "train epoch: 34 [89728/221852 (40%)]\tLoss: 0.222767\tAcc: 76.00\n",
      "train epoch: 34 [102528/221852 (46%)]\tLoss: 0.314032\tAcc: 74.00\n",
      "train epoch: 34 [115328/221852 (52%)]\tLoss: 0.188156\tAcc: 72.00\n",
      "train epoch: 34 [128128/221852 (58%)]\tLoss: 0.525024\tAcc: 79.00\n",
      "train epoch: 34 [140928/221852 (64%)]\tLoss: 0.404219\tAcc: 60.00\n",
      "train epoch: 34 [153728/221852 (69%)]\tLoss: 0.289562\tAcc: 69.00\n",
      "train epoch: 34 [166528/221852 (75%)]\tLoss: 0.263644\tAcc: 66.00\n",
      "train epoch: 34 [179328/221852 (81%)]\tLoss: 0.274807\tAcc: 65.00\n",
      "train epoch: 34 [192128/221852 (87%)]\tLoss: 0.455150\tAcc: 61.00\n",
      "val epoch: 34 [128/221852 (0%)]\tLoss: 0.273102\tAcc: 67.00\n",
      "val epoch: 34 [12928/221852 (6%)]\tLoss: 0.327798\tAcc: 66.00\n",
      "train epoch: 35 [128/221852 (0%)]\tLoss: 0.443176\tAcc: 62.00\n",
      "train epoch: 35 [12928/221852 (6%)]\tLoss: 0.363896\tAcc: 59.00\n",
      "train epoch: 35 [25728/221852 (12%)]\tLoss: 0.251313\tAcc: 66.00\n",
      "train epoch: 35 [38528/221852 (17%)]\tLoss: 0.265416\tAcc: 68.00\n",
      "train epoch: 35 [51328/221852 (23%)]\tLoss: 0.261432\tAcc: 66.00\n",
      "train epoch: 35 [64128/221852 (29%)]\tLoss: 0.222862\tAcc: 65.00\n",
      "train epoch: 35 [76928/221852 (35%)]\tLoss: 0.257703\tAcc: 70.00\n",
      "train epoch: 35 [89728/221852 (40%)]\tLoss: 0.247287\tAcc: 67.00\n",
      "train epoch: 35 [102528/221852 (46%)]\tLoss: 0.353572\tAcc: 65.00\n",
      "train epoch: 35 [115328/221852 (52%)]\tLoss: 0.196816\tAcc: 70.00\n",
      "train epoch: 35 [128128/221852 (58%)]\tLoss: 0.254830\tAcc: 65.00\n",
      "train epoch: 35 [140928/221852 (64%)]\tLoss: 0.190113\tAcc: 74.00\n",
      "train epoch: 35 [153728/221852 (69%)]\tLoss: 0.283810\tAcc: 75.00\n",
      "train epoch: 35 [166528/221852 (75%)]\tLoss: 0.261594\tAcc: 76.00\n",
      "train epoch: 35 [179328/221852 (81%)]\tLoss: 0.253866\tAcc: 73.00\n",
      "train epoch: 35 [192128/221852 (87%)]\tLoss: 0.190106\tAcc: 70.00\n",
      "val epoch: 35 [128/221852 (0%)]\tLoss: 0.182279\tAcc: 74.00\n",
      "val epoch: 35 [12928/221852 (6%)]\tLoss: 0.186023\tAcc: 75.00\n",
      "train epoch: 36 [128/221852 (0%)]\tLoss: 0.353564\tAcc: 70.00\n",
      "train epoch: 36 [12928/221852 (6%)]\tLoss: 0.179049\tAcc: 80.00\n",
      "train epoch: 36 [25728/221852 (12%)]\tLoss: 0.263274\tAcc: 73.00\n",
      "train epoch: 36 [38528/221852 (17%)]\tLoss: 0.244777\tAcc: 74.00\n",
      "train epoch: 36 [51328/221852 (23%)]\tLoss: 0.561150\tAcc: 63.00\n",
      "train epoch: 36 [64128/221852 (29%)]\tLoss: 0.372953\tAcc: 68.00\n",
      "train epoch: 36 [76928/221852 (35%)]\tLoss: 0.366835\tAcc: 59.00\n",
      "train epoch: 36 [89728/221852 (40%)]\tLoss: 0.306372\tAcc: 66.00\n",
      "train epoch: 36 [102528/221852 (46%)]\tLoss: 0.248446\tAcc: 62.00\n",
      "train epoch: 36 [115328/221852 (52%)]\tLoss: 0.254119\tAcc: 71.00\n",
      "train epoch: 36 [128128/221852 (58%)]\tLoss: 0.223829\tAcc: 72.00\n",
      "train epoch: 36 [140928/221852 (64%)]\tLoss: 0.278844\tAcc: 69.00\n",
      "train epoch: 36 [153728/221852 (69%)]\tLoss: 0.258758\tAcc: 76.00\n",
      "train epoch: 36 [166528/221852 (75%)]\tLoss: 0.199111\tAcc: 79.00\n",
      "train epoch: 36 [179328/221852 (81%)]\tLoss: 0.244919\tAcc: 73.00\n",
      "train epoch: 36 [192128/221852 (87%)]\tLoss: 0.242090\tAcc: 76.00\n",
      "val epoch: 36 [128/221852 (0%)]\tLoss: 0.188572\tAcc: 71.00\n",
      "val epoch: 36 [12928/221852 (6%)]\tLoss: 0.197782\tAcc: 70.00\n",
      "train epoch: 37 [128/221852 (0%)]\tLoss: 0.168914\tAcc: 73.00\n",
      "train epoch: 37 [12928/221852 (6%)]\tLoss: 0.271902\tAcc: 66.00\n",
      "train epoch: 37 [25728/221852 (12%)]\tLoss: 0.249839\tAcc: 72.00\n",
      "train epoch: 37 [38528/221852 (17%)]\tLoss: 0.218377\tAcc: 70.00\n",
      "train epoch: 37 [51328/221852 (23%)]\tLoss: 0.241767\tAcc: 70.00\n",
      "train epoch: 37 [64128/221852 (29%)]\tLoss: 0.223304\tAcc: 70.00\n",
      "train epoch: 37 [76928/221852 (35%)]\tLoss: 0.270922\tAcc: 67.00\n",
      "train epoch: 37 [89728/221852 (40%)]\tLoss: 0.385205\tAcc: 72.00\n",
      "train epoch: 37 [102528/221852 (46%)]\tLoss: 0.241413\tAcc: 73.00\n",
      "train epoch: 37 [115328/221852 (52%)]\tLoss: 0.250535\tAcc: 73.00\n",
      "train epoch: 37 [128128/221852 (58%)]\tLoss: 0.217693\tAcc: 75.00\n",
      "train epoch: 37 [140928/221852 (64%)]\tLoss: 0.205834\tAcc: 78.00\n",
      "train epoch: 37 [153728/221852 (69%)]\tLoss: 0.380040\tAcc: 66.00\n",
      "train epoch: 37 [166528/221852 (75%)]\tLoss: 0.292069\tAcc: 73.00\n",
      "train epoch: 37 [179328/221852 (81%)]\tLoss: 0.191593\tAcc: 72.00\n",
      "train epoch: 37 [192128/221852 (87%)]\tLoss: 0.194181\tAcc: 73.00\n",
      "val epoch: 37 [128/221852 (0%)]\tLoss: 0.308786\tAcc: 73.00\n",
      "val epoch: 37 [12928/221852 (6%)]\tLoss: 0.351520\tAcc: 75.00\n",
      "train epoch: 38 [128/221852 (0%)]\tLoss: 0.348804\tAcc: 69.00\n",
      "train epoch: 38 [12928/221852 (6%)]\tLoss: 0.172845\tAcc: 79.00\n",
      "train epoch: 38 [25728/221852 (12%)]\tLoss: 0.340667\tAcc: 65.00\n",
      "train epoch: 38 [38528/221852 (17%)]\tLoss: 0.417816\tAcc: 76.00\n",
      "train epoch: 38 [51328/221852 (23%)]\tLoss: 0.297241\tAcc: 74.00\n",
      "train epoch: 38 [64128/221852 (29%)]\tLoss: 0.293992\tAcc: 76.00\n",
      "train epoch: 38 [76928/221852 (35%)]\tLoss: 0.235478\tAcc: 73.00\n",
      "train epoch: 38 [89728/221852 (40%)]\tLoss: 0.303946\tAcc: 73.00\n",
      "train epoch: 38 [102528/221852 (46%)]\tLoss: 0.393066\tAcc: 64.00\n",
      "train epoch: 38 [115328/221852 (52%)]\tLoss: 0.269991\tAcc: 77.00\n",
      "train epoch: 38 [128128/221852 (58%)]\tLoss: 0.134252\tAcc: 77.00\n",
      "train epoch: 38 [140928/221852 (64%)]\tLoss: 0.222260\tAcc: 71.00\n",
      "train epoch: 38 [153728/221852 (69%)]\tLoss: 0.189545\tAcc: 72.00\n",
      "train epoch: 38 [166528/221852 (75%)]\tLoss: 0.310199\tAcc: 75.00\n",
      "train epoch: 38 [179328/221852 (81%)]\tLoss: 0.201710\tAcc: 73.00\n",
      "train epoch: 38 [192128/221852 (87%)]\tLoss: 0.597875\tAcc: 76.00\n",
      "val epoch: 38 [128/221852 (0%)]\tLoss: 0.382948\tAcc: 74.00\n",
      "val epoch: 38 [12928/221852 (6%)]\tLoss: 0.317143\tAcc: 80.00\n",
      "train epoch: 39 [128/221852 (0%)]\tLoss: 0.344160\tAcc: 74.00\n",
      "train epoch: 39 [12928/221852 (6%)]\tLoss: 0.241386\tAcc: 77.00\n",
      "train epoch: 39 [25728/221852 (12%)]\tLoss: 0.198798\tAcc: 78.00\n",
      "train epoch: 39 [38528/221852 (17%)]\tLoss: 0.204204\tAcc: 75.00\n",
      "train epoch: 39 [51328/221852 (23%)]\tLoss: 0.263810\tAcc: 73.00\n",
      "train epoch: 39 [64128/221852 (29%)]\tLoss: 0.250404\tAcc: 77.00\n",
      "train epoch: 39 [76928/221852 (35%)]\tLoss: 0.224332\tAcc: 78.00\n",
      "train epoch: 39 [89728/221852 (40%)]\tLoss: 0.169435\tAcc: 77.00\n",
      "train epoch: 39 [102528/221852 (46%)]\tLoss: 0.285055\tAcc: 76.00\n",
      "train epoch: 39 [115328/221852 (52%)]\tLoss: 0.283915\tAcc: 72.00\n",
      "train epoch: 39 [128128/221852 (58%)]\tLoss: 0.253386\tAcc: 79.00\n",
      "train epoch: 39 [140928/221852 (64%)]\tLoss: 0.270812\tAcc: 76.00\n",
      "train epoch: 39 [153728/221852 (69%)]\tLoss: 0.227488\tAcc: 77.00\n",
      "train epoch: 39 [166528/221852 (75%)]\tLoss: 0.354740\tAcc: 73.00\n",
      "train epoch: 39 [179328/221852 (81%)]\tLoss: 0.289671\tAcc: 72.00\n",
      "train epoch: 39 [192128/221852 (87%)]\tLoss: 0.241303\tAcc: 71.00\n",
      "val epoch: 39 [128/221852 (0%)]\tLoss: 0.237002\tAcc: 72.00\n",
      "val epoch: 39 [12928/221852 (6%)]\tLoss: 0.215110\tAcc: 76.00\n",
      "train epoch: 40 [128/221852 (0%)]\tLoss: 0.250161\tAcc: 75.00\n",
      "train epoch: 40 [12928/221852 (6%)]\tLoss: 0.481487\tAcc: 73.00\n",
      "train epoch: 40 [25728/221852 (12%)]\tLoss: 0.159802\tAcc: 80.00\n",
      "train epoch: 40 [38528/221852 (17%)]\tLoss: 0.285489\tAcc: 71.00\n",
      "train epoch: 40 [51328/221852 (23%)]\tLoss: 0.192788\tAcc: 82.00\n",
      "train epoch: 40 [64128/221852 (29%)]\tLoss: 0.231895\tAcc: 74.00\n",
      "train epoch: 40 [76928/221852 (35%)]\tLoss: 0.263636\tAcc: 70.00\n",
      "train epoch: 40 [89728/221852 (40%)]\tLoss: 0.262869\tAcc: 73.00\n",
      "train epoch: 40 [102528/221852 (46%)]\tLoss: 0.278545\tAcc: 76.00\n",
      "train epoch: 40 [115328/221852 (52%)]\tLoss: 0.231812\tAcc: 71.00\n",
      "train epoch: 40 [128128/221852 (58%)]\tLoss: 0.307475\tAcc: 70.00\n",
      "train epoch: 40 [140928/221852 (64%)]\tLoss: 0.201385\tAcc: 75.00\n",
      "train epoch: 40 [153728/221852 (69%)]\tLoss: 0.280177\tAcc: 79.00\n",
      "train epoch: 40 [166528/221852 (75%)]\tLoss: 0.284870\tAcc: 66.00\n",
      "train epoch: 40 [179328/221852 (81%)]\tLoss: 0.233659\tAcc: 73.00\n",
      "train epoch: 40 [192128/221852 (87%)]\tLoss: 0.229818\tAcc: 75.00\n",
      "val epoch: 40 [128/221852 (0%)]\tLoss: 0.252681\tAcc: 73.00\n",
      "val epoch: 40 [12928/221852 (6%)]\tLoss: 0.163468\tAcc: 73.00\n",
      "train epoch: 41 [128/221852 (0%)]\tLoss: 0.255149\tAcc: 71.00\n",
      "train epoch: 41 [12928/221852 (6%)]\tLoss: 0.250343\tAcc: 75.00\n",
      "train epoch: 41 [25728/221852 (12%)]\tLoss: 0.187614\tAcc: 76.00\n",
      "train epoch: 41 [38528/221852 (17%)]\tLoss: 0.265600\tAcc: 72.00\n",
      "train epoch: 41 [51328/221852 (23%)]\tLoss: 0.297282\tAcc: 77.00\n",
      "train epoch: 41 [64128/221852 (29%)]\tLoss: 0.261032\tAcc: 73.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 41 [76928/221852 (35%)]\tLoss: 0.154756\tAcc: 80.00\n",
      "train epoch: 41 [89728/221852 (40%)]\tLoss: 0.264636\tAcc: 75.00\n",
      "train epoch: 41 [102528/221852 (46%)]\tLoss: 0.232617\tAcc: 77.00\n",
      "train epoch: 41 [115328/221852 (52%)]\tLoss: 0.249962\tAcc: 70.00\n",
      "train epoch: 41 [128128/221852 (58%)]\tLoss: 0.231810\tAcc: 76.00\n",
      "train epoch: 41 [140928/221852 (64%)]\tLoss: 0.228038\tAcc: 78.00\n",
      "train epoch: 41 [153728/221852 (69%)]\tLoss: 0.243395\tAcc: 73.00\n",
      "train epoch: 41 [166528/221852 (75%)]\tLoss: 0.270777\tAcc: 76.00\n",
      "train epoch: 41 [179328/221852 (81%)]\tLoss: 0.250830\tAcc: 75.00\n",
      "train epoch: 41 [192128/221852 (87%)]\tLoss: 0.241592\tAcc: 70.00\n",
      "val epoch: 41 [128/221852 (0%)]\tLoss: 0.136244\tAcc: 77.00\n",
      "val epoch: 41 [12928/221852 (6%)]\tLoss: 0.214516\tAcc: 74.00\n",
      "train epoch: 42 [128/221852 (0%)]\tLoss: 0.320536\tAcc: 70.00\n",
      "train epoch: 42 [12928/221852 (6%)]\tLoss: 0.291104\tAcc: 69.00\n",
      "train epoch: 42 [25728/221852 (12%)]\tLoss: 0.205991\tAcc: 80.00\n",
      "train epoch: 42 [38528/221852 (17%)]\tLoss: 0.239903\tAcc: 84.00\n",
      "train epoch: 42 [51328/221852 (23%)]\tLoss: 0.178197\tAcc: 74.00\n",
      "train epoch: 42 [64128/221852 (29%)]\tLoss: 0.246029\tAcc: 73.00\n",
      "train epoch: 42 [76928/221852 (35%)]\tLoss: 0.274583\tAcc: 75.00\n",
      "train epoch: 42 [89728/221852 (40%)]\tLoss: 0.213969\tAcc: 76.00\n",
      "train epoch: 42 [102528/221852 (46%)]\tLoss: 0.179493\tAcc: 75.00\n",
      "train epoch: 42 [115328/221852 (52%)]\tLoss: 0.283383\tAcc: 72.00\n",
      "train epoch: 42 [128128/221852 (58%)]\tLoss: 0.204414\tAcc: 78.00\n",
      "train epoch: 42 [140928/221852 (64%)]\tLoss: 0.217687\tAcc: 74.00\n",
      "train epoch: 42 [153728/221852 (69%)]\tLoss: 0.239592\tAcc: 78.00\n",
      "train epoch: 42 [166528/221852 (75%)]\tLoss: 0.234802\tAcc: 72.00\n",
      "train epoch: 42 [179328/221852 (81%)]\tLoss: 0.630001\tAcc: 79.00\n",
      "train epoch: 42 [192128/221852 (87%)]\tLoss: 0.248084\tAcc: 80.00\n",
      "val epoch: 42 [128/221852 (0%)]\tLoss: 0.237034\tAcc: 76.00\n",
      "val epoch: 42 [12928/221852 (6%)]\tLoss: 0.208991\tAcc: 73.00\n",
      "train epoch: 43 [128/221852 (0%)]\tLoss: 0.277589\tAcc: 74.00\n",
      "train epoch: 43 [12928/221852 (6%)]\tLoss: 0.219340\tAcc: 81.00\n",
      "train epoch: 43 [25728/221852 (12%)]\tLoss: 0.194673\tAcc: 81.00\n",
      "train epoch: 43 [38528/221852 (17%)]\tLoss: 0.281016\tAcc: 71.00\n",
      "train epoch: 43 [51328/221852 (23%)]\tLoss: 0.237625\tAcc: 77.00\n",
      "train epoch: 43 [64128/221852 (29%)]\tLoss: 0.272742\tAcc: 69.00\n",
      "train epoch: 43 [76928/221852 (35%)]\tLoss: 0.271092\tAcc: 76.00\n",
      "train epoch: 43 [89728/221852 (40%)]\tLoss: 0.326356\tAcc: 65.00\n",
      "train epoch: 43 [102528/221852 (46%)]\tLoss: 0.412527\tAcc: 66.00\n",
      "train epoch: 43 [115328/221852 (52%)]\tLoss: 0.317230\tAcc: 71.00\n",
      "train epoch: 43 [128128/221852 (58%)]\tLoss: 0.195702\tAcc: 78.00\n",
      "train epoch: 43 [140928/221852 (64%)]\tLoss: 0.286971\tAcc: 67.00\n",
      "train epoch: 43 [153728/221852 (69%)]\tLoss: 0.261034\tAcc: 70.00\n",
      "train epoch: 43 [166528/221852 (75%)]\tLoss: 0.258970\tAcc: 71.00\n",
      "train epoch: 43 [179328/221852 (81%)]\tLoss: 0.312819\tAcc: 68.00\n",
      "train epoch: 43 [192128/221852 (87%)]\tLoss: 0.259373\tAcc: 70.00\n",
      "val epoch: 43 [128/221852 (0%)]\tLoss: 0.280460\tAcc: 77.00\n",
      "val epoch: 43 [12928/221852 (6%)]\tLoss: 0.360701\tAcc: 63.00\n",
      "train epoch: 44 [128/221852 (0%)]\tLoss: 0.354152\tAcc: 69.00\n",
      "train epoch: 44 [12928/221852 (6%)]\tLoss: 0.291578\tAcc: 73.00\n",
      "train epoch: 44 [25728/221852 (12%)]\tLoss: 0.272842\tAcc: 68.00\n",
      "train epoch: 44 [38528/221852 (17%)]\tLoss: 0.204136\tAcc: 71.00\n",
      "train epoch: 44 [51328/221852 (23%)]\tLoss: 0.204153\tAcc: 76.00\n",
      "train epoch: 44 [64128/221852 (29%)]\tLoss: 0.233987\tAcc: 73.00\n",
      "train epoch: 44 [76928/221852 (35%)]\tLoss: 0.208343\tAcc: 73.00\n",
      "train epoch: 44 [89728/221852 (40%)]\tLoss: 0.232995\tAcc: 70.00\n",
      "train epoch: 44 [102528/221852 (46%)]\tLoss: 0.308377\tAcc: 66.00\n",
      "train epoch: 44 [115328/221852 (52%)]\tLoss: 0.225240\tAcc: 72.00\n",
      "train epoch: 44 [128128/221852 (58%)]\tLoss: 0.260440\tAcc: 78.00\n",
      "train epoch: 44 [140928/221852 (64%)]\tLoss: 0.243890\tAcc: 74.00\n",
      "train epoch: 44 [153728/221852 (69%)]\tLoss: 0.293007\tAcc: 70.00\n",
      "train epoch: 44 [166528/221852 (75%)]\tLoss: 0.485714\tAcc: 66.00\n",
      "train epoch: 44 [179328/221852 (81%)]\tLoss: 0.322692\tAcc: 55.00\n",
      "train epoch: 44 [192128/221852 (87%)]\tLoss: 0.251553\tAcc: 75.00\n",
      "val epoch: 44 [128/221852 (0%)]\tLoss: 0.284966\tAcc: 66.00\n",
      "val epoch: 44 [12928/221852 (6%)]\tLoss: 0.216410\tAcc: 72.00\n",
      "train epoch: 45 [128/221852 (0%)]\tLoss: 0.181682\tAcc: 69.00\n",
      "train epoch: 45 [12928/221852 (6%)]\tLoss: 0.360936\tAcc: 65.00\n",
      "train epoch: 45 [25728/221852 (12%)]\tLoss: 0.208981\tAcc: 73.00\n",
      "train epoch: 45 [38528/221852 (17%)]\tLoss: 0.231907\tAcc: 76.00\n",
      "train epoch: 45 [51328/221852 (23%)]\tLoss: 0.199883\tAcc: 77.00\n",
      "train epoch: 45 [64128/221852 (29%)]\tLoss: 0.347216\tAcc: 62.00\n",
      "train epoch: 45 [76928/221852 (35%)]\tLoss: 0.319488\tAcc: 81.00\n",
      "train epoch: 45 [89728/221852 (40%)]\tLoss: 0.236721\tAcc: 80.00\n",
      "train epoch: 45 [102528/221852 (46%)]\tLoss: 0.313937\tAcc: 69.00\n",
      "train epoch: 45 [115328/221852 (52%)]\tLoss: 0.245302\tAcc: 76.00\n",
      "train epoch: 45 [128128/221852 (58%)]\tLoss: 0.242962\tAcc: 83.00\n",
      "train epoch: 45 [140928/221852 (64%)]\tLoss: 0.223314\tAcc: 71.00\n",
      "train epoch: 45 [153728/221852 (69%)]\tLoss: 0.232519\tAcc: 73.00\n",
      "train epoch: 45 [166528/221852 (75%)]\tLoss: 0.180325\tAcc: 77.00\n",
      "train epoch: 45 [179328/221852 (81%)]\tLoss: 0.262977\tAcc: 73.00\n",
      "train epoch: 45 [192128/221852 (87%)]\tLoss: 0.316426\tAcc: 70.00\n",
      "val epoch: 45 [128/221852 (0%)]\tLoss: 0.247416\tAcc: 63.00\n",
      "val epoch: 45 [12928/221852 (6%)]\tLoss: 0.237884\tAcc: 75.00\n",
      "train epoch: 46 [128/221852 (0%)]\tLoss: 0.252097\tAcc: 66.00\n",
      "train epoch: 46 [12928/221852 (6%)]\tLoss: 0.327359\tAcc: 73.00\n",
      "train epoch: 46 [25728/221852 (12%)]\tLoss: 0.258745\tAcc: 70.00\n",
      "train epoch: 46 [38528/221852 (17%)]\tLoss: 0.186348\tAcc: 76.00\n",
      "train epoch: 46 [51328/221852 (23%)]\tLoss: 0.177261\tAcc: 81.00\n",
      "train epoch: 46 [64128/221852 (29%)]\tLoss: 0.276121\tAcc: 71.00\n",
      "train epoch: 46 [76928/221852 (35%)]\tLoss: 1.085605\tAcc: 73.00\n",
      "train epoch: 46 [89728/221852 (40%)]\tLoss: 0.350459\tAcc: 65.00\n",
      "train epoch: 46 [102528/221852 (46%)]\tLoss: 0.351848\tAcc: 73.00\n",
      "train epoch: 46 [115328/221852 (52%)]\tLoss: 0.211011\tAcc: 76.00\n",
      "train epoch: 46 [128128/221852 (58%)]\tLoss: 0.265744\tAcc: 70.00\n",
      "train epoch: 46 [140928/221852 (64%)]\tLoss: 0.264084\tAcc: 73.00\n",
      "train epoch: 46 [153728/221852 (69%)]\tLoss: 0.271851\tAcc: 70.00\n",
      "train epoch: 46 [166528/221852 (75%)]\tLoss: 0.166588\tAcc: 77.00\n",
      "train epoch: 46 [179328/221852 (81%)]\tLoss: 0.362929\tAcc: 62.00\n",
      "train epoch: 46 [192128/221852 (87%)]\tLoss: 0.192544\tAcc: 68.00\n",
      "val epoch: 46 [128/221852 (0%)]\tLoss: 0.247286\tAcc: 70.00\n",
      "val epoch: 46 [12928/221852 (6%)]\tLoss: 0.310710\tAcc: 78.00\n",
      "train epoch: 47 [128/221852 (0%)]\tLoss: 0.281276\tAcc: 66.00\n",
      "train epoch: 47 [12928/221852 (6%)]\tLoss: 0.137889\tAcc: 74.00\n",
      "train epoch: 47 [25728/221852 (12%)]\tLoss: 0.191639\tAcc: 77.00\n",
      "train epoch: 47 [38528/221852 (17%)]\tLoss: 0.138280\tAcc: 77.00\n",
      "train epoch: 47 [51328/221852 (23%)]\tLoss: 0.353682\tAcc: 70.00\n",
      "train epoch: 47 [64128/221852 (29%)]\tLoss: 0.270999\tAcc: 77.00\n",
      "train epoch: 47 [76928/221852 (35%)]\tLoss: 0.195798\tAcc: 70.00\n",
      "train epoch: 47 [89728/221852 (40%)]\tLoss: 0.219713\tAcc: 71.00\n",
      "train epoch: 47 [102528/221852 (46%)]\tLoss: 0.247187\tAcc: 67.00\n",
      "train epoch: 47 [115328/221852 (52%)]\tLoss: 0.251617\tAcc: 70.00\n",
      "train epoch: 47 [128128/221852 (58%)]\tLoss: 0.220270\tAcc: 72.00\n",
      "train epoch: 47 [140928/221852 (64%)]\tLoss: 0.241325\tAcc: 74.00\n",
      "train epoch: 47 [153728/221852 (69%)]\tLoss: 0.301196\tAcc: 74.00\n",
      "train epoch: 47 [166528/221852 (75%)]\tLoss: 0.197181\tAcc: 74.00\n",
      "train epoch: 47 [179328/221852 (81%)]\tLoss: 0.206890\tAcc: 84.00\n",
      "train epoch: 47 [192128/221852 (87%)]\tLoss: 0.266272\tAcc: 83.00\n",
      "val epoch: 47 [128/221852 (0%)]\tLoss: 0.294819\tAcc: 68.00\n",
      "val epoch: 47 [12928/221852 (6%)]\tLoss: 0.218275\tAcc: 73.00\n",
      "train epoch: 48 [128/221852 (0%)]\tLoss: 0.240531\tAcc: 70.00\n",
      "train epoch: 48 [12928/221852 (6%)]\tLoss: 0.447678\tAcc: 68.00\n",
      "train epoch: 48 [25728/221852 (12%)]\tLoss: 0.255235\tAcc: 77.00\n",
      "train epoch: 48 [38528/221852 (17%)]\tLoss: 0.170691\tAcc: 77.00\n",
      "train epoch: 48 [51328/221852 (23%)]\tLoss: 0.178499\tAcc: 78.00\n",
      "train epoch: 48 [64128/221852 (29%)]\tLoss: 0.467210\tAcc: 55.00\n",
      "train epoch: 48 [76928/221852 (35%)]\tLoss: 0.208636\tAcc: 78.00\n",
      "train epoch: 48 [89728/221852 (40%)]\tLoss: 0.161180\tAcc: 77.00\n",
      "train epoch: 48 [102528/221852 (46%)]\tLoss: 0.214345\tAcc: 70.00\n",
      "train epoch: 48 [115328/221852 (52%)]\tLoss: 0.287055\tAcc: 66.00\n",
      "train epoch: 48 [128128/221852 (58%)]\tLoss: 0.166275\tAcc: 77.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 48 [140928/221852 (64%)]\tLoss: 0.237417\tAcc: 64.00\n",
      "train epoch: 48 [153728/221852 (69%)]\tLoss: 0.266383\tAcc: 74.00\n",
      "train epoch: 48 [166528/221852 (75%)]\tLoss: 0.201890\tAcc: 78.00\n",
      "train epoch: 48 [179328/221852 (81%)]\tLoss: 0.251724\tAcc: 77.00\n",
      "train epoch: 48 [192128/221852 (87%)]\tLoss: 0.195761\tAcc: 75.00\n",
      "val epoch: 48 [128/221852 (0%)]\tLoss: 0.216643\tAcc: 78.00\n",
      "val epoch: 48 [12928/221852 (6%)]\tLoss: 0.210020\tAcc: 74.00\n",
      "train epoch: 49 [128/221852 (0%)]\tLoss: 0.278521\tAcc: 70.00\n",
      "train epoch: 49 [12928/221852 (6%)]\tLoss: 0.200286\tAcc: 68.00\n",
      "train epoch: 49 [25728/221852 (12%)]\tLoss: 0.267640\tAcc: 70.00\n",
      "train epoch: 49 [38528/221852 (17%)]\tLoss: 0.252283\tAcc: 73.00\n",
      "train epoch: 49 [51328/221852 (23%)]\tLoss: 0.234312\tAcc: 77.00\n",
      "train epoch: 49 [64128/221852 (29%)]\tLoss: 0.217205\tAcc: 74.00\n",
      "train epoch: 49 [76928/221852 (35%)]\tLoss: 0.332894\tAcc: 78.00\n",
      "train epoch: 49 [89728/221852 (40%)]\tLoss: 0.195233\tAcc: 74.00\n",
      "train epoch: 49 [102528/221852 (46%)]\tLoss: 0.181927\tAcc: 84.00\n",
      "train epoch: 49 [115328/221852 (52%)]\tLoss: 0.265844\tAcc: 79.00\n",
      "train epoch: 49 [128128/221852 (58%)]\tLoss: 0.236256\tAcc: 80.00\n",
      "train epoch: 49 [140928/221852 (64%)]\tLoss: 0.214112\tAcc: 75.00\n",
      "train epoch: 49 [153728/221852 (69%)]\tLoss: 0.161904\tAcc: 80.00\n",
      "train epoch: 49 [166528/221852 (75%)]\tLoss: 0.206085\tAcc: 77.00\n",
      "train epoch: 49 [179328/221852 (81%)]\tLoss: 0.206086\tAcc: 76.00\n",
      "train epoch: 49 [192128/221852 (87%)]\tLoss: 0.206886\tAcc: 78.00\n",
      "val epoch: 49 [128/221852 (0%)]\tLoss: 0.193569\tAcc: 75.00\n",
      "val epoch: 49 [12928/221852 (6%)]\tLoss: 0.212301\tAcc: 81.00\n",
      "train epoch: 50 [128/221852 (0%)]\tLoss: 0.099708\tAcc: 81.00\n",
      "train epoch: 50 [12928/221852 (6%)]\tLoss: 0.281265\tAcc: 73.00\n",
      "train epoch: 50 [25728/221852 (12%)]\tLoss: 0.206676\tAcc: 73.00\n",
      "train epoch: 50 [38528/221852 (17%)]\tLoss: 0.254718\tAcc: 76.00\n",
      "train epoch: 50 [51328/221852 (23%)]\tLoss: 0.382513\tAcc: 67.00\n",
      "train epoch: 50 [64128/221852 (29%)]\tLoss: 0.229155\tAcc: 73.00\n",
      "train epoch: 50 [76928/221852 (35%)]\tLoss: 0.187807\tAcc: 75.00\n",
      "train epoch: 50 [89728/221852 (40%)]\tLoss: 0.189780\tAcc: 81.00\n",
      "train epoch: 50 [102528/221852 (46%)]\tLoss: 0.197831\tAcc: 74.00\n",
      "train epoch: 50 [115328/221852 (52%)]\tLoss: 0.172989\tAcc: 77.00\n",
      "train epoch: 50 [128128/221852 (58%)]\tLoss: 0.305398\tAcc: 70.00\n",
      "train epoch: 50 [140928/221852 (64%)]\tLoss: 0.241799\tAcc: 69.00\n",
      "train epoch: 50 [153728/221852 (69%)]\tLoss: 0.258335\tAcc: 78.00\n",
      "train epoch: 50 [166528/221852 (75%)]\tLoss: 0.241463\tAcc: 69.00\n",
      "train epoch: 50 [179328/221852 (81%)]\tLoss: 0.253989\tAcc: 70.00\n",
      "train epoch: 50 [192128/221852 (87%)]\tLoss: 0.152473\tAcc: 81.00\n",
      "val epoch: 50 [128/221852 (0%)]\tLoss: 0.211099\tAcc: 73.00\n",
      "val epoch: 50 [12928/221852 (6%)]\tLoss: 0.256441\tAcc: 69.00\n",
      "train epoch: 51 [128/221852 (0%)]\tLoss: 0.275044\tAcc: 78.00\n",
      "train epoch: 51 [12928/221852 (6%)]\tLoss: 0.230926\tAcc: 76.00\n",
      "train epoch: 51 [25728/221852 (12%)]\tLoss: 0.192375\tAcc: 70.00\n",
      "train epoch: 51 [38528/221852 (17%)]\tLoss: 0.212682\tAcc: 80.00\n",
      "train epoch: 51 [51328/221852 (23%)]\tLoss: 0.255900\tAcc: 76.00\n",
      "train epoch: 51 [64128/221852 (29%)]\tLoss: 0.249243\tAcc: 74.00\n",
      "train epoch: 51 [76928/221852 (35%)]\tLoss: 0.171637\tAcc: 78.00\n",
      "train epoch: 51 [89728/221852 (40%)]\tLoss: 0.226418\tAcc: 73.00\n",
      "train epoch: 51 [102528/221852 (46%)]\tLoss: 0.267465\tAcc: 66.00\n",
      "train epoch: 51 [115328/221852 (52%)]\tLoss: 0.333741\tAcc: 68.00\n",
      "train epoch: 51 [128128/221852 (58%)]\tLoss: 0.241982\tAcc: 75.00\n",
      "train epoch: 51 [140928/221852 (64%)]\tLoss: 0.303467\tAcc: 75.00\n",
      "train epoch: 51 [153728/221852 (69%)]\tLoss: 0.192311\tAcc: 72.00\n",
      "train epoch: 51 [166528/221852 (75%)]\tLoss: 0.204220\tAcc: 76.00\n",
      "train epoch: 51 [179328/221852 (81%)]\tLoss: 0.204301\tAcc: 75.00\n",
      "train epoch: 51 [192128/221852 (87%)]\tLoss: 0.255923\tAcc: 72.00\n",
      "val epoch: 51 [128/221852 (0%)]\tLoss: 0.195885\tAcc: 77.00\n",
      "val epoch: 51 [12928/221852 (6%)]\tLoss: 0.262808\tAcc: 68.00\n",
      "train epoch: 52 [128/221852 (0%)]\tLoss: 0.277893\tAcc: 72.00\n",
      "train epoch: 52 [12928/221852 (6%)]\tLoss: 0.195176\tAcc: 79.00\n",
      "train epoch: 52 [25728/221852 (12%)]\tLoss: 0.167815\tAcc: 77.00\n",
      "train epoch: 52 [38528/221852 (17%)]\tLoss: 0.194139\tAcc: 79.00\n",
      "train epoch: 52 [51328/221852 (23%)]\tLoss: 0.229815\tAcc: 79.00\n",
      "train epoch: 52 [64128/221852 (29%)]\tLoss: 0.236272\tAcc: 76.00\n",
      "train epoch: 52 [76928/221852 (35%)]\tLoss: 0.407433\tAcc: 66.00\n",
      "train epoch: 52 [89728/221852 (40%)]\tLoss: 0.287456\tAcc: 83.00\n",
      "train epoch: 52 [102528/221852 (46%)]\tLoss: 0.401626\tAcc: 68.00\n",
      "train epoch: 52 [115328/221852 (52%)]\tLoss: 0.229273\tAcc: 72.00\n",
      "train epoch: 52 [128128/221852 (58%)]\tLoss: 0.209091\tAcc: 79.00\n",
      "train epoch: 52 [140928/221852 (64%)]\tLoss: 0.295280\tAcc: 65.00\n",
      "train epoch: 52 [153728/221852 (69%)]\tLoss: 0.279659\tAcc: 71.00\n",
      "train epoch: 52 [166528/221852 (75%)]\tLoss: 0.184785\tAcc: 80.00\n",
      "train epoch: 52 [179328/221852 (81%)]\tLoss: 0.173202\tAcc: 78.00\n",
      "train epoch: 52 [192128/221852 (87%)]\tLoss: 0.238632\tAcc: 74.00\n",
      "val epoch: 52 [128/221852 (0%)]\tLoss: 0.214801\tAcc: 78.00\n",
      "val epoch: 52 [12928/221852 (6%)]\tLoss: 0.189670\tAcc: 80.00\n",
      "train epoch: 53 [128/221852 (0%)]\tLoss: 0.191153\tAcc: 77.00\n",
      "train epoch: 53 [12928/221852 (6%)]\tLoss: 0.209220\tAcc: 77.00\n",
      "train epoch: 53 [25728/221852 (12%)]\tLoss: 0.221746\tAcc: 82.00\n",
      "train epoch: 53 [38528/221852 (17%)]\tLoss: 0.246257\tAcc: 81.00\n",
      "train epoch: 53 [51328/221852 (23%)]\tLoss: 0.252852\tAcc: 68.00\n",
      "train epoch: 53 [64128/221852 (29%)]\tLoss: 0.211072\tAcc: 72.00\n",
      "train epoch: 53 [76928/221852 (35%)]\tLoss: 0.189363\tAcc: 84.00\n",
      "train epoch: 53 [89728/221852 (40%)]\tLoss: 0.305727\tAcc: 73.00\n",
      "train epoch: 53 [102528/221852 (46%)]\tLoss: 0.209159\tAcc: 73.00\n",
      "train epoch: 53 [115328/221852 (52%)]\tLoss: 0.203640\tAcc: 71.00\n",
      "train epoch: 53 [128128/221852 (58%)]\tLoss: 0.205976\tAcc: 77.00\n",
      "train epoch: 53 [140928/221852 (64%)]\tLoss: 0.315362\tAcc: 71.00\n",
      "train epoch: 53 [153728/221852 (69%)]\tLoss: 0.323519\tAcc: 78.00\n",
      "train epoch: 53 [166528/221852 (75%)]\tLoss: 0.226941\tAcc: 73.00\n",
      "train epoch: 53 [179328/221852 (81%)]\tLoss: 0.341185\tAcc: 66.00\n",
      "train epoch: 53 [192128/221852 (87%)]\tLoss: 0.254547\tAcc: 75.00\n",
      "val epoch: 53 [128/221852 (0%)]\tLoss: 0.237748\tAcc: 70.00\n",
      "val epoch: 53 [12928/221852 (6%)]\tLoss: 0.232825\tAcc: 73.00\n",
      "train epoch: 54 [128/221852 (0%)]\tLoss: 0.242735\tAcc: 69.00\n",
      "train epoch: 54 [12928/221852 (6%)]\tLoss: 0.176857\tAcc: 79.00\n",
      "train epoch: 54 [25728/221852 (12%)]\tLoss: 0.245210\tAcc: 77.00\n",
      "train epoch: 54 [38528/221852 (17%)]\tLoss: 0.339977\tAcc: 70.00\n",
      "train epoch: 54 [51328/221852 (23%)]\tLoss: 0.231750\tAcc: 77.00\n",
      "train epoch: 54 [64128/221852 (29%)]\tLoss: 0.255340\tAcc: 80.00\n",
      "train epoch: 54 [76928/221852 (35%)]\tLoss: 0.187440\tAcc: 77.00\n",
      "train epoch: 54 [89728/221852 (40%)]\tLoss: 0.381432\tAcc: 66.00\n",
      "train epoch: 54 [102528/221852 (46%)]\tLoss: 0.213276\tAcc: 73.00\n",
      "train epoch: 54 [115328/221852 (52%)]\tLoss: 0.450196\tAcc: 60.00\n",
      "train epoch: 54 [128128/221852 (58%)]\tLoss: 0.217700\tAcc: 73.00\n",
      "train epoch: 54 [140928/221852 (64%)]\tLoss: 0.225878\tAcc: 70.00\n",
      "train epoch: 54 [153728/221852 (69%)]\tLoss: 0.151699\tAcc: 78.00\n",
      "train epoch: 54 [166528/221852 (75%)]\tLoss: 0.156358\tAcc: 72.00\n",
      "train epoch: 54 [179328/221852 (81%)]\tLoss: 0.357319\tAcc: 67.00\n",
      "train epoch: 54 [192128/221852 (87%)]\tLoss: 0.189950\tAcc: 79.00\n",
      "val epoch: 54 [128/221852 (0%)]\tLoss: 0.198440\tAcc: 83.00\n",
      "val epoch: 54 [12928/221852 (6%)]\tLoss: 0.180948\tAcc: 74.00\n",
      "train epoch: 55 [128/221852 (0%)]\tLoss: 0.281358\tAcc: 71.00\n",
      "train epoch: 55 [12928/221852 (6%)]\tLoss: 0.127531\tAcc: 80.00\n",
      "train epoch: 55 [25728/221852 (12%)]\tLoss: 0.278395\tAcc: 66.00\n",
      "train epoch: 55 [38528/221852 (17%)]\tLoss: 0.293426\tAcc: 72.00\n",
      "train epoch: 55 [51328/221852 (23%)]\tLoss: 0.245805\tAcc: 74.00\n",
      "train epoch: 55 [64128/221852 (29%)]\tLoss: 0.206477\tAcc: 79.00\n",
      "train epoch: 55 [76928/221852 (35%)]\tLoss: 0.259114\tAcc: 70.00\n",
      "train epoch: 55 [89728/221852 (40%)]\tLoss: 0.260542\tAcc: 70.00\n",
      "train epoch: 55 [102528/221852 (46%)]\tLoss: 0.265164\tAcc: 69.00\n",
      "train epoch: 55 [115328/221852 (52%)]\tLoss: 0.183260\tAcc: 74.00\n",
      "train epoch: 55 [128128/221852 (58%)]\tLoss: 0.145610\tAcc: 76.00\n",
      "train epoch: 55 [140928/221852 (64%)]\tLoss: 0.213291\tAcc: 76.00\n",
      "train epoch: 55 [153728/221852 (69%)]\tLoss: 0.132935\tAcc: 76.00\n",
      "train epoch: 55 [166528/221852 (75%)]\tLoss: 0.211372\tAcc: 81.00\n",
      "train epoch: 55 [179328/221852 (81%)]\tLoss: 0.339926\tAcc: 75.00\n",
      "train epoch: 55 [192128/221852 (87%)]\tLoss: 0.198742\tAcc: 84.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 55 [128/221852 (0%)]\tLoss: 0.171386\tAcc: 78.00\n",
      "val epoch: 55 [12928/221852 (6%)]\tLoss: 0.245729\tAcc: 77.00\n",
      "train epoch: 56 [128/221852 (0%)]\tLoss: 0.162188\tAcc: 76.00\n",
      "train epoch: 56 [12928/221852 (6%)]\tLoss: 0.189255\tAcc: 78.00\n",
      "train epoch: 56 [25728/221852 (12%)]\tLoss: 0.238399\tAcc: 68.00\n",
      "train epoch: 56 [38528/221852 (17%)]\tLoss: 0.162353\tAcc: 73.00\n",
      "train epoch: 56 [51328/221852 (23%)]\tLoss: 0.275152\tAcc: 66.00\n",
      "train epoch: 56 [64128/221852 (29%)]\tLoss: 0.140956\tAcc: 77.00\n",
      "train epoch: 56 [76928/221852 (35%)]\tLoss: 0.303714\tAcc: 70.00\n",
      "train epoch: 56 [89728/221852 (40%)]\tLoss: 0.233955\tAcc: 68.00\n",
      "train epoch: 56 [102528/221852 (46%)]\tLoss: 0.146779\tAcc: 78.00\n",
      "train epoch: 56 [115328/221852 (52%)]\tLoss: 0.311819\tAcc: 77.00\n",
      "train epoch: 56 [128128/221852 (58%)]\tLoss: 0.177716\tAcc: 70.00\n",
      "train epoch: 56 [140928/221852 (64%)]\tLoss: 0.151239\tAcc: 77.00\n",
      "train epoch: 56 [153728/221852 (69%)]\tLoss: 0.171623\tAcc: 80.00\n",
      "train epoch: 56 [166528/221852 (75%)]\tLoss: 0.180882\tAcc: 73.00\n",
      "train epoch: 56 [179328/221852 (81%)]\tLoss: 0.192585\tAcc: 70.00\n",
      "train epoch: 56 [192128/221852 (87%)]\tLoss: 0.128043\tAcc: 72.00\n",
      "val epoch: 56 [128/221852 (0%)]\tLoss: 0.211737\tAcc: 78.00\n",
      "val epoch: 56 [12928/221852 (6%)]\tLoss: 0.226692\tAcc: 74.00\n",
      "train epoch: 57 [128/221852 (0%)]\tLoss: 0.200927\tAcc: 75.00\n",
      "train epoch: 57 [12928/221852 (6%)]\tLoss: 0.161044\tAcc: 74.00\n",
      "train epoch: 57 [25728/221852 (12%)]\tLoss: 0.153992\tAcc: 79.00\n",
      "train epoch: 57 [38528/221852 (17%)]\tLoss: 0.267861\tAcc: 68.00\n",
      "train epoch: 57 [51328/221852 (23%)]\tLoss: 0.228979\tAcc: 73.00\n",
      "train epoch: 57 [64128/221852 (29%)]\tLoss: 0.180398\tAcc: 77.00\n",
      "train epoch: 57 [76928/221852 (35%)]\tLoss: 0.206316\tAcc: 77.00\n",
      "train epoch: 57 [89728/221852 (40%)]\tLoss: 0.184183\tAcc: 79.00\n",
      "train epoch: 57 [102528/221852 (46%)]\tLoss: 0.244268\tAcc: 82.00\n",
      "train epoch: 57 [115328/221852 (52%)]\tLoss: 0.280264\tAcc: 78.00\n",
      "train epoch: 57 [128128/221852 (58%)]\tLoss: 0.220260\tAcc: 77.00\n",
      "train epoch: 57 [140928/221852 (64%)]\tLoss: 0.216597\tAcc: 78.00\n",
      "train epoch: 57 [153728/221852 (69%)]\tLoss: 0.355812\tAcc: 75.00\n",
      "train epoch: 57 [166528/221852 (75%)]\tLoss: 0.234745\tAcc: 76.00\n",
      "train epoch: 57 [179328/221852 (81%)]\tLoss: 0.269928\tAcc: 73.00\n",
      "train epoch: 57 [192128/221852 (87%)]\tLoss: 0.169376\tAcc: 73.00\n",
      "val epoch: 57 [128/221852 (0%)]\tLoss: 0.181399\tAcc: 80.00\n",
      "val epoch: 57 [12928/221852 (6%)]\tLoss: 0.252369\tAcc: 74.00\n",
      "train epoch: 58 [128/221852 (0%)]\tLoss: 0.213093\tAcc: 76.00\n",
      "train epoch: 58 [12928/221852 (6%)]\tLoss: 0.177484\tAcc: 77.00\n",
      "train epoch: 58 [25728/221852 (12%)]\tLoss: 0.262304\tAcc: 75.00\n",
      "train epoch: 58 [38528/221852 (17%)]\tLoss: 0.118199\tAcc: 78.00\n",
      "train epoch: 58 [51328/221852 (23%)]\tLoss: 0.195999\tAcc: 74.00\n",
      "train epoch: 58 [64128/221852 (29%)]\tLoss: 0.138051\tAcc: 81.00\n",
      "train epoch: 58 [76928/221852 (35%)]\tLoss: 0.168021\tAcc: 77.00\n",
      "train epoch: 58 [89728/221852 (40%)]\tLoss: 0.193278\tAcc: 73.00\n",
      "train epoch: 58 [102528/221852 (46%)]\tLoss: 0.242546\tAcc: 80.00\n",
      "train epoch: 58 [115328/221852 (52%)]\tLoss: 0.213827\tAcc: 74.00\n",
      "train epoch: 58 [128128/221852 (58%)]\tLoss: 0.192243\tAcc: 78.00\n",
      "train epoch: 58 [140928/221852 (64%)]\tLoss: 0.223248\tAcc: 75.00\n",
      "train epoch: 58 [153728/221852 (69%)]\tLoss: 0.117437\tAcc: 85.00\n",
      "train epoch: 58 [166528/221852 (75%)]\tLoss: 1.401950\tAcc: 73.00\n",
      "train epoch: 58 [179328/221852 (81%)]\tLoss: 0.225289\tAcc: 72.00\n",
      "train epoch: 58 [192128/221852 (87%)]\tLoss: 0.204124\tAcc: 85.00\n",
      "val epoch: 58 [128/221852 (0%)]\tLoss: 0.255160\tAcc: 70.00\n",
      "val epoch: 58 [12928/221852 (6%)]\tLoss: 0.240745\tAcc: 78.00\n",
      "train epoch: 59 [128/221852 (0%)]\tLoss: 0.194040\tAcc: 68.00\n",
      "train epoch: 59 [12928/221852 (6%)]\tLoss: 0.223224\tAcc: 71.00\n",
      "train epoch: 59 [25728/221852 (12%)]\tLoss: 0.165826\tAcc: 75.00\n",
      "train epoch: 59 [38528/221852 (17%)]\tLoss: 0.185764\tAcc: 80.00\n",
      "train epoch: 59 [51328/221852 (23%)]\tLoss: 0.268746\tAcc: 73.00\n",
      "train epoch: 59 [64128/221852 (29%)]\tLoss: 0.210317\tAcc: 73.00\n",
      "train epoch: 59 [76928/221852 (35%)]\tLoss: 0.250520\tAcc: 68.00\n",
      "train epoch: 59 [89728/221852 (40%)]\tLoss: 0.289770\tAcc: 73.00\n",
      "train epoch: 59 [102528/221852 (46%)]\tLoss: 0.361614\tAcc: 73.00\n",
      "train epoch: 59 [115328/221852 (52%)]\tLoss: 0.215617\tAcc: 74.00\n",
      "train epoch: 59 [128128/221852 (58%)]\tLoss: 0.243951\tAcc: 76.00\n",
      "train epoch: 59 [140928/221852 (64%)]\tLoss: 0.213036\tAcc: 71.00\n",
      "train epoch: 59 [153728/221852 (69%)]\tLoss: 0.189094\tAcc: 78.00\n",
      "train epoch: 59 [166528/221852 (75%)]\tLoss: 0.292904\tAcc: 70.00\n",
      "train epoch: 59 [179328/221852 (81%)]\tLoss: 0.282245\tAcc: 77.00\n",
      "train epoch: 59 [192128/221852 (87%)]\tLoss: 0.248197\tAcc: 77.00\n",
      "val epoch: 59 [128/221852 (0%)]\tLoss: 0.224207\tAcc: 79.00\n",
      "val epoch: 59 [12928/221852 (6%)]\tLoss: 0.270933\tAcc: 78.00\n",
      "train epoch: 60 [128/221852 (0%)]\tLoss: 0.238365\tAcc: 80.00\n",
      "train epoch: 60 [12928/221852 (6%)]\tLoss: 0.244340\tAcc: 80.00\n",
      "train epoch: 60 [25728/221852 (12%)]\tLoss: 0.280732\tAcc: 76.00\n",
      "train epoch: 60 [38528/221852 (17%)]\tLoss: 0.331574\tAcc: 70.00\n",
      "train epoch: 60 [51328/221852 (23%)]\tLoss: 0.160307\tAcc: 73.00\n",
      "train epoch: 60 [64128/221852 (29%)]\tLoss: 0.167711\tAcc: 75.00\n",
      "train epoch: 60 [76928/221852 (35%)]\tLoss: 0.093936\tAcc: 82.00\n",
      "train epoch: 60 [89728/221852 (40%)]\tLoss: 0.402825\tAcc: 58.00\n",
      "train epoch: 60 [102528/221852 (46%)]\tLoss: 0.317675\tAcc: 72.00\n",
      "train epoch: 60 [115328/221852 (52%)]\tLoss: 0.215774\tAcc: 73.00\n",
      "train epoch: 60 [128128/221852 (58%)]\tLoss: 0.255368\tAcc: 73.00\n",
      "train epoch: 60 [140928/221852 (64%)]\tLoss: 0.252558\tAcc: 78.00\n",
      "train epoch: 60 [153728/221852 (69%)]\tLoss: 0.179041\tAcc: 77.00\n",
      "train epoch: 60 [166528/221852 (75%)]\tLoss: 0.252153\tAcc: 71.00\n",
      "train epoch: 60 [179328/221852 (81%)]\tLoss: 0.225894\tAcc: 73.00\n",
      "train epoch: 60 [192128/221852 (87%)]\tLoss: 0.223547\tAcc: 70.00\n",
      "val epoch: 60 [128/221852 (0%)]\tLoss: 0.311962\tAcc: 74.00\n",
      "val epoch: 60 [12928/221852 (6%)]\tLoss: 0.261813\tAcc: 69.00\n",
      "train epoch: 61 [128/221852 (0%)]\tLoss: 0.148991\tAcc: 73.00\n",
      "train epoch: 61 [12928/221852 (6%)]\tLoss: 0.207419\tAcc: 74.00\n",
      "train epoch: 61 [25728/221852 (12%)]\tLoss: 0.145403\tAcc: 80.00\n",
      "train epoch: 61 [38528/221852 (17%)]\tLoss: 0.188449\tAcc: 73.00\n",
      "train epoch: 61 [51328/221852 (23%)]\tLoss: 0.146866\tAcc: 79.00\n",
      "train epoch: 61 [64128/221852 (29%)]\tLoss: 0.166977\tAcc: 77.00\n",
      "train epoch: 61 [76928/221852 (35%)]\tLoss: 0.187963\tAcc: 77.00\n",
      "train epoch: 61 [89728/221852 (40%)]\tLoss: 0.133552\tAcc: 77.00\n",
      "train epoch: 61 [102528/221852 (46%)]\tLoss: 0.270355\tAcc: 78.00\n",
      "train epoch: 61 [115328/221852 (52%)]\tLoss: 0.286316\tAcc: 74.00\n",
      "train epoch: 61 [128128/221852 (58%)]\tLoss: 0.286513\tAcc: 72.00\n",
      "train epoch: 61 [140928/221852 (64%)]\tLoss: 0.238749\tAcc: 74.00\n",
      "train epoch: 61 [153728/221852 (69%)]\tLoss: 0.183223\tAcc: 85.00\n",
      "train epoch: 61 [166528/221852 (75%)]\tLoss: 0.240035\tAcc: 75.00\n",
      "train epoch: 61 [179328/221852 (81%)]\tLoss: 0.182181\tAcc: 73.00\n",
      "train epoch: 61 [192128/221852 (87%)]\tLoss: 0.231313\tAcc: 75.00\n",
      "val epoch: 61 [128/221852 (0%)]\tLoss: 0.141729\tAcc: 84.00\n",
      "val epoch: 61 [12928/221852 (6%)]\tLoss: 0.154708\tAcc: 82.00\n",
      "train epoch: 62 [128/221852 (0%)]\tLoss: 0.183761\tAcc: 80.00\n",
      "train epoch: 62 [12928/221852 (6%)]\tLoss: 0.222406\tAcc: 77.00\n",
      "train epoch: 62 [25728/221852 (12%)]\tLoss: 0.232331\tAcc: 74.00\n",
      "train epoch: 62 [38528/221852 (17%)]\tLoss: 0.242128\tAcc: 75.00\n",
      "train epoch: 62 [51328/221852 (23%)]\tLoss: 0.271009\tAcc: 77.00\n",
      "train epoch: 62 [64128/221852 (29%)]\tLoss: 0.236234\tAcc: 77.00\n",
      "train epoch: 62 [76928/221852 (35%)]\tLoss: 0.180810\tAcc: 81.00\n",
      "train epoch: 62 [89728/221852 (40%)]\tLoss: 0.191417\tAcc: 74.00\n",
      "train epoch: 62 [102528/221852 (46%)]\tLoss: 0.149424\tAcc: 80.00\n",
      "train epoch: 62 [115328/221852 (52%)]\tLoss: 0.273622\tAcc: 75.00\n",
      "train epoch: 62 [128128/221852 (58%)]\tLoss: 0.210578\tAcc: 73.00\n",
      "train epoch: 62 [140928/221852 (64%)]\tLoss: 0.178267\tAcc: 77.00\n",
      "train epoch: 62 [153728/221852 (69%)]\tLoss: 0.124941\tAcc: 73.00\n",
      "train epoch: 62 [166528/221852 (75%)]\tLoss: 0.196327\tAcc: 79.00\n",
      "train epoch: 62 [179328/221852 (81%)]\tLoss: 0.171160\tAcc: 80.00\n",
      "train epoch: 62 [192128/221852 (87%)]\tLoss: 0.184345\tAcc: 72.00\n",
      "val epoch: 62 [128/221852 (0%)]\tLoss: 0.197795\tAcc: 77.00\n",
      "val epoch: 62 [12928/221852 (6%)]\tLoss: 0.238891\tAcc: 76.00\n",
      "train epoch: 63 [128/221852 (0%)]\tLoss: 0.207537\tAcc: 75.00\n",
      "train epoch: 63 [12928/221852 (6%)]\tLoss: 0.121263\tAcc: 72.00\n",
      "train epoch: 63 [25728/221852 (12%)]\tLoss: 0.207124\tAcc: 73.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 63 [38528/221852 (17%)]\tLoss: 0.259118\tAcc: 78.00\n",
      "train epoch: 63 [51328/221852 (23%)]\tLoss: 0.261316\tAcc: 70.00\n",
      "train epoch: 63 [64128/221852 (29%)]\tLoss: 0.174442\tAcc: 73.00\n",
      "train epoch: 63 [76928/221852 (35%)]\tLoss: 0.152041\tAcc: 80.00\n",
      "train epoch: 63 [89728/221852 (40%)]\tLoss: 0.215446\tAcc: 74.00\n",
      "train epoch: 63 [102528/221852 (46%)]\tLoss: 0.157803\tAcc: 75.00\n",
      "train epoch: 63 [115328/221852 (52%)]\tLoss: 0.250179\tAcc: 75.00\n",
      "train epoch: 63 [128128/221852 (58%)]\tLoss: 0.188911\tAcc: 83.00\n",
      "train epoch: 63 [140928/221852 (64%)]\tLoss: 0.195732\tAcc: 81.00\n",
      "train epoch: 63 [153728/221852 (69%)]\tLoss: 0.241882\tAcc: 75.00\n",
      "train epoch: 63 [166528/221852 (75%)]\tLoss: 0.221948\tAcc: 66.00\n",
      "train epoch: 63 [179328/221852 (81%)]\tLoss: 0.173161\tAcc: 80.00\n",
      "train epoch: 63 [192128/221852 (87%)]\tLoss: 0.269418\tAcc: 72.00\n",
      "val epoch: 63 [128/221852 (0%)]\tLoss: 0.173773\tAcc: 78.00\n",
      "val epoch: 63 [12928/221852 (6%)]\tLoss: 0.246201\tAcc: 80.00\n",
      "train epoch: 64 [128/221852 (0%)]\tLoss: 0.239686\tAcc: 75.00\n",
      "train epoch: 64 [12928/221852 (6%)]\tLoss: 0.151856\tAcc: 88.00\n",
      "train epoch: 64 [25728/221852 (12%)]\tLoss: 0.320388\tAcc: 71.00\n",
      "train epoch: 64 [38528/221852 (17%)]\tLoss: 0.293915\tAcc: 76.00\n",
      "train epoch: 64 [51328/221852 (23%)]\tLoss: 0.174268\tAcc: 71.00\n",
      "train epoch: 64 [64128/221852 (29%)]\tLoss: 0.190821\tAcc: 79.00\n",
      "train epoch: 64 [76928/221852 (35%)]\tLoss: 0.163328\tAcc: 79.00\n",
      "train epoch: 64 [89728/221852 (40%)]\tLoss: 0.170373\tAcc: 79.00\n",
      "train epoch: 64 [102528/221852 (46%)]\tLoss: 0.325487\tAcc: 76.00\n",
      "train epoch: 64 [115328/221852 (52%)]\tLoss: 0.236599\tAcc: 77.00\n",
      "train epoch: 64 [128128/221852 (58%)]\tLoss: 0.214802\tAcc: 77.00\n",
      "train epoch: 64 [140928/221852 (64%)]\tLoss: 0.304500\tAcc: 75.00\n",
      "train epoch: 64 [153728/221852 (69%)]\tLoss: 0.195811\tAcc: 81.00\n",
      "train epoch: 64 [166528/221852 (75%)]\tLoss: 0.298178\tAcc: 69.00\n",
      "train epoch: 64 [179328/221852 (81%)]\tLoss: 0.235798\tAcc: 80.00\n",
      "train epoch: 64 [192128/221852 (87%)]\tLoss: 0.151107\tAcc: 78.00\n",
      "val epoch: 64 [128/221852 (0%)]\tLoss: 0.200670\tAcc: 77.00\n",
      "val epoch: 64 [12928/221852 (6%)]\tLoss: 0.136112\tAcc: 81.00\n",
      "train epoch: 65 [128/221852 (0%)]\tLoss: 0.149356\tAcc: 77.00\n",
      "train epoch: 65 [12928/221852 (6%)]\tLoss: 0.369650\tAcc: 74.00\n",
      "train epoch: 65 [25728/221852 (12%)]\tLoss: 0.254632\tAcc: 77.00\n",
      "train epoch: 65 [38528/221852 (17%)]\tLoss: 0.222829\tAcc: 81.00\n",
      "train epoch: 65 [51328/221852 (23%)]\tLoss: 0.170589\tAcc: 73.00\n",
      "train epoch: 65 [64128/221852 (29%)]\tLoss: 0.239036\tAcc: 73.00\n",
      "train epoch: 65 [76928/221852 (35%)]\tLoss: 0.244662\tAcc: 81.00\n",
      "train epoch: 65 [89728/221852 (40%)]\tLoss: 0.253635\tAcc: 77.00\n",
      "train epoch: 65 [102528/221852 (46%)]\tLoss: 0.312403\tAcc: 77.00\n",
      "train epoch: 65 [115328/221852 (52%)]\tLoss: 0.139436\tAcc: 84.00\n",
      "train epoch: 65 [128128/221852 (58%)]\tLoss: 0.195506\tAcc: 76.00\n",
      "train epoch: 65 [140928/221852 (64%)]\tLoss: 0.237045\tAcc: 75.00\n",
      "train epoch: 65 [153728/221852 (69%)]\tLoss: 0.196740\tAcc: 73.00\n",
      "train epoch: 65 [166528/221852 (75%)]\tLoss: 0.288438\tAcc: 72.00\n",
      "train epoch: 65 [179328/221852 (81%)]\tLoss: 0.162253\tAcc: 83.00\n",
      "train epoch: 65 [192128/221852 (87%)]\tLoss: 0.159305\tAcc: 76.00\n",
      "val epoch: 65 [128/221852 (0%)]\tLoss: 0.188333\tAcc: 81.00\n",
      "val epoch: 65 [12928/221852 (6%)]\tLoss: 0.249247\tAcc: 71.00\n",
      "train epoch: 66 [128/221852 (0%)]\tLoss: 0.209146\tAcc: 73.00\n",
      "train epoch: 66 [12928/221852 (6%)]\tLoss: 0.201475\tAcc: 80.00\n",
      "train epoch: 66 [25728/221852 (12%)]\tLoss: 0.173257\tAcc: 76.00\n",
      "train epoch: 66 [38528/221852 (17%)]\tLoss: 0.271140\tAcc: 68.00\n",
      "train epoch: 66 [51328/221852 (23%)]\tLoss: 0.234398\tAcc: 76.00\n",
      "train epoch: 66 [64128/221852 (29%)]\tLoss: 0.186260\tAcc: 76.00\n",
      "train epoch: 66 [76928/221852 (35%)]\tLoss: 0.173458\tAcc: 77.00\n",
      "train epoch: 66 [89728/221852 (40%)]\tLoss: 0.197153\tAcc: 79.00\n",
      "train epoch: 66 [102528/221852 (46%)]\tLoss: 0.197744\tAcc: 77.00\n",
      "train epoch: 66 [115328/221852 (52%)]\tLoss: 0.204408\tAcc: 80.00\n",
      "train epoch: 66 [128128/221852 (58%)]\tLoss: 0.151861\tAcc: 77.00\n",
      "train epoch: 66 [140928/221852 (64%)]\tLoss: 0.233550\tAcc: 76.00\n",
      "train epoch: 66 [153728/221852 (69%)]\tLoss: 0.239323\tAcc: 73.00\n",
      "train epoch: 66 [166528/221852 (75%)]\tLoss: 0.316590\tAcc: 77.00\n",
      "train epoch: 66 [179328/221852 (81%)]\tLoss: 0.183387\tAcc: 80.00\n",
      "train epoch: 66 [192128/221852 (87%)]\tLoss: 0.248990\tAcc: 70.00\n",
      "val epoch: 66 [128/221852 (0%)]\tLoss: 0.140535\tAcc: 82.00\n",
      "val epoch: 66 [12928/221852 (6%)]\tLoss: 0.210052\tAcc: 79.00\n",
      "train epoch: 67 [128/221852 (0%)]\tLoss: 0.216299\tAcc: 80.00\n",
      "train epoch: 67 [12928/221852 (6%)]\tLoss: 0.242636\tAcc: 73.00\n",
      "train epoch: 67 [25728/221852 (12%)]\tLoss: 0.280802\tAcc: 65.00\n",
      "train epoch: 67 [38528/221852 (17%)]\tLoss: 0.316950\tAcc: 73.00\n",
      "train epoch: 67 [51328/221852 (23%)]\tLoss: 0.327698\tAcc: 73.00\n",
      "train epoch: 67 [64128/221852 (29%)]\tLoss: 0.193729\tAcc: 73.00\n",
      "train epoch: 67 [76928/221852 (35%)]\tLoss: 0.177783\tAcc: 77.00\n",
      "train epoch: 67 [89728/221852 (40%)]\tLoss: 0.202099\tAcc: 74.00\n",
      "train epoch: 67 [102528/221852 (46%)]\tLoss: 0.207733\tAcc: 79.00\n",
      "train epoch: 67 [115328/221852 (52%)]\tLoss: 0.249754\tAcc: 71.00\n",
      "train epoch: 67 [128128/221852 (58%)]\tLoss: 0.181162\tAcc: 78.00\n",
      "train epoch: 67 [140928/221852 (64%)]\tLoss: 0.153526\tAcc: 76.00\n",
      "train epoch: 67 [153728/221852 (69%)]\tLoss: 0.216772\tAcc: 78.00\n",
      "train epoch: 67 [166528/221852 (75%)]\tLoss: 0.193932\tAcc: 80.00\n",
      "train epoch: 67 [179328/221852 (81%)]\tLoss: 0.259434\tAcc: 78.00\n",
      "train epoch: 67 [192128/221852 (87%)]\tLoss: 0.171983\tAcc: 84.00\n",
      "val epoch: 67 [128/221852 (0%)]\tLoss: 0.205784\tAcc: 73.00\n",
      "val epoch: 67 [12928/221852 (6%)]\tLoss: 0.288698\tAcc: 76.00\n",
      "train epoch: 68 [128/221852 (0%)]\tLoss: 0.325329\tAcc: 70.00\n",
      "train epoch: 68 [12928/221852 (6%)]\tLoss: 0.327117\tAcc: 77.00\n",
      "train epoch: 68 [25728/221852 (12%)]\tLoss: 0.206879\tAcc: 78.00\n",
      "train epoch: 68 [38528/221852 (17%)]\tLoss: 0.218868\tAcc: 73.00\n",
      "train epoch: 68 [51328/221852 (23%)]\tLoss: 0.156617\tAcc: 83.00\n",
      "train epoch: 68 [64128/221852 (29%)]\tLoss: 0.249656\tAcc: 77.00\n",
      "train epoch: 68 [76928/221852 (35%)]\tLoss: 0.160541\tAcc: 77.00\n",
      "train epoch: 68 [89728/221852 (40%)]\tLoss: 0.295485\tAcc: 77.00\n",
      "train epoch: 68 [102528/221852 (46%)]\tLoss: 0.149629\tAcc: 80.00\n",
      "train epoch: 68 [115328/221852 (52%)]\tLoss: 0.192308\tAcc: 79.00\n",
      "train epoch: 68 [128128/221852 (58%)]\tLoss: 0.493127\tAcc: 62.00\n",
      "train epoch: 68 [140928/221852 (64%)]\tLoss: 0.212650\tAcc: 77.00\n",
      "train epoch: 68 [153728/221852 (69%)]\tLoss: 0.235303\tAcc: 70.00\n",
      "train epoch: 68 [166528/221852 (75%)]\tLoss: 0.144398\tAcc: 77.00\n",
      "train epoch: 68 [179328/221852 (81%)]\tLoss: 0.237016\tAcc: 81.00\n",
      "train epoch: 68 [192128/221852 (87%)]\tLoss: 0.101329\tAcc: 82.00\n",
      "val epoch: 68 [128/221852 (0%)]\tLoss: 0.201622\tAcc: 80.00\n",
      "val epoch: 68 [12928/221852 (6%)]\tLoss: 0.264608\tAcc: 75.00\n",
      "train epoch: 69 [128/221852 (0%)]\tLoss: 0.269579\tAcc: 79.00\n",
      "train epoch: 69 [12928/221852 (6%)]\tLoss: 0.220220\tAcc: 78.00\n",
      "train epoch: 69 [25728/221852 (12%)]\tLoss: 0.222771\tAcc: 74.00\n",
      "train epoch: 69 [38528/221852 (17%)]\tLoss: 0.324040\tAcc: 71.00\n",
      "train epoch: 69 [51328/221852 (23%)]\tLoss: 0.188851\tAcc: 80.00\n",
      "train epoch: 69 [64128/221852 (29%)]\tLoss: 0.168832\tAcc: 76.00\n",
      "train epoch: 69 [76928/221852 (35%)]\tLoss: 0.133121\tAcc: 77.00\n",
      "train epoch: 69 [89728/221852 (40%)]\tLoss: 0.210895\tAcc: 77.00\n",
      "train epoch: 69 [102528/221852 (46%)]\tLoss: 0.185879\tAcc: 77.00\n",
      "train epoch: 69 [115328/221852 (52%)]\tLoss: 0.277262\tAcc: 75.00\n",
      "train epoch: 69 [128128/221852 (58%)]\tLoss: 0.248530\tAcc: 76.00\n",
      "train epoch: 69 [140928/221852 (64%)]\tLoss: 0.212763\tAcc: 77.00\n",
      "train epoch: 69 [153728/221852 (69%)]\tLoss: 0.220284\tAcc: 79.00\n",
      "train epoch: 69 [166528/221852 (75%)]\tLoss: 0.180216\tAcc: 74.00\n",
      "train epoch: 69 [179328/221852 (81%)]\tLoss: 0.188570\tAcc: 77.00\n",
      "train epoch: 69 [192128/221852 (87%)]\tLoss: 0.207538\tAcc: 75.00\n",
      "val epoch: 69 [128/221852 (0%)]\tLoss: 0.107343\tAcc: 87.00\n",
      "val epoch: 69 [12928/221852 (6%)]\tLoss: 0.143636\tAcc: 73.00\n",
      "train epoch: 70 [128/221852 (0%)]\tLoss: 0.206886\tAcc: 80.00\n",
      "train epoch: 70 [12928/221852 (6%)]\tLoss: 0.189658\tAcc: 80.00\n",
      "train epoch: 70 [25728/221852 (12%)]\tLoss: 0.234064\tAcc: 75.00\n",
      "train epoch: 70 [38528/221852 (17%)]\tLoss: 0.168489\tAcc: 86.00\n",
      "train epoch: 70 [51328/221852 (23%)]\tLoss: 0.202476\tAcc: 73.00\n",
      "train epoch: 70 [64128/221852 (29%)]\tLoss: 0.225151\tAcc: 77.00\n",
      "train epoch: 70 [76928/221852 (35%)]\tLoss: 0.245830\tAcc: 77.00\n",
      "train epoch: 70 [89728/221852 (40%)]\tLoss: 0.167822\tAcc: 76.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 70 [102528/221852 (46%)]\tLoss: 0.158729\tAcc: 79.00\n",
      "train epoch: 70 [115328/221852 (52%)]\tLoss: 0.179877\tAcc: 73.00\n",
      "train epoch: 70 [128128/221852 (58%)]\tLoss: 0.166345\tAcc: 73.00\n",
      "train epoch: 70 [140928/221852 (64%)]\tLoss: 0.172960\tAcc: 75.00\n",
      "train epoch: 70 [153728/221852 (69%)]\tLoss: 0.148294\tAcc: 82.00\n",
      "train epoch: 70 [166528/221852 (75%)]\tLoss: 0.136944\tAcc: 82.00\n",
      "train epoch: 70 [179328/221852 (81%)]\tLoss: 0.182405\tAcc: 83.00\n",
      "train epoch: 70 [192128/221852 (87%)]\tLoss: 0.310939\tAcc: 73.00\n",
      "val epoch: 70 [128/221852 (0%)]\tLoss: 0.130722\tAcc: 80.00\n",
      "val epoch: 70 [12928/221852 (6%)]\tLoss: 0.212220\tAcc: 81.00\n",
      "train epoch: 71 [128/221852 (0%)]\tLoss: 0.246233\tAcc: 72.00\n",
      "train epoch: 71 [12928/221852 (6%)]\tLoss: 0.213545\tAcc: 78.00\n",
      "train epoch: 71 [25728/221852 (12%)]\tLoss: 0.175695\tAcc: 78.00\n",
      "train epoch: 71 [38528/221852 (17%)]\tLoss: 0.253967\tAcc: 75.00\n",
      "train epoch: 71 [51328/221852 (23%)]\tLoss: 0.274874\tAcc: 77.00\n",
      "train epoch: 71 [64128/221852 (29%)]\tLoss: 0.221173\tAcc: 76.00\n",
      "train epoch: 71 [76928/221852 (35%)]\tLoss: 0.279511\tAcc: 70.00\n",
      "train epoch: 71 [89728/221852 (40%)]\tLoss: 0.223155\tAcc: 78.00\n",
      "train epoch: 71 [102528/221852 (46%)]\tLoss: 0.170050\tAcc: 76.00\n",
      "train epoch: 71 [115328/221852 (52%)]\tLoss: 0.238761\tAcc: 77.00\n",
      "train epoch: 71 [128128/221852 (58%)]\tLoss: 0.248337\tAcc: 77.00\n",
      "train epoch: 71 [140928/221852 (64%)]\tLoss: 0.332647\tAcc: 76.00\n",
      "train epoch: 71 [153728/221852 (69%)]\tLoss: 0.211962\tAcc: 75.00\n",
      "train epoch: 71 [166528/221852 (75%)]\tLoss: 0.218613\tAcc: 77.00\n",
      "train epoch: 71 [179328/221852 (81%)]\tLoss: 0.149081\tAcc: 78.00\n",
      "train epoch: 71 [192128/221852 (87%)]\tLoss: 0.289434\tAcc: 70.00\n",
      "val epoch: 71 [128/221852 (0%)]\tLoss: 0.243034\tAcc: 73.00\n",
      "val epoch: 71 [12928/221852 (6%)]\tLoss: 0.146305\tAcc: 77.00\n",
      "train epoch: 72 [128/221852 (0%)]\tLoss: 0.218303\tAcc: 75.00\n",
      "train epoch: 72 [12928/221852 (6%)]\tLoss: 0.163642\tAcc: 83.00\n",
      "train epoch: 72 [25728/221852 (12%)]\tLoss: 0.230216\tAcc: 73.00\n",
      "train epoch: 72 [38528/221852 (17%)]\tLoss: 0.250787\tAcc: 78.00\n",
      "train epoch: 72 [51328/221852 (23%)]\tLoss: 0.278415\tAcc: 71.00\n",
      "train epoch: 72 [64128/221852 (29%)]\tLoss: 0.201822\tAcc: 76.00\n",
      "train epoch: 72 [76928/221852 (35%)]\tLoss: 0.134039\tAcc: 86.00\n",
      "train epoch: 72 [89728/221852 (40%)]\tLoss: 0.248341\tAcc: 80.00\n",
      "train epoch: 72 [102528/221852 (46%)]\tLoss: 0.317401\tAcc: 67.00\n",
      "train epoch: 72 [115328/221852 (52%)]\tLoss: 0.198814\tAcc: 77.00\n",
      "train epoch: 72 [128128/221852 (58%)]\tLoss: 0.106926\tAcc: 80.00\n",
      "train epoch: 72 [140928/221852 (64%)]\tLoss: 0.163539\tAcc: 84.00\n",
      "train epoch: 72 [153728/221852 (69%)]\tLoss: 0.180394\tAcc: 77.00\n",
      "train epoch: 72 [166528/221852 (75%)]\tLoss: 0.155934\tAcc: 78.00\n",
      "train epoch: 72 [179328/221852 (81%)]\tLoss: 0.267175\tAcc: 77.00\n",
      "train epoch: 72 [192128/221852 (87%)]\tLoss: 0.476375\tAcc: 65.00\n",
      "val epoch: 72 [128/221852 (0%)]\tLoss: 0.382709\tAcc: 58.00\n",
      "val epoch: 72 [12928/221852 (6%)]\tLoss: 0.359991\tAcc: 70.00\n",
      "train epoch: 73 [128/221852 (0%)]\tLoss: 0.399074\tAcc: 53.00\n",
      "train epoch: 73 [12928/221852 (6%)]\tLoss: 0.289405\tAcc: 71.00\n",
      "train epoch: 73 [25728/221852 (12%)]\tLoss: 0.212428\tAcc: 70.00\n",
      "train epoch: 73 [38528/221852 (17%)]\tLoss: 0.316359\tAcc: 66.00\n",
      "train epoch: 73 [51328/221852 (23%)]\tLoss: 0.273681\tAcc: 75.00\n",
      "train epoch: 73 [64128/221852 (29%)]\tLoss: 0.199578\tAcc: 72.00\n",
      "train epoch: 73 [76928/221852 (35%)]\tLoss: 0.220106\tAcc: 75.00\n",
      "train epoch: 73 [89728/221852 (40%)]\tLoss: 0.205019\tAcc: 79.00\n",
      "train epoch: 73 [102528/221852 (46%)]\tLoss: 0.387572\tAcc: 66.00\n",
      "train epoch: 73 [115328/221852 (52%)]\tLoss: 0.217830\tAcc: 74.00\n",
      "train epoch: 73 [128128/221852 (58%)]\tLoss: 0.226573\tAcc: 75.00\n",
      "train epoch: 73 [140928/221852 (64%)]\tLoss: 0.315265\tAcc: 70.00\n",
      "train epoch: 73 [153728/221852 (69%)]\tLoss: 0.270944\tAcc: 68.00\n",
      "train epoch: 73 [166528/221852 (75%)]\tLoss: 0.258741\tAcc: 68.00\n",
      "train epoch: 73 [179328/221852 (81%)]\tLoss: 0.515634\tAcc: 65.00\n",
      "train epoch: 73 [192128/221852 (87%)]\tLoss: 0.216838\tAcc: 74.00\n",
      "val epoch: 73 [128/221852 (0%)]\tLoss: 0.259271\tAcc: 65.00\n",
      "val epoch: 73 [12928/221852 (6%)]\tLoss: 0.189952\tAcc: 77.00\n",
      "train epoch: 74 [128/221852 (0%)]\tLoss: 0.183219\tAcc: 73.00\n",
      "train epoch: 74 [12928/221852 (6%)]\tLoss: 0.311415\tAcc: 67.00\n",
      "train epoch: 74 [25728/221852 (12%)]\tLoss: 0.594460\tAcc: 83.00\n",
      "train epoch: 74 [38528/221852 (17%)]\tLoss: 0.186904\tAcc: 71.00\n",
      "train epoch: 74 [51328/221852 (23%)]\tLoss: 0.220388\tAcc: 76.00\n",
      "train epoch: 74 [64128/221852 (29%)]\tLoss: 0.231181\tAcc: 76.00\n",
      "train epoch: 74 [76928/221852 (35%)]\tLoss: 0.171697\tAcc: 77.00\n",
      "train epoch: 74 [89728/221852 (40%)]\tLoss: 0.213494\tAcc: 83.00\n",
      "train epoch: 74 [102528/221852 (46%)]\tLoss: 0.252610\tAcc: 79.00\n",
      "train epoch: 74 [115328/221852 (52%)]\tLoss: 0.340165\tAcc: 81.00\n",
      "train epoch: 74 [128128/221852 (58%)]\tLoss: 0.244133\tAcc: 79.00\n",
      "train epoch: 74 [140928/221852 (64%)]\tLoss: 0.253974\tAcc: 73.00\n",
      "train epoch: 74 [153728/221852 (69%)]\tLoss: 0.264279\tAcc: 79.00\n",
      "train epoch: 74 [166528/221852 (75%)]\tLoss: 0.184404\tAcc: 72.00\n",
      "train epoch: 74 [179328/221852 (81%)]\tLoss: 0.282960\tAcc: 77.00\n",
      "train epoch: 74 [192128/221852 (87%)]\tLoss: 0.185045\tAcc: 81.00\n",
      "val epoch: 74 [128/221852 (0%)]\tLoss: 0.231794\tAcc: 73.00\n",
      "val epoch: 74 [12928/221852 (6%)]\tLoss: 0.225633\tAcc: 77.00\n",
      "train epoch: 75 [128/221852 (0%)]\tLoss: 0.158535\tAcc: 80.00\n",
      "train epoch: 75 [12928/221852 (6%)]\tLoss: 0.217854\tAcc: 77.00\n",
      "train epoch: 75 [25728/221852 (12%)]\tLoss: 0.211459\tAcc: 79.00\n",
      "train epoch: 75 [38528/221852 (17%)]\tLoss: 0.315776\tAcc: 70.00\n",
      "train epoch: 75 [51328/221852 (23%)]\tLoss: 0.226129\tAcc: 73.00\n",
      "train epoch: 75 [64128/221852 (29%)]\tLoss: 0.179776\tAcc: 82.00\n",
      "train epoch: 75 [76928/221852 (35%)]\tLoss: 0.200203\tAcc: 76.00\n",
      "train epoch: 75 [89728/221852 (40%)]\tLoss: 0.112222\tAcc: 79.00\n",
      "train epoch: 75 [102528/221852 (46%)]\tLoss: 0.206430\tAcc: 79.00\n",
      "train epoch: 75 [115328/221852 (52%)]\tLoss: 0.232032\tAcc: 72.00\n",
      "train epoch: 75 [128128/221852 (58%)]\tLoss: 0.291503\tAcc: 73.00\n",
      "train epoch: 75 [140928/221852 (64%)]\tLoss: 0.324286\tAcc: 66.00\n",
      "train epoch: 75 [153728/221852 (69%)]\tLoss: 0.145620\tAcc: 81.00\n",
      "train epoch: 75 [166528/221852 (75%)]\tLoss: 0.186649\tAcc: 77.00\n",
      "train epoch: 75 [179328/221852 (81%)]\tLoss: 0.187227\tAcc: 74.00\n",
      "train epoch: 75 [192128/221852 (87%)]\tLoss: 0.216143\tAcc: 77.00\n",
      "val epoch: 75 [128/221852 (0%)]\tLoss: 0.207496\tAcc: 77.00\n",
      "val epoch: 75 [12928/221852 (6%)]\tLoss: 0.182272\tAcc: 74.00\n",
      "train epoch: 76 [128/221852 (0%)]\tLoss: 0.203929\tAcc: 75.00\n",
      "train epoch: 76 [12928/221852 (6%)]\tLoss: 0.172342\tAcc: 77.00\n",
      "train epoch: 76 [25728/221852 (12%)]\tLoss: 0.162783\tAcc: 79.00\n",
      "train epoch: 76 [38528/221852 (17%)]\tLoss: 0.126384\tAcc: 80.00\n",
      "train epoch: 76 [51328/221852 (23%)]\tLoss: 0.254713\tAcc: 72.00\n",
      "train epoch: 76 [64128/221852 (29%)]\tLoss: 0.160794\tAcc: 83.00\n",
      "train epoch: 76 [76928/221852 (35%)]\tLoss: 0.225822\tAcc: 71.00\n",
      "train epoch: 76 [89728/221852 (40%)]\tLoss: 0.195315\tAcc: 77.00\n",
      "train epoch: 76 [102528/221852 (46%)]\tLoss: 0.185458\tAcc: 74.00\n",
      "train epoch: 76 [115328/221852 (52%)]\tLoss: 0.171161\tAcc: 78.00\n",
      "train epoch: 76 [128128/221852 (58%)]\tLoss: 0.191823\tAcc: 78.00\n",
      "train epoch: 76 [140928/221852 (64%)]\tLoss: 0.180459\tAcc: 73.00\n",
      "train epoch: 76 [153728/221852 (69%)]\tLoss: 0.151921\tAcc: 74.00\n",
      "train epoch: 76 [166528/221852 (75%)]\tLoss: 0.213911\tAcc: 78.00\n",
      "train epoch: 76 [179328/221852 (81%)]\tLoss: 0.228650\tAcc: 77.00\n",
      "train epoch: 76 [192128/221852 (87%)]\tLoss: 0.328510\tAcc: 73.00\n",
      "val epoch: 76 [128/221852 (0%)]\tLoss: 0.164363\tAcc: 85.00\n",
      "val epoch: 76 [12928/221852 (6%)]\tLoss: 0.249504\tAcc: 76.00\n",
      "train epoch: 77 [128/221852 (0%)]\tLoss: 0.223327\tAcc: 82.00\n",
      "train epoch: 77 [12928/221852 (6%)]\tLoss: 0.277806\tAcc: 76.00\n",
      "train epoch: 77 [25728/221852 (12%)]\tLoss: 0.185406\tAcc: 76.00\n",
      "train epoch: 77 [38528/221852 (17%)]\tLoss: 0.164497\tAcc: 77.00\n",
      "train epoch: 77 [51328/221852 (23%)]\tLoss: 0.245117\tAcc: 81.00\n",
      "train epoch: 77 [64128/221852 (29%)]\tLoss: 0.178665\tAcc: 73.00\n",
      "train epoch: 77 [76928/221852 (35%)]\tLoss: 0.223527\tAcc: 76.00\n",
      "train epoch: 77 [89728/221852 (40%)]\tLoss: 0.182776\tAcc: 77.00\n",
      "train epoch: 77 [102528/221852 (46%)]\tLoss: 0.188645\tAcc: 77.00\n",
      "train epoch: 77 [115328/221852 (52%)]\tLoss: 0.168000\tAcc: 78.00\n",
      "train epoch: 77 [128128/221852 (58%)]\tLoss: 0.221745\tAcc: 71.00\n",
      "train epoch: 77 [140928/221852 (64%)]\tLoss: 0.185788\tAcc: 77.00\n",
      "train epoch: 77 [153728/221852 (69%)]\tLoss: 0.151793\tAcc: 77.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 77 [166528/221852 (75%)]\tLoss: 0.228243\tAcc: 77.00\n",
      "train epoch: 77 [179328/221852 (81%)]\tLoss: 0.380034\tAcc: 70.00\n",
      "train epoch: 77 [192128/221852 (87%)]\tLoss: 0.304789\tAcc: 68.00\n",
      "val epoch: 77 [128/221852 (0%)]\tLoss: 0.323791\tAcc: 71.00\n",
      "val epoch: 77 [12928/221852 (6%)]\tLoss: 0.290313\tAcc: 66.00\n",
      "train epoch: 78 [128/221852 (0%)]\tLoss: 0.301376\tAcc: 67.00\n",
      "train epoch: 78 [12928/221852 (6%)]\tLoss: 0.353150\tAcc: 66.00\n",
      "train epoch: 78 [25728/221852 (12%)]\tLoss: 0.203621\tAcc: 76.00\n",
      "train epoch: 78 [38528/221852 (17%)]\tLoss: 0.158703\tAcc: 68.00\n",
      "train epoch: 78 [51328/221852 (23%)]\tLoss: 0.207685\tAcc: 74.00\n",
      "train epoch: 78 [64128/221852 (29%)]\tLoss: 0.252640\tAcc: 78.00\n",
      "train epoch: 78 [76928/221852 (35%)]\tLoss: 0.201640\tAcc: 68.00\n",
      "train epoch: 78 [89728/221852 (40%)]\tLoss: 0.290819\tAcc: 76.00\n",
      "train epoch: 78 [102528/221852 (46%)]\tLoss: 0.147935\tAcc: 81.00\n",
      "train epoch: 78 [115328/221852 (52%)]\tLoss: 0.209129\tAcc: 78.00\n",
      "train epoch: 78 [128128/221852 (58%)]\tLoss: 0.126275\tAcc: 79.00\n",
      "train epoch: 78 [140928/221852 (64%)]\tLoss: 0.159197\tAcc: 79.00\n",
      "train epoch: 78 [153728/221852 (69%)]\tLoss: 0.290395\tAcc: 74.00\n",
      "train epoch: 78 [166528/221852 (75%)]\tLoss: 0.129109\tAcc: 76.00\n",
      "train epoch: 78 [179328/221852 (81%)]\tLoss: 0.248209\tAcc: 79.00\n",
      "train epoch: 78 [192128/221852 (87%)]\tLoss: 0.190155\tAcc: 79.00\n",
      "val epoch: 78 [128/221852 (0%)]\tLoss: 0.296527\tAcc: 74.00\n",
      "val epoch: 78 [12928/221852 (6%)]\tLoss: 0.198079\tAcc: 72.00\n",
      "train epoch: 79 [128/221852 (0%)]\tLoss: 0.251655\tAcc: 73.00\n",
      "train epoch: 79 [12928/221852 (6%)]\tLoss: 0.281403\tAcc: 70.00\n",
      "train epoch: 79 [25728/221852 (12%)]\tLoss: 0.117462\tAcc: 80.00\n",
      "train epoch: 79 [38528/221852 (17%)]\tLoss: 0.229810\tAcc: 75.00\n",
      "train epoch: 79 [51328/221852 (23%)]\tLoss: 0.323918\tAcc: 70.00\n",
      "train epoch: 79 [64128/221852 (29%)]\tLoss: 0.255782\tAcc: 79.00\n",
      "train epoch: 79 [76928/221852 (35%)]\tLoss: 0.145710\tAcc: 73.00\n",
      "train epoch: 79 [89728/221852 (40%)]\tLoss: 0.191016\tAcc: 73.00\n",
      "train epoch: 79 [102528/221852 (46%)]\tLoss: 0.190866\tAcc: 80.00\n",
      "train epoch: 79 [115328/221852 (52%)]\tLoss: 0.178050\tAcc: 79.00\n",
      "train epoch: 79 [128128/221852 (58%)]\tLoss: 0.170319\tAcc: 85.00\n",
      "train epoch: 79 [140928/221852 (64%)]\tLoss: 0.184325\tAcc: 78.00\n",
      "train epoch: 79 [153728/221852 (69%)]\tLoss: 0.362679\tAcc: 71.00\n",
      "train epoch: 79 [166528/221852 (75%)]\tLoss: 0.292011\tAcc: 73.00\n",
      "train epoch: 79 [179328/221852 (81%)]\tLoss: 0.171327\tAcc: 82.00\n",
      "train epoch: 79 [192128/221852 (87%)]\tLoss: 0.141005\tAcc: 77.00\n",
      "val epoch: 79 [128/221852 (0%)]\tLoss: 0.177816\tAcc: 77.00\n",
      "val epoch: 79 [12928/221852 (6%)]\tLoss: 0.150572\tAcc: 79.00\n",
      "train epoch: 80 [128/221852 (0%)]\tLoss: 0.225694\tAcc: 76.00\n",
      "train epoch: 80 [12928/221852 (6%)]\tLoss: 0.246766\tAcc: 70.00\n",
      "train epoch: 80 [25728/221852 (12%)]\tLoss: 0.095626\tAcc: 77.00\n",
      "train epoch: 80 [38528/221852 (17%)]\tLoss: 0.121959\tAcc: 86.00\n",
      "train epoch: 80 [51328/221852 (23%)]\tLoss: 0.116511\tAcc: 86.00\n",
      "train epoch: 80 [64128/221852 (29%)]\tLoss: 0.182825\tAcc: 84.00\n",
      "train epoch: 80 [76928/221852 (35%)]\tLoss: 0.215137\tAcc: 76.00\n",
      "train epoch: 80 [89728/221852 (40%)]\tLoss: 0.187600\tAcc: 74.00\n",
      "train epoch: 80 [102528/221852 (46%)]\tLoss: 0.149715\tAcc: 80.00\n",
      "train epoch: 80 [115328/221852 (52%)]\tLoss: 0.132282\tAcc: 74.00\n",
      "train epoch: 80 [128128/221852 (58%)]\tLoss: 0.190092\tAcc: 83.00\n",
      "train epoch: 80 [140928/221852 (64%)]\tLoss: 0.264144\tAcc: 73.00\n",
      "train epoch: 80 [153728/221852 (69%)]\tLoss: 0.253843\tAcc: 75.00\n",
      "train epoch: 80 [166528/221852 (75%)]\tLoss: 0.205294\tAcc: 77.00\n",
      "train epoch: 80 [179328/221852 (81%)]\tLoss: 0.134903\tAcc: 80.00\n",
      "train epoch: 80 [192128/221852 (87%)]\tLoss: 0.193393\tAcc: 77.00\n",
      "val epoch: 80 [128/221852 (0%)]\tLoss: 0.198753\tAcc: 81.00\n",
      "val epoch: 80 [12928/221852 (6%)]\tLoss: 0.174422\tAcc: 78.00\n",
      "train epoch: 81 [128/221852 (0%)]\tLoss: 0.214659\tAcc: 79.00\n",
      "train epoch: 81 [12928/221852 (6%)]\tLoss: 0.237792\tAcc: 80.00\n",
      "train epoch: 81 [25728/221852 (12%)]\tLoss: 0.140126\tAcc: 80.00\n",
      "train epoch: 81 [38528/221852 (17%)]\tLoss: 0.213550\tAcc: 80.00\n",
      "train epoch: 81 [51328/221852 (23%)]\tLoss: 0.202949\tAcc: 71.00\n",
      "train epoch: 81 [64128/221852 (29%)]\tLoss: 0.186438\tAcc: 82.00\n",
      "train epoch: 81 [76928/221852 (35%)]\tLoss: 0.165082\tAcc: 83.00\n",
      "train epoch: 81 [89728/221852 (40%)]\tLoss: 0.217146\tAcc: 80.00\n",
      "train epoch: 81 [102528/221852 (46%)]\tLoss: 0.183078\tAcc: 76.00\n",
      "train epoch: 81 [115328/221852 (52%)]\tLoss: 0.190891\tAcc: 80.00\n",
      "train epoch: 81 [128128/221852 (58%)]\tLoss: 0.280198\tAcc: 78.00\n",
      "train epoch: 81 [140928/221852 (64%)]\tLoss: 0.235663\tAcc: 77.00\n",
      "train epoch: 81 [153728/221852 (69%)]\tLoss: 0.264192\tAcc: 77.00\n",
      "train epoch: 81 [166528/221852 (75%)]\tLoss: 0.202820\tAcc: 80.00\n",
      "train epoch: 81 [179328/221852 (81%)]\tLoss: 0.263508\tAcc: 75.00\n",
      "train epoch: 81 [192128/221852 (87%)]\tLoss: 0.238440\tAcc: 76.00\n",
      "val epoch: 81 [128/221852 (0%)]\tLoss: 0.181435\tAcc: 78.00\n",
      "val epoch: 81 [12928/221852 (6%)]\tLoss: 0.158069\tAcc: 75.00\n",
      "train epoch: 82 [128/221852 (0%)]\tLoss: 0.122007\tAcc: 79.00\n",
      "train epoch: 82 [12928/221852 (6%)]\tLoss: 0.135626\tAcc: 77.00\n",
      "train epoch: 82 [25728/221852 (12%)]\tLoss: 0.163832\tAcc: 81.00\n",
      "train epoch: 82 [38528/221852 (17%)]\tLoss: 0.193210\tAcc: 75.00\n",
      "train epoch: 82 [51328/221852 (23%)]\tLoss: 0.185800\tAcc: 74.00\n",
      "train epoch: 82 [64128/221852 (29%)]\tLoss: 0.234634\tAcc: 71.00\n",
      "train epoch: 82 [76928/221852 (35%)]\tLoss: 0.217484\tAcc: 77.00\n",
      "train epoch: 82 [89728/221852 (40%)]\tLoss: 0.279329\tAcc: 75.00\n",
      "train epoch: 82 [102528/221852 (46%)]\tLoss: 0.141372\tAcc: 73.00\n",
      "train epoch: 82 [115328/221852 (52%)]\tLoss: 0.171390\tAcc: 79.00\n",
      "train epoch: 82 [128128/221852 (58%)]\tLoss: 0.222258\tAcc: 77.00\n",
      "train epoch: 82 [140928/221852 (64%)]\tLoss: 0.191184\tAcc: 79.00\n",
      "train epoch: 82 [153728/221852 (69%)]\tLoss: 0.146150\tAcc: 84.00\n",
      "train epoch: 82 [166528/221852 (75%)]\tLoss: 0.237240\tAcc: 77.00\n",
      "train epoch: 82 [179328/221852 (81%)]\tLoss: 0.188968\tAcc: 82.00\n",
      "train epoch: 82 [192128/221852 (87%)]\tLoss: 0.094663\tAcc: 86.00\n",
      "val epoch: 82 [128/221852 (0%)]\tLoss: 0.196924\tAcc: 80.00\n",
      "val epoch: 82 [12928/221852 (6%)]\tLoss: 0.245548\tAcc: 81.00\n",
      "train epoch: 83 [128/221852 (0%)]\tLoss: 0.244256\tAcc: 81.00\n",
      "train epoch: 83 [12928/221852 (6%)]\tLoss: 0.238796\tAcc: 81.00\n",
      "train epoch: 83 [25728/221852 (12%)]\tLoss: 0.198336\tAcc: 79.00\n",
      "train epoch: 83 [38528/221852 (17%)]\tLoss: 0.214180\tAcc: 73.00\n",
      "train epoch: 83 [51328/221852 (23%)]\tLoss: 0.196110\tAcc: 80.00\n",
      "train epoch: 83 [64128/221852 (29%)]\tLoss: 0.135923\tAcc: 75.00\n",
      "train epoch: 83 [76928/221852 (35%)]\tLoss: 0.150852\tAcc: 84.00\n",
      "train epoch: 83 [89728/221852 (40%)]\tLoss: 0.205451\tAcc: 80.00\n",
      "train epoch: 83 [102528/221852 (46%)]\tLoss: 0.259717\tAcc: 77.00\n",
      "train epoch: 83 [115328/221852 (52%)]\tLoss: 0.204154\tAcc: 76.00\n",
      "train epoch: 83 [128128/221852 (58%)]\tLoss: 0.214760\tAcc: 77.00\n",
      "train epoch: 83 [140928/221852 (64%)]\tLoss: 0.206185\tAcc: 84.00\n",
      "train epoch: 83 [153728/221852 (69%)]\tLoss: 0.242496\tAcc: 77.00\n",
      "train epoch: 83 [166528/221852 (75%)]\tLoss: 0.225842\tAcc: 78.00\n",
      "train epoch: 83 [179328/221852 (81%)]\tLoss: 0.149099\tAcc: 79.00\n",
      "train epoch: 83 [192128/221852 (87%)]\tLoss: 0.157473\tAcc: 81.00\n",
      "val epoch: 83 [128/221852 (0%)]\tLoss: 0.106364\tAcc: 82.00\n",
      "val epoch: 83 [12928/221852 (6%)]\tLoss: 0.140241\tAcc: 82.00\n",
      "train epoch: 84 [128/221852 (0%)]\tLoss: 0.182815\tAcc: 74.00\n",
      "train epoch: 84 [12928/221852 (6%)]\tLoss: 0.167968\tAcc: 79.00\n",
      "train epoch: 84 [25728/221852 (12%)]\tLoss: 0.186533\tAcc: 78.00\n",
      "train epoch: 84 [38528/221852 (17%)]\tLoss: 0.185738\tAcc: 83.00\n",
      "train epoch: 84 [51328/221852 (23%)]\tLoss: 0.207901\tAcc: 76.00\n",
      "train epoch: 84 [64128/221852 (29%)]\tLoss: 0.171569\tAcc: 79.00\n",
      "train epoch: 84 [76928/221852 (35%)]\tLoss: 0.310078\tAcc: 68.00\n",
      "train epoch: 84 [89728/221852 (40%)]\tLoss: 0.165379\tAcc: 82.00\n",
      "train epoch: 84 [102528/221852 (46%)]\tLoss: 0.155943\tAcc: 78.00\n",
      "train epoch: 84 [115328/221852 (52%)]\tLoss: 0.149569\tAcc: 80.00\n",
      "train epoch: 84 [128128/221852 (58%)]\tLoss: 0.140695\tAcc: 71.00\n",
      "train epoch: 84 [140928/221852 (64%)]\tLoss: 0.216072\tAcc: 73.00\n",
      "train epoch: 84 [153728/221852 (69%)]\tLoss: 0.165609\tAcc: 77.00\n",
      "train epoch: 84 [166528/221852 (75%)]\tLoss: 0.181464\tAcc: 83.00\n",
      "train epoch: 84 [179328/221852 (81%)]\tLoss: 0.198854\tAcc: 78.00\n",
      "train epoch: 84 [192128/221852 (87%)]\tLoss: 0.206018\tAcc: 74.00\n",
      "val epoch: 84 [128/221852 (0%)]\tLoss: 0.174818\tAcc: 82.00\n",
      "val epoch: 84 [12928/221852 (6%)]\tLoss: 0.191324\tAcc: 77.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 85 [128/221852 (0%)]\tLoss: 0.219432\tAcc: 73.00\n",
      "train epoch: 85 [12928/221852 (6%)]\tLoss: 0.129772\tAcc: 80.00\n",
      "train epoch: 85 [25728/221852 (12%)]\tLoss: 0.101795\tAcc: 76.00\n",
      "train epoch: 85 [38528/221852 (17%)]\tLoss: 0.231612\tAcc: 78.00\n",
      "train epoch: 85 [51328/221852 (23%)]\tLoss: 0.215920\tAcc: 85.00\n",
      "train epoch: 85 [64128/221852 (29%)]\tLoss: 0.220007\tAcc: 80.00\n",
      "train epoch: 85 [76928/221852 (35%)]\tLoss: 0.235504\tAcc: 77.00\n",
      "train epoch: 85 [89728/221852 (40%)]\tLoss: 0.162637\tAcc: 88.00\n",
      "train epoch: 85 [102528/221852 (46%)]\tLoss: 0.205681\tAcc: 77.00\n",
      "train epoch: 85 [115328/221852 (52%)]\tLoss: 0.225333\tAcc: 81.00\n",
      "train epoch: 85 [128128/221852 (58%)]\tLoss: 0.214229\tAcc: 76.00\n",
      "train epoch: 85 [140928/221852 (64%)]\tLoss: 0.161248\tAcc: 86.00\n",
      "train epoch: 85 [153728/221852 (69%)]\tLoss: 0.181440\tAcc: 71.00\n",
      "train epoch: 85 [166528/221852 (75%)]\tLoss: 0.158948\tAcc: 78.00\n",
      "train epoch: 85 [179328/221852 (81%)]\tLoss: 0.210709\tAcc: 71.00\n",
      "train epoch: 85 [192128/221852 (87%)]\tLoss: 0.273149\tAcc: 75.00\n",
      "val epoch: 85 [128/221852 (0%)]\tLoss: 0.153087\tAcc: 73.00\n",
      "val epoch: 85 [12928/221852 (6%)]\tLoss: 0.208484\tAcc: 77.00\n",
      "train epoch: 86 [128/221852 (0%)]\tLoss: 0.159543\tAcc: 87.00\n",
      "train epoch: 86 [12928/221852 (6%)]\tLoss: 0.153813\tAcc: 74.00\n",
      "train epoch: 86 [25728/221852 (12%)]\tLoss: 0.312877\tAcc: 75.00\n",
      "train epoch: 86 [38528/221852 (17%)]\tLoss: 0.202943\tAcc: 77.00\n",
      "train epoch: 86 [51328/221852 (23%)]\tLoss: 0.229856\tAcc: 70.00\n",
      "train epoch: 86 [64128/221852 (29%)]\tLoss: 0.198169\tAcc: 83.00\n",
      "train epoch: 86 [76928/221852 (35%)]\tLoss: 0.242952\tAcc: 70.00\n",
      "train epoch: 86 [89728/221852 (40%)]\tLoss: 0.194975\tAcc: 77.00\n",
      "train epoch: 86 [102528/221852 (46%)]\tLoss: 0.120556\tAcc: 80.00\n",
      "train epoch: 86 [115328/221852 (52%)]\tLoss: 0.139740\tAcc: 85.00\n",
      "train epoch: 86 [128128/221852 (58%)]\tLoss: 0.199796\tAcc: 84.00\n",
      "train epoch: 86 [140928/221852 (64%)]\tLoss: 0.147785\tAcc: 80.00\n",
      "train epoch: 86 [153728/221852 (69%)]\tLoss: 0.270061\tAcc: 77.00\n",
      "train epoch: 86 [166528/221852 (75%)]\tLoss: 0.379608\tAcc: 78.00\n",
      "train epoch: 86 [179328/221852 (81%)]\tLoss: 0.197999\tAcc: 77.00\n",
      "train epoch: 86 [192128/221852 (87%)]\tLoss: 0.148860\tAcc: 80.00\n",
      "val epoch: 86 [128/221852 (0%)]\tLoss: 0.168880\tAcc: 82.00\n",
      "val epoch: 86 [12928/221852 (6%)]\tLoss: 0.136185\tAcc: 82.00\n",
      "train epoch: 87 [128/221852 (0%)]\tLoss: 0.202341\tAcc: 73.00\n",
      "train epoch: 87 [12928/221852 (6%)]\tLoss: 0.285238\tAcc: 71.00\n",
      "train epoch: 87 [25728/221852 (12%)]\tLoss: 0.323552\tAcc: 76.00\n",
      "train epoch: 87 [38528/221852 (17%)]\tLoss: 0.226428\tAcc: 70.00\n",
      "train epoch: 87 [51328/221852 (23%)]\tLoss: 0.401159\tAcc: 72.00\n",
      "train epoch: 87 [64128/221852 (29%)]\tLoss: 0.178100\tAcc: 76.00\n",
      "train epoch: 87 [76928/221852 (35%)]\tLoss: 0.152005\tAcc: 80.00\n",
      "train epoch: 87 [89728/221852 (40%)]\tLoss: 0.235733\tAcc: 73.00\n",
      "train epoch: 87 [102528/221852 (46%)]\tLoss: 0.247135\tAcc: 70.00\n",
      "train epoch: 87 [115328/221852 (52%)]\tLoss: 0.201439\tAcc: 79.00\n",
      "train epoch: 87 [128128/221852 (58%)]\tLoss: 0.101054\tAcc: 82.00\n",
      "train epoch: 87 [140928/221852 (64%)]\tLoss: 0.194345\tAcc: 83.00\n",
      "train epoch: 87 [153728/221852 (69%)]\tLoss: 0.142397\tAcc: 73.00\n",
      "train epoch: 87 [166528/221852 (75%)]\tLoss: 0.214223\tAcc: 76.00\n",
      "train epoch: 87 [179328/221852 (81%)]\tLoss: 0.160823\tAcc: 83.00\n",
      "train epoch: 87 [192128/221852 (87%)]\tLoss: 0.281788\tAcc: 79.00\n",
      "val epoch: 87 [128/221852 (0%)]\tLoss: 0.249826\tAcc: 74.00\n",
      "val epoch: 87 [12928/221852 (6%)]\tLoss: 0.293207\tAcc: 70.00\n",
      "train epoch: 88 [128/221852 (0%)]\tLoss: 0.300714\tAcc: 73.00\n",
      "train epoch: 88 [12928/221852 (6%)]\tLoss: 0.230187\tAcc: 73.00\n",
      "train epoch: 88 [25728/221852 (12%)]\tLoss: 0.252748\tAcc: 76.00\n",
      "train epoch: 88 [38528/221852 (17%)]\tLoss: 0.172449\tAcc: 74.00\n",
      "train epoch: 88 [51328/221852 (23%)]\tLoss: 0.157713\tAcc: 79.00\n",
      "train epoch: 88 [64128/221852 (29%)]\tLoss: 0.194151\tAcc: 76.00\n",
      "train epoch: 88 [76928/221852 (35%)]\tLoss: 0.181464\tAcc: 73.00\n",
      "train epoch: 88 [89728/221852 (40%)]\tLoss: 0.217306\tAcc: 79.00\n",
      "train epoch: 88 [102528/221852 (46%)]\tLoss: 0.218500\tAcc: 76.00\n",
      "train epoch: 88 [115328/221852 (52%)]\tLoss: 0.197163\tAcc: 75.00\n",
      "train epoch: 88 [128128/221852 (58%)]\tLoss: 0.281865\tAcc: 75.00\n",
      "train epoch: 88 [140928/221852 (64%)]\tLoss: 0.137896\tAcc: 82.00\n",
      "train epoch: 88 [153728/221852 (69%)]\tLoss: 0.225722\tAcc: 77.00\n",
      "train epoch: 88 [166528/221852 (75%)]\tLoss: 0.161103\tAcc: 81.00\n",
      "train epoch: 88 [179328/221852 (81%)]\tLoss: 0.222430\tAcc: 78.00\n",
      "train epoch: 88 [192128/221852 (87%)]\tLoss: 0.121053\tAcc: 82.00\n",
      "val epoch: 88 [128/221852 (0%)]\tLoss: 0.143699\tAcc: 79.00\n",
      "val epoch: 88 [12928/221852 (6%)]\tLoss: 0.161123\tAcc: 82.00\n",
      "train epoch: 89 [128/221852 (0%)]\tLoss: 0.195947\tAcc: 77.00\n",
      "train epoch: 89 [12928/221852 (6%)]\tLoss: 0.207047\tAcc: 75.00\n",
      "train epoch: 89 [25728/221852 (12%)]\tLoss: 0.180739\tAcc: 79.00\n",
      "train epoch: 89 [38528/221852 (17%)]\tLoss: 0.122348\tAcc: 84.00\n",
      "train epoch: 89 [51328/221852 (23%)]\tLoss: 0.176353\tAcc: 78.00\n",
      "train epoch: 89 [64128/221852 (29%)]\tLoss: 0.176673\tAcc: 81.00\n",
      "train epoch: 89 [76928/221852 (35%)]\tLoss: 0.274526\tAcc: 71.00\n",
      "train epoch: 89 [89728/221852 (40%)]\tLoss: 0.132293\tAcc: 89.00\n",
      "train epoch: 89 [102528/221852 (46%)]\tLoss: 0.209784\tAcc: 79.00\n",
      "train epoch: 89 [115328/221852 (52%)]\tLoss: 0.216196\tAcc: 74.00\n",
      "train epoch: 89 [128128/221852 (58%)]\tLoss: 0.213715\tAcc: 76.00\n",
      "train epoch: 89 [140928/221852 (64%)]\tLoss: 0.194227\tAcc: 81.00\n",
      "train epoch: 89 [153728/221852 (69%)]\tLoss: 0.190229\tAcc: 77.00\n",
      "train epoch: 89 [166528/221852 (75%)]\tLoss: 0.252014\tAcc: 76.00\n",
      "train epoch: 89 [179328/221852 (81%)]\tLoss: 0.131623\tAcc: 75.00\n",
      "train epoch: 89 [192128/221852 (87%)]\tLoss: 0.246324\tAcc: 73.00\n",
      "val epoch: 89 [128/221852 (0%)]\tLoss: 0.196171\tAcc: 78.00\n",
      "val epoch: 89 [12928/221852 (6%)]\tLoss: 0.198732\tAcc: 75.00\n",
      "train epoch: 90 [128/221852 (0%)]\tLoss: 0.185232\tAcc: 79.00\n",
      "train epoch: 90 [12928/221852 (6%)]\tLoss: 0.138211\tAcc: 80.00\n",
      "train epoch: 90 [25728/221852 (12%)]\tLoss: 0.135160\tAcc: 76.00\n",
      "train epoch: 90 [38528/221852 (17%)]\tLoss: 0.147975\tAcc: 82.00\n",
      "train epoch: 90 [51328/221852 (23%)]\tLoss: 0.362165\tAcc: 73.00\n",
      "train epoch: 90 [64128/221852 (29%)]\tLoss: 0.226863\tAcc: 80.00\n",
      "train epoch: 90 [76928/221852 (35%)]\tLoss: 0.222864\tAcc: 77.00\n",
      "train epoch: 90 [89728/221852 (40%)]\tLoss: 0.196185\tAcc: 77.00\n",
      "train epoch: 90 [102528/221852 (46%)]\tLoss: 0.251478\tAcc: 84.00\n",
      "train epoch: 90 [115328/221852 (52%)]\tLoss: 0.146442\tAcc: 88.00\n",
      "train epoch: 90 [128128/221852 (58%)]\tLoss: 0.238463\tAcc: 71.00\n",
      "train epoch: 90 [140928/221852 (64%)]\tLoss: 0.205017\tAcc: 77.00\n",
      "train epoch: 90 [153728/221852 (69%)]\tLoss: 0.160308\tAcc: 78.00\n",
      "train epoch: 90 [166528/221852 (75%)]\tLoss: 0.193074\tAcc: 74.00\n",
      "train epoch: 90 [179328/221852 (81%)]\tLoss: 0.168465\tAcc: 75.00\n",
      "train epoch: 90 [192128/221852 (87%)]\tLoss: 0.141631\tAcc: 77.00\n",
      "val epoch: 90 [128/221852 (0%)]\tLoss: 0.220172\tAcc: 80.00\n",
      "val epoch: 90 [12928/221852 (6%)]\tLoss: 0.237129\tAcc: 80.00\n",
      "train epoch: 91 [128/221852 (0%)]\tLoss: 0.208499\tAcc: 78.00\n",
      "train epoch: 91 [12928/221852 (6%)]\tLoss: 0.135708\tAcc: 72.00\n",
      "train epoch: 91 [25728/221852 (12%)]\tLoss: 0.146919\tAcc: 79.00\n",
      "train epoch: 91 [38528/221852 (17%)]\tLoss: 0.150725\tAcc: 81.00\n",
      "train epoch: 91 [51328/221852 (23%)]\tLoss: 0.144350\tAcc: 75.00\n",
      "train epoch: 91 [64128/221852 (29%)]\tLoss: 0.133497\tAcc: 77.00\n",
      "train epoch: 91 [76928/221852 (35%)]\tLoss: 0.259561\tAcc: 79.00\n",
      "train epoch: 91 [89728/221852 (40%)]\tLoss: 0.219252\tAcc: 79.00\n",
      "train epoch: 91 [102528/221852 (46%)]\tLoss: 0.144649\tAcc: 80.00\n",
      "train epoch: 91 [115328/221852 (52%)]\tLoss: 0.160212\tAcc: 80.00\n",
      "train epoch: 91 [128128/221852 (58%)]\tLoss: 0.195202\tAcc: 70.00\n",
      "train epoch: 91 [140928/221852 (64%)]\tLoss: 0.216161\tAcc: 77.00\n",
      "train epoch: 91 [153728/221852 (69%)]\tLoss: 0.192020\tAcc: 77.00\n",
      "train epoch: 91 [166528/221852 (75%)]\tLoss: 0.205959\tAcc: 81.00\n",
      "train epoch: 91 [179328/221852 (81%)]\tLoss: 0.253886\tAcc: 75.00\n",
      "train epoch: 91 [192128/221852 (87%)]\tLoss: 0.220839\tAcc: 73.00\n",
      "val epoch: 91 [128/221852 (0%)]\tLoss: 0.314567\tAcc: 67.00\n",
      "val epoch: 91 [12928/221852 (6%)]\tLoss: 0.102428\tAcc: 80.00\n",
      "train epoch: 92 [128/221852 (0%)]\tLoss: 0.177684\tAcc: 75.00\n",
      "train epoch: 92 [12928/221852 (6%)]\tLoss: 0.293087\tAcc: 77.00\n",
      "train epoch: 92 [25728/221852 (12%)]\tLoss: 0.216095\tAcc: 81.00\n",
      "train epoch: 92 [38528/221852 (17%)]\tLoss: 0.158003\tAcc: 75.00\n",
      "train epoch: 92 [51328/221852 (23%)]\tLoss: 0.132886\tAcc: 82.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 92 [64128/221852 (29%)]\tLoss: 0.229102\tAcc: 77.00\n",
      "train epoch: 92 [76928/221852 (35%)]\tLoss: 0.180623\tAcc: 80.00\n",
      "train epoch: 92 [89728/221852 (40%)]\tLoss: 0.323117\tAcc: 73.00\n",
      "train epoch: 92 [102528/221852 (46%)]\tLoss: 0.151627\tAcc: 76.00\n",
      "train epoch: 92 [115328/221852 (52%)]\tLoss: 0.176475\tAcc: 77.00\n",
      "train epoch: 92 [128128/221852 (58%)]\tLoss: 0.142787\tAcc: 78.00\n",
      "train epoch: 92 [140928/221852 (64%)]\tLoss: 0.224618\tAcc: 80.00\n",
      "train epoch: 92 [153728/221852 (69%)]\tLoss: 0.185031\tAcc: 80.00\n",
      "train epoch: 92 [166528/221852 (75%)]\tLoss: 0.236358\tAcc: 73.00\n",
      "train epoch: 92 [179328/221852 (81%)]\tLoss: 0.236854\tAcc: 79.00\n",
      "train epoch: 92 [192128/221852 (87%)]\tLoss: 0.229308\tAcc: 76.00\n",
      "val epoch: 92 [128/221852 (0%)]\tLoss: 0.148066\tAcc: 73.00\n",
      "val epoch: 92 [12928/221852 (6%)]\tLoss: 0.204608\tAcc: 80.00\n",
      "train epoch: 93 [128/221852 (0%)]\tLoss: 0.304404\tAcc: 64.00\n",
      "train epoch: 93 [12928/221852 (6%)]\tLoss: 0.154007\tAcc: 79.00\n",
      "train epoch: 93 [25728/221852 (12%)]\tLoss: 0.255780\tAcc: 77.00\n",
      "train epoch: 93 [38528/221852 (17%)]\tLoss: 0.164573\tAcc: 79.00\n",
      "train epoch: 93 [51328/221852 (23%)]\tLoss: 0.186623\tAcc: 82.00\n",
      "train epoch: 93 [64128/221852 (29%)]\tLoss: 0.140492\tAcc: 75.00\n",
      "train epoch: 93 [76928/221852 (35%)]\tLoss: 0.156657\tAcc: 77.00\n",
      "train epoch: 93 [89728/221852 (40%)]\tLoss: 0.272698\tAcc: 75.00\n",
      "train epoch: 93 [102528/221852 (46%)]\tLoss: 0.225503\tAcc: 76.00\n",
      "train epoch: 93 [115328/221852 (52%)]\tLoss: 0.148722\tAcc: 73.00\n",
      "train epoch: 93 [128128/221852 (58%)]\tLoss: 0.157580\tAcc: 77.00\n",
      "train epoch: 93 [140928/221852 (64%)]\tLoss: 0.212654\tAcc: 79.00\n",
      "train epoch: 93 [153728/221852 (69%)]\tLoss: 0.196606\tAcc: 79.00\n",
      "train epoch: 93 [166528/221852 (75%)]\tLoss: 0.172955\tAcc: 71.00\n",
      "train epoch: 93 [179328/221852 (81%)]\tLoss: 0.229862\tAcc: 75.00\n",
      "train epoch: 93 [192128/221852 (87%)]\tLoss: 0.170358\tAcc: 83.00\n",
      "val epoch: 93 [128/221852 (0%)]\tLoss: 0.213422\tAcc: 77.00\n",
      "val epoch: 93 [12928/221852 (6%)]\tLoss: 0.251134\tAcc: 74.00\n",
      "train epoch: 94 [128/221852 (0%)]\tLoss: 0.141653\tAcc: 83.00\n",
      "train epoch: 94 [12928/221852 (6%)]\tLoss: 0.190394\tAcc: 75.00\n",
      "train epoch: 94 [25728/221852 (12%)]\tLoss: 0.174990\tAcc: 70.00\n",
      "train epoch: 94 [38528/221852 (17%)]\tLoss: 0.234680\tAcc: 82.00\n",
      "train epoch: 94 [51328/221852 (23%)]\tLoss: 0.245950\tAcc: 78.00\n",
      "train epoch: 94 [64128/221852 (29%)]\tLoss: 0.165925\tAcc: 82.00\n",
      "train epoch: 94 [76928/221852 (35%)]\tLoss: 0.134641\tAcc: 84.00\n",
      "train epoch: 94 [89728/221852 (40%)]\tLoss: 0.132837\tAcc: 79.00\n",
      "train epoch: 94 [102528/221852 (46%)]\tLoss: 0.272543\tAcc: 76.00\n",
      "train epoch: 94 [115328/221852 (52%)]\tLoss: 0.297822\tAcc: 68.00\n",
      "train epoch: 94 [128128/221852 (58%)]\tLoss: 0.224430\tAcc: 76.00\n",
      "train epoch: 94 [140928/221852 (64%)]\tLoss: 0.130840\tAcc: 81.00\n",
      "train epoch: 94 [153728/221852 (69%)]\tLoss: 0.217222\tAcc: 77.00\n",
      "train epoch: 94 [166528/221852 (75%)]\tLoss: 0.217133\tAcc: 73.00\n",
      "train epoch: 94 [179328/221852 (81%)]\tLoss: 0.113186\tAcc: 82.00\n",
      "train epoch: 94 [192128/221852 (87%)]\tLoss: 0.139191\tAcc: 75.00\n",
      "val epoch: 94 [128/221852 (0%)]\tLoss: 0.264314\tAcc: 77.00\n",
      "val epoch: 94 [12928/221852 (6%)]\tLoss: 0.358621\tAcc: 70.00\n",
      "train epoch: 95 [128/221852 (0%)]\tLoss: 0.213664\tAcc: 79.00\n",
      "train epoch: 95 [12928/221852 (6%)]\tLoss: 0.143653\tAcc: 78.00\n",
      "train epoch: 95 [25728/221852 (12%)]\tLoss: 0.253549\tAcc: 79.00\n",
      "train epoch: 95 [38528/221852 (17%)]\tLoss: 0.130865\tAcc: 75.00\n",
      "train epoch: 95 [51328/221852 (23%)]\tLoss: 0.140785\tAcc: 77.00\n",
      "train epoch: 95 [64128/221852 (29%)]\tLoss: 0.196563\tAcc: 80.00\n",
      "train epoch: 95 [76928/221852 (35%)]\tLoss: 0.145481\tAcc: 83.00\n",
      "train epoch: 95 [89728/221852 (40%)]\tLoss: 0.183502\tAcc: 82.00\n",
      "train epoch: 95 [102528/221852 (46%)]\tLoss: 0.117261\tAcc: 80.00\n",
      "train epoch: 95 [115328/221852 (52%)]\tLoss: 0.206256\tAcc: 81.00\n",
      "train epoch: 95 [128128/221852 (58%)]\tLoss: 0.182164\tAcc: 83.00\n",
      "train epoch: 95 [140928/221852 (64%)]\tLoss: 0.142587\tAcc: 80.00\n",
      "train epoch: 95 [153728/221852 (69%)]\tLoss: 0.203117\tAcc: 79.00\n",
      "train epoch: 95 [166528/221852 (75%)]\tLoss: 0.176146\tAcc: 84.00\n",
      "train epoch: 95 [179328/221852 (81%)]\tLoss: 0.232172\tAcc: 79.00\n",
      "train epoch: 95 [192128/221852 (87%)]\tLoss: 0.218217\tAcc: 79.00\n",
      "val epoch: 95 [128/221852 (0%)]\tLoss: 0.194374\tAcc: 80.00\n",
      "val epoch: 95 [12928/221852 (6%)]\tLoss: 0.194044\tAcc: 73.00\n",
      "train epoch: 96 [128/221852 (0%)]\tLoss: 0.186394\tAcc: 76.00\n",
      "train epoch: 96 [12928/221852 (6%)]\tLoss: 0.142333\tAcc: 82.00\n",
      "train epoch: 96 [25728/221852 (12%)]\tLoss: 0.309333\tAcc: 76.00\n",
      "train epoch: 96 [38528/221852 (17%)]\tLoss: 0.866710\tAcc: 75.00\n",
      "train epoch: 96 [51328/221852 (23%)]\tLoss: 0.181766\tAcc: 84.00\n",
      "train epoch: 96 [64128/221852 (29%)]\tLoss: 0.173349\tAcc: 77.00\n",
      "train epoch: 96 [76928/221852 (35%)]\tLoss: 0.205667\tAcc: 73.00\n",
      "train epoch: 96 [89728/221852 (40%)]\tLoss: 0.084043\tAcc: 85.00\n",
      "train epoch: 96 [102528/221852 (46%)]\tLoss: 0.208701\tAcc: 76.00\n",
      "train epoch: 96 [115328/221852 (52%)]\tLoss: 0.207921\tAcc: 78.00\n",
      "train epoch: 96 [128128/221852 (58%)]\tLoss: 0.497633\tAcc: 72.00\n",
      "train epoch: 96 [140928/221852 (64%)]\tLoss: 0.170942\tAcc: 80.00\n",
      "train epoch: 96 [153728/221852 (69%)]\tLoss: 0.253720\tAcc: 71.00\n",
      "train epoch: 96 [166528/221852 (75%)]\tLoss: 0.208472\tAcc: 79.00\n",
      "train epoch: 96 [179328/221852 (81%)]\tLoss: 0.144086\tAcc: 84.00\n",
      "train epoch: 96 [192128/221852 (87%)]\tLoss: 0.182193\tAcc: 74.00\n",
      "val epoch: 96 [128/221852 (0%)]\tLoss: 0.198260\tAcc: 79.00\n",
      "val epoch: 96 [12928/221852 (6%)]\tLoss: 0.211490\tAcc: 77.00\n",
      "train epoch: 97 [128/221852 (0%)]\tLoss: 0.161378\tAcc: 79.00\n",
      "train epoch: 97 [12928/221852 (6%)]\tLoss: 0.169943\tAcc: 73.00\n",
      "train epoch: 97 [25728/221852 (12%)]\tLoss: 0.152750\tAcc: 81.00\n",
      "train epoch: 97 [38528/221852 (17%)]\tLoss: 0.211028\tAcc: 80.00\n",
      "train epoch: 97 [51328/221852 (23%)]\tLoss: 0.202861\tAcc: 78.00\n",
      "train epoch: 97 [64128/221852 (29%)]\tLoss: 0.216911\tAcc: 79.00\n",
      "train epoch: 97 [76928/221852 (35%)]\tLoss: 0.216756\tAcc: 70.00\n",
      "train epoch: 97 [89728/221852 (40%)]\tLoss: 0.261203\tAcc: 78.00\n",
      "train epoch: 97 [102528/221852 (46%)]\tLoss: 0.190962\tAcc: 80.00\n",
      "train epoch: 97 [115328/221852 (52%)]\tLoss: 0.174879\tAcc: 75.00\n",
      "train epoch: 97 [128128/221852 (58%)]\tLoss: 0.247559\tAcc: 84.00\n",
      "train epoch: 97 [140928/221852 (64%)]\tLoss: 0.208356\tAcc: 73.00\n",
      "train epoch: 97 [153728/221852 (69%)]\tLoss: 0.182614\tAcc: 77.00\n",
      "train epoch: 97 [166528/221852 (75%)]\tLoss: 0.118641\tAcc: 85.00\n",
      "train epoch: 97 [179328/221852 (81%)]\tLoss: 0.216774\tAcc: 80.00\n",
      "train epoch: 97 [192128/221852 (87%)]\tLoss: 0.257137\tAcc: 77.00\n",
      "val epoch: 97 [128/221852 (0%)]\tLoss: 0.189367\tAcc: 69.00\n",
      "val epoch: 97 [12928/221852 (6%)]\tLoss: 0.126316\tAcc: 77.00\n",
      "train epoch: 98 [128/221852 (0%)]\tLoss: 0.254824\tAcc: 77.00\n",
      "train epoch: 98 [12928/221852 (6%)]\tLoss: 0.277858\tAcc: 70.00\n",
      "train epoch: 98 [25728/221852 (12%)]\tLoss: 0.251258\tAcc: 78.00\n",
      "train epoch: 98 [38528/221852 (17%)]\tLoss: 0.191592\tAcc: 82.00\n",
      "train epoch: 98 [51328/221852 (23%)]\tLoss: 0.201419\tAcc: 81.00\n",
      "train epoch: 98 [64128/221852 (29%)]\tLoss: 0.241283\tAcc: 73.00\n",
      "train epoch: 98 [76928/221852 (35%)]\tLoss: 0.142876\tAcc: 80.00\n",
      "train epoch: 98 [89728/221852 (40%)]\tLoss: 0.129559\tAcc: 77.00\n",
      "train epoch: 98 [102528/221852 (46%)]\tLoss: 0.312614\tAcc: 77.00\n",
      "train epoch: 98 [115328/221852 (52%)]\tLoss: 0.185503\tAcc: 81.00\n",
      "train epoch: 98 [128128/221852 (58%)]\tLoss: 0.209997\tAcc: 76.00\n",
      "train epoch: 98 [140928/221852 (64%)]\tLoss: 0.246540\tAcc: 81.00\n",
      "train epoch: 98 [153728/221852 (69%)]\tLoss: 0.315533\tAcc: 70.00\n",
      "train epoch: 98 [166528/221852 (75%)]\tLoss: 0.202819\tAcc: 77.00\n",
      "train epoch: 98 [179328/221852 (81%)]\tLoss: 0.115350\tAcc: 79.00\n",
      "train epoch: 98 [192128/221852 (87%)]\tLoss: 0.268869\tAcc: 74.00\n",
      "val epoch: 98 [128/221852 (0%)]\tLoss: 0.188745\tAcc: 80.00\n",
      "val epoch: 98 [12928/221852 (6%)]\tLoss: 0.248845\tAcc: 77.00\n",
      "train epoch: 99 [128/221852 (0%)]\tLoss: 0.169396\tAcc: 84.00\n",
      "train epoch: 99 [12928/221852 (6%)]\tLoss: 0.166426\tAcc: 78.00\n",
      "train epoch: 99 [25728/221852 (12%)]\tLoss: 0.195601\tAcc: 80.00\n",
      "train epoch: 99 [38528/221852 (17%)]\tLoss: 0.295339\tAcc: 77.00\n",
      "train epoch: 99 [51328/221852 (23%)]\tLoss: 0.168896\tAcc: 77.00\n",
      "train epoch: 99 [64128/221852 (29%)]\tLoss: 0.193013\tAcc: 75.00\n",
      "train epoch: 99 [76928/221852 (35%)]\tLoss: 0.216134\tAcc: 76.00\n",
      "train epoch: 99 [89728/221852 (40%)]\tLoss: 0.205174\tAcc: 77.00\n",
      "train epoch: 99 [102528/221852 (46%)]\tLoss: 0.404033\tAcc: 77.00\n",
      "train epoch: 99 [115328/221852 (52%)]\tLoss: 0.173878\tAcc: 80.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 99 [128128/221852 (58%)]\tLoss: 0.190741\tAcc: 84.00\n",
      "train epoch: 99 [140928/221852 (64%)]\tLoss: 0.240540\tAcc: 68.00\n",
      "train epoch: 99 [153728/221852 (69%)]\tLoss: 0.315310\tAcc: 75.00\n",
      "train epoch: 99 [166528/221852 (75%)]\tLoss: 0.257776\tAcc: 74.00\n",
      "train epoch: 99 [179328/221852 (81%)]\tLoss: 0.336851\tAcc: 72.00\n",
      "train epoch: 99 [192128/221852 (87%)]\tLoss: 0.200529\tAcc: 80.00\n",
      "val epoch: 99 [128/221852 (0%)]\tLoss: 0.204080\tAcc: 80.00\n",
      "val epoch: 99 [12928/221852 (6%)]\tLoss: 0.245448\tAcc: 76.00\n",
      "train epoch: 100 [128/221852 (0%)]\tLoss: 0.169268\tAcc: 71.00\n",
      "train epoch: 100 [12928/221852 (6%)]\tLoss: 0.151981\tAcc: 78.00\n",
      "train epoch: 100 [25728/221852 (12%)]\tLoss: 0.182608\tAcc: 74.00\n",
      "train epoch: 100 [38528/221852 (17%)]\tLoss: 0.139978\tAcc: 80.00\n",
      "train epoch: 100 [51328/221852 (23%)]\tLoss: 0.276874\tAcc: 79.00\n",
      "train epoch: 100 [64128/221852 (29%)]\tLoss: 0.128943\tAcc: 82.00\n",
      "train epoch: 100 [76928/221852 (35%)]\tLoss: 0.156823\tAcc: 80.00\n",
      "train epoch: 100 [89728/221852 (40%)]\tLoss: 0.084313\tAcc: 80.00\n",
      "train epoch: 100 [102528/221852 (46%)]\tLoss: 0.352724\tAcc: 84.00\n",
      "train epoch: 100 [115328/221852 (52%)]\tLoss: 0.308910\tAcc: 80.00\n",
      "train epoch: 100 [128128/221852 (58%)]\tLoss: 0.269027\tAcc: 85.00\n",
      "train epoch: 100 [140928/221852 (64%)]\tLoss: 0.166737\tAcc: 84.00\n",
      "train epoch: 100 [153728/221852 (69%)]\tLoss: 0.192149\tAcc: 78.00\n",
      "train epoch: 100 [166528/221852 (75%)]\tLoss: 0.276394\tAcc: 81.00\n",
      "train epoch: 100 [179328/221852 (81%)]\tLoss: 0.163095\tAcc: 80.00\n",
      "train epoch: 100 [192128/221852 (87%)]\tLoss: 0.183399\tAcc: 78.00\n",
      "val epoch: 100 [128/221852 (0%)]\tLoss: 0.223849\tAcc: 74.00\n",
      "val epoch: 100 [12928/221852 (6%)]\tLoss: 0.146361\tAcc: 84.00\n",
      "train epoch: 101 [128/221852 (0%)]\tLoss: 0.199538\tAcc: 75.00\n",
      "train epoch: 101 [12928/221852 (6%)]\tLoss: 0.161326\tAcc: 76.00\n",
      "train epoch: 101 [25728/221852 (12%)]\tLoss: 0.231738\tAcc: 76.00\n",
      "train epoch: 101 [38528/221852 (17%)]\tLoss: 0.272906\tAcc: 82.00\n",
      "train epoch: 101 [51328/221852 (23%)]\tLoss: 0.169282\tAcc: 78.00\n",
      "train epoch: 101 [64128/221852 (29%)]\tLoss: 0.145528\tAcc: 73.00\n",
      "train epoch: 101 [76928/221852 (35%)]\tLoss: 0.189819\tAcc: 78.00\n",
      "train epoch: 101 [89728/221852 (40%)]\tLoss: 0.139608\tAcc: 83.00\n",
      "train epoch: 101 [102528/221852 (46%)]\tLoss: 0.193119\tAcc: 85.00\n",
      "train epoch: 101 [115328/221852 (52%)]\tLoss: 0.191820\tAcc: 84.00\n",
      "train epoch: 101 [128128/221852 (58%)]\tLoss: 0.135750\tAcc: 84.00\n",
      "train epoch: 101 [140928/221852 (64%)]\tLoss: 0.908091\tAcc: 73.00\n",
      "train epoch: 101 [153728/221852 (69%)]\tLoss: 0.198449\tAcc: 79.00\n",
      "train epoch: 101 [166528/221852 (75%)]\tLoss: 0.169339\tAcc: 80.00\n",
      "train epoch: 101 [179328/221852 (81%)]\tLoss: 0.212397\tAcc: 77.00\n",
      "train epoch: 101 [192128/221852 (87%)]\tLoss: 0.239221\tAcc: 76.00\n",
      "val epoch: 101 [128/221852 (0%)]\tLoss: 0.164648\tAcc: 84.00\n",
      "val epoch: 101 [12928/221852 (6%)]\tLoss: 0.212537\tAcc: 78.00\n",
      "train epoch: 102 [128/221852 (0%)]\tLoss: 0.280983\tAcc: 75.00\n",
      "train epoch: 102 [12928/221852 (6%)]\tLoss: 0.246548\tAcc: 71.00\n",
      "train epoch: 102 [25728/221852 (12%)]\tLoss: 0.690636\tAcc: 75.00\n",
      "train epoch: 102 [38528/221852 (17%)]\tLoss: 0.224817\tAcc: 79.00\n",
      "train epoch: 102 [51328/221852 (23%)]\tLoss: 0.218763\tAcc: 75.00\n",
      "train epoch: 102 [64128/221852 (29%)]\tLoss: 0.186013\tAcc: 78.00\n",
      "train epoch: 102 [76928/221852 (35%)]\tLoss: 0.236193\tAcc: 74.00\n",
      "train epoch: 102 [89728/221852 (40%)]\tLoss: 0.162267\tAcc: 86.00\n",
      "train epoch: 102 [102528/221852 (46%)]\tLoss: 0.208542\tAcc: 79.00\n",
      "train epoch: 102 [115328/221852 (52%)]\tLoss: 0.206632\tAcc: 76.00\n",
      "train epoch: 102 [128128/221852 (58%)]\tLoss: 0.303348\tAcc: 70.00\n",
      "train epoch: 102 [140928/221852 (64%)]\tLoss: 0.195615\tAcc: 81.00\n",
      "train epoch: 102 [153728/221852 (69%)]\tLoss: 0.119319\tAcc: 81.00\n",
      "train epoch: 102 [166528/221852 (75%)]\tLoss: 0.189841\tAcc: 80.00\n",
      "train epoch: 102 [179328/221852 (81%)]\tLoss: 0.218494\tAcc: 79.00\n",
      "train epoch: 102 [192128/221852 (87%)]\tLoss: 0.144942\tAcc: 79.00\n",
      "val epoch: 102 [128/221852 (0%)]\tLoss: 0.262277\tAcc: 74.00\n",
      "val epoch: 102 [12928/221852 (6%)]\tLoss: 0.206894\tAcc: 77.00\n",
      "train epoch: 103 [128/221852 (0%)]\tLoss: 0.269186\tAcc: 74.00\n",
      "train epoch: 103 [12928/221852 (6%)]\tLoss: 0.192747\tAcc: 81.00\n",
      "train epoch: 103 [25728/221852 (12%)]\tLoss: 0.169700\tAcc: 75.00\n",
      "train epoch: 103 [38528/221852 (17%)]\tLoss: 0.221170\tAcc: 78.00\n",
      "train epoch: 103 [51328/221852 (23%)]\tLoss: 0.248815\tAcc: 74.00\n",
      "train epoch: 103 [64128/221852 (29%)]\tLoss: 0.213069\tAcc: 76.00\n",
      "train epoch: 103 [76928/221852 (35%)]\tLoss: 0.171404\tAcc: 80.00\n",
      "train epoch: 103 [89728/221852 (40%)]\tLoss: 0.206257\tAcc: 81.00\n",
      "train epoch: 103 [102528/221852 (46%)]\tLoss: 0.158897\tAcc: 77.00\n",
      "train epoch: 103 [115328/221852 (52%)]\tLoss: 0.205391\tAcc: 79.00\n",
      "train epoch: 103 [128128/221852 (58%)]\tLoss: 0.177993\tAcc: 74.00\n",
      "train epoch: 103 [140928/221852 (64%)]\tLoss: 0.236703\tAcc: 77.00\n",
      "train epoch: 103 [153728/221852 (69%)]\tLoss: 0.158812\tAcc: 79.00\n",
      "train epoch: 103 [166528/221852 (75%)]\tLoss: 0.079842\tAcc: 82.00\n",
      "train epoch: 103 [179328/221852 (81%)]\tLoss: 0.140328\tAcc: 83.00\n",
      "train epoch: 103 [192128/221852 (87%)]\tLoss: 0.197804\tAcc: 78.00\n",
      "val epoch: 103 [128/221852 (0%)]\tLoss: 0.268208\tAcc: 78.00\n",
      "val epoch: 103 [12928/221852 (6%)]\tLoss: 0.155437\tAcc: 77.00\n",
      "train epoch: 104 [128/221852 (0%)]\tLoss: 0.174301\tAcc: 80.00\n",
      "train epoch: 104 [12928/221852 (6%)]\tLoss: 0.309882\tAcc: 77.00\n",
      "train epoch: 104 [25728/221852 (12%)]\tLoss: 0.131977\tAcc: 84.00\n",
      "train epoch: 104 [38528/221852 (17%)]\tLoss: 0.156465\tAcc: 80.00\n",
      "train epoch: 104 [51328/221852 (23%)]\tLoss: 0.208776\tAcc: 73.00\n",
      "train epoch: 104 [64128/221852 (29%)]\tLoss: 0.135553\tAcc: 80.00\n",
      "train epoch: 104 [76928/221852 (35%)]\tLoss: 0.155520\tAcc: 81.00\n",
      "train epoch: 104 [89728/221852 (40%)]\tLoss: 0.190855\tAcc: 83.00\n",
      "train epoch: 104 [102528/221852 (46%)]\tLoss: 0.175273\tAcc: 80.00\n",
      "train epoch: 104 [115328/221852 (52%)]\tLoss: 0.170535\tAcc: 81.00\n",
      "train epoch: 104 [128128/221852 (58%)]\tLoss: 0.154868\tAcc: 80.00\n",
      "train epoch: 104 [140928/221852 (64%)]\tLoss: 0.289096\tAcc: 74.00\n",
      "train epoch: 104 [153728/221852 (69%)]\tLoss: 0.190775\tAcc: 81.00\n",
      "train epoch: 104 [166528/221852 (75%)]\tLoss: 0.158590\tAcc: 81.00\n",
      "train epoch: 104 [179328/221852 (81%)]\tLoss: 0.201834\tAcc: 73.00\n",
      "train epoch: 104 [192128/221852 (87%)]\tLoss: 0.252274\tAcc: 73.00\n",
      "val epoch: 104 [128/221852 (0%)]\tLoss: 0.240408\tAcc: 78.00\n",
      "val epoch: 104 [12928/221852 (6%)]\tLoss: 0.147292\tAcc: 88.00\n",
      "train epoch: 105 [128/221852 (0%)]\tLoss: 0.184751\tAcc: 73.00\n",
      "train epoch: 105 [12928/221852 (6%)]\tLoss: 0.202533\tAcc: 76.00\n",
      "train epoch: 105 [25728/221852 (12%)]\tLoss: 0.156082\tAcc: 82.00\n",
      "train epoch: 105 [38528/221852 (17%)]\tLoss: 0.168391\tAcc: 80.00\n",
      "train epoch: 105 [51328/221852 (23%)]\tLoss: 0.152659\tAcc: 78.00\n",
      "train epoch: 105 [64128/221852 (29%)]\tLoss: 0.183498\tAcc: 74.00\n",
      "train epoch: 105 [76928/221852 (35%)]\tLoss: 0.236506\tAcc: 77.00\n",
      "train epoch: 105 [89728/221852 (40%)]\tLoss: 0.171890\tAcc: 78.00\n",
      "train epoch: 105 [102528/221852 (46%)]\tLoss: 0.194512\tAcc: 76.00\n",
      "train epoch: 105 [115328/221852 (52%)]\tLoss: 0.206552\tAcc: 76.00\n",
      "train epoch: 105 [128128/221852 (58%)]\tLoss: 0.129099\tAcc: 76.00\n",
      "train epoch: 105 [140928/221852 (64%)]\tLoss: 0.226942\tAcc: 76.00\n",
      "train epoch: 105 [153728/221852 (69%)]\tLoss: 0.230029\tAcc: 83.00\n",
      "train epoch: 105 [166528/221852 (75%)]\tLoss: 0.166359\tAcc: 74.00\n",
      "train epoch: 105 [179328/221852 (81%)]\tLoss: 0.250651\tAcc: 74.00\n",
      "train epoch: 105 [192128/221852 (87%)]\tLoss: 0.210019\tAcc: 75.00\n",
      "val epoch: 105 [128/221852 (0%)]\tLoss: 0.236812\tAcc: 77.00\n",
      "val epoch: 105 [12928/221852 (6%)]\tLoss: 0.238625\tAcc: 81.00\n",
      "train epoch: 106 [128/221852 (0%)]\tLoss: 0.261752\tAcc: 75.00\n",
      "train epoch: 106 [12928/221852 (6%)]\tLoss: 0.187327\tAcc: 80.00\n",
      "train epoch: 106 [25728/221852 (12%)]\tLoss: 0.119096\tAcc: 88.00\n",
      "train epoch: 106 [38528/221852 (17%)]\tLoss: 0.223464\tAcc: 80.00\n",
      "train epoch: 106 [51328/221852 (23%)]\tLoss: 0.191741\tAcc: 76.00\n",
      "train epoch: 106 [64128/221852 (29%)]\tLoss: 0.156076\tAcc: 84.00\n",
      "train epoch: 106 [76928/221852 (35%)]\tLoss: 0.194428\tAcc: 78.00\n",
      "train epoch: 106 [89728/221852 (40%)]\tLoss: 0.217162\tAcc: 80.00\n",
      "train epoch: 106 [102528/221852 (46%)]\tLoss: 0.176167\tAcc: 80.00\n",
      "train epoch: 106 [115328/221852 (52%)]\tLoss: 0.170786\tAcc: 75.00\n",
      "train epoch: 106 [128128/221852 (58%)]\tLoss: 0.157194\tAcc: 80.00\n",
      "train epoch: 106 [140928/221852 (64%)]\tLoss: 0.175631\tAcc: 79.00\n",
      "train epoch: 106 [153728/221852 (69%)]\tLoss: 0.110770\tAcc: 78.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 106 [166528/221852 (75%)]\tLoss: 0.175792\tAcc: 79.00\n",
      "train epoch: 106 [179328/221852 (81%)]\tLoss: 0.170383\tAcc: 77.00\n",
      "train epoch: 106 [192128/221852 (87%)]\tLoss: 0.233545\tAcc: 79.00\n",
      "val epoch: 106 [128/221852 (0%)]\tLoss: 0.136783\tAcc: 77.00\n",
      "val epoch: 106 [12928/221852 (6%)]\tLoss: 0.225349\tAcc: 85.00\n",
      "train epoch: 107 [128/221852 (0%)]\tLoss: 0.203252\tAcc: 82.00\n",
      "train epoch: 107 [12928/221852 (6%)]\tLoss: 0.187703\tAcc: 76.00\n",
      "train epoch: 107 [25728/221852 (12%)]\tLoss: 0.213694\tAcc: 77.00\n",
      "train epoch: 107 [38528/221852 (17%)]\tLoss: 0.201207\tAcc: 77.00\n",
      "train epoch: 107 [51328/221852 (23%)]\tLoss: 0.106681\tAcc: 82.00\n",
      "train epoch: 107 [64128/221852 (29%)]\tLoss: 0.167393\tAcc: 71.00\n",
      "train epoch: 107 [76928/221852 (35%)]\tLoss: 0.112706\tAcc: 80.00\n",
      "train epoch: 107 [89728/221852 (40%)]\tLoss: 0.185017\tAcc: 78.00\n",
      "train epoch: 107 [102528/221852 (46%)]\tLoss: 0.129863\tAcc: 76.00\n",
      "train epoch: 107 [115328/221852 (52%)]\tLoss: 0.154019\tAcc: 88.00\n",
      "train epoch: 107 [128128/221852 (58%)]\tLoss: 0.266721\tAcc: 75.00\n",
      "train epoch: 107 [140928/221852 (64%)]\tLoss: 0.094437\tAcc: 82.00\n",
      "train epoch: 107 [153728/221852 (69%)]\tLoss: 0.305375\tAcc: 81.00\n",
      "train epoch: 107 [166528/221852 (75%)]\tLoss: 0.200084\tAcc: 72.00\n",
      "train epoch: 107 [179328/221852 (81%)]\tLoss: 0.132639\tAcc: 84.00\n",
      "train epoch: 107 [192128/221852 (87%)]\tLoss: 0.253558\tAcc: 70.00\n",
      "val epoch: 107 [128/221852 (0%)]\tLoss: 0.223856\tAcc: 79.00\n",
      "val epoch: 107 [12928/221852 (6%)]\tLoss: 0.205116\tAcc: 80.00\n",
      "train epoch: 108 [128/221852 (0%)]\tLoss: 0.290957\tAcc: 81.00\n",
      "train epoch: 108 [12928/221852 (6%)]\tLoss: 0.276030\tAcc: 77.00\n",
      "train epoch: 108 [25728/221852 (12%)]\tLoss: 0.230775\tAcc: 80.00\n",
      "train epoch: 108 [38528/221852 (17%)]\tLoss: 0.320729\tAcc: 77.00\n",
      "train epoch: 108 [51328/221852 (23%)]\tLoss: 0.168056\tAcc: 80.00\n",
      "train epoch: 108 [64128/221852 (29%)]\tLoss: 0.203262\tAcc: 76.00\n",
      "train epoch: 108 [76928/221852 (35%)]\tLoss: 0.257349\tAcc: 77.00\n",
      "train epoch: 108 [89728/221852 (40%)]\tLoss: 0.226498\tAcc: 75.00\n",
      "train epoch: 108 [102528/221852 (46%)]\tLoss: 0.199510\tAcc: 72.00\n",
      "train epoch: 108 [115328/221852 (52%)]\tLoss: 0.176269\tAcc: 73.00\n",
      "train epoch: 108 [128128/221852 (58%)]\tLoss: 0.225344\tAcc: 78.00\n",
      "train epoch: 108 [140928/221852 (64%)]\tLoss: 0.171098\tAcc: 78.00\n",
      "train epoch: 108 [153728/221852 (69%)]\tLoss: 0.123936\tAcc: 80.00\n",
      "train epoch: 108 [166528/221852 (75%)]\tLoss: 0.137000\tAcc: 80.00\n",
      "train epoch: 108 [179328/221852 (81%)]\tLoss: 0.274237\tAcc: 73.00\n",
      "train epoch: 108 [192128/221852 (87%)]\tLoss: 0.198060\tAcc: 73.00\n",
      "val epoch: 108 [128/221852 (0%)]\tLoss: 0.282176\tAcc: 70.00\n",
      "val epoch: 108 [12928/221852 (6%)]\tLoss: 0.181757\tAcc: 77.00\n",
      "train epoch: 109 [128/221852 (0%)]\tLoss: 0.295684\tAcc: 76.00\n",
      "train epoch: 109 [12928/221852 (6%)]\tLoss: 0.118597\tAcc: 88.00\n",
      "train epoch: 109 [25728/221852 (12%)]\tLoss: 0.216448\tAcc: 84.00\n",
      "train epoch: 109 [38528/221852 (17%)]\tLoss: 0.272561\tAcc: 69.00\n",
      "train epoch: 109 [51328/221852 (23%)]\tLoss: 0.240093\tAcc: 76.00\n",
      "train epoch: 109 [64128/221852 (29%)]\tLoss: 0.120232\tAcc: 80.00\n",
      "train epoch: 109 [76928/221852 (35%)]\tLoss: 0.183519\tAcc: 77.00\n",
      "train epoch: 109 [89728/221852 (40%)]\tLoss: 0.259626\tAcc: 80.00\n",
      "train epoch: 109 [102528/221852 (46%)]\tLoss: 0.260266\tAcc: 78.00\n",
      "train epoch: 109 [115328/221852 (52%)]\tLoss: 0.145051\tAcc: 80.00\n",
      "train epoch: 109 [128128/221852 (58%)]\tLoss: 0.160985\tAcc: 79.00\n",
      "train epoch: 109 [140928/221852 (64%)]\tLoss: 0.122462\tAcc: 84.00\n",
      "train epoch: 109 [153728/221852 (69%)]\tLoss: 0.163504\tAcc: 79.00\n",
      "train epoch: 109 [166528/221852 (75%)]\tLoss: 0.271607\tAcc: 75.00\n",
      "train epoch: 109 [179328/221852 (81%)]\tLoss: 0.170492\tAcc: 77.00\n",
      "train epoch: 109 [192128/221852 (87%)]\tLoss: 0.244438\tAcc: 77.00\n",
      "val epoch: 109 [128/221852 (0%)]\tLoss: 0.197881\tAcc: 81.00\n",
      "val epoch: 109 [12928/221852 (6%)]\tLoss: 0.139937\tAcc: 83.00\n",
      "train epoch: 110 [128/221852 (0%)]\tLoss: 0.198955\tAcc: 78.00\n",
      "train epoch: 110 [12928/221852 (6%)]\tLoss: 0.146049\tAcc: 79.00\n",
      "train epoch: 110 [25728/221852 (12%)]\tLoss: 0.215217\tAcc: 77.00\n",
      "train epoch: 110 [38528/221852 (17%)]\tLoss: 0.199686\tAcc: 80.00\n",
      "train epoch: 110 [51328/221852 (23%)]\tLoss: 0.175797\tAcc: 74.00\n",
      "train epoch: 110 [64128/221852 (29%)]\tLoss: 0.138288\tAcc: 75.00\n",
      "train epoch: 110 [76928/221852 (35%)]\tLoss: 0.174368\tAcc: 76.00\n",
      "train epoch: 110 [89728/221852 (40%)]\tLoss: 0.164159\tAcc: 74.00\n",
      "train epoch: 110 [102528/221852 (46%)]\tLoss: 0.167355\tAcc: 78.00\n",
      "train epoch: 110 [115328/221852 (52%)]\tLoss: 0.279826\tAcc: 74.00\n",
      "train epoch: 110 [128128/221852 (58%)]\tLoss: 0.132138\tAcc: 83.00\n",
      "train epoch: 110 [140928/221852 (64%)]\tLoss: 0.215591\tAcc: 80.00\n",
      "train epoch: 110 [153728/221852 (69%)]\tLoss: 0.182756\tAcc: 80.00\n",
      "train epoch: 110 [166528/221852 (75%)]\tLoss: 0.177915\tAcc: 81.00\n",
      "train epoch: 110 [179328/221852 (81%)]\tLoss: 0.253770\tAcc: 81.00\n",
      "train epoch: 110 [192128/221852 (87%)]\tLoss: 0.171899\tAcc: 73.00\n",
      "val epoch: 110 [128/221852 (0%)]\tLoss: 0.233336\tAcc: 80.00\n",
      "val epoch: 110 [12928/221852 (6%)]\tLoss: 0.143671\tAcc: 80.00\n",
      "train epoch: 111 [128/221852 (0%)]\tLoss: 0.162851\tAcc: 80.00\n",
      "train epoch: 111 [12928/221852 (6%)]\tLoss: 0.200523\tAcc: 79.00\n",
      "train epoch: 111 [25728/221852 (12%)]\tLoss: 0.224755\tAcc: 84.00\n",
      "train epoch: 111 [38528/221852 (17%)]\tLoss: 0.222747\tAcc: 77.00\n",
      "train epoch: 111 [51328/221852 (23%)]\tLoss: 0.139366\tAcc: 78.00\n",
      "train epoch: 111 [64128/221852 (29%)]\tLoss: 0.178593\tAcc: 79.00\n",
      "train epoch: 111 [76928/221852 (35%)]\tLoss: 0.212719\tAcc: 83.00\n",
      "train epoch: 111 [89728/221852 (40%)]\tLoss: 0.193403\tAcc: 79.00\n",
      "train epoch: 111 [102528/221852 (46%)]\tLoss: 0.171107\tAcc: 77.00\n",
      "train epoch: 111 [115328/221852 (52%)]\tLoss: 0.220158\tAcc: 75.00\n",
      "train epoch: 111 [128128/221852 (58%)]\tLoss: 0.192216\tAcc: 77.00\n",
      "train epoch: 111 [140928/221852 (64%)]\tLoss: 0.184252\tAcc: 77.00\n",
      "train epoch: 111 [153728/221852 (69%)]\tLoss: 0.151904\tAcc: 79.00\n",
      "train epoch: 111 [166528/221852 (75%)]\tLoss: 0.203308\tAcc: 71.00\n",
      "train epoch: 111 [179328/221852 (81%)]\tLoss: 0.158050\tAcc: 79.00\n",
      "train epoch: 111 [192128/221852 (87%)]\tLoss: 0.199655\tAcc: 77.00\n",
      "val epoch: 111 [128/221852 (0%)]\tLoss: 0.180691\tAcc: 81.00\n",
      "val epoch: 111 [12928/221852 (6%)]\tLoss: 0.195219\tAcc: 84.00\n",
      "train epoch: 112 [128/221852 (0%)]\tLoss: 0.204961\tAcc: 77.00\n",
      "train epoch: 112 [12928/221852 (6%)]\tLoss: 0.170272\tAcc: 81.00\n",
      "train epoch: 112 [25728/221852 (12%)]\tLoss: 0.129212\tAcc: 84.00\n",
      "train epoch: 112 [38528/221852 (17%)]\tLoss: 0.288741\tAcc: 76.00\n",
      "train epoch: 112 [51328/221852 (23%)]\tLoss: 0.181401\tAcc: 84.00\n",
      "train epoch: 112 [64128/221852 (29%)]\tLoss: 0.141001\tAcc: 82.00\n",
      "train epoch: 112 [76928/221852 (35%)]\tLoss: 0.121363\tAcc: 85.00\n",
      "train epoch: 112 [89728/221852 (40%)]\tLoss: 0.188878\tAcc: 78.00\n",
      "train epoch: 112 [102528/221852 (46%)]\tLoss: 0.097817\tAcc: 77.00\n",
      "train epoch: 112 [115328/221852 (52%)]\tLoss: 0.184644\tAcc: 74.00\n",
      "train epoch: 112 [128128/221852 (58%)]\tLoss: 0.168451\tAcc: 76.00\n",
      "train epoch: 112 [140928/221852 (64%)]\tLoss: 0.201951\tAcc: 80.00\n",
      "train epoch: 112 [153728/221852 (69%)]\tLoss: 0.146323\tAcc: 76.00\n",
      "train epoch: 112 [166528/221852 (75%)]\tLoss: 0.196333\tAcc: 75.00\n",
      "train epoch: 112 [179328/221852 (81%)]\tLoss: 0.124628\tAcc: 80.00\n",
      "train epoch: 112 [192128/221852 (87%)]\tLoss: 0.164067\tAcc: 80.00\n",
      "val epoch: 112 [128/221852 (0%)]\tLoss: 0.237911\tAcc: 74.00\n",
      "val epoch: 112 [12928/221852 (6%)]\tLoss: 0.168187\tAcc: 78.00\n",
      "train epoch: 113 [128/221852 (0%)]\tLoss: 0.239959\tAcc: 75.00\n",
      "train epoch: 113 [12928/221852 (6%)]\tLoss: 0.175492\tAcc: 80.00\n",
      "train epoch: 113 [25728/221852 (12%)]\tLoss: 0.258909\tAcc: 79.00\n",
      "train epoch: 113 [38528/221852 (17%)]\tLoss: 0.210515\tAcc: 72.00\n",
      "train epoch: 113 [51328/221852 (23%)]\tLoss: 0.327339\tAcc: 73.00\n",
      "train epoch: 113 [64128/221852 (29%)]\tLoss: 0.139578\tAcc: 81.00\n",
      "train epoch: 113 [76928/221852 (35%)]\tLoss: 0.184466\tAcc: 79.00\n",
      "train epoch: 113 [89728/221852 (40%)]\tLoss: 0.135623\tAcc: 87.00\n",
      "train epoch: 113 [102528/221852 (46%)]\tLoss: 0.108118\tAcc: 83.00\n",
      "train epoch: 113 [115328/221852 (52%)]\tLoss: 0.186116\tAcc: 77.00\n",
      "train epoch: 113 [128128/221852 (58%)]\tLoss: 0.131069\tAcc: 80.00\n",
      "train epoch: 113 [140928/221852 (64%)]\tLoss: 0.173783\tAcc: 84.00\n",
      "train epoch: 113 [153728/221852 (69%)]\tLoss: 0.114163\tAcc: 81.00\n",
      "train epoch: 113 [166528/221852 (75%)]\tLoss: 0.144517\tAcc: 87.00\n",
      "train epoch: 113 [179328/221852 (81%)]\tLoss: 0.216372\tAcc: 78.00\n",
      "train epoch: 113 [192128/221852 (87%)]\tLoss: 0.200495\tAcc: 76.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 113 [128/221852 (0%)]\tLoss: 0.145154\tAcc: 87.00\n",
      "val epoch: 113 [12928/221852 (6%)]\tLoss: 0.168288\tAcc: 80.00\n",
      "train epoch: 114 [128/221852 (0%)]\tLoss: 0.169136\tAcc: 91.00\n",
      "train epoch: 114 [12928/221852 (6%)]\tLoss: 0.192824\tAcc: 81.00\n",
      "train epoch: 114 [25728/221852 (12%)]\tLoss: 0.298872\tAcc: 76.00\n",
      "train epoch: 114 [38528/221852 (17%)]\tLoss: 0.211609\tAcc: 75.00\n",
      "train epoch: 114 [51328/221852 (23%)]\tLoss: 0.182458\tAcc: 77.00\n",
      "train epoch: 114 [64128/221852 (29%)]\tLoss: 0.197070\tAcc: 83.00\n",
      "train epoch: 114 [76928/221852 (35%)]\tLoss: 0.186110\tAcc: 86.00\n",
      "train epoch: 114 [89728/221852 (40%)]\tLoss: 0.180672\tAcc: 77.00\n",
      "train epoch: 114 [102528/221852 (46%)]\tLoss: 0.280739\tAcc: 76.00\n",
      "train epoch: 114 [115328/221852 (52%)]\tLoss: 0.188817\tAcc: 78.00\n",
      "train epoch: 114 [128128/221852 (58%)]\tLoss: 0.195293\tAcc: 85.00\n",
      "train epoch: 114 [140928/221852 (64%)]\tLoss: 0.247547\tAcc: 70.00\n",
      "train epoch: 114 [153728/221852 (69%)]\tLoss: 0.204117\tAcc: 77.00\n",
      "train epoch: 114 [166528/221852 (75%)]\tLoss: 0.148270\tAcc: 73.00\n",
      "train epoch: 114 [179328/221852 (81%)]\tLoss: 0.162465\tAcc: 80.00\n",
      "train epoch: 114 [192128/221852 (87%)]\tLoss: 0.164090\tAcc: 82.00\n",
      "val epoch: 114 [128/221852 (0%)]\tLoss: 0.210538\tAcc: 79.00\n",
      "val epoch: 114 [12928/221852 (6%)]\tLoss: 0.210097\tAcc: 78.00\n",
      "train epoch: 115 [128/221852 (0%)]\tLoss: 0.103467\tAcc: 85.00\n",
      "train epoch: 115 [12928/221852 (6%)]\tLoss: 0.150520\tAcc: 77.00\n",
      "train epoch: 115 [25728/221852 (12%)]\tLoss: 0.113860\tAcc: 81.00\n",
      "train epoch: 115 [38528/221852 (17%)]\tLoss: 0.248505\tAcc: 78.00\n",
      "train epoch: 115 [51328/221852 (23%)]\tLoss: 0.142966\tAcc: 73.00\n",
      "train epoch: 115 [64128/221852 (29%)]\tLoss: 0.143739\tAcc: 77.00\n",
      "train epoch: 115 [76928/221852 (35%)]\tLoss: 0.210168\tAcc: 82.00\n",
      "train epoch: 115 [89728/221852 (40%)]\tLoss: 0.157086\tAcc: 85.00\n",
      "train epoch: 115 [102528/221852 (46%)]\tLoss: 0.122803\tAcc: 82.00\n",
      "train epoch: 115 [115328/221852 (52%)]\tLoss: 0.155136\tAcc: 82.00\n",
      "train epoch: 115 [128128/221852 (58%)]\tLoss: 0.231727\tAcc: 78.00\n",
      "train epoch: 115 [140928/221852 (64%)]\tLoss: 0.175773\tAcc: 74.00\n",
      "train epoch: 115 [153728/221852 (69%)]\tLoss: 0.260473\tAcc: 74.00\n",
      "train epoch: 115 [166528/221852 (75%)]\tLoss: 0.202937\tAcc: 77.00\n",
      "train epoch: 115 [179328/221852 (81%)]\tLoss: 0.251558\tAcc: 82.00\n",
      "train epoch: 115 [192128/221852 (87%)]\tLoss: 0.205332\tAcc: 78.00\n",
      "val epoch: 115 [128/221852 (0%)]\tLoss: 0.116770\tAcc: 80.00\n",
      "val epoch: 115 [12928/221852 (6%)]\tLoss: 0.181100\tAcc: 81.00\n",
      "train epoch: 116 [128/221852 (0%)]\tLoss: 0.180029\tAcc: 77.00\n",
      "train epoch: 116 [12928/221852 (6%)]\tLoss: 0.145396\tAcc: 85.00\n",
      "train epoch: 116 [25728/221852 (12%)]\tLoss: 0.209565\tAcc: 79.00\n",
      "train epoch: 116 [38528/221852 (17%)]\tLoss: 0.171566\tAcc: 83.00\n",
      "train epoch: 116 [51328/221852 (23%)]\tLoss: 0.153484\tAcc: 77.00\n",
      "train epoch: 116 [64128/221852 (29%)]\tLoss: 0.157636\tAcc: 77.00\n",
      "train epoch: 116 [76928/221852 (35%)]\tLoss: 0.181538\tAcc: 78.00\n",
      "train epoch: 116 [89728/221852 (40%)]\tLoss: 0.089867\tAcc: 84.00\n",
      "train epoch: 116 [102528/221852 (46%)]\tLoss: 0.199275\tAcc: 78.00\n",
      "train epoch: 116 [115328/221852 (52%)]\tLoss: 0.181617\tAcc: 74.00\n",
      "train epoch: 116 [128128/221852 (58%)]\tLoss: 0.202378\tAcc: 80.00\n",
      "train epoch: 116 [140928/221852 (64%)]\tLoss: 0.299262\tAcc: 73.00\n",
      "train epoch: 116 [153728/221852 (69%)]\tLoss: 0.200357\tAcc: 74.00\n",
      "train epoch: 116 [166528/221852 (75%)]\tLoss: 0.129217\tAcc: 80.00\n",
      "train epoch: 116 [179328/221852 (81%)]\tLoss: 0.213406\tAcc: 77.00\n",
      "train epoch: 116 [192128/221852 (87%)]\tLoss: 0.182155\tAcc: 85.00\n",
      "val epoch: 116 [128/221852 (0%)]\tLoss: 0.204774\tAcc: 82.00\n",
      "val epoch: 116 [12928/221852 (6%)]\tLoss: 0.217310\tAcc: 79.00\n",
      "train epoch: 117 [128/221852 (0%)]\tLoss: 0.103434\tAcc: 80.00\n",
      "train epoch: 117 [12928/221852 (6%)]\tLoss: 0.273043\tAcc: 77.00\n",
      "train epoch: 117 [25728/221852 (12%)]\tLoss: 0.252088\tAcc: 81.00\n",
      "train epoch: 117 [38528/221852 (17%)]\tLoss: 0.240611\tAcc: 72.00\n",
      "train epoch: 117 [51328/221852 (23%)]\tLoss: 0.172642\tAcc: 80.00\n",
      "train epoch: 117 [64128/221852 (29%)]\tLoss: 0.119121\tAcc: 84.00\n",
      "train epoch: 117 [76928/221852 (35%)]\tLoss: 0.383778\tAcc: 77.00\n",
      "train epoch: 117 [89728/221852 (40%)]\tLoss: 0.269445\tAcc: 76.00\n",
      "train epoch: 117 [102528/221852 (46%)]\tLoss: 0.198581\tAcc: 75.00\n",
      "train epoch: 117 [115328/221852 (52%)]\tLoss: 0.188268\tAcc: 79.00\n",
      "train epoch: 117 [128128/221852 (58%)]\tLoss: 0.162555\tAcc: 87.00\n",
      "train epoch: 117 [140928/221852 (64%)]\tLoss: 0.228335\tAcc: 82.00\n",
      "train epoch: 117 [153728/221852 (69%)]\tLoss: 0.209569\tAcc: 81.00\n",
      "train epoch: 117 [166528/221852 (75%)]\tLoss: 0.108897\tAcc: 87.00\n",
      "train epoch: 117 [179328/221852 (81%)]\tLoss: 0.200345\tAcc: 80.00\n",
      "train epoch: 117 [192128/221852 (87%)]\tLoss: 0.306973\tAcc: 68.00\n",
      "val epoch: 117 [128/221852 (0%)]\tLoss: 0.137462\tAcc: 88.00\n",
      "val epoch: 117 [12928/221852 (6%)]\tLoss: 0.205220\tAcc: 76.00\n",
      "train epoch: 118 [128/221852 (0%)]\tLoss: 0.127558\tAcc: 86.00\n",
      "train epoch: 118 [12928/221852 (6%)]\tLoss: 0.222901\tAcc: 75.00\n",
      "train epoch: 118 [25728/221852 (12%)]\tLoss: 0.160339\tAcc: 82.00\n",
      "train epoch: 118 [38528/221852 (17%)]\tLoss: 0.251055\tAcc: 80.00\n",
      "train epoch: 118 [51328/221852 (23%)]\tLoss: 0.128513\tAcc: 87.00\n",
      "train epoch: 118 [64128/221852 (29%)]\tLoss: 0.148616\tAcc: 84.00\n",
      "train epoch: 118 [76928/221852 (35%)]\tLoss: 0.579164\tAcc: 80.00\n",
      "train epoch: 118 [89728/221852 (40%)]\tLoss: 0.165792\tAcc: 75.00\n",
      "train epoch: 118 [102528/221852 (46%)]\tLoss: 0.206303\tAcc: 77.00\n",
      "train epoch: 118 [115328/221852 (52%)]\tLoss: 0.150244\tAcc: 80.00\n",
      "train epoch: 118 [128128/221852 (58%)]\tLoss: 0.198651\tAcc: 83.00\n",
      "train epoch: 118 [140928/221852 (64%)]\tLoss: 0.201421\tAcc: 77.00\n",
      "train epoch: 118 [153728/221852 (69%)]\tLoss: 0.142139\tAcc: 83.00\n",
      "train epoch: 118 [166528/221852 (75%)]\tLoss: 0.158891\tAcc: 81.00\n",
      "train epoch: 118 [179328/221852 (81%)]\tLoss: 0.141309\tAcc: 80.00\n",
      "train epoch: 118 [192128/221852 (87%)]\tLoss: 0.351922\tAcc: 77.00\n",
      "val epoch: 118 [128/221852 (0%)]\tLoss: 0.259252\tAcc: 71.00\n",
      "val epoch: 118 [12928/221852 (6%)]\tLoss: 0.168093\tAcc: 83.00\n",
      "train epoch: 119 [128/221852 (0%)]\tLoss: 0.227229\tAcc: 79.00\n",
      "train epoch: 119 [12928/221852 (6%)]\tLoss: 0.132982\tAcc: 88.00\n",
      "train epoch: 119 [25728/221852 (12%)]\tLoss: 0.176201\tAcc: 79.00\n",
      "train epoch: 119 [38528/221852 (17%)]\tLoss: 0.128118\tAcc: 84.00\n",
      "train epoch: 119 [51328/221852 (23%)]\tLoss: 0.173666\tAcc: 77.00\n",
      "train epoch: 119 [64128/221852 (29%)]\tLoss: 0.221475\tAcc: 75.00\n",
      "train epoch: 119 [76928/221852 (35%)]\tLoss: 0.176190\tAcc: 77.00\n",
      "train epoch: 119 [89728/221852 (40%)]\tLoss: 0.150035\tAcc: 84.00\n",
      "train epoch: 119 [102528/221852 (46%)]\tLoss: 0.205054\tAcc: 74.00\n",
      "train epoch: 119 [115328/221852 (52%)]\tLoss: 0.203817\tAcc: 74.00\n",
      "train epoch: 119 [128128/221852 (58%)]\tLoss: 0.157732\tAcc: 84.00\n",
      "train epoch: 119 [140928/221852 (64%)]\tLoss: 0.151772\tAcc: 78.00\n",
      "train epoch: 119 [153728/221852 (69%)]\tLoss: 0.130172\tAcc: 81.00\n",
      "train epoch: 119 [166528/221852 (75%)]\tLoss: 0.185178\tAcc: 81.00\n",
      "train epoch: 119 [179328/221852 (81%)]\tLoss: 0.113111\tAcc: 77.00\n",
      "train epoch: 119 [192128/221852 (87%)]\tLoss: 0.179581\tAcc: 84.00\n",
      "val epoch: 119 [128/221852 (0%)]\tLoss: 0.264902\tAcc: 75.00\n",
      "val epoch: 119 [12928/221852 (6%)]\tLoss: 0.163023\tAcc: 81.00\n",
      "train epoch: 120 [128/221852 (0%)]\tLoss: 0.188171\tAcc: 77.00\n",
      "train epoch: 120 [12928/221852 (6%)]\tLoss: 0.243570\tAcc: 75.00\n",
      "train epoch: 120 [25728/221852 (12%)]\tLoss: 0.218055\tAcc: 77.00\n",
      "train epoch: 120 [38528/221852 (17%)]\tLoss: 0.177744\tAcc: 84.00\n",
      "train epoch: 120 [51328/221852 (23%)]\tLoss: 0.178935\tAcc: 76.00\n",
      "train epoch: 120 [64128/221852 (29%)]\tLoss: 0.180751\tAcc: 81.00\n",
      "train epoch: 120 [76928/221852 (35%)]\tLoss: 0.196384\tAcc: 83.00\n",
      "train epoch: 120 [89728/221852 (40%)]\tLoss: 0.202599\tAcc: 77.00\n",
      "train epoch: 120 [102528/221852 (46%)]\tLoss: 0.145811\tAcc: 77.00\n",
      "train epoch: 120 [115328/221852 (52%)]\tLoss: 0.152142\tAcc: 81.00\n",
      "train epoch: 120 [128128/221852 (58%)]\tLoss: 0.173572\tAcc: 74.00\n",
      "train epoch: 120 [140928/221852 (64%)]\tLoss: 0.115261\tAcc: 85.00\n",
      "train epoch: 120 [153728/221852 (69%)]\tLoss: 0.131167\tAcc: 70.00\n",
      "train epoch: 120 [166528/221852 (75%)]\tLoss: 0.138737\tAcc: 86.00\n",
      "train epoch: 120 [179328/221852 (81%)]\tLoss: 0.275900\tAcc: 71.00\n",
      "train epoch: 120 [192128/221852 (87%)]\tLoss: 0.165899\tAcc: 77.00\n",
      "val epoch: 120 [128/221852 (0%)]\tLoss: 0.115180\tAcc: 81.00\n",
      "val epoch: 120 [12928/221852 (6%)]\tLoss: 0.188152\tAcc: 73.00\n",
      "train epoch: 121 [128/221852 (0%)]\tLoss: 0.227046\tAcc: 71.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 121 [12928/221852 (6%)]\tLoss: 0.183626\tAcc: 76.00\n",
      "train epoch: 121 [25728/221852 (12%)]\tLoss: 0.206857\tAcc: 79.00\n",
      "train epoch: 121 [38528/221852 (17%)]\tLoss: 0.112872\tAcc: 81.00\n",
      "train epoch: 121 [51328/221852 (23%)]\tLoss: 0.216248\tAcc: 80.00\n",
      "train epoch: 121 [64128/221852 (29%)]\tLoss: 0.239574\tAcc: 77.00\n",
      "train epoch: 121 [76928/221852 (35%)]\tLoss: 0.203891\tAcc: 79.00\n",
      "train epoch: 121 [89728/221852 (40%)]\tLoss: 0.215825\tAcc: 77.00\n",
      "train epoch: 121 [102528/221852 (46%)]\tLoss: 0.263671\tAcc: 67.00\n",
      "train epoch: 121 [115328/221852 (52%)]\tLoss: 0.183587\tAcc: 78.00\n",
      "train epoch: 121 [128128/221852 (58%)]\tLoss: 0.178219\tAcc: 76.00\n",
      "train epoch: 121 [140928/221852 (64%)]\tLoss: 0.205322\tAcc: 83.00\n",
      "train epoch: 121 [153728/221852 (69%)]\tLoss: 0.162153\tAcc: 82.00\n",
      "train epoch: 121 [166528/221852 (75%)]\tLoss: 0.172059\tAcc: 77.00\n",
      "train epoch: 121 [179328/221852 (81%)]\tLoss: 0.195699\tAcc: 75.00\n",
      "train epoch: 121 [192128/221852 (87%)]\tLoss: 0.138261\tAcc: 71.00\n",
      "val epoch: 121 [128/221852 (0%)]\tLoss: 0.180902\tAcc: 79.00\n",
      "val epoch: 121 [12928/221852 (6%)]\tLoss: 0.148264\tAcc: 80.00\n",
      "train epoch: 122 [128/221852 (0%)]\tLoss: 0.172372\tAcc: 83.00\n",
      "train epoch: 122 [12928/221852 (6%)]\tLoss: 0.212797\tAcc: 79.00\n",
      "train epoch: 122 [25728/221852 (12%)]\tLoss: 0.181530\tAcc: 78.00\n",
      "train epoch: 122 [38528/221852 (17%)]\tLoss: 0.107735\tAcc: 80.00\n",
      "train epoch: 122 [51328/221852 (23%)]\tLoss: 0.242898\tAcc: 80.00\n",
      "train epoch: 122 [64128/221852 (29%)]\tLoss: 0.260150\tAcc: 77.00\n",
      "train epoch: 122 [76928/221852 (35%)]\tLoss: 0.224827\tAcc: 70.00\n",
      "train epoch: 122 [89728/221852 (40%)]\tLoss: 0.153447\tAcc: 77.00\n",
      "train epoch: 122 [102528/221852 (46%)]\tLoss: 0.164080\tAcc: 82.00\n",
      "train epoch: 122 [115328/221852 (52%)]\tLoss: 0.206022\tAcc: 70.00\n",
      "train epoch: 122 [128128/221852 (58%)]\tLoss: 0.245131\tAcc: 81.00\n",
      "train epoch: 122 [140928/221852 (64%)]\tLoss: 0.234905\tAcc: 75.00\n",
      "train epoch: 122 [153728/221852 (69%)]\tLoss: 0.091649\tAcc: 84.00\n",
      "train epoch: 122 [166528/221852 (75%)]\tLoss: 0.221363\tAcc: 75.00\n",
      "train epoch: 122 [179328/221852 (81%)]\tLoss: 0.176047\tAcc: 80.00\n",
      "train epoch: 122 [192128/221852 (87%)]\tLoss: 0.169322\tAcc: 80.00\n",
      "val epoch: 122 [128/221852 (0%)]\tLoss: 0.158674\tAcc: 77.00\n",
      "val epoch: 122 [12928/221852 (6%)]\tLoss: 0.255194\tAcc: 74.00\n",
      "train epoch: 123 [128/221852 (0%)]\tLoss: 0.209364\tAcc: 82.00\n",
      "train epoch: 123 [12928/221852 (6%)]\tLoss: 0.224837\tAcc: 76.00\n",
      "train epoch: 123 [25728/221852 (12%)]\tLoss: 0.095858\tAcc: 84.00\n",
      "train epoch: 123 [38528/221852 (17%)]\tLoss: 0.230871\tAcc: 78.00\n",
      "train epoch: 123 [51328/221852 (23%)]\tLoss: 0.104721\tAcc: 84.00\n",
      "train epoch: 123 [64128/221852 (29%)]\tLoss: 0.112116\tAcc: 85.00\n",
      "train epoch: 123 [76928/221852 (35%)]\tLoss: 0.248245\tAcc: 81.00\n",
      "train epoch: 123 [89728/221852 (40%)]\tLoss: 0.217016\tAcc: 77.00\n",
      "train epoch: 123 [102528/221852 (46%)]\tLoss: 0.298239\tAcc: 77.00\n",
      "train epoch: 123 [115328/221852 (52%)]\tLoss: 0.091427\tAcc: 79.00\n",
      "train epoch: 123 [128128/221852 (58%)]\tLoss: 0.144270\tAcc: 80.00\n",
      "train epoch: 123 [140928/221852 (64%)]\tLoss: 0.274985\tAcc: 74.00\n",
      "train epoch: 123 [153728/221852 (69%)]\tLoss: 0.219451\tAcc: 77.00\n",
      "train epoch: 123 [166528/221852 (75%)]\tLoss: 0.176865\tAcc: 77.00\n",
      "train epoch: 123 [179328/221852 (81%)]\tLoss: 0.142999\tAcc: 80.00\n",
      "train epoch: 123 [192128/221852 (87%)]\tLoss: 0.158076\tAcc: 78.00\n",
      "val epoch: 123 [128/221852 (0%)]\tLoss: 0.232028\tAcc: 73.00\n",
      "val epoch: 123 [12928/221852 (6%)]\tLoss: 0.191967\tAcc: 76.00\n",
      "train epoch: 124 [128/221852 (0%)]\tLoss: 0.261332\tAcc: 80.00\n",
      "train epoch: 124 [12928/221852 (6%)]\tLoss: 0.232217\tAcc: 76.00\n",
      "train epoch: 124 [25728/221852 (12%)]\tLoss: 0.234705\tAcc: 76.00\n",
      "train epoch: 124 [38528/221852 (17%)]\tLoss: 0.160784\tAcc: 80.00\n",
      "train epoch: 124 [51328/221852 (23%)]\tLoss: 0.207902\tAcc: 80.00\n",
      "train epoch: 124 [64128/221852 (29%)]\tLoss: 0.135962\tAcc: 80.00\n",
      "train epoch: 124 [76928/221852 (35%)]\tLoss: 0.159905\tAcc: 74.00\n",
      "train epoch: 124 [89728/221852 (40%)]\tLoss: 0.210331\tAcc: 77.00\n",
      "train epoch: 124 [102528/221852 (46%)]\tLoss: 0.228916\tAcc: 77.00\n",
      "train epoch: 124 [115328/221852 (52%)]\tLoss: 0.238627\tAcc: 81.00\n",
      "train epoch: 124 [128128/221852 (58%)]\tLoss: 0.151230\tAcc: 77.00\n",
      "train epoch: 124 [140928/221852 (64%)]\tLoss: 0.122183\tAcc: 83.00\n",
      "train epoch: 124 [153728/221852 (69%)]\tLoss: 0.141653\tAcc: 77.00\n",
      "train epoch: 124 [166528/221852 (75%)]\tLoss: 0.119560\tAcc: 84.00\n",
      "train epoch: 124 [179328/221852 (81%)]\tLoss: 0.118256\tAcc: 84.00\n",
      "train epoch: 124 [192128/221852 (87%)]\tLoss: 0.151476\tAcc: 82.00\n",
      "val epoch: 124 [128/221852 (0%)]\tLoss: 0.182128\tAcc: 82.00\n",
      "val epoch: 124 [12928/221852 (6%)]\tLoss: 0.175017\tAcc: 77.00\n",
      "train epoch: 125 [128/221852 (0%)]\tLoss: 0.164385\tAcc: 82.00\n",
      "train epoch: 125 [12928/221852 (6%)]\tLoss: 0.283000\tAcc: 83.00\n",
      "train epoch: 125 [25728/221852 (12%)]\tLoss: 0.258625\tAcc: 83.00\n",
      "train epoch: 125 [38528/221852 (17%)]\tLoss: 0.150681\tAcc: 73.00\n",
      "train epoch: 125 [51328/221852 (23%)]\tLoss: 0.283614\tAcc: 79.00\n",
      "train epoch: 125 [64128/221852 (29%)]\tLoss: 0.194489\tAcc: 75.00\n",
      "train epoch: 125 [76928/221852 (35%)]\tLoss: 0.249162\tAcc: 80.00\n",
      "train epoch: 125 [89728/221852 (40%)]\tLoss: 0.159307\tAcc: 80.00\n",
      "train epoch: 125 [102528/221852 (46%)]\tLoss: 0.226698\tAcc: 76.00\n",
      "train epoch: 125 [115328/221852 (52%)]\tLoss: 0.175556\tAcc: 72.00\n",
      "train epoch: 125 [128128/221852 (58%)]\tLoss: 0.212056\tAcc: 79.00\n",
      "train epoch: 125 [140928/221852 (64%)]\tLoss: 0.219241\tAcc: 72.00\n",
      "train epoch: 125 [153728/221852 (69%)]\tLoss: 0.103136\tAcc: 85.00\n",
      "train epoch: 125 [166528/221852 (75%)]\tLoss: 0.165414\tAcc: 74.00\n",
      "train epoch: 125 [179328/221852 (81%)]\tLoss: 0.208082\tAcc: 77.00\n",
      "train epoch: 125 [192128/221852 (87%)]\tLoss: 0.132691\tAcc: 82.00\n",
      "val epoch: 125 [128/221852 (0%)]\tLoss: 0.199802\tAcc: 76.00\n",
      "val epoch: 125 [12928/221852 (6%)]\tLoss: 0.182475\tAcc: 75.00\n",
      "train epoch: 126 [128/221852 (0%)]\tLoss: 0.173872\tAcc: 80.00\n",
      "train epoch: 126 [12928/221852 (6%)]\tLoss: 0.155117\tAcc: 79.00\n",
      "train epoch: 126 [25728/221852 (12%)]\tLoss: 0.135511\tAcc: 82.00\n",
      "train epoch: 126 [38528/221852 (17%)]\tLoss: 0.213126\tAcc: 77.00\n",
      "train epoch: 126 [51328/221852 (23%)]\tLoss: 0.239534\tAcc: 73.00\n",
      "train epoch: 126 [64128/221852 (29%)]\tLoss: 0.216761\tAcc: 82.00\n",
      "train epoch: 126 [76928/221852 (35%)]\tLoss: 0.191833\tAcc: 84.00\n",
      "train epoch: 126 [89728/221852 (40%)]\tLoss: 0.223156\tAcc: 77.00\n",
      "train epoch: 126 [102528/221852 (46%)]\tLoss: 0.176555\tAcc: 82.00\n",
      "train epoch: 126 [115328/221852 (52%)]\tLoss: 0.220240\tAcc: 82.00\n",
      "train epoch: 126 [128128/221852 (58%)]\tLoss: 0.113880\tAcc: 82.00\n",
      "train epoch: 126 [140928/221852 (64%)]\tLoss: 0.154455\tAcc: 85.00\n",
      "train epoch: 126 [153728/221852 (69%)]\tLoss: 0.139476\tAcc: 82.00\n",
      "train epoch: 126 [166528/221852 (75%)]\tLoss: 0.130807\tAcc: 85.00\n",
      "train epoch: 126 [179328/221852 (81%)]\tLoss: 0.230548\tAcc: 79.00\n",
      "train epoch: 126 [192128/221852 (87%)]\tLoss: 0.191911\tAcc: 80.00\n",
      "val epoch: 126 [128/221852 (0%)]\tLoss: 0.395568\tAcc: 81.00\n",
      "val epoch: 126 [12928/221852 (6%)]\tLoss: 0.362245\tAcc: 82.00\n",
      "train epoch: 127 [128/221852 (0%)]\tLoss: 0.454774\tAcc: 78.00\n",
      "train epoch: 127 [12928/221852 (6%)]\tLoss: 0.259440\tAcc: 80.00\n",
      "train epoch: 127 [25728/221852 (12%)]\tLoss: 0.166043\tAcc: 88.00\n",
      "train epoch: 127 [38528/221852 (17%)]\tLoss: 0.227198\tAcc: 72.00\n",
      "train epoch: 127 [51328/221852 (23%)]\tLoss: 0.261887\tAcc: 72.00\n",
      "train epoch: 127 [64128/221852 (29%)]\tLoss: 0.242193\tAcc: 73.00\n",
      "train epoch: 127 [76928/221852 (35%)]\tLoss: 0.207529\tAcc: 82.00\n",
      "train epoch: 127 [89728/221852 (40%)]\tLoss: 0.163872\tAcc: 83.00\n",
      "train epoch: 127 [102528/221852 (46%)]\tLoss: 0.145671\tAcc: 80.00\n",
      "train epoch: 127 [115328/221852 (52%)]\tLoss: 0.141087\tAcc: 82.00\n",
      "train epoch: 127 [128128/221852 (58%)]\tLoss: 0.421464\tAcc: 74.00\n",
      "train epoch: 127 [140928/221852 (64%)]\tLoss: 0.182097\tAcc: 78.00\n",
      "train epoch: 127 [153728/221852 (69%)]\tLoss: 0.266542\tAcc: 80.00\n",
      "train epoch: 127 [166528/221852 (75%)]\tLoss: 0.168658\tAcc: 78.00\n",
      "train epoch: 127 [179328/221852 (81%)]\tLoss: 0.189430\tAcc: 76.00\n",
      "train epoch: 127 [192128/221852 (87%)]\tLoss: 0.155211\tAcc: 74.00\n",
      "val epoch: 127 [128/221852 (0%)]\tLoss: 0.159779\tAcc: 79.00\n",
      "val epoch: 127 [12928/221852 (6%)]\tLoss: 0.173349\tAcc: 80.00\n",
      "train epoch: 128 [128/221852 (0%)]\tLoss: 0.155316\tAcc: 81.00\n",
      "train epoch: 128 [12928/221852 (6%)]\tLoss: 0.177448\tAcc: 83.00\n",
      "train epoch: 128 [25728/221852 (12%)]\tLoss: 0.293510\tAcc: 80.00\n",
      "train epoch: 128 [38528/221852 (17%)]\tLoss: 0.197284\tAcc: 77.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 128 [51328/221852 (23%)]\tLoss: 0.162612\tAcc: 74.00\n",
      "train epoch: 128 [64128/221852 (29%)]\tLoss: 0.189459\tAcc: 80.00\n",
      "train epoch: 128 [76928/221852 (35%)]\tLoss: 0.111089\tAcc: 83.00\n",
      "train epoch: 128 [89728/221852 (40%)]\tLoss: 0.125906\tAcc: 73.00\n",
      "train epoch: 128 [102528/221852 (46%)]\tLoss: 0.137206\tAcc: 82.00\n",
      "train epoch: 128 [115328/221852 (52%)]\tLoss: 0.268199\tAcc: 73.00\n",
      "train epoch: 128 [128128/221852 (58%)]\tLoss: 0.197774\tAcc: 74.00\n",
      "train epoch: 128 [140928/221852 (64%)]\tLoss: 0.108350\tAcc: 86.00\n",
      "train epoch: 128 [153728/221852 (69%)]\tLoss: 0.176469\tAcc: 81.00\n",
      "train epoch: 128 [166528/221852 (75%)]\tLoss: 0.169858\tAcc: 81.00\n",
      "train epoch: 128 [179328/221852 (81%)]\tLoss: 0.242316\tAcc: 73.00\n",
      "train epoch: 128 [192128/221852 (87%)]\tLoss: 0.233121\tAcc: 86.00\n",
      "val epoch: 128 [128/221852 (0%)]\tLoss: 0.181805\tAcc: 76.00\n",
      "val epoch: 128 [12928/221852 (6%)]\tLoss: 0.104983\tAcc: 84.00\n",
      "train epoch: 129 [128/221852 (0%)]\tLoss: 0.157182\tAcc: 83.00\n",
      "train epoch: 129 [12928/221852 (6%)]\tLoss: 0.153870\tAcc: 73.00\n",
      "train epoch: 129 [25728/221852 (12%)]\tLoss: 0.301331\tAcc: 75.00\n",
      "train epoch: 129 [38528/221852 (17%)]\tLoss: 0.170117\tAcc: 79.00\n",
      "train epoch: 129 [51328/221852 (23%)]\tLoss: 0.156632\tAcc: 85.00\n",
      "train epoch: 129 [64128/221852 (29%)]\tLoss: 0.337745\tAcc: 80.00\n",
      "train epoch: 129 [76928/221852 (35%)]\tLoss: 0.164798\tAcc: 77.00\n",
      "train epoch: 129 [89728/221852 (40%)]\tLoss: 0.192093\tAcc: 80.00\n",
      "train epoch: 129 [102528/221852 (46%)]\tLoss: 0.146352\tAcc: 79.00\n",
      "train epoch: 129 [115328/221852 (52%)]\tLoss: 0.184190\tAcc: 78.00\n",
      "train epoch: 129 [128128/221852 (58%)]\tLoss: 0.159321\tAcc: 84.00\n",
      "train epoch: 129 [140928/221852 (64%)]\tLoss: 0.183832\tAcc: 85.00\n",
      "train epoch: 129 [153728/221852 (69%)]\tLoss: 0.160689\tAcc: 80.00\n",
      "train epoch: 129 [166528/221852 (75%)]\tLoss: 0.167550\tAcc: 75.00\n",
      "train epoch: 129 [179328/221852 (81%)]\tLoss: 0.113077\tAcc: 84.00\n",
      "train epoch: 129 [192128/221852 (87%)]\tLoss: 0.204671\tAcc: 81.00\n",
      "val epoch: 129 [128/221852 (0%)]\tLoss: 0.102408\tAcc: 82.00\n",
      "val epoch: 129 [12928/221852 (6%)]\tLoss: 0.201091\tAcc: 71.00\n",
      "train epoch: 130 [128/221852 (0%)]\tLoss: 0.166554\tAcc: 72.00\n",
      "train epoch: 130 [12928/221852 (6%)]\tLoss: 0.122713\tAcc: 82.00\n",
      "train epoch: 130 [25728/221852 (12%)]\tLoss: 0.140638\tAcc: 78.00\n",
      "train epoch: 130 [38528/221852 (17%)]\tLoss: 0.210133\tAcc: 80.00\n",
      "train epoch: 130 [51328/221852 (23%)]\tLoss: 0.206370\tAcc: 78.00\n",
      "train epoch: 130 [64128/221852 (29%)]\tLoss: 0.198874\tAcc: 80.00\n",
      "train epoch: 130 [76928/221852 (35%)]\tLoss: 0.151664\tAcc: 76.00\n",
      "train epoch: 130 [89728/221852 (40%)]\tLoss: 0.224139\tAcc: 80.00\n",
      "train epoch: 130 [102528/221852 (46%)]\tLoss: 0.185724\tAcc: 75.00\n",
      "train epoch: 130 [115328/221852 (52%)]\tLoss: 0.141413\tAcc: 88.00\n",
      "train epoch: 130 [128128/221852 (58%)]\tLoss: 0.212879\tAcc: 77.00\n",
      "train epoch: 130 [140928/221852 (64%)]\tLoss: 0.109433\tAcc: 81.00\n",
      "train epoch: 130 [153728/221852 (69%)]\tLoss: 0.223097\tAcc: 78.00\n",
      "train epoch: 130 [166528/221852 (75%)]\tLoss: 0.211286\tAcc: 81.00\n",
      "train epoch: 130 [179328/221852 (81%)]\tLoss: 0.187285\tAcc: 78.00\n",
      "train epoch: 130 [192128/221852 (87%)]\tLoss: 0.178151\tAcc: 84.00\n",
      "val epoch: 130 [128/221852 (0%)]\tLoss: 0.220088\tAcc: 80.00\n",
      "val epoch: 130 [12928/221852 (6%)]\tLoss: 0.198008\tAcc: 78.00\n",
      "train epoch: 131 [128/221852 (0%)]\tLoss: 0.219488\tAcc: 77.00\n",
      "train epoch: 131 [12928/221852 (6%)]\tLoss: 0.143433\tAcc: 84.00\n",
      "train epoch: 131 [25728/221852 (12%)]\tLoss: 0.143800\tAcc: 87.00\n",
      "train epoch: 131 [38528/221852 (17%)]\tLoss: 0.153392\tAcc: 84.00\n",
      "train epoch: 131 [51328/221852 (23%)]\tLoss: 0.201922\tAcc: 76.00\n",
      "train epoch: 131 [64128/221852 (29%)]\tLoss: 0.206358\tAcc: 77.00\n",
      "train epoch: 131 [76928/221852 (35%)]\tLoss: 0.266171\tAcc: 75.00\n",
      "train epoch: 131 [89728/221852 (40%)]\tLoss: 0.141815\tAcc: 86.00\n",
      "train epoch: 131 [102528/221852 (46%)]\tLoss: 0.141081\tAcc: 77.00\n",
      "train epoch: 131 [115328/221852 (52%)]\tLoss: 0.174277\tAcc: 75.00\n",
      "train epoch: 131 [128128/221852 (58%)]\tLoss: 0.226588\tAcc: 73.00\n",
      "train epoch: 131 [140928/221852 (64%)]\tLoss: 0.114112\tAcc: 84.00\n",
      "train epoch: 131 [153728/221852 (69%)]\tLoss: 0.198277\tAcc: 79.00\n",
      "train epoch: 131 [166528/221852 (75%)]\tLoss: 0.189275\tAcc: 80.00\n",
      "train epoch: 131 [179328/221852 (81%)]\tLoss: 0.188823\tAcc: 78.00\n",
      "train epoch: 131 [192128/221852 (87%)]\tLoss: 0.164182\tAcc: 79.00\n",
      "val epoch: 131 [128/221852 (0%)]\tLoss: 0.226312\tAcc: 80.00\n",
      "val epoch: 131 [12928/221852 (6%)]\tLoss: 0.254510\tAcc: 78.00\n",
      "train epoch: 132 [128/221852 (0%)]\tLoss: 0.209762\tAcc: 78.00\n",
      "train epoch: 132 [12928/221852 (6%)]\tLoss: 0.165751\tAcc: 79.00\n",
      "train epoch: 132 [25728/221852 (12%)]\tLoss: 0.132710\tAcc: 80.00\n",
      "train epoch: 132 [38528/221852 (17%)]\tLoss: 0.169861\tAcc: 83.00\n",
      "train epoch: 132 [51328/221852 (23%)]\tLoss: 0.262756\tAcc: 78.00\n",
      "train epoch: 132 [64128/221852 (29%)]\tLoss: 0.150472\tAcc: 80.00\n",
      "train epoch: 132 [76928/221852 (35%)]\tLoss: 0.241103\tAcc: 74.00\n",
      "train epoch: 132 [89728/221852 (40%)]\tLoss: 0.182354\tAcc: 73.00\n",
      "train epoch: 132 [102528/221852 (46%)]\tLoss: 0.190487\tAcc: 72.00\n",
      "train epoch: 132 [115328/221852 (52%)]\tLoss: 0.156865\tAcc: 79.00\n",
      "train epoch: 132 [128128/221852 (58%)]\tLoss: 0.140723\tAcc: 80.00\n",
      "train epoch: 132 [140928/221852 (64%)]\tLoss: 0.210850\tAcc: 80.00\n",
      "train epoch: 132 [153728/221852 (69%)]\tLoss: 0.171532\tAcc: 80.00\n",
      "train epoch: 132 [166528/221852 (75%)]\tLoss: 0.130700\tAcc: 77.00\n",
      "train epoch: 132 [179328/221852 (81%)]\tLoss: 0.132146\tAcc: 78.00\n",
      "train epoch: 132 [192128/221852 (87%)]\tLoss: 0.131902\tAcc: 84.00\n",
      "val epoch: 132 [128/221852 (0%)]\tLoss: 0.215793\tAcc: 80.00\n",
      "val epoch: 132 [12928/221852 (6%)]\tLoss: 0.190947\tAcc: 80.00\n",
      "train epoch: 133 [128/221852 (0%)]\tLoss: 0.199692\tAcc: 84.00\n",
      "train epoch: 133 [12928/221852 (6%)]\tLoss: 0.246173\tAcc: 79.00\n",
      "train epoch: 133 [25728/221852 (12%)]\tLoss: 0.196294\tAcc: 80.00\n",
      "train epoch: 133 [38528/221852 (17%)]\tLoss: 0.168360\tAcc: 78.00\n",
      "train epoch: 133 [51328/221852 (23%)]\tLoss: 0.216619\tAcc: 77.00\n",
      "train epoch: 133 [64128/221852 (29%)]\tLoss: 0.149752\tAcc: 77.00\n",
      "train epoch: 133 [76928/221852 (35%)]\tLoss: 0.183165\tAcc: 86.00\n",
      "train epoch: 133 [89728/221852 (40%)]\tLoss: 0.171826\tAcc: 84.00\n",
      "train epoch: 133 [102528/221852 (46%)]\tLoss: 0.111473\tAcc: 85.00\n",
      "train epoch: 133 [115328/221852 (52%)]\tLoss: 0.238025\tAcc: 71.00\n",
      "train epoch: 133 [128128/221852 (58%)]\tLoss: 0.243438\tAcc: 80.00\n",
      "train epoch: 133 [140928/221852 (64%)]\tLoss: 0.209817\tAcc: 79.00\n",
      "train epoch: 133 [153728/221852 (69%)]\tLoss: 0.101953\tAcc: 80.00\n",
      "train epoch: 133 [166528/221852 (75%)]\tLoss: 0.183377\tAcc: 77.00\n",
      "train epoch: 133 [179328/221852 (81%)]\tLoss: 0.268971\tAcc: 76.00\n",
      "train epoch: 133 [192128/221852 (87%)]\tLoss: 0.195618\tAcc: 80.00\n",
      "val epoch: 133 [128/221852 (0%)]\tLoss: 0.302611\tAcc: 80.00\n",
      "val epoch: 133 [12928/221852 (6%)]\tLoss: 0.300508\tAcc: 79.00\n",
      "train epoch: 134 [128/221852 (0%)]\tLoss: 0.318938\tAcc: 80.00\n",
      "train epoch: 134 [12928/221852 (6%)]\tLoss: 0.180302\tAcc: 77.00\n",
      "train epoch: 134 [25728/221852 (12%)]\tLoss: 0.153979\tAcc: 84.00\n",
      "train epoch: 134 [38528/221852 (17%)]\tLoss: 0.181993\tAcc: 76.00\n",
      "train epoch: 134 [51328/221852 (23%)]\tLoss: 0.200553\tAcc: 83.00\n",
      "train epoch: 134 [64128/221852 (29%)]\tLoss: 0.132214\tAcc: 81.00\n",
      "train epoch: 134 [76928/221852 (35%)]\tLoss: 0.177005\tAcc: 83.00\n",
      "train epoch: 134 [89728/221852 (40%)]\tLoss: 0.195703\tAcc: 83.00\n",
      "train epoch: 134 [102528/221852 (46%)]\tLoss: 0.139805\tAcc: 87.00\n",
      "train epoch: 134 [115328/221852 (52%)]\tLoss: 0.200824\tAcc: 80.00\n",
      "train epoch: 134 [128128/221852 (58%)]\tLoss: 0.177133\tAcc: 85.00\n",
      "train epoch: 134 [140928/221852 (64%)]\tLoss: 0.184429\tAcc: 81.00\n",
      "train epoch: 134 [153728/221852 (69%)]\tLoss: 0.181082\tAcc: 84.00\n",
      "train epoch: 134 [166528/221852 (75%)]\tLoss: 0.177384\tAcc: 80.00\n",
      "train epoch: 134 [179328/221852 (81%)]\tLoss: 0.162898\tAcc: 85.00\n",
      "train epoch: 134 [192128/221852 (87%)]\tLoss: 0.198950\tAcc: 75.00\n",
      "val epoch: 134 [128/221852 (0%)]\tLoss: 0.184459\tAcc: 83.00\n",
      "val epoch: 134 [12928/221852 (6%)]\tLoss: 0.128278\tAcc: 82.00\n",
      "train epoch: 135 [128/221852 (0%)]\tLoss: 0.116240\tAcc: 85.00\n",
      "train epoch: 135 [12928/221852 (6%)]\tLoss: 0.128698\tAcc: 84.00\n",
      "train epoch: 135 [25728/221852 (12%)]\tLoss: 0.275425\tAcc: 79.00\n",
      "train epoch: 135 [38528/221852 (17%)]\tLoss: 0.128336\tAcc: 81.00\n",
      "train epoch: 135 [51328/221852 (23%)]\tLoss: 0.214858\tAcc: 76.00\n",
      "train epoch: 135 [64128/221852 (29%)]\tLoss: 0.226453\tAcc: 80.00\n",
      "train epoch: 135 [76928/221852 (35%)]\tLoss: 0.142472\tAcc: 82.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 135 [89728/221852 (40%)]\tLoss: 0.147123\tAcc: 82.00\n",
      "train epoch: 135 [102528/221852 (46%)]\tLoss: 0.178183\tAcc: 77.00\n",
      "train epoch: 135 [115328/221852 (52%)]\tLoss: 0.255798\tAcc: 82.00\n",
      "train epoch: 135 [128128/221852 (58%)]\tLoss: 0.271661\tAcc: 80.00\n",
      "train epoch: 135 [140928/221852 (64%)]\tLoss: 0.181986\tAcc: 80.00\n",
      "train epoch: 135 [153728/221852 (69%)]\tLoss: 0.164301\tAcc: 81.00\n",
      "train epoch: 135 [166528/221852 (75%)]\tLoss: 0.193465\tAcc: 82.00\n",
      "train epoch: 135 [179328/221852 (81%)]\tLoss: 0.111249\tAcc: 84.00\n",
      "train epoch: 135 [192128/221852 (87%)]\tLoss: 0.161507\tAcc: 82.00\n",
      "val epoch: 135 [128/221852 (0%)]\tLoss: 0.208441\tAcc: 77.00\n",
      "val epoch: 135 [12928/221852 (6%)]\tLoss: 0.099584\tAcc: 85.00\n",
      "train epoch: 136 [128/221852 (0%)]\tLoss: 0.175473\tAcc: 86.00\n",
      "train epoch: 136 [12928/221852 (6%)]\tLoss: 0.130718\tAcc: 80.00\n",
      "train epoch: 136 [25728/221852 (12%)]\tLoss: 0.211210\tAcc: 86.00\n",
      "train epoch: 136 [38528/221852 (17%)]\tLoss: 0.179126\tAcc: 74.00\n",
      "train epoch: 136 [51328/221852 (23%)]\tLoss: 0.136200\tAcc: 83.00\n",
      "train epoch: 136 [64128/221852 (29%)]\tLoss: 0.175519\tAcc: 82.00\n",
      "train epoch: 136 [76928/221852 (35%)]\tLoss: 0.160092\tAcc: 84.00\n",
      "train epoch: 136 [89728/221852 (40%)]\tLoss: 0.173204\tAcc: 80.00\n",
      "train epoch: 136 [102528/221852 (46%)]\tLoss: 0.167626\tAcc: 84.00\n",
      "train epoch: 136 [115328/221852 (52%)]\tLoss: 0.146923\tAcc: 87.00\n",
      "train epoch: 136 [128128/221852 (58%)]\tLoss: 0.200824\tAcc: 76.00\n",
      "train epoch: 136 [140928/221852 (64%)]\tLoss: 0.182514\tAcc: 82.00\n",
      "train epoch: 136 [153728/221852 (69%)]\tLoss: 0.742107\tAcc: 76.00\n",
      "train epoch: 136 [166528/221852 (75%)]\tLoss: 0.209914\tAcc: 71.00\n",
      "train epoch: 136 [179328/221852 (81%)]\tLoss: 0.152163\tAcc: 81.00\n",
      "train epoch: 136 [192128/221852 (87%)]\tLoss: 0.195476\tAcc: 79.00\n",
      "val epoch: 136 [128/221852 (0%)]\tLoss: 0.243206\tAcc: 80.00\n",
      "val epoch: 136 [12928/221852 (6%)]\tLoss: 0.145153\tAcc: 78.00\n",
      "train epoch: 137 [128/221852 (0%)]\tLoss: 0.144988\tAcc: 79.00\n",
      "train epoch: 137 [12928/221852 (6%)]\tLoss: 0.178125\tAcc: 81.00\n",
      "train epoch: 137 [25728/221852 (12%)]\tLoss: 0.184255\tAcc: 75.00\n",
      "train epoch: 137 [38528/221852 (17%)]\tLoss: 0.285145\tAcc: 80.00\n",
      "train epoch: 137 [51328/221852 (23%)]\tLoss: 0.228152\tAcc: 79.00\n",
      "train epoch: 137 [64128/221852 (29%)]\tLoss: 0.190190\tAcc: 76.00\n",
      "train epoch: 137 [76928/221852 (35%)]\tLoss: 0.109372\tAcc: 72.00\n",
      "train epoch: 137 [89728/221852 (40%)]\tLoss: 0.214710\tAcc: 78.00\n",
      "train epoch: 137 [102528/221852 (46%)]\tLoss: 0.145367\tAcc: 83.00\n",
      "train epoch: 137 [115328/221852 (52%)]\tLoss: 0.233809\tAcc: 78.00\n",
      "train epoch: 137 [128128/221852 (58%)]\tLoss: 0.172287\tAcc: 76.00\n",
      "train epoch: 137 [140928/221852 (64%)]\tLoss: 0.182339\tAcc: 84.00\n",
      "train epoch: 137 [153728/221852 (69%)]\tLoss: 0.209349\tAcc: 77.00\n",
      "train epoch: 137 [166528/221852 (75%)]\tLoss: 0.222210\tAcc: 80.00\n",
      "train epoch: 137 [179328/221852 (81%)]\tLoss: 0.246312\tAcc: 77.00\n",
      "train epoch: 137 [192128/221852 (87%)]\tLoss: 0.191191\tAcc: 77.00\n",
      "val epoch: 137 [128/221852 (0%)]\tLoss: 0.187400\tAcc: 84.00\n",
      "val epoch: 137 [12928/221852 (6%)]\tLoss: 0.099527\tAcc: 80.00\n",
      "train epoch: 138 [128/221852 (0%)]\tLoss: 0.240331\tAcc: 84.00\n",
      "train epoch: 138 [12928/221852 (6%)]\tLoss: 0.163712\tAcc: 78.00\n",
      "train epoch: 138 [25728/221852 (12%)]\tLoss: 0.183969\tAcc: 81.00\n",
      "train epoch: 138 [38528/221852 (17%)]\tLoss: 0.161671\tAcc: 74.00\n",
      "train epoch: 138 [51328/221852 (23%)]\tLoss: 0.186827\tAcc: 82.00\n",
      "train epoch: 138 [64128/221852 (29%)]\tLoss: 0.207545\tAcc: 78.00\n",
      "train epoch: 138 [76928/221852 (35%)]\tLoss: 0.181188\tAcc: 82.00\n",
      "train epoch: 138 [89728/221852 (40%)]\tLoss: 0.184642\tAcc: 79.00\n",
      "train epoch: 138 [102528/221852 (46%)]\tLoss: 0.197801\tAcc: 77.00\n",
      "train epoch: 138 [115328/221852 (52%)]\tLoss: 0.105664\tAcc: 85.00\n",
      "train epoch: 138 [128128/221852 (58%)]\tLoss: 0.164706\tAcc: 80.00\n",
      "train epoch: 138 [140928/221852 (64%)]\tLoss: 0.171807\tAcc: 74.00\n",
      "train epoch: 138 [153728/221852 (69%)]\tLoss: 0.224093\tAcc: 77.00\n",
      "train epoch: 138 [166528/221852 (75%)]\tLoss: 0.079485\tAcc: 86.00\n",
      "train epoch: 138 [179328/221852 (81%)]\tLoss: 0.203170\tAcc: 84.00\n",
      "train epoch: 138 [192128/221852 (87%)]\tLoss: 0.192154\tAcc: 79.00\n",
      "val epoch: 138 [128/221852 (0%)]\tLoss: 0.101341\tAcc: 81.00\n",
      "val epoch: 138 [12928/221852 (6%)]\tLoss: 0.144347\tAcc: 80.00\n",
      "train epoch: 139 [128/221852 (0%)]\tLoss: 0.184416\tAcc: 81.00\n",
      "train epoch: 139 [12928/221852 (6%)]\tLoss: 0.229016\tAcc: 75.00\n",
      "train epoch: 139 [25728/221852 (12%)]\tLoss: 0.163234\tAcc: 84.00\n",
      "train epoch: 139 [38528/221852 (17%)]\tLoss: 0.212164\tAcc: 84.00\n",
      "train epoch: 139 [51328/221852 (23%)]\tLoss: 0.204012\tAcc: 86.00\n",
      "train epoch: 139 [64128/221852 (29%)]\tLoss: 0.234794\tAcc: 80.00\n",
      "train epoch: 139 [76928/221852 (35%)]\tLoss: 0.201711\tAcc: 81.00\n",
      "train epoch: 139 [89728/221852 (40%)]\tLoss: 0.222404\tAcc: 76.00\n",
      "train epoch: 139 [102528/221852 (46%)]\tLoss: 0.250282\tAcc: 80.00\n",
      "train epoch: 139 [115328/221852 (52%)]\tLoss: 0.233310\tAcc: 79.00\n",
      "train epoch: 139 [128128/221852 (58%)]\tLoss: 0.131409\tAcc: 80.00\n",
      "train epoch: 139 [140928/221852 (64%)]\tLoss: 0.203433\tAcc: 84.00\n",
      "train epoch: 139 [153728/221852 (69%)]\tLoss: 0.256135\tAcc: 80.00\n",
      "train epoch: 139 [166528/221852 (75%)]\tLoss: 0.237495\tAcc: 80.00\n",
      "train epoch: 139 [179328/221852 (81%)]\tLoss: 0.159570\tAcc: 83.00\n",
      "train epoch: 139 [192128/221852 (87%)]\tLoss: 0.150161\tAcc: 85.00\n",
      "val epoch: 139 [128/221852 (0%)]\tLoss: 0.225691\tAcc: 82.00\n",
      "val epoch: 139 [12928/221852 (6%)]\tLoss: 0.148798\tAcc: 77.00\n",
      "train epoch: 140 [128/221852 (0%)]\tLoss: 0.204598\tAcc: 84.00\n",
      "train epoch: 140 [12928/221852 (6%)]\tLoss: 0.164797\tAcc: 84.00\n",
      "train epoch: 140 [25728/221852 (12%)]\tLoss: 0.159676\tAcc: 80.00\n",
      "train epoch: 140 [38528/221852 (17%)]\tLoss: 0.235912\tAcc: 77.00\n",
      "train epoch: 140 [51328/221852 (23%)]\tLoss: 0.146967\tAcc: 80.00\n",
      "train epoch: 140 [64128/221852 (29%)]\tLoss: 0.209151\tAcc: 80.00\n",
      "train epoch: 140 [76928/221852 (35%)]\tLoss: 0.157591\tAcc: 80.00\n",
      "train epoch: 140 [89728/221852 (40%)]\tLoss: 0.149330\tAcc: 82.00\n",
      "train epoch: 140 [102528/221852 (46%)]\tLoss: 0.150590\tAcc: 81.00\n",
      "train epoch: 140 [115328/221852 (52%)]\tLoss: 0.141143\tAcc: 81.00\n",
      "train epoch: 140 [128128/221852 (58%)]\tLoss: 0.187904\tAcc: 80.00\n",
      "train epoch: 140 [140928/221852 (64%)]\tLoss: 0.155645\tAcc: 82.00\n",
      "train epoch: 140 [153728/221852 (69%)]\tLoss: 0.186010\tAcc: 81.00\n",
      "train epoch: 140 [166528/221852 (75%)]\tLoss: 0.140538\tAcc: 89.00\n",
      "train epoch: 140 [179328/221852 (81%)]\tLoss: 0.246167\tAcc: 76.00\n",
      "train epoch: 140 [192128/221852 (87%)]\tLoss: 0.247274\tAcc: 80.00\n",
      "val epoch: 140 [128/221852 (0%)]\tLoss: 0.188248\tAcc: 77.00\n",
      "val epoch: 140 [12928/221852 (6%)]\tLoss: 0.280850\tAcc: 79.00\n",
      "train epoch: 141 [128/221852 (0%)]\tLoss: 0.188050\tAcc: 81.00\n",
      "train epoch: 141 [12928/221852 (6%)]\tLoss: 0.185781\tAcc: 82.00\n",
      "train epoch: 141 [25728/221852 (12%)]\tLoss: 0.190191\tAcc: 70.00\n",
      "train epoch: 141 [38528/221852 (17%)]\tLoss: 0.159937\tAcc: 81.00\n",
      "train epoch: 141 [51328/221852 (23%)]\tLoss: 0.145382\tAcc: 84.00\n",
      "train epoch: 141 [64128/221852 (29%)]\tLoss: 0.168175\tAcc: 84.00\n",
      "train epoch: 141 [76928/221852 (35%)]\tLoss: 0.173060\tAcc: 80.00\n",
      "train epoch: 141 [89728/221852 (40%)]\tLoss: 0.220831\tAcc: 78.00\n",
      "train epoch: 141 [102528/221852 (46%)]\tLoss: 0.172406\tAcc: 80.00\n",
      "train epoch: 141 [115328/221852 (52%)]\tLoss: 0.093980\tAcc: 85.00\n",
      "train epoch: 141 [128128/221852 (58%)]\tLoss: 0.165494\tAcc: 78.00\n",
      "train epoch: 141 [140928/221852 (64%)]\tLoss: 0.141975\tAcc: 81.00\n",
      "train epoch: 141 [153728/221852 (69%)]\tLoss: 0.222161\tAcc: 73.00\n",
      "train epoch: 141 [166528/221852 (75%)]\tLoss: 0.111448\tAcc: 84.00\n",
      "train epoch: 141 [179328/221852 (81%)]\tLoss: 0.102238\tAcc: 88.00\n",
      "train epoch: 141 [192128/221852 (87%)]\tLoss: 0.222908\tAcc: 78.00\n",
      "val epoch: 141 [128/221852 (0%)]\tLoss: 0.154707\tAcc: 77.00\n",
      "val epoch: 141 [12928/221852 (6%)]\tLoss: 0.209500\tAcc: 81.00\n",
      "train epoch: 142 [128/221852 (0%)]\tLoss: 0.145319\tAcc: 77.00\n",
      "train epoch: 142 [12928/221852 (6%)]\tLoss: 0.185685\tAcc: 77.00\n",
      "train epoch: 142 [25728/221852 (12%)]\tLoss: 0.177261\tAcc: 82.00\n",
      "train epoch: 142 [38528/221852 (17%)]\tLoss: 0.142097\tAcc: 79.00\n",
      "train epoch: 142 [51328/221852 (23%)]\tLoss: 0.286868\tAcc: 81.00\n",
      "train epoch: 142 [64128/221852 (29%)]\tLoss: 0.260628\tAcc: 75.00\n",
      "train epoch: 142 [76928/221852 (35%)]\tLoss: 0.109734\tAcc: 82.00\n",
      "train epoch: 142 [89728/221852 (40%)]\tLoss: 0.199350\tAcc: 80.00\n",
      "train epoch: 142 [102528/221852 (46%)]\tLoss: 0.193253\tAcc: 81.00\n",
      "train epoch: 142 [115328/221852 (52%)]\tLoss: 0.112760\tAcc: 82.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 142 [128128/221852 (58%)]\tLoss: 0.174444\tAcc: 83.00\n",
      "train epoch: 142 [140928/221852 (64%)]\tLoss: 0.216616\tAcc: 80.00\n",
      "train epoch: 142 [153728/221852 (69%)]\tLoss: 0.214580\tAcc: 75.00\n",
      "train epoch: 142 [166528/221852 (75%)]\tLoss: 0.166366\tAcc: 78.00\n",
      "train epoch: 142 [179328/221852 (81%)]\tLoss: 0.132573\tAcc: 72.00\n",
      "train epoch: 142 [192128/221852 (87%)]\tLoss: 0.268527\tAcc: 80.00\n",
      "val epoch: 142 [128/221852 (0%)]\tLoss: 0.298162\tAcc: 73.00\n",
      "val epoch: 142 [12928/221852 (6%)]\tLoss: 0.250624\tAcc: 74.00\n",
      "train epoch: 143 [128/221852 (0%)]\tLoss: 0.282010\tAcc: 86.00\n",
      "train epoch: 143 [12928/221852 (6%)]\tLoss: 0.186888\tAcc: 78.00\n",
      "train epoch: 143 [25728/221852 (12%)]\tLoss: 0.270352\tAcc: 89.00\n",
      "train epoch: 143 [38528/221852 (17%)]\tLoss: 0.242831\tAcc: 75.00\n",
      "train epoch: 143 [51328/221852 (23%)]\tLoss: 0.168984\tAcc: 79.00\n",
      "train epoch: 143 [64128/221852 (29%)]\tLoss: 0.179363\tAcc: 77.00\n",
      "train epoch: 143 [76928/221852 (35%)]\tLoss: 0.254364\tAcc: 78.00\n",
      "train epoch: 143 [89728/221852 (40%)]\tLoss: 0.169712\tAcc: 80.00\n",
      "train epoch: 143 [102528/221852 (46%)]\tLoss: 0.108380\tAcc: 85.00\n",
      "train epoch: 143 [115328/221852 (52%)]\tLoss: 0.234514\tAcc: 85.00\n",
      "train epoch: 143 [128128/221852 (58%)]\tLoss: 0.174121\tAcc: 79.00\n",
      "train epoch: 143 [140928/221852 (64%)]\tLoss: 0.147245\tAcc: 85.00\n",
      "train epoch: 143 [153728/221852 (69%)]\tLoss: 0.251943\tAcc: 77.00\n",
      "train epoch: 143 [166528/221852 (75%)]\tLoss: 0.240461\tAcc: 82.00\n",
      "train epoch: 143 [179328/221852 (81%)]\tLoss: 0.236364\tAcc: 69.00\n",
      "train epoch: 143 [192128/221852 (87%)]\tLoss: 0.153960\tAcc: 86.00\n",
      "val epoch: 143 [128/221852 (0%)]\tLoss: 0.122212\tAcc: 87.00\n",
      "val epoch: 143 [12928/221852 (6%)]\tLoss: 0.197231\tAcc: 75.00\n",
      "train epoch: 144 [128/221852 (0%)]\tLoss: 0.199959\tAcc: 84.00\n",
      "train epoch: 144 [12928/221852 (6%)]\tLoss: 0.082428\tAcc: 88.00\n",
      "train epoch: 144 [25728/221852 (12%)]\tLoss: 0.162621\tAcc: 80.00\n",
      "train epoch: 144 [38528/221852 (17%)]\tLoss: 0.208074\tAcc: 73.00\n",
      "train epoch: 144 [51328/221852 (23%)]\tLoss: 0.170997\tAcc: 80.00\n",
      "train epoch: 144 [64128/221852 (29%)]\tLoss: 0.192922\tAcc: 74.00\n",
      "train epoch: 144 [76928/221852 (35%)]\tLoss: 0.118652\tAcc: 85.00\n",
      "train epoch: 144 [89728/221852 (40%)]\tLoss: 0.197024\tAcc: 78.00\n",
      "train epoch: 144 [102528/221852 (46%)]\tLoss: 0.154629\tAcc: 80.00\n",
      "train epoch: 144 [115328/221852 (52%)]\tLoss: 0.235672\tAcc: 70.00\n",
      "train epoch: 144 [128128/221852 (58%)]\tLoss: 0.114525\tAcc: 79.00\n",
      "train epoch: 144 [140928/221852 (64%)]\tLoss: 0.116341\tAcc: 80.00\n",
      "train epoch: 144 [153728/221852 (69%)]\tLoss: 0.309985\tAcc: 75.00\n",
      "train epoch: 144 [166528/221852 (75%)]\tLoss: 0.171887\tAcc: 77.00\n",
      "train epoch: 144 [179328/221852 (81%)]\tLoss: 0.207287\tAcc: 76.00\n",
      "train epoch: 144 [192128/221852 (87%)]\tLoss: 0.140856\tAcc: 83.00\n",
      "val epoch: 144 [128/221852 (0%)]\tLoss: 0.186728\tAcc: 72.00\n",
      "val epoch: 144 [12928/221852 (6%)]\tLoss: 0.175975\tAcc: 79.00\n",
      "train epoch: 145 [128/221852 (0%)]\tLoss: 0.138685\tAcc: 84.00\n",
      "train epoch: 145 [12928/221852 (6%)]\tLoss: 0.221854\tAcc: 80.00\n",
      "train epoch: 145 [25728/221852 (12%)]\tLoss: 0.279094\tAcc: 75.00\n",
      "train epoch: 145 [38528/221852 (17%)]\tLoss: 0.186700\tAcc: 88.00\n",
      "train epoch: 145 [51328/221852 (23%)]\tLoss: 0.185057\tAcc: 74.00\n",
      "train epoch: 145 [64128/221852 (29%)]\tLoss: 0.227015\tAcc: 80.00\n",
      "train epoch: 145 [76928/221852 (35%)]\tLoss: 0.286809\tAcc: 78.00\n",
      "train epoch: 145 [89728/221852 (40%)]\tLoss: 0.122685\tAcc: 85.00\n",
      "train epoch: 145 [102528/221852 (46%)]\tLoss: 0.194923\tAcc: 83.00\n",
      "train epoch: 145 [115328/221852 (52%)]\tLoss: 0.179129\tAcc: 77.00\n",
      "train epoch: 145 [128128/221852 (58%)]\tLoss: 0.212809\tAcc: 81.00\n",
      "train epoch: 145 [140928/221852 (64%)]\tLoss: 0.265846\tAcc: 71.00\n",
      "train epoch: 145 [153728/221852 (69%)]\tLoss: 0.195120\tAcc: 80.00\n",
      "train epoch: 145 [166528/221852 (75%)]\tLoss: 0.187422\tAcc: 81.00\n",
      "train epoch: 145 [179328/221852 (81%)]\tLoss: 0.125191\tAcc: 77.00\n",
      "train epoch: 145 [192128/221852 (87%)]\tLoss: 0.189783\tAcc: 80.00\n",
      "val epoch: 145 [128/221852 (0%)]\tLoss: 0.222169\tAcc: 84.00\n",
      "val epoch: 145 [12928/221852 (6%)]\tLoss: 0.169121\tAcc: 80.00\n",
      "train epoch: 146 [128/221852 (0%)]\tLoss: 0.172416\tAcc: 78.00\n",
      "train epoch: 146 [12928/221852 (6%)]\tLoss: 0.171164\tAcc: 84.00\n",
      "train epoch: 146 [25728/221852 (12%)]\tLoss: 0.207072\tAcc: 79.00\n",
      "train epoch: 146 [38528/221852 (17%)]\tLoss: 0.244554\tAcc: 70.00\n",
      "train epoch: 146 [51328/221852 (23%)]\tLoss: 0.152278\tAcc: 80.00\n",
      "train epoch: 146 [64128/221852 (29%)]\tLoss: 0.160081\tAcc: 80.00\n",
      "train epoch: 146 [76928/221852 (35%)]\tLoss: 0.189287\tAcc: 78.00\n",
      "train epoch: 146 [89728/221852 (40%)]\tLoss: 0.185533\tAcc: 81.00\n",
      "train epoch: 146 [102528/221852 (46%)]\tLoss: 0.358570\tAcc: 76.00\n",
      "train epoch: 146 [115328/221852 (52%)]\tLoss: 0.209931\tAcc: 83.00\n",
      "train epoch: 146 [128128/221852 (58%)]\tLoss: 0.172927\tAcc: 78.00\n",
      "train epoch: 146 [140928/221852 (64%)]\tLoss: 0.125678\tAcc: 80.00\n",
      "train epoch: 146 [153728/221852 (69%)]\tLoss: 0.158503\tAcc: 77.00\n",
      "train epoch: 146 [166528/221852 (75%)]\tLoss: 0.157038\tAcc: 80.00\n",
      "train epoch: 146 [179328/221852 (81%)]\tLoss: 0.183854\tAcc: 83.00\n",
      "train epoch: 146 [192128/221852 (87%)]\tLoss: 0.130775\tAcc: 88.00\n",
      "val epoch: 146 [128/221852 (0%)]\tLoss: 0.200453\tAcc: 81.00\n",
      "val epoch: 146 [12928/221852 (6%)]\tLoss: 0.190353\tAcc: 77.00\n",
      "train epoch: 147 [128/221852 (0%)]\tLoss: 0.202592\tAcc: 80.00\n",
      "train epoch: 147 [12928/221852 (6%)]\tLoss: 0.174874\tAcc: 84.00\n",
      "train epoch: 147 [25728/221852 (12%)]\tLoss: 0.142843\tAcc: 88.00\n",
      "train epoch: 147 [38528/221852 (17%)]\tLoss: 0.232026\tAcc: 77.00\n",
      "train epoch: 147 [51328/221852 (23%)]\tLoss: 0.172142\tAcc: 75.00\n",
      "train epoch: 147 [64128/221852 (29%)]\tLoss: 0.208887\tAcc: 82.00\n",
      "train epoch: 147 [76928/221852 (35%)]\tLoss: 0.194128\tAcc: 79.00\n",
      "train epoch: 147 [89728/221852 (40%)]\tLoss: 0.159565\tAcc: 75.00\n",
      "train epoch: 147 [102528/221852 (46%)]\tLoss: 0.156230\tAcc: 81.00\n",
      "train epoch: 147 [115328/221852 (52%)]\tLoss: 0.185850\tAcc: 79.00\n",
      "train epoch: 147 [128128/221852 (58%)]\tLoss: 0.154091\tAcc: 74.00\n",
      "train epoch: 147 [140928/221852 (64%)]\tLoss: 0.168290\tAcc: 80.00\n",
      "train epoch: 147 [153728/221852 (69%)]\tLoss: 0.158758\tAcc: 79.00\n",
      "train epoch: 147 [166528/221852 (75%)]\tLoss: 0.163355\tAcc: 80.00\n",
      "train epoch: 147 [179328/221852 (81%)]\tLoss: 0.132982\tAcc: 79.00\n",
      "train epoch: 147 [192128/221852 (87%)]\tLoss: 0.243468\tAcc: 76.00\n",
      "val epoch: 147 [128/221852 (0%)]\tLoss: 0.184441\tAcc: 84.00\n",
      "val epoch: 147 [12928/221852 (6%)]\tLoss: 0.226028\tAcc: 77.00\n",
      "train epoch: 148 [128/221852 (0%)]\tLoss: 0.146074\tAcc: 82.00\n",
      "train epoch: 148 [12928/221852 (6%)]\tLoss: 0.163159\tAcc: 83.00\n",
      "train epoch: 148 [25728/221852 (12%)]\tLoss: 0.147522\tAcc: 80.00\n",
      "train epoch: 148 [38528/221852 (17%)]\tLoss: 0.213267\tAcc: 74.00\n",
      "train epoch: 148 [51328/221852 (23%)]\tLoss: 0.192958\tAcc: 75.00\n",
      "train epoch: 148 [64128/221852 (29%)]\tLoss: 0.276706\tAcc: 77.00\n",
      "train epoch: 148 [76928/221852 (35%)]\tLoss: 0.141105\tAcc: 85.00\n",
      "train epoch: 148 [89728/221852 (40%)]\tLoss: 0.135729\tAcc: 82.00\n",
      "train epoch: 148 [102528/221852 (46%)]\tLoss: 0.264555\tAcc: 80.00\n",
      "train epoch: 148 [115328/221852 (52%)]\tLoss: 0.229570\tAcc: 74.00\n",
      "train epoch: 148 [128128/221852 (58%)]\tLoss: 0.171011\tAcc: 80.00\n",
      "train epoch: 148 [140928/221852 (64%)]\tLoss: 0.256289\tAcc: 80.00\n",
      "train epoch: 148 [153728/221852 (69%)]\tLoss: 0.224146\tAcc: 77.00\n",
      "train epoch: 148 [166528/221852 (75%)]\tLoss: 0.166963\tAcc: 78.00\n",
      "train epoch: 148 [179328/221852 (81%)]\tLoss: 0.222696\tAcc: 72.00\n",
      "train epoch: 148 [192128/221852 (87%)]\tLoss: 0.249035\tAcc: 77.00\n",
      "val epoch: 148 [128/221852 (0%)]\tLoss: 0.220625\tAcc: 78.00\n",
      "val epoch: 148 [12928/221852 (6%)]\tLoss: 0.173445\tAcc: 80.00\n",
      "train epoch: 149 [128/221852 (0%)]\tLoss: 0.131529\tAcc: 87.00\n",
      "train epoch: 149 [12928/221852 (6%)]\tLoss: 0.296042\tAcc: 72.00\n",
      "train epoch: 149 [25728/221852 (12%)]\tLoss: 0.162491\tAcc: 82.00\n",
      "train epoch: 149 [38528/221852 (17%)]\tLoss: 0.191744\tAcc: 76.00\n",
      "train epoch: 149 [51328/221852 (23%)]\tLoss: 0.230107\tAcc: 73.00\n",
      "train epoch: 149 [64128/221852 (29%)]\tLoss: 0.238458\tAcc: 82.00\n",
      "train epoch: 149 [76928/221852 (35%)]\tLoss: 0.260044\tAcc: 77.00\n",
      "train epoch: 149 [89728/221852 (40%)]\tLoss: 0.153024\tAcc: 81.00\n",
      "train epoch: 149 [102528/221852 (46%)]\tLoss: 0.266426\tAcc: 73.00\n",
      "train epoch: 149 [115328/221852 (52%)]\tLoss: 0.153984\tAcc: 80.00\n",
      "train epoch: 149 [128128/221852 (58%)]\tLoss: 0.131437\tAcc: 80.00\n",
      "train epoch: 149 [140928/221852 (64%)]\tLoss: 0.182182\tAcc: 84.00\n",
      "train epoch: 149 [153728/221852 (69%)]\tLoss: 0.098473\tAcc: 83.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 149 [166528/221852 (75%)]\tLoss: 0.150645\tAcc: 84.00\n",
      "train epoch: 149 [179328/221852 (81%)]\tLoss: 0.155471\tAcc: 78.00\n",
      "train epoch: 149 [192128/221852 (87%)]\tLoss: 0.184344\tAcc: 82.00\n",
      "val epoch: 149 [128/221852 (0%)]\tLoss: 0.143430\tAcc: 78.00\n",
      "val epoch: 149 [12928/221852 (6%)]\tLoss: 0.136579\tAcc: 83.00\n",
      "train epoch: 150 [128/221852 (0%)]\tLoss: 0.237091\tAcc: 77.00\n",
      "train epoch: 150 [12928/221852 (6%)]\tLoss: 0.172703\tAcc: 80.00\n",
      "train epoch: 150 [25728/221852 (12%)]\tLoss: 0.221002\tAcc: 78.00\n",
      "train epoch: 150 [38528/221852 (17%)]\tLoss: 0.131002\tAcc: 82.00\n",
      "train epoch: 150 [51328/221852 (23%)]\tLoss: 0.227594\tAcc: 76.00\n",
      "train epoch: 150 [64128/221852 (29%)]\tLoss: 0.141370\tAcc: 81.00\n",
      "train epoch: 150 [76928/221852 (35%)]\tLoss: 0.277453\tAcc: 79.00\n",
      "train epoch: 150 [89728/221852 (40%)]\tLoss: 0.241305\tAcc: 77.00\n",
      "train epoch: 150 [102528/221852 (46%)]\tLoss: 0.106564\tAcc: 77.00\n",
      "train epoch: 150 [115328/221852 (52%)]\tLoss: 0.194400\tAcc: 84.00\n",
      "train epoch: 150 [128128/221852 (58%)]\tLoss: 0.148692\tAcc: 77.00\n",
      "train epoch: 150 [140928/221852 (64%)]\tLoss: 0.172507\tAcc: 80.00\n",
      "train epoch: 150 [153728/221852 (69%)]\tLoss: 0.294731\tAcc: 77.00\n",
      "train epoch: 150 [166528/221852 (75%)]\tLoss: 0.259272\tAcc: 73.00\n",
      "train epoch: 150 [179328/221852 (81%)]\tLoss: 0.191303\tAcc: 77.00\n",
      "train epoch: 150 [192128/221852 (87%)]\tLoss: 0.129657\tAcc: 84.00\n",
      "val epoch: 150 [128/221852 (0%)]\tLoss: 0.149032\tAcc: 84.00\n",
      "val epoch: 150 [12928/221852 (6%)]\tLoss: 0.221126\tAcc: 79.00\n",
      "train epoch: 151 [128/221852 (0%)]\tLoss: 0.320303\tAcc: 69.00\n",
      "train epoch: 151 [12928/221852 (6%)]\tLoss: 0.139339\tAcc: 80.00\n",
      "train epoch: 151 [25728/221852 (12%)]\tLoss: 0.170955\tAcc: 79.00\n",
      "train epoch: 151 [38528/221852 (17%)]\tLoss: 0.170198\tAcc: 77.00\n",
      "train epoch: 151 [51328/221852 (23%)]\tLoss: 0.216615\tAcc: 83.00\n",
      "train epoch: 151 [64128/221852 (29%)]\tLoss: 0.157653\tAcc: 84.00\n",
      "train epoch: 151 [76928/221852 (35%)]\tLoss: 0.154134\tAcc: 84.00\n",
      "train epoch: 151 [89728/221852 (40%)]\tLoss: 0.156403\tAcc: 81.00\n",
      "train epoch: 151 [102528/221852 (46%)]\tLoss: 0.136946\tAcc: 81.00\n",
      "train epoch: 151 [115328/221852 (52%)]\tLoss: 0.178528\tAcc: 83.00\n",
      "train epoch: 151 [128128/221852 (58%)]\tLoss: 0.194418\tAcc: 86.00\n",
      "train epoch: 151 [140928/221852 (64%)]\tLoss: 0.205144\tAcc: 75.00\n",
      "train epoch: 151 [153728/221852 (69%)]\tLoss: 0.277558\tAcc: 78.00\n",
      "train epoch: 151 [166528/221852 (75%)]\tLoss: 0.136097\tAcc: 83.00\n",
      "train epoch: 151 [179328/221852 (81%)]\tLoss: 0.152403\tAcc: 82.00\n",
      "train epoch: 151 [192128/221852 (87%)]\tLoss: 0.142193\tAcc: 73.00\n",
      "val epoch: 151 [128/221852 (0%)]\tLoss: 0.187875\tAcc: 80.00\n",
      "val epoch: 151 [12928/221852 (6%)]\tLoss: 0.237920\tAcc: 77.00\n",
      "train epoch: 152 [128/221852 (0%)]\tLoss: 0.309268\tAcc: 75.00\n",
      "train epoch: 152 [12928/221852 (6%)]\tLoss: 0.102466\tAcc: 83.00\n",
      "train epoch: 152 [25728/221852 (12%)]\tLoss: 0.139265\tAcc: 83.00\n",
      "train epoch: 152 [38528/221852 (17%)]\tLoss: 0.148168\tAcc: 83.00\n",
      "train epoch: 152 [51328/221852 (23%)]\tLoss: 0.210398\tAcc: 74.00\n",
      "train epoch: 152 [64128/221852 (29%)]\tLoss: 0.216826\tAcc: 77.00\n",
      "train epoch: 152 [76928/221852 (35%)]\tLoss: 0.116725\tAcc: 80.00\n",
      "train epoch: 152 [89728/221852 (40%)]\tLoss: 0.154498\tAcc: 76.00\n",
      "train epoch: 152 [102528/221852 (46%)]\tLoss: 0.204603\tAcc: 78.00\n",
      "train epoch: 152 [115328/221852 (52%)]\tLoss: 0.184118\tAcc: 76.00\n",
      "train epoch: 152 [128128/221852 (58%)]\tLoss: 0.159612\tAcc: 81.00\n",
      "train epoch: 152 [140928/221852 (64%)]\tLoss: 0.526752\tAcc: 69.00\n",
      "train epoch: 152 [153728/221852 (69%)]\tLoss: 0.197452\tAcc: 68.00\n",
      "train epoch: 152 [166528/221852 (75%)]\tLoss: 0.209333\tAcc: 77.00\n",
      "train epoch: 152 [179328/221852 (81%)]\tLoss: 0.156128\tAcc: 82.00\n",
      "train epoch: 152 [192128/221852 (87%)]\tLoss: 0.225584\tAcc: 73.00\n",
      "val epoch: 152 [128/221852 (0%)]\tLoss: 0.187656\tAcc: 80.00\n",
      "val epoch: 152 [12928/221852 (6%)]\tLoss: 0.177236\tAcc: 75.00\n",
      "train epoch: 153 [128/221852 (0%)]\tLoss: 0.185344\tAcc: 84.00\n",
      "train epoch: 153 [12928/221852 (6%)]\tLoss: 0.256721\tAcc: 76.00\n",
      "train epoch: 153 [25728/221852 (12%)]\tLoss: 0.187999\tAcc: 78.00\n",
      "train epoch: 153 [38528/221852 (17%)]\tLoss: 0.228696\tAcc: 78.00\n",
      "train epoch: 153 [51328/221852 (23%)]\tLoss: 0.286942\tAcc: 77.00\n",
      "train epoch: 153 [64128/221852 (29%)]\tLoss: 0.224468\tAcc: 82.00\n",
      "train epoch: 153 [76928/221852 (35%)]\tLoss: 0.185538\tAcc: 83.00\n",
      "train epoch: 153 [89728/221852 (40%)]\tLoss: 0.184208\tAcc: 81.00\n",
      "train epoch: 153 [102528/221852 (46%)]\tLoss: 0.181988\tAcc: 73.00\n",
      "train epoch: 153 [115328/221852 (52%)]\tLoss: 0.175044\tAcc: 80.00\n",
      "train epoch: 153 [128128/221852 (58%)]\tLoss: 0.140098\tAcc: 78.00\n",
      "train epoch: 153 [140928/221852 (64%)]\tLoss: 0.216996\tAcc: 79.00\n",
      "train epoch: 153 [153728/221852 (69%)]\tLoss: 0.190129\tAcc: 82.00\n",
      "train epoch: 153 [166528/221852 (75%)]\tLoss: 0.193074\tAcc: 77.00\n",
      "train epoch: 153 [179328/221852 (81%)]\tLoss: 0.176364\tAcc: 82.00\n",
      "train epoch: 153 [192128/221852 (87%)]\tLoss: 0.186518\tAcc: 78.00\n",
      "val epoch: 153 [128/221852 (0%)]\tLoss: 0.154643\tAcc: 83.00\n",
      "val epoch: 153 [12928/221852 (6%)]\tLoss: 0.150305\tAcc: 82.00\n",
      "train epoch: 154 [128/221852 (0%)]\tLoss: 0.139642\tAcc: 88.00\n",
      "train epoch: 154 [12928/221852 (6%)]\tLoss: 0.145708\tAcc: 81.00\n",
      "train epoch: 154 [25728/221852 (12%)]\tLoss: 0.150401\tAcc: 80.00\n",
      "train epoch: 154 [38528/221852 (17%)]\tLoss: 0.139339\tAcc: 82.00\n",
      "train epoch: 154 [51328/221852 (23%)]\tLoss: 0.269300\tAcc: 78.00\n",
      "train epoch: 154 [64128/221852 (29%)]\tLoss: 0.178247\tAcc: 85.00\n",
      "train epoch: 154 [76928/221852 (35%)]\tLoss: 0.183364\tAcc: 82.00\n",
      "train epoch: 154 [89728/221852 (40%)]\tLoss: 0.108861\tAcc: 81.00\n",
      "train epoch: 154 [102528/221852 (46%)]\tLoss: 0.096933\tAcc: 84.00\n",
      "train epoch: 154 [115328/221852 (52%)]\tLoss: 0.133813\tAcc: 80.00\n",
      "train epoch: 154 [128128/221852 (58%)]\tLoss: 0.188958\tAcc: 78.00\n",
      "train epoch: 154 [140928/221852 (64%)]\tLoss: 0.214589\tAcc: 73.00\n",
      "train epoch: 154 [153728/221852 (69%)]\tLoss: 0.140045\tAcc: 75.00\n",
      "train epoch: 154 [166528/221852 (75%)]\tLoss: 0.182229\tAcc: 77.00\n",
      "train epoch: 154 [179328/221852 (81%)]\tLoss: 0.144061\tAcc: 85.00\n",
      "train epoch: 154 [192128/221852 (87%)]\tLoss: 0.131213\tAcc: 82.00\n",
      "val epoch: 154 [128/221852 (0%)]\tLoss: 0.144125\tAcc: 80.00\n",
      "val epoch: 154 [12928/221852 (6%)]\tLoss: 0.260294\tAcc: 75.00\n",
      "train epoch: 155 [128/221852 (0%)]\tLoss: 0.196086\tAcc: 86.00\n",
      "train epoch: 155 [12928/221852 (6%)]\tLoss: 0.141389\tAcc: 79.00\n",
      "train epoch: 155 [25728/221852 (12%)]\tLoss: 0.271110\tAcc: 70.00\n",
      "train epoch: 155 [38528/221852 (17%)]\tLoss: 0.174197\tAcc: 81.00\n",
      "train epoch: 155 [51328/221852 (23%)]\tLoss: 0.125747\tAcc: 84.00\n",
      "train epoch: 155 [64128/221852 (29%)]\tLoss: 0.256766\tAcc: 77.00\n",
      "train epoch: 155 [76928/221852 (35%)]\tLoss: 0.234065\tAcc: 75.00\n",
      "train epoch: 155 [89728/221852 (40%)]\tLoss: 0.148392\tAcc: 84.00\n",
      "train epoch: 155 [102528/221852 (46%)]\tLoss: 0.058773\tAcc: 86.00\n",
      "train epoch: 155 [115328/221852 (52%)]\tLoss: 0.288705\tAcc: 77.00\n",
      "train epoch: 155 [128128/221852 (58%)]\tLoss: 0.182948\tAcc: 75.00\n",
      "train epoch: 155 [140928/221852 (64%)]\tLoss: 0.134914\tAcc: 88.00\n",
      "train epoch: 155 [153728/221852 (69%)]\tLoss: 0.187812\tAcc: 77.00\n",
      "train epoch: 155 [166528/221852 (75%)]\tLoss: 0.230118\tAcc: 82.00\n",
      "train epoch: 155 [179328/221852 (81%)]\tLoss: 0.187929\tAcc: 82.00\n",
      "train epoch: 155 [192128/221852 (87%)]\tLoss: 0.184169\tAcc: 81.00\n",
      "val epoch: 155 [128/221852 (0%)]\tLoss: 0.250613\tAcc: 79.00\n",
      "val epoch: 155 [12928/221852 (6%)]\tLoss: 0.327308\tAcc: 74.00\n",
      "train epoch: 156 [128/221852 (0%)]\tLoss: 0.471200\tAcc: 75.00\n",
      "train epoch: 156 [12928/221852 (6%)]\tLoss: 0.194314\tAcc: 83.00\n",
      "train epoch: 156 [25728/221852 (12%)]\tLoss: 0.202493\tAcc: 76.00\n",
      "train epoch: 156 [38528/221852 (17%)]\tLoss: 0.105451\tAcc: 84.00\n",
      "train epoch: 156 [51328/221852 (23%)]\tLoss: 0.147789\tAcc: 86.00\n",
      "train epoch: 156 [64128/221852 (29%)]\tLoss: 0.216505\tAcc: 73.00\n",
      "train epoch: 156 [76928/221852 (35%)]\tLoss: 0.284631\tAcc: 77.00\n",
      "train epoch: 156 [89728/221852 (40%)]\tLoss: 0.261221\tAcc: 79.00\n",
      "train epoch: 156 [102528/221852 (46%)]\tLoss: 0.199724\tAcc: 78.00\n",
      "train epoch: 156 [115328/221852 (52%)]\tLoss: 0.227673\tAcc: 77.00\n",
      "train epoch: 156 [128128/221852 (58%)]\tLoss: 0.155915\tAcc: 83.00\n",
      "train epoch: 156 [140928/221852 (64%)]\tLoss: 0.131783\tAcc: 81.00\n",
      "train epoch: 156 [153728/221852 (69%)]\tLoss: 0.149937\tAcc: 79.00\n",
      "train epoch: 156 [166528/221852 (75%)]\tLoss: 0.218939\tAcc: 78.00\n",
      "train epoch: 156 [179328/221852 (81%)]\tLoss: 0.147620\tAcc: 84.00\n",
      "train epoch: 156 [192128/221852 (87%)]\tLoss: 0.197227\tAcc: 76.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 156 [128/221852 (0%)]\tLoss: 0.218551\tAcc: 79.00\n",
      "val epoch: 156 [12928/221852 (6%)]\tLoss: 0.207263\tAcc: 80.00\n",
      "train epoch: 157 [128/221852 (0%)]\tLoss: 0.221873\tAcc: 77.00\n",
      "train epoch: 157 [12928/221852 (6%)]\tLoss: 0.251443\tAcc: 73.00\n",
      "train epoch: 157 [25728/221852 (12%)]\tLoss: 0.317782\tAcc: 73.00\n",
      "train epoch: 157 [38528/221852 (17%)]\tLoss: 0.159533\tAcc: 80.00\n",
      "train epoch: 157 [51328/221852 (23%)]\tLoss: 0.151926\tAcc: 77.00\n",
      "train epoch: 157 [64128/221852 (29%)]\tLoss: 0.164690\tAcc: 84.00\n",
      "train epoch: 157 [76928/221852 (35%)]\tLoss: 0.081122\tAcc: 82.00\n",
      "train epoch: 157 [89728/221852 (40%)]\tLoss: 0.159912\tAcc: 79.00\n",
      "train epoch: 157 [102528/221852 (46%)]\tLoss: 0.260440\tAcc: 72.00\n",
      "train epoch: 157 [115328/221852 (52%)]\tLoss: 0.154110\tAcc: 85.00\n",
      "train epoch: 157 [128128/221852 (58%)]\tLoss: 0.148053\tAcc: 88.00\n",
      "train epoch: 157 [140928/221852 (64%)]\tLoss: 0.160609\tAcc: 76.00\n",
      "train epoch: 157 [153728/221852 (69%)]\tLoss: 0.182113\tAcc: 77.00\n",
      "train epoch: 157 [166528/221852 (75%)]\tLoss: 0.163516\tAcc: 80.00\n",
      "train epoch: 157 [179328/221852 (81%)]\tLoss: 0.192033\tAcc: 79.00\n",
      "train epoch: 157 [192128/221852 (87%)]\tLoss: 0.108670\tAcc: 84.00\n",
      "val epoch: 157 [128/221852 (0%)]\tLoss: 0.174911\tAcc: 86.00\n",
      "val epoch: 157 [12928/221852 (6%)]\tLoss: 0.126859\tAcc: 86.00\n",
      "train epoch: 158 [128/221852 (0%)]\tLoss: 0.180136\tAcc: 77.00\n",
      "train epoch: 158 [12928/221852 (6%)]\tLoss: 0.187397\tAcc: 81.00\n",
      "train epoch: 158 [25728/221852 (12%)]\tLoss: 0.123216\tAcc: 81.00\n",
      "train epoch: 158 [38528/221852 (17%)]\tLoss: 0.244746\tAcc: 80.00\n",
      "train epoch: 158 [51328/221852 (23%)]\tLoss: 0.239569\tAcc: 82.00\n",
      "train epoch: 158 [64128/221852 (29%)]\tLoss: 0.288457\tAcc: 86.00\n",
      "train epoch: 158 [76928/221852 (35%)]\tLoss: 0.114915\tAcc: 82.00\n",
      "train epoch: 158 [89728/221852 (40%)]\tLoss: 0.161030\tAcc: 85.00\n",
      "train epoch: 158 [102528/221852 (46%)]\tLoss: 0.172650\tAcc: 80.00\n",
      "train epoch: 158 [115328/221852 (52%)]\tLoss: 0.213869\tAcc: 81.00\n",
      "train epoch: 158 [128128/221852 (58%)]\tLoss: 0.163310\tAcc: 82.00\n",
      "train epoch: 158 [140928/221852 (64%)]\tLoss: 0.091631\tAcc: 79.00\n",
      "train epoch: 158 [153728/221852 (69%)]\tLoss: 0.296429\tAcc: 70.00\n",
      "train epoch: 158 [166528/221852 (75%)]\tLoss: 0.189046\tAcc: 76.00\n",
      "train epoch: 158 [179328/221852 (81%)]\tLoss: 0.102784\tAcc: 70.00\n",
      "train epoch: 158 [192128/221852 (87%)]\tLoss: 0.280566\tAcc: 77.00\n",
      "val epoch: 158 [128/221852 (0%)]\tLoss: 0.174640\tAcc: 82.00\n",
      "val epoch: 158 [12928/221852 (6%)]\tLoss: 0.194843\tAcc: 76.00\n",
      "train epoch: 159 [128/221852 (0%)]\tLoss: 0.194509\tAcc: 83.00\n",
      "train epoch: 159 [12928/221852 (6%)]\tLoss: 0.092099\tAcc: 80.00\n",
      "train epoch: 159 [25728/221852 (12%)]\tLoss: 0.136383\tAcc: 82.00\n",
      "train epoch: 159 [38528/221852 (17%)]\tLoss: 0.141083\tAcc: 76.00\n",
      "train epoch: 159 [51328/221852 (23%)]\tLoss: 0.141799\tAcc: 85.00\n",
      "train epoch: 159 [64128/221852 (29%)]\tLoss: 0.142250\tAcc: 80.00\n",
      "train epoch: 159 [76928/221852 (35%)]\tLoss: 0.185148\tAcc: 84.00\n",
      "train epoch: 159 [89728/221852 (40%)]\tLoss: 0.314837\tAcc: 77.00\n",
      "train epoch: 159 [102528/221852 (46%)]\tLoss: 0.128175\tAcc: 83.00\n",
      "train epoch: 159 [115328/221852 (52%)]\tLoss: 0.121244\tAcc: 83.00\n",
      "train epoch: 159 [128128/221852 (58%)]\tLoss: 0.167118\tAcc: 83.00\n",
      "train epoch: 159 [140928/221852 (64%)]\tLoss: 0.131695\tAcc: 86.00\n",
      "train epoch: 159 [153728/221852 (69%)]\tLoss: 0.228439\tAcc: 77.00\n",
      "train epoch: 159 [166528/221852 (75%)]\tLoss: 0.150023\tAcc: 75.00\n",
      "train epoch: 159 [179328/221852 (81%)]\tLoss: 0.261431\tAcc: 76.00\n",
      "train epoch: 159 [192128/221852 (87%)]\tLoss: 0.174843\tAcc: 84.00\n",
      "val epoch: 159 [128/221852 (0%)]\tLoss: 0.182104\tAcc: 84.00\n",
      "val epoch: 159 [12928/221852 (6%)]\tLoss: 0.113815\tAcc: 82.00\n",
      "train epoch: 160 [128/221852 (0%)]\tLoss: 0.129418\tAcc: 84.00\n",
      "train epoch: 160 [12928/221852 (6%)]\tLoss: 0.266737\tAcc: 73.00\n",
      "train epoch: 160 [25728/221852 (12%)]\tLoss: 0.167288\tAcc: 73.00\n",
      "train epoch: 160 [38528/221852 (17%)]\tLoss: 0.128431\tAcc: 80.00\n",
      "train epoch: 160 [51328/221852 (23%)]\tLoss: 0.106787\tAcc: 79.00\n",
      "train epoch: 160 [64128/221852 (29%)]\tLoss: 0.185338\tAcc: 82.00\n",
      "train epoch: 160 [76928/221852 (35%)]\tLoss: 0.132902\tAcc: 80.00\n",
      "train epoch: 160 [89728/221852 (40%)]\tLoss: 0.163478\tAcc: 80.00\n",
      "train epoch: 160 [102528/221852 (46%)]\tLoss: 0.134498\tAcc: 83.00\n",
      "train epoch: 160 [115328/221852 (52%)]\tLoss: 0.237847\tAcc: 76.00\n",
      "train epoch: 160 [128128/221852 (58%)]\tLoss: 0.156657\tAcc: 83.00\n",
      "train epoch: 160 [140928/221852 (64%)]\tLoss: 0.195075\tAcc: 81.00\n",
      "train epoch: 160 [153728/221852 (69%)]\tLoss: 0.124864\tAcc: 84.00\n",
      "train epoch: 160 [166528/221852 (75%)]\tLoss: 0.221580\tAcc: 73.00\n",
      "train epoch: 160 [179328/221852 (81%)]\tLoss: 0.158912\tAcc: 77.00\n",
      "train epoch: 160 [192128/221852 (87%)]\tLoss: 0.194842\tAcc: 75.00\n",
      "val epoch: 160 [128/221852 (0%)]\tLoss: 0.179229\tAcc: 82.00\n",
      "val epoch: 160 [12928/221852 (6%)]\tLoss: 0.220939\tAcc: 79.00\n",
      "train epoch: 161 [128/221852 (0%)]\tLoss: 0.133378\tAcc: 82.00\n",
      "train epoch: 161 [12928/221852 (6%)]\tLoss: 0.205610\tAcc: 74.00\n",
      "train epoch: 161 [25728/221852 (12%)]\tLoss: 0.206891\tAcc: 73.00\n",
      "train epoch: 161 [38528/221852 (17%)]\tLoss: 0.149265\tAcc: 80.00\n",
      "train epoch: 161 [51328/221852 (23%)]\tLoss: 0.153068\tAcc: 83.00\n",
      "train epoch: 161 [64128/221852 (29%)]\tLoss: 0.120326\tAcc: 78.00\n",
      "train epoch: 161 [76928/221852 (35%)]\tLoss: 0.164939\tAcc: 72.00\n",
      "train epoch: 161 [89728/221852 (40%)]\tLoss: 0.180283\tAcc: 82.00\n",
      "train epoch: 161 [102528/221852 (46%)]\tLoss: 0.125480\tAcc: 81.00\n",
      "train epoch: 161 [115328/221852 (52%)]\tLoss: 0.166077\tAcc: 82.00\n",
      "train epoch: 161 [128128/221852 (58%)]\tLoss: 0.179257\tAcc: 80.00\n",
      "train epoch: 161 [140928/221852 (64%)]\tLoss: 0.187509\tAcc: 78.00\n",
      "train epoch: 161 [153728/221852 (69%)]\tLoss: 0.142495\tAcc: 84.00\n",
      "train epoch: 161 [166528/221852 (75%)]\tLoss: 0.107222\tAcc: 80.00\n",
      "train epoch: 161 [179328/221852 (81%)]\tLoss: 1.198587\tAcc: 84.00\n",
      "train epoch: 161 [192128/221852 (87%)]\tLoss: 0.179788\tAcc: 77.00\n",
      "val epoch: 161 [128/221852 (0%)]\tLoss: 0.182878\tAcc: 75.00\n",
      "val epoch: 161 [12928/221852 (6%)]\tLoss: 0.151910\tAcc: 81.00\n",
      "train epoch: 162 [128/221852 (0%)]\tLoss: 0.170508\tAcc: 76.00\n",
      "train epoch: 162 [12928/221852 (6%)]\tLoss: 0.119805\tAcc: 78.00\n",
      "train epoch: 162 [25728/221852 (12%)]\tLoss: 0.176883\tAcc: 81.00\n",
      "train epoch: 162 [38528/221852 (17%)]\tLoss: 0.221149\tAcc: 81.00\n",
      "train epoch: 162 [51328/221852 (23%)]\tLoss: 0.201589\tAcc: 80.00\n",
      "train epoch: 162 [64128/221852 (29%)]\tLoss: 0.194733\tAcc: 80.00\n",
      "train epoch: 162 [76928/221852 (35%)]\tLoss: 0.141478\tAcc: 84.00\n",
      "train epoch: 162 [89728/221852 (40%)]\tLoss: 0.158509\tAcc: 80.00\n",
      "train epoch: 162 [102528/221852 (46%)]\tLoss: 0.224736\tAcc: 79.00\n",
      "train epoch: 162 [115328/221852 (52%)]\tLoss: 0.203580\tAcc: 76.00\n",
      "train epoch: 162 [128128/221852 (58%)]\tLoss: 0.183905\tAcc: 77.00\n",
      "train epoch: 162 [140928/221852 (64%)]\tLoss: 0.173317\tAcc: 80.00\n",
      "train epoch: 162 [153728/221852 (69%)]\tLoss: 0.231264\tAcc: 77.00\n",
      "train epoch: 162 [166528/221852 (75%)]\tLoss: 0.198700\tAcc: 79.00\n",
      "train epoch: 162 [179328/221852 (81%)]\tLoss: 0.190980\tAcc: 85.00\n",
      "train epoch: 162 [192128/221852 (87%)]\tLoss: 0.222321\tAcc: 79.00\n",
      "val epoch: 162 [128/221852 (0%)]\tLoss: 0.171857\tAcc: 84.00\n",
      "val epoch: 162 [12928/221852 (6%)]\tLoss: 0.247392\tAcc: 76.00\n",
      "train epoch: 163 [128/221852 (0%)]\tLoss: 0.203892\tAcc: 75.00\n",
      "train epoch: 163 [12928/221852 (6%)]\tLoss: 0.239974\tAcc: 81.00\n",
      "train epoch: 163 [25728/221852 (12%)]\tLoss: 0.166864\tAcc: 84.00\n",
      "train epoch: 163 [38528/221852 (17%)]\tLoss: 0.101732\tAcc: 83.00\n",
      "train epoch: 163 [51328/221852 (23%)]\tLoss: 0.143010\tAcc: 84.00\n",
      "train epoch: 163 [64128/221852 (29%)]\tLoss: 0.117991\tAcc: 77.00\n",
      "train epoch: 163 [76928/221852 (35%)]\tLoss: 0.108271\tAcc: 82.00\n",
      "train epoch: 163 [89728/221852 (40%)]\tLoss: 0.110477\tAcc: 86.00\n",
      "train epoch: 163 [102528/221852 (46%)]\tLoss: 0.123414\tAcc: 81.00\n",
      "train epoch: 163 [115328/221852 (52%)]\tLoss: 0.130499\tAcc: 82.00\n",
      "train epoch: 163 [128128/221852 (58%)]\tLoss: 0.214334\tAcc: 81.00\n",
      "train epoch: 163 [140928/221852 (64%)]\tLoss: 0.203780\tAcc: 80.00\n",
      "train epoch: 163 [153728/221852 (69%)]\tLoss: 0.162645\tAcc: 80.00\n",
      "train epoch: 163 [166528/221852 (75%)]\tLoss: 0.134464\tAcc: 79.00\n",
      "train epoch: 163 [179328/221852 (81%)]\tLoss: 0.219007\tAcc: 73.00\n",
      "train epoch: 163 [192128/221852 (87%)]\tLoss: 0.181883\tAcc: 82.00\n",
      "val epoch: 163 [128/221852 (0%)]\tLoss: 0.150732\tAcc: 78.00\n",
      "val epoch: 163 [12928/221852 (6%)]\tLoss: 0.172489\tAcc: 88.00\n",
      "train epoch: 164 [128/221852 (0%)]\tLoss: 0.129313\tAcc: 78.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 164 [12928/221852 (6%)]\tLoss: 0.141143\tAcc: 85.00\n",
      "train epoch: 164 [25728/221852 (12%)]\tLoss: 0.096010\tAcc: 83.00\n",
      "train epoch: 164 [38528/221852 (17%)]\tLoss: 0.179543\tAcc: 74.00\n",
      "train epoch: 164 [51328/221852 (23%)]\tLoss: 0.205978\tAcc: 75.00\n",
      "train epoch: 164 [64128/221852 (29%)]\tLoss: 0.144372\tAcc: 76.00\n",
      "train epoch: 164 [76928/221852 (35%)]\tLoss: 0.122733\tAcc: 81.00\n",
      "train epoch: 164 [89728/221852 (40%)]\tLoss: 0.207313\tAcc: 72.00\n",
      "train epoch: 164 [102528/221852 (46%)]\tLoss: 0.143076\tAcc: 80.00\n",
      "train epoch: 164 [115328/221852 (52%)]\tLoss: 0.254032\tAcc: 77.00\n",
      "train epoch: 164 [128128/221852 (58%)]\tLoss: 0.147363\tAcc: 88.00\n",
      "train epoch: 164 [140928/221852 (64%)]\tLoss: 0.214819\tAcc: 77.00\n",
      "train epoch: 164 [153728/221852 (69%)]\tLoss: 0.169388\tAcc: 81.00\n",
      "train epoch: 164 [166528/221852 (75%)]\tLoss: 0.157211\tAcc: 80.00\n",
      "train epoch: 164 [179328/221852 (81%)]\tLoss: 0.167753\tAcc: 82.00\n",
      "train epoch: 164 [192128/221852 (87%)]\tLoss: 0.193295\tAcc: 83.00\n",
      "val epoch: 164 [128/221852 (0%)]\tLoss: 0.202309\tAcc: 76.00\n",
      "val epoch: 164 [12928/221852 (6%)]\tLoss: 0.258793\tAcc: 71.00\n",
      "train epoch: 165 [128/221852 (0%)]\tLoss: 0.319353\tAcc: 77.00\n",
      "train epoch: 165 [12928/221852 (6%)]\tLoss: 0.226108\tAcc: 74.00\n",
      "train epoch: 165 [25728/221852 (12%)]\tLoss: 0.261494\tAcc: 80.00\n",
      "train epoch: 165 [38528/221852 (17%)]\tLoss: 0.203059\tAcc: 82.00\n",
      "train epoch: 165 [51328/221852 (23%)]\tLoss: 0.231171\tAcc: 78.00\n",
      "train epoch: 165 [64128/221852 (29%)]\tLoss: 0.119095\tAcc: 75.00\n",
      "train epoch: 165 [76928/221852 (35%)]\tLoss: 0.132810\tAcc: 79.00\n",
      "train epoch: 165 [89728/221852 (40%)]\tLoss: 0.112304\tAcc: 80.00\n",
      "train epoch: 165 [102528/221852 (46%)]\tLoss: 0.114278\tAcc: 77.00\n",
      "train epoch: 165 [115328/221852 (52%)]\tLoss: 0.264936\tAcc: 83.00\n",
      "train epoch: 165 [128128/221852 (58%)]\tLoss: 0.168241\tAcc: 77.00\n",
      "train epoch: 165 [140928/221852 (64%)]\tLoss: 0.263707\tAcc: 77.00\n",
      "train epoch: 165 [153728/221852 (69%)]\tLoss: 0.287617\tAcc: 74.00\n",
      "train epoch: 165 [166528/221852 (75%)]\tLoss: 0.150193\tAcc: 80.00\n",
      "train epoch: 165 [179328/221852 (81%)]\tLoss: 0.113770\tAcc: 84.00\n",
      "train epoch: 165 [192128/221852 (87%)]\tLoss: 0.201653\tAcc: 77.00\n",
      "val epoch: 165 [128/221852 (0%)]\tLoss: 0.254292\tAcc: 79.00\n",
      "val epoch: 165 [12928/221852 (6%)]\tLoss: 0.139367\tAcc: 77.00\n",
      "train epoch: 166 [128/221852 (0%)]\tLoss: 0.190909\tAcc: 84.00\n",
      "train epoch: 166 [12928/221852 (6%)]\tLoss: 0.100437\tAcc: 83.00\n",
      "train epoch: 166 [25728/221852 (12%)]\tLoss: 0.187768\tAcc: 75.00\n",
      "train epoch: 166 [38528/221852 (17%)]\tLoss: 0.119731\tAcc: 80.00\n",
      "train epoch: 166 [51328/221852 (23%)]\tLoss: 0.158280\tAcc: 80.00\n",
      "train epoch: 166 [64128/221852 (29%)]\tLoss: 0.168101\tAcc: 80.00\n",
      "train epoch: 166 [76928/221852 (35%)]\tLoss: 0.169292\tAcc: 76.00\n",
      "train epoch: 166 [89728/221852 (40%)]\tLoss: 0.183165\tAcc: 80.00\n",
      "train epoch: 166 [102528/221852 (46%)]\tLoss: 0.144084\tAcc: 80.00\n",
      "train epoch: 166 [115328/221852 (52%)]\tLoss: 0.275764\tAcc: 73.00\n",
      "train epoch: 166 [128128/221852 (58%)]\tLoss: 0.169730\tAcc: 83.00\n",
      "train epoch: 166 [140928/221852 (64%)]\tLoss: 0.237115\tAcc: 79.00\n",
      "train epoch: 166 [153728/221852 (69%)]\tLoss: 0.171181\tAcc: 76.00\n",
      "train epoch: 166 [166528/221852 (75%)]\tLoss: 0.181973\tAcc: 77.00\n",
      "train epoch: 166 [179328/221852 (81%)]\tLoss: 0.142553\tAcc: 83.00\n",
      "train epoch: 166 [192128/221852 (87%)]\tLoss: 0.136104\tAcc: 80.00\n",
      "val epoch: 166 [128/221852 (0%)]\tLoss: 0.235592\tAcc: 76.00\n",
      "val epoch: 166 [12928/221852 (6%)]\tLoss: 0.163504\tAcc: 85.00\n",
      "train epoch: 167 [128/221852 (0%)]\tLoss: 0.116543\tAcc: 84.00\n",
      "train epoch: 167 [12928/221852 (6%)]\tLoss: 0.297344\tAcc: 79.00\n",
      "train epoch: 167 [25728/221852 (12%)]\tLoss: 0.352215\tAcc: 73.00\n",
      "train epoch: 167 [38528/221852 (17%)]\tLoss: 0.109886\tAcc: 77.00\n",
      "train epoch: 167 [51328/221852 (23%)]\tLoss: 0.274308\tAcc: 77.00\n",
      "train epoch: 167 [64128/221852 (29%)]\tLoss: 0.171030\tAcc: 77.00\n",
      "train epoch: 167 [76928/221852 (35%)]\tLoss: 0.147476\tAcc: 81.00\n",
      "train epoch: 167 [89728/221852 (40%)]\tLoss: 0.253390\tAcc: 77.00\n",
      "train epoch: 167 [102528/221852 (46%)]\tLoss: 0.215957\tAcc: 82.00\n",
      "train epoch: 167 [115328/221852 (52%)]\tLoss: 0.185632\tAcc: 78.00\n",
      "train epoch: 167 [128128/221852 (58%)]\tLoss: 0.113388\tAcc: 84.00\n",
      "train epoch: 167 [140928/221852 (64%)]\tLoss: 0.167887\tAcc: 80.00\n",
      "train epoch: 167 [153728/221852 (69%)]\tLoss: 0.132162\tAcc: 80.00\n",
      "train epoch: 167 [166528/221852 (75%)]\tLoss: 0.124070\tAcc: 86.00\n",
      "train epoch: 167 [179328/221852 (81%)]\tLoss: 0.091583\tAcc: 82.00\n",
      "train epoch: 167 [192128/221852 (87%)]\tLoss: 0.093778\tAcc: 82.00\n",
      "val epoch: 167 [128/221852 (0%)]\tLoss: 0.095472\tAcc: 85.00\n",
      "val epoch: 167 [12928/221852 (6%)]\tLoss: 0.205336\tAcc: 85.00\n",
      "train epoch: 168 [128/221852 (0%)]\tLoss: 0.178666\tAcc: 77.00\n",
      "train epoch: 168 [12928/221852 (6%)]\tLoss: 0.156621\tAcc: 76.00\n",
      "train epoch: 168 [25728/221852 (12%)]\tLoss: 0.150008\tAcc: 81.00\n",
      "train epoch: 168 [38528/221852 (17%)]\tLoss: 0.244310\tAcc: 84.00\n",
      "train epoch: 168 [51328/221852 (23%)]\tLoss: 0.114856\tAcc: 80.00\n",
      "train epoch: 168 [64128/221852 (29%)]\tLoss: 0.137813\tAcc: 79.00\n",
      "train epoch: 168 [76928/221852 (35%)]\tLoss: 0.156024\tAcc: 81.00\n",
      "train epoch: 168 [89728/221852 (40%)]\tLoss: 0.282647\tAcc: 75.00\n",
      "train epoch: 168 [102528/221852 (46%)]\tLoss: 0.123825\tAcc: 75.00\n",
      "train epoch: 168 [115328/221852 (52%)]\tLoss: 0.110621\tAcc: 84.00\n",
      "train epoch: 168 [128128/221852 (58%)]\tLoss: 0.162480\tAcc: 82.00\n",
      "train epoch: 168 [140928/221852 (64%)]\tLoss: 0.223530\tAcc: 77.00\n",
      "train epoch: 168 [153728/221852 (69%)]\tLoss: 0.132085\tAcc: 80.00\n",
      "train epoch: 168 [166528/221852 (75%)]\tLoss: 0.160457\tAcc: 80.00\n",
      "train epoch: 168 [179328/221852 (81%)]\tLoss: 0.172510\tAcc: 80.00\n",
      "train epoch: 168 [192128/221852 (87%)]\tLoss: 0.102302\tAcc: 84.00\n",
      "val epoch: 168 [128/221852 (0%)]\tLoss: 0.085983\tAcc: 82.00\n",
      "val epoch: 168 [12928/221852 (6%)]\tLoss: 0.123497\tAcc: 84.00\n",
      "train epoch: 169 [128/221852 (0%)]\tLoss: 0.172955\tAcc: 77.00\n",
      "train epoch: 169 [12928/221852 (6%)]\tLoss: 0.213699\tAcc: 76.00\n",
      "train epoch: 169 [25728/221852 (12%)]\tLoss: 0.205224\tAcc: 80.00\n",
      "train epoch: 169 [38528/221852 (17%)]\tLoss: 0.138284\tAcc: 84.00\n",
      "train epoch: 169 [51328/221852 (23%)]\tLoss: 0.111107\tAcc: 79.00\n",
      "train epoch: 169 [64128/221852 (29%)]\tLoss: 0.175671\tAcc: 77.00\n",
      "train epoch: 169 [76928/221852 (35%)]\tLoss: 0.191125\tAcc: 73.00\n",
      "train epoch: 169 [89728/221852 (40%)]\tLoss: 0.294365\tAcc: 80.00\n",
      "train epoch: 169 [102528/221852 (46%)]\tLoss: 0.205861\tAcc: 77.00\n",
      "train epoch: 169 [115328/221852 (52%)]\tLoss: 0.226078\tAcc: 78.00\n",
      "train epoch: 169 [128128/221852 (58%)]\tLoss: 0.148101\tAcc: 85.00\n",
      "train epoch: 169 [140928/221852 (64%)]\tLoss: 0.129561\tAcc: 79.00\n",
      "train epoch: 169 [153728/221852 (69%)]\tLoss: 0.128901\tAcc: 80.00\n",
      "train epoch: 169 [166528/221852 (75%)]\tLoss: 0.163181\tAcc: 84.00\n",
      "train epoch: 169 [179328/221852 (81%)]\tLoss: 0.223899\tAcc: 84.00\n",
      "train epoch: 169 [192128/221852 (87%)]\tLoss: 0.133590\tAcc: 87.00\n",
      "val epoch: 169 [128/221852 (0%)]\tLoss: 0.287473\tAcc: 76.00\n",
      "val epoch: 169 [12928/221852 (6%)]\tLoss: 0.152203\tAcc: 85.00\n",
      "train epoch: 170 [128/221852 (0%)]\tLoss: 0.221007\tAcc: 87.00\n",
      "train epoch: 170 [12928/221852 (6%)]\tLoss: 0.257256\tAcc: 79.00\n",
      "train epoch: 170 [25728/221852 (12%)]\tLoss: 0.139287\tAcc: 80.00\n",
      "train epoch: 170 [38528/221852 (17%)]\tLoss: 0.207763\tAcc: 78.00\n",
      "train epoch: 170 [51328/221852 (23%)]\tLoss: 0.246045\tAcc: 83.00\n",
      "train epoch: 170 [64128/221852 (29%)]\tLoss: 0.247777\tAcc: 76.00\n",
      "train epoch: 170 [76928/221852 (35%)]\tLoss: 0.156027\tAcc: 76.00\n",
      "train epoch: 170 [89728/221852 (40%)]\tLoss: 0.158385\tAcc: 82.00\n",
      "train epoch: 170 [102528/221852 (46%)]\tLoss: 0.178239\tAcc: 82.00\n",
      "train epoch: 170 [115328/221852 (52%)]\tLoss: 0.172181\tAcc: 75.00\n",
      "train epoch: 170 [128128/221852 (58%)]\tLoss: 0.152607\tAcc: 89.00\n",
      "train epoch: 170 [140928/221852 (64%)]\tLoss: 0.224276\tAcc: 75.00\n",
      "train epoch: 170 [153728/221852 (69%)]\tLoss: 0.244172\tAcc: 74.00\n",
      "train epoch: 170 [166528/221852 (75%)]\tLoss: 0.563905\tAcc: 78.00\n",
      "train epoch: 170 [179328/221852 (81%)]\tLoss: 0.172569\tAcc: 79.00\n",
      "train epoch: 170 [192128/221852 (87%)]\tLoss: 0.140556\tAcc: 81.00\n",
      "val epoch: 170 [128/221852 (0%)]\tLoss: 0.145640\tAcc: 80.00\n",
      "val epoch: 170 [12928/221852 (6%)]\tLoss: 0.175931\tAcc: 79.00\n",
      "train epoch: 171 [128/221852 (0%)]\tLoss: 0.209640\tAcc: 77.00\n",
      "train epoch: 171 [12928/221852 (6%)]\tLoss: 0.170718\tAcc: 80.00\n",
      "train epoch: 171 [25728/221852 (12%)]\tLoss: 0.184572\tAcc: 77.00\n",
      "train epoch: 171 [38528/221852 (17%)]\tLoss: 0.113813\tAcc: 84.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 171 [51328/221852 (23%)]\tLoss: 0.225550\tAcc: 75.00\n",
      "train epoch: 171 [64128/221852 (29%)]\tLoss: 0.198673\tAcc: 77.00\n",
      "train epoch: 171 [76928/221852 (35%)]\tLoss: 0.257674\tAcc: 80.00\n",
      "train epoch: 171 [89728/221852 (40%)]\tLoss: 0.164741\tAcc: 80.00\n",
      "train epoch: 171 [102528/221852 (46%)]\tLoss: 0.130227\tAcc: 83.00\n",
      "train epoch: 171 [115328/221852 (52%)]\tLoss: 0.183035\tAcc: 77.00\n",
      "train epoch: 171 [128128/221852 (58%)]\tLoss: 0.174293\tAcc: 78.00\n",
      "train epoch: 171 [140928/221852 (64%)]\tLoss: 0.121336\tAcc: 74.00\n",
      "train epoch: 171 [153728/221852 (69%)]\tLoss: 0.175387\tAcc: 79.00\n",
      "train epoch: 171 [166528/221852 (75%)]\tLoss: 0.167884\tAcc: 74.00\n",
      "train epoch: 171 [179328/221852 (81%)]\tLoss: 0.150179\tAcc: 80.00\n",
      "train epoch: 171 [192128/221852 (87%)]\tLoss: 0.249653\tAcc: 81.00\n",
      "val epoch: 171 [128/221852 (0%)]\tLoss: 0.143445\tAcc: 78.00\n",
      "val epoch: 171 [12928/221852 (6%)]\tLoss: 0.167808\tAcc: 77.00\n",
      "train epoch: 172 [128/221852 (0%)]\tLoss: 0.185488\tAcc: 76.00\n",
      "train epoch: 172 [12928/221852 (6%)]\tLoss: 0.176982\tAcc: 80.00\n",
      "train epoch: 172 [25728/221852 (12%)]\tLoss: 0.290071\tAcc: 74.00\n",
      "train epoch: 172 [38528/221852 (17%)]\tLoss: 0.165022\tAcc: 80.00\n",
      "train epoch: 172 [51328/221852 (23%)]\tLoss: 0.144271\tAcc: 82.00\n",
      "train epoch: 172 [64128/221852 (29%)]\tLoss: 0.159893\tAcc: 74.00\n",
      "train epoch: 172 [76928/221852 (35%)]\tLoss: 0.266527\tAcc: 77.00\n",
      "train epoch: 172 [89728/221852 (40%)]\tLoss: 0.211944\tAcc: 75.00\n",
      "train epoch: 172 [102528/221852 (46%)]\tLoss: 0.163066\tAcc: 81.00\n",
      "train epoch: 172 [115328/221852 (52%)]\tLoss: 0.233442\tAcc: 82.00\n",
      "train epoch: 172 [128128/221852 (58%)]\tLoss: 0.170188\tAcc: 81.00\n",
      "train epoch: 172 [140928/221852 (64%)]\tLoss: 0.100057\tAcc: 86.00\n",
      "train epoch: 172 [153728/221852 (69%)]\tLoss: 0.225653\tAcc: 75.00\n",
      "train epoch: 172 [166528/221852 (75%)]\tLoss: 0.135907\tAcc: 84.00\n",
      "train epoch: 172 [179328/221852 (81%)]\tLoss: 0.115868\tAcc: 74.00\n",
      "train epoch: 172 [192128/221852 (87%)]\tLoss: 0.145781\tAcc: 77.00\n",
      "val epoch: 172 [128/221852 (0%)]\tLoss: 0.138575\tAcc: 80.00\n",
      "val epoch: 172 [12928/221852 (6%)]\tLoss: 0.219679\tAcc: 81.00\n",
      "train epoch: 173 [128/221852 (0%)]\tLoss: 0.216790\tAcc: 83.00\n",
      "train epoch: 173 [12928/221852 (6%)]\tLoss: 0.269854\tAcc: 78.00\n",
      "train epoch: 173 [25728/221852 (12%)]\tLoss: 0.171637\tAcc: 84.00\n",
      "train epoch: 173 [38528/221852 (17%)]\tLoss: 0.187915\tAcc: 79.00\n",
      "train epoch: 173 [51328/221852 (23%)]\tLoss: 0.151467\tAcc: 80.00\n",
      "train epoch: 173 [64128/221852 (29%)]\tLoss: 0.155480\tAcc: 80.00\n",
      "train epoch: 173 [76928/221852 (35%)]\tLoss: 0.223085\tAcc: 77.00\n",
      "train epoch: 173 [89728/221852 (40%)]\tLoss: 0.167177\tAcc: 84.00\n",
      "train epoch: 173 [102528/221852 (46%)]\tLoss: 0.177846\tAcc: 84.00\n",
      "train epoch: 173 [115328/221852 (52%)]\tLoss: 0.080206\tAcc: 80.00\n",
      "train epoch: 173 [128128/221852 (58%)]\tLoss: 0.142178\tAcc: 80.00\n",
      "train epoch: 173 [140928/221852 (64%)]\tLoss: 0.128876\tAcc: 80.00\n",
      "train epoch: 173 [153728/221852 (69%)]\tLoss: 0.207668\tAcc: 79.00\n",
      "train epoch: 173 [166528/221852 (75%)]\tLoss: 0.179606\tAcc: 79.00\n",
      "train epoch: 173 [179328/221852 (81%)]\tLoss: 0.101701\tAcc: 80.00\n",
      "train epoch: 173 [192128/221852 (87%)]\tLoss: 0.153920\tAcc: 80.00\n",
      "val epoch: 173 [128/221852 (0%)]\tLoss: 0.105819\tAcc: 78.00\n",
      "val epoch: 173 [12928/221852 (6%)]\tLoss: 0.121819\tAcc: 80.00\n",
      "train epoch: 174 [128/221852 (0%)]\tLoss: 0.197873\tAcc: 73.00\n",
      "train epoch: 174 [12928/221852 (6%)]\tLoss: 0.252775\tAcc: 73.00\n",
      "train epoch: 174 [25728/221852 (12%)]\tLoss: 0.141999\tAcc: 84.00\n",
      "train epoch: 174 [38528/221852 (17%)]\tLoss: 0.157929\tAcc: 79.00\n",
      "train epoch: 174 [51328/221852 (23%)]\tLoss: 0.083450\tAcc: 82.00\n",
      "train epoch: 174 [64128/221852 (29%)]\tLoss: 0.128844\tAcc: 84.00\n",
      "train epoch: 174 [76928/221852 (35%)]\tLoss: 0.226193\tAcc: 76.00\n",
      "train epoch: 174 [89728/221852 (40%)]\tLoss: 0.273329\tAcc: 77.00\n",
      "train epoch: 174 [102528/221852 (46%)]\tLoss: 0.146117\tAcc: 79.00\n",
      "train epoch: 174 [115328/221852 (52%)]\tLoss: 0.192383\tAcc: 81.00\n",
      "train epoch: 174 [128128/221852 (58%)]\tLoss: 0.165557\tAcc: 80.00\n",
      "train epoch: 174 [140928/221852 (64%)]\tLoss: 0.111711\tAcc: 83.00\n",
      "train epoch: 174 [153728/221852 (69%)]\tLoss: 0.125455\tAcc: 84.00\n",
      "train epoch: 174 [166528/221852 (75%)]\tLoss: 0.180033\tAcc: 87.00\n",
      "train epoch: 174 [179328/221852 (81%)]\tLoss: 0.112635\tAcc: 90.00\n",
      "train epoch: 174 [192128/221852 (87%)]\tLoss: 0.237960\tAcc: 83.00\n",
      "val epoch: 174 [128/221852 (0%)]\tLoss: 0.113123\tAcc: 80.00\n",
      "val epoch: 174 [12928/221852 (6%)]\tLoss: 0.141278\tAcc: 77.00\n",
      "train epoch: 175 [128/221852 (0%)]\tLoss: 0.183489\tAcc: 82.00\n",
      "train epoch: 175 [12928/221852 (6%)]\tLoss: 0.116154\tAcc: 85.00\n",
      "train epoch: 175 [25728/221852 (12%)]\tLoss: 0.198496\tAcc: 82.00\n",
      "train epoch: 175 [38528/221852 (17%)]\tLoss: 0.181352\tAcc: 80.00\n",
      "train epoch: 175 [51328/221852 (23%)]\tLoss: 0.103667\tAcc: 90.00\n",
      "train epoch: 175 [64128/221852 (29%)]\tLoss: 0.105251\tAcc: 84.00\n",
      "train epoch: 175 [76928/221852 (35%)]\tLoss: 0.305087\tAcc: 71.00\n",
      "train epoch: 175 [89728/221852 (40%)]\tLoss: 0.176503\tAcc: 86.00\n",
      "train epoch: 175 [102528/221852 (46%)]\tLoss: 0.134670\tAcc: 86.00\n",
      "train epoch: 175 [115328/221852 (52%)]\tLoss: 0.159336\tAcc: 85.00\n",
      "train epoch: 175 [128128/221852 (58%)]\tLoss: 0.180236\tAcc: 84.00\n",
      "train epoch: 175 [140928/221852 (64%)]\tLoss: 0.156329\tAcc: 80.00\n",
      "train epoch: 175 [153728/221852 (69%)]\tLoss: 0.204940\tAcc: 83.00\n",
      "train epoch: 175 [166528/221852 (75%)]\tLoss: 0.164328\tAcc: 80.00\n",
      "train epoch: 175 [179328/221852 (81%)]\tLoss: 0.088228\tAcc: 88.00\n",
      "train epoch: 175 [192128/221852 (87%)]\tLoss: 0.099750\tAcc: 87.00\n",
      "val epoch: 175 [128/221852 (0%)]\tLoss: 0.132146\tAcc: 85.00\n",
      "val epoch: 175 [12928/221852 (6%)]\tLoss: 0.195284\tAcc: 76.00\n",
      "train epoch: 176 [128/221852 (0%)]\tLoss: 0.150985\tAcc: 73.00\n",
      "train epoch: 176 [12928/221852 (6%)]\tLoss: 0.134227\tAcc: 82.00\n",
      "train epoch: 176 [25728/221852 (12%)]\tLoss: 0.189424\tAcc: 80.00\n",
      "train epoch: 176 [38528/221852 (17%)]\tLoss: 0.218046\tAcc: 79.00\n",
      "train epoch: 176 [51328/221852 (23%)]\tLoss: 0.108183\tAcc: 80.00\n",
      "train epoch: 176 [64128/221852 (29%)]\tLoss: 0.139644\tAcc: 77.00\n",
      "train epoch: 176 [76928/221852 (35%)]\tLoss: 0.185376\tAcc: 77.00\n",
      "train epoch: 176 [89728/221852 (40%)]\tLoss: 0.117555\tAcc: 77.00\n",
      "train epoch: 176 [102528/221852 (46%)]\tLoss: 0.139193\tAcc: 78.00\n",
      "train epoch: 176 [115328/221852 (52%)]\tLoss: 0.126502\tAcc: 80.00\n",
      "train epoch: 176 [128128/221852 (58%)]\tLoss: 0.436412\tAcc: 81.00\n",
      "train epoch: 176 [140928/221852 (64%)]\tLoss: 0.197001\tAcc: 73.00\n",
      "train epoch: 176 [153728/221852 (69%)]\tLoss: 0.174316\tAcc: 80.00\n",
      "train epoch: 176 [166528/221852 (75%)]\tLoss: 0.346034\tAcc: 76.00\n",
      "train epoch: 176 [179328/221852 (81%)]\tLoss: 0.147367\tAcc: 78.00\n",
      "train epoch: 176 [192128/221852 (87%)]\tLoss: 0.199307\tAcc: 76.00\n",
      "val epoch: 176 [128/221852 (0%)]\tLoss: 0.183270\tAcc: 82.00\n",
      "val epoch: 176 [12928/221852 (6%)]\tLoss: 0.184103\tAcc: 85.00\n",
      "train epoch: 177 [128/221852 (0%)]\tLoss: 0.147226\tAcc: 79.00\n",
      "train epoch: 177 [12928/221852 (6%)]\tLoss: 0.144327\tAcc: 88.00\n",
      "train epoch: 177 [25728/221852 (12%)]\tLoss: 0.220251\tAcc: 79.00\n",
      "train epoch: 177 [38528/221852 (17%)]\tLoss: 0.217420\tAcc: 80.00\n",
      "train epoch: 177 [51328/221852 (23%)]\tLoss: 0.181184\tAcc: 74.00\n",
      "train epoch: 177 [64128/221852 (29%)]\tLoss: 0.155622\tAcc: 77.00\n",
      "train epoch: 177 [76928/221852 (35%)]\tLoss: 0.195018\tAcc: 83.00\n",
      "train epoch: 177 [89728/221852 (40%)]\tLoss: 0.198214\tAcc: 76.00\n",
      "train epoch: 177 [102528/221852 (46%)]\tLoss: 0.094146\tAcc: 83.00\n",
      "train epoch: 177 [115328/221852 (52%)]\tLoss: 0.191863\tAcc: 78.00\n",
      "train epoch: 177 [128128/221852 (58%)]\tLoss: 0.164137\tAcc: 79.00\n",
      "train epoch: 177 [140928/221852 (64%)]\tLoss: 0.170877\tAcc: 81.00\n",
      "train epoch: 177 [153728/221852 (69%)]\tLoss: 0.143799\tAcc: 80.00\n",
      "train epoch: 177 [166528/221852 (75%)]\tLoss: 0.148548\tAcc: 84.00\n",
      "train epoch: 177 [179328/221852 (81%)]\tLoss: 0.136363\tAcc: 81.00\n",
      "train epoch: 177 [192128/221852 (87%)]\tLoss: 0.181084\tAcc: 80.00\n",
      "val epoch: 177 [128/221852 (0%)]\tLoss: 0.174410\tAcc: 83.00\n",
      "val epoch: 177 [12928/221852 (6%)]\tLoss: 0.142703\tAcc: 84.00\n",
      "train epoch: 178 [128/221852 (0%)]\tLoss: 0.137119\tAcc: 80.00\n",
      "train epoch: 178 [12928/221852 (6%)]\tLoss: 0.142973\tAcc: 82.00\n",
      "train epoch: 178 [25728/221852 (12%)]\tLoss: 0.206987\tAcc: 75.00\n",
      "train epoch: 178 [38528/221852 (17%)]\tLoss: 0.277817\tAcc: 80.00\n",
      "train epoch: 178 [51328/221852 (23%)]\tLoss: 0.104594\tAcc: 84.00\n",
      "train epoch: 178 [64128/221852 (29%)]\tLoss: 0.190312\tAcc: 80.00\n",
      "train epoch: 178 [76928/221852 (35%)]\tLoss: 0.160797\tAcc: 80.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 178 [89728/221852 (40%)]\tLoss: 0.191927\tAcc: 78.00\n",
      "train epoch: 178 [102528/221852 (46%)]\tLoss: 0.261798\tAcc: 75.00\n",
      "train epoch: 178 [115328/221852 (52%)]\tLoss: 0.131189\tAcc: 80.00\n",
      "train epoch: 178 [128128/221852 (58%)]\tLoss: 0.206968\tAcc: 79.00\n",
      "train epoch: 178 [140928/221852 (64%)]\tLoss: 0.269609\tAcc: 76.00\n",
      "train epoch: 178 [153728/221852 (69%)]\tLoss: 0.126074\tAcc: 79.00\n",
      "train epoch: 178 [166528/221852 (75%)]\tLoss: 0.112992\tAcc: 84.00\n",
      "train epoch: 178 [179328/221852 (81%)]\tLoss: 0.153874\tAcc: 83.00\n",
      "train epoch: 178 [192128/221852 (87%)]\tLoss: 0.137466\tAcc: 83.00\n",
      "val epoch: 178 [128/221852 (0%)]\tLoss: 0.166149\tAcc: 78.00\n",
      "val epoch: 178 [12928/221852 (6%)]\tLoss: 0.111220\tAcc: 81.00\n",
      "train epoch: 179 [128/221852 (0%)]\tLoss: 0.152442\tAcc: 75.00\n",
      "train epoch: 179 [12928/221852 (6%)]\tLoss: 0.480065\tAcc: 78.00\n",
      "train epoch: 179 [25728/221852 (12%)]\tLoss: 0.226191\tAcc: 79.00\n",
      "train epoch: 179 [38528/221852 (17%)]\tLoss: 0.151427\tAcc: 75.00\n",
      "train epoch: 179 [51328/221852 (23%)]\tLoss: 0.105020\tAcc: 81.00\n",
      "train epoch: 179 [64128/221852 (29%)]\tLoss: 0.224075\tAcc: 76.00\n",
      "train epoch: 179 [76928/221852 (35%)]\tLoss: 0.120340\tAcc: 85.00\n",
      "train epoch: 179 [89728/221852 (40%)]\tLoss: 0.163028\tAcc: 77.00\n",
      "train epoch: 179 [102528/221852 (46%)]\tLoss: 0.169720\tAcc: 82.00\n",
      "train epoch: 179 [115328/221852 (52%)]\tLoss: 0.159917\tAcc: 83.00\n",
      "train epoch: 179 [128128/221852 (58%)]\tLoss: 0.179662\tAcc: 79.00\n",
      "train epoch: 179 [140928/221852 (64%)]\tLoss: 0.151649\tAcc: 78.00\n",
      "train epoch: 179 [153728/221852 (69%)]\tLoss: 0.147624\tAcc: 80.00\n",
      "train epoch: 179 [166528/221852 (75%)]\tLoss: 0.140764\tAcc: 80.00\n",
      "train epoch: 179 [179328/221852 (81%)]\tLoss: 0.156395\tAcc: 83.00\n",
      "train epoch: 179 [192128/221852 (87%)]\tLoss: 0.192141\tAcc: 75.00\n",
      "val epoch: 179 [128/221852 (0%)]\tLoss: 0.190759\tAcc: 80.00\n",
      "val epoch: 179 [12928/221852 (6%)]\tLoss: 0.180894\tAcc: 82.00\n",
      "train epoch: 180 [128/221852 (0%)]\tLoss: 0.192080\tAcc: 84.00\n",
      "train epoch: 180 [12928/221852 (6%)]\tLoss: 0.156063\tAcc: 84.00\n",
      "train epoch: 180 [25728/221852 (12%)]\tLoss: 0.303059\tAcc: 80.00\n",
      "train epoch: 180 [38528/221852 (17%)]\tLoss: 0.169017\tAcc: 78.00\n",
      "train epoch: 180 [51328/221852 (23%)]\tLoss: 0.193581\tAcc: 81.00\n",
      "train epoch: 180 [64128/221852 (29%)]\tLoss: 0.110603\tAcc: 83.00\n",
      "train epoch: 180 [76928/221852 (35%)]\tLoss: 0.098285\tAcc: 84.00\n",
      "train epoch: 180 [89728/221852 (40%)]\tLoss: 0.122051\tAcc: 82.00\n",
      "train epoch: 180 [102528/221852 (46%)]\tLoss: 0.160035\tAcc: 79.00\n",
      "train epoch: 180 [115328/221852 (52%)]\tLoss: 0.189265\tAcc: 75.00\n",
      "train epoch: 180 [128128/221852 (58%)]\tLoss: 0.200664\tAcc: 82.00\n",
      "train epoch: 180 [140928/221852 (64%)]\tLoss: 0.140678\tAcc: 88.00\n",
      "train epoch: 180 [153728/221852 (69%)]\tLoss: 0.246134\tAcc: 85.00\n",
      "train epoch: 180 [166528/221852 (75%)]\tLoss: 0.110490\tAcc: 84.00\n",
      "train epoch: 180 [179328/221852 (81%)]\tLoss: 0.153515\tAcc: 80.00\n",
      "train epoch: 180 [192128/221852 (87%)]\tLoss: 0.091269\tAcc: 81.00\n",
      "val epoch: 180 [128/221852 (0%)]\tLoss: 0.178892\tAcc: 80.00\n",
      "val epoch: 180 [12928/221852 (6%)]\tLoss: 0.227458\tAcc: 83.00\n",
      "train epoch: 181 [128/221852 (0%)]\tLoss: 0.141785\tAcc: 78.00\n",
      "train epoch: 181 [12928/221852 (6%)]\tLoss: 0.141954\tAcc: 84.00\n",
      "train epoch: 181 [25728/221852 (12%)]\tLoss: 0.145445\tAcc: 75.00\n",
      "train epoch: 181 [38528/221852 (17%)]\tLoss: 0.090122\tAcc: 82.00\n",
      "train epoch: 181 [51328/221852 (23%)]\tLoss: 0.236969\tAcc: 82.00\n",
      "train epoch: 181 [64128/221852 (29%)]\tLoss: 0.174762\tAcc: 76.00\n",
      "train epoch: 181 [76928/221852 (35%)]\tLoss: 0.234432\tAcc: 73.00\n",
      "train epoch: 181 [89728/221852 (40%)]\tLoss: 0.284948\tAcc: 76.00\n",
      "train epoch: 181 [102528/221852 (46%)]\tLoss: 0.274067\tAcc: 78.00\n",
      "train epoch: 181 [115328/221852 (52%)]\tLoss: 0.164294\tAcc: 77.00\n",
      "train epoch: 181 [128128/221852 (58%)]\tLoss: 0.149447\tAcc: 79.00\n",
      "train epoch: 181 [140928/221852 (64%)]\tLoss: 0.117545\tAcc: 87.00\n",
      "train epoch: 181 [153728/221852 (69%)]\tLoss: 0.136699\tAcc: 77.00\n",
      "train epoch: 181 [166528/221852 (75%)]\tLoss: 0.168284\tAcc: 87.00\n",
      "train epoch: 181 [179328/221852 (81%)]\tLoss: 0.251526\tAcc: 80.00\n",
      "train epoch: 181 [192128/221852 (87%)]\tLoss: 0.238810\tAcc: 78.00\n",
      "val epoch: 181 [128/221852 (0%)]\tLoss: 0.174743\tAcc: 80.00\n",
      "val epoch: 181 [12928/221852 (6%)]\tLoss: 0.165342\tAcc: 81.00\n",
      "train epoch: 182 [128/221852 (0%)]\tLoss: 0.141431\tAcc: 78.00\n",
      "train epoch: 182 [12928/221852 (6%)]\tLoss: 0.096051\tAcc: 84.00\n",
      "train epoch: 182 [25728/221852 (12%)]\tLoss: 0.160941\tAcc: 82.00\n",
      "train epoch: 182 [38528/221852 (17%)]\tLoss: 0.110999\tAcc: 84.00\n",
      "train epoch: 182 [51328/221852 (23%)]\tLoss: 0.208129\tAcc: 76.00\n",
      "train epoch: 182 [64128/221852 (29%)]\tLoss: 0.159106\tAcc: 80.00\n",
      "train epoch: 182 [76928/221852 (35%)]\tLoss: 0.163680\tAcc: 73.00\n",
      "train epoch: 182 [89728/221852 (40%)]\tLoss: 0.216203\tAcc: 80.00\n",
      "train epoch: 182 [102528/221852 (46%)]\tLoss: 0.179586\tAcc: 82.00\n",
      "train epoch: 182 [115328/221852 (52%)]\tLoss: 0.121133\tAcc: 82.00\n",
      "train epoch: 182 [128128/221852 (58%)]\tLoss: 0.127633\tAcc: 81.00\n",
      "train epoch: 182 [140928/221852 (64%)]\tLoss: 0.162220\tAcc: 80.00\n",
      "train epoch: 182 [153728/221852 (69%)]\tLoss: 0.206373\tAcc: 83.00\n",
      "train epoch: 182 [166528/221852 (75%)]\tLoss: 0.157903\tAcc: 81.00\n",
      "train epoch: 182 [179328/221852 (81%)]\tLoss: 0.152380\tAcc: 84.00\n",
      "train epoch: 182 [192128/221852 (87%)]\tLoss: 0.181768\tAcc: 79.00\n",
      "val epoch: 182 [128/221852 (0%)]\tLoss: 0.149561\tAcc: 77.00\n",
      "val epoch: 182 [12928/221852 (6%)]\tLoss: 0.219095\tAcc: 79.00\n",
      "train epoch: 183 [128/221852 (0%)]\tLoss: 0.132056\tAcc: 77.00\n",
      "train epoch: 183 [12928/221852 (6%)]\tLoss: 0.114579\tAcc: 82.00\n",
      "train epoch: 183 [25728/221852 (12%)]\tLoss: 0.105500\tAcc: 85.00\n",
      "train epoch: 183 [38528/221852 (17%)]\tLoss: 0.203697\tAcc: 82.00\n",
      "train epoch: 183 [51328/221852 (23%)]\tLoss: 0.138250\tAcc: 83.00\n",
      "train epoch: 183 [64128/221852 (29%)]\tLoss: 0.131170\tAcc: 82.00\n",
      "train epoch: 183 [76928/221852 (35%)]\tLoss: 0.147976\tAcc: 79.00\n",
      "train epoch: 183 [89728/221852 (40%)]\tLoss: 0.177136\tAcc: 70.00\n",
      "train epoch: 183 [102528/221852 (46%)]\tLoss: 0.166443\tAcc: 78.00\n",
      "train epoch: 183 [115328/221852 (52%)]\tLoss: 0.128961\tAcc: 84.00\n",
      "train epoch: 183 [128128/221852 (58%)]\tLoss: 0.150556\tAcc: 77.00\n",
      "train epoch: 183 [140928/221852 (64%)]\tLoss: 0.181859\tAcc: 80.00\n",
      "train epoch: 183 [153728/221852 (69%)]\tLoss: 0.139250\tAcc: 82.00\n",
      "train epoch: 183 [166528/221852 (75%)]\tLoss: 0.132177\tAcc: 79.00\n",
      "train epoch: 183 [179328/221852 (81%)]\tLoss: 0.139620\tAcc: 80.00\n",
      "train epoch: 183 [192128/221852 (87%)]\tLoss: 0.165060\tAcc: 81.00\n",
      "val epoch: 183 [128/221852 (0%)]\tLoss: 0.130718\tAcc: 80.00\n",
      "val epoch: 183 [12928/221852 (6%)]\tLoss: 0.216165\tAcc: 77.00\n",
      "train epoch: 184 [128/221852 (0%)]\tLoss: 0.304912\tAcc: 70.00\n",
      "train epoch: 184 [12928/221852 (6%)]\tLoss: 0.258353\tAcc: 75.00\n",
      "train epoch: 184 [25728/221852 (12%)]\tLoss: 0.216561\tAcc: 78.00\n",
      "train epoch: 184 [38528/221852 (17%)]\tLoss: 0.166044\tAcc: 82.00\n",
      "train epoch: 184 [51328/221852 (23%)]\tLoss: 0.149858\tAcc: 80.00\n",
      "train epoch: 184 [64128/221852 (29%)]\tLoss: 0.108625\tAcc: 80.00\n",
      "train epoch: 184 [76928/221852 (35%)]\tLoss: 0.211447\tAcc: 79.00\n",
      "train epoch: 184 [89728/221852 (40%)]\tLoss: 0.169725\tAcc: 84.00\n",
      "train epoch: 184 [102528/221852 (46%)]\tLoss: 0.178808\tAcc: 79.00\n",
      "train epoch: 184 [115328/221852 (52%)]\tLoss: 0.204991\tAcc: 81.00\n",
      "train epoch: 184 [128128/221852 (58%)]\tLoss: 0.168343\tAcc: 73.00\n",
      "train epoch: 184 [140928/221852 (64%)]\tLoss: 0.322862\tAcc: 77.00\n",
      "train epoch: 184 [153728/221852 (69%)]\tLoss: 0.209394\tAcc: 79.00\n",
      "train epoch: 184 [166528/221852 (75%)]\tLoss: 0.162004\tAcc: 76.00\n",
      "train epoch: 184 [179328/221852 (81%)]\tLoss: 0.179368\tAcc: 82.00\n",
      "train epoch: 184 [192128/221852 (87%)]\tLoss: 0.132100\tAcc: 80.00\n",
      "val epoch: 184 [128/221852 (0%)]\tLoss: 0.131685\tAcc: 85.00\n",
      "val epoch: 184 [12928/221852 (6%)]\tLoss: 0.192707\tAcc: 80.00\n",
      "train epoch: 185 [128/221852 (0%)]\tLoss: 0.189871\tAcc: 80.00\n",
      "train epoch: 185 [12928/221852 (6%)]\tLoss: 0.231321\tAcc: 77.00\n",
      "train epoch: 185 [25728/221852 (12%)]\tLoss: 0.201469\tAcc: 82.00\n",
      "train epoch: 185 [38528/221852 (17%)]\tLoss: 0.123356\tAcc: 80.00\n",
      "train epoch: 185 [51328/221852 (23%)]\tLoss: 0.147250\tAcc: 87.00\n",
      "train epoch: 185 [64128/221852 (29%)]\tLoss: 0.158907\tAcc: 80.00\n",
      "train epoch: 185 [76928/221852 (35%)]\tLoss: 0.205356\tAcc: 77.00\n",
      "train epoch: 185 [89728/221852 (40%)]\tLoss: 0.221047\tAcc: 77.00\n",
      "train epoch: 185 [102528/221852 (46%)]\tLoss: 0.238498\tAcc: 77.00\n",
      "train epoch: 185 [115328/221852 (52%)]\tLoss: 0.192386\tAcc: 80.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 185 [128128/221852 (58%)]\tLoss: 0.146937\tAcc: 77.00\n",
      "train epoch: 185 [140928/221852 (64%)]\tLoss: 0.188984\tAcc: 77.00\n",
      "train epoch: 185 [153728/221852 (69%)]\tLoss: 0.144887\tAcc: 80.00\n",
      "train epoch: 185 [166528/221852 (75%)]\tLoss: 0.173503\tAcc: 85.00\n",
      "train epoch: 185 [179328/221852 (81%)]\tLoss: 0.162585\tAcc: 81.00\n",
      "train epoch: 185 [192128/221852 (87%)]\tLoss: 0.162334\tAcc: 79.00\n",
      "val epoch: 185 [128/221852 (0%)]\tLoss: 0.206331\tAcc: 76.00\n",
      "val epoch: 185 [12928/221852 (6%)]\tLoss: 0.233631\tAcc: 77.00\n",
      "train epoch: 186 [128/221852 (0%)]\tLoss: 0.265387\tAcc: 70.00\n",
      "train epoch: 186 [12928/221852 (6%)]\tLoss: 0.098748\tAcc: 75.00\n",
      "train epoch: 186 [25728/221852 (12%)]\tLoss: 0.188965\tAcc: 85.00\n",
      "train epoch: 186 [38528/221852 (17%)]\tLoss: 0.179133\tAcc: 83.00\n",
      "train epoch: 186 [51328/221852 (23%)]\tLoss: 0.096414\tAcc: 83.00\n",
      "train epoch: 186 [64128/221852 (29%)]\tLoss: 0.125042\tAcc: 80.00\n",
      "train epoch: 186 [76928/221852 (35%)]\tLoss: 0.161939\tAcc: 77.00\n",
      "train epoch: 186 [89728/221852 (40%)]\tLoss: 0.322587\tAcc: 83.00\n",
      "train epoch: 186 [102528/221852 (46%)]\tLoss: 0.129637\tAcc: 78.00\n",
      "train epoch: 186 [115328/221852 (52%)]\tLoss: 0.193555\tAcc: 83.00\n",
      "train epoch: 186 [128128/221852 (58%)]\tLoss: 0.213560\tAcc: 77.00\n",
      "train epoch: 186 [140928/221852 (64%)]\tLoss: 0.108314\tAcc: 80.00\n",
      "train epoch: 186 [153728/221852 (69%)]\tLoss: 0.185670\tAcc: 77.00\n",
      "train epoch: 186 [166528/221852 (75%)]\tLoss: 0.104523\tAcc: 84.00\n",
      "train epoch: 186 [179328/221852 (81%)]\tLoss: 0.161323\tAcc: 76.00\n",
      "train epoch: 186 [192128/221852 (87%)]\tLoss: 0.148890\tAcc: 77.00\n",
      "val epoch: 186 [128/221852 (0%)]\tLoss: 0.160327\tAcc: 82.00\n",
      "val epoch: 186 [12928/221852 (6%)]\tLoss: 0.173295\tAcc: 81.00\n",
      "train epoch: 187 [128/221852 (0%)]\tLoss: 0.134166\tAcc: 84.00\n",
      "train epoch: 187 [12928/221852 (6%)]\tLoss: 0.176332\tAcc: 77.00\n",
      "train epoch: 187 [25728/221852 (12%)]\tLoss: 0.193416\tAcc: 77.00\n",
      "train epoch: 187 [38528/221852 (17%)]\tLoss: 0.273071\tAcc: 73.00\n",
      "train epoch: 187 [51328/221852 (23%)]\tLoss: 0.109513\tAcc: 87.00\n",
      "train epoch: 187 [64128/221852 (29%)]\tLoss: 0.211049\tAcc: 75.00\n",
      "train epoch: 187 [76928/221852 (35%)]\tLoss: 0.152572\tAcc: 80.00\n",
      "train epoch: 187 [89728/221852 (40%)]\tLoss: 0.129846\tAcc: 80.00\n",
      "train epoch: 187 [102528/221852 (46%)]\tLoss: 0.267645\tAcc: 73.00\n",
      "train epoch: 187 [115328/221852 (52%)]\tLoss: 0.203973\tAcc: 75.00\n",
      "train epoch: 187 [128128/221852 (58%)]\tLoss: 0.125387\tAcc: 85.00\n",
      "train epoch: 187 [140928/221852 (64%)]\tLoss: 0.292583\tAcc: 67.00\n",
      "train epoch: 187 [153728/221852 (69%)]\tLoss: 0.117661\tAcc: 85.00\n",
      "train epoch: 187 [166528/221852 (75%)]\tLoss: 0.150786\tAcc: 83.00\n",
      "train epoch: 187 [179328/221852 (81%)]\tLoss: 0.148779\tAcc: 79.00\n",
      "train epoch: 187 [192128/221852 (87%)]\tLoss: 0.216187\tAcc: 77.00\n",
      "val epoch: 187 [128/221852 (0%)]\tLoss: 0.197470\tAcc: 77.00\n",
      "val epoch: 187 [12928/221852 (6%)]\tLoss: 0.183683\tAcc: 77.00\n",
      "train epoch: 188 [128/221852 (0%)]\tLoss: 0.135099\tAcc: 75.00\n",
      "train epoch: 188 [12928/221852 (6%)]\tLoss: 0.144906\tAcc: 85.00\n",
      "train epoch: 188 [25728/221852 (12%)]\tLoss: 0.189864\tAcc: 85.00\n",
      "train epoch: 188 [38528/221852 (17%)]\tLoss: 0.179081\tAcc: 75.00\n",
      "train epoch: 188 [51328/221852 (23%)]\tLoss: 0.171775\tAcc: 80.00\n",
      "train epoch: 188 [64128/221852 (29%)]\tLoss: 0.129099\tAcc: 84.00\n",
      "train epoch: 188 [76928/221852 (35%)]\tLoss: 0.137925\tAcc: 86.00\n",
      "train epoch: 188 [89728/221852 (40%)]\tLoss: 0.165651\tAcc: 84.00\n",
      "train epoch: 188 [102528/221852 (46%)]\tLoss: 0.150987\tAcc: 84.00\n",
      "train epoch: 188 [115328/221852 (52%)]\tLoss: 0.115458\tAcc: 80.00\n",
      "train epoch: 188 [128128/221852 (58%)]\tLoss: 0.215811\tAcc: 81.00\n",
      "train epoch: 188 [140928/221852 (64%)]\tLoss: 0.140915\tAcc: 84.00\n",
      "train epoch: 188 [153728/221852 (69%)]\tLoss: 0.145299\tAcc: 80.00\n",
      "train epoch: 188 [166528/221852 (75%)]\tLoss: 0.157325\tAcc: 79.00\n",
      "train epoch: 188 [179328/221852 (81%)]\tLoss: 0.161698\tAcc: 80.00\n",
      "train epoch: 188 [192128/221852 (87%)]\tLoss: 0.143294\tAcc: 83.00\n",
      "val epoch: 188 [128/221852 (0%)]\tLoss: 0.187691\tAcc: 76.00\n",
      "val epoch: 188 [12928/221852 (6%)]\tLoss: 0.201806\tAcc: 84.00\n",
      "train epoch: 189 [128/221852 (0%)]\tLoss: 0.194288\tAcc: 79.00\n",
      "train epoch: 189 [12928/221852 (6%)]\tLoss: 0.179881\tAcc: 80.00\n",
      "train epoch: 189 [25728/221852 (12%)]\tLoss: 0.153996\tAcc: 73.00\n",
      "train epoch: 189 [38528/221852 (17%)]\tLoss: 0.176156\tAcc: 79.00\n",
      "train epoch: 189 [51328/221852 (23%)]\tLoss: 0.143806\tAcc: 84.00\n",
      "train epoch: 189 [64128/221852 (29%)]\tLoss: 0.181654\tAcc: 77.00\n",
      "train epoch: 189 [76928/221852 (35%)]\tLoss: 0.210261\tAcc: 77.00\n",
      "train epoch: 189 [89728/221852 (40%)]\tLoss: 0.178516\tAcc: 81.00\n",
      "train epoch: 189 [102528/221852 (46%)]\tLoss: 0.127588\tAcc: 76.00\n",
      "train epoch: 189 [115328/221852 (52%)]\tLoss: 0.188199\tAcc: 84.00\n",
      "train epoch: 189 [128128/221852 (58%)]\tLoss: 0.119684\tAcc: 85.00\n",
      "train epoch: 189 [140928/221852 (64%)]\tLoss: 0.184238\tAcc: 80.00\n",
      "train epoch: 189 [153728/221852 (69%)]\tLoss: 0.166556\tAcc: 82.00\n",
      "train epoch: 189 [166528/221852 (75%)]\tLoss: 0.258796\tAcc: 77.00\n",
      "train epoch: 189 [179328/221852 (81%)]\tLoss: 0.153986\tAcc: 84.00\n",
      "train epoch: 189 [192128/221852 (87%)]\tLoss: 0.177263\tAcc: 79.00\n",
      "val epoch: 189 [128/221852 (0%)]\tLoss: 0.185918\tAcc: 83.00\n",
      "val epoch: 189 [12928/221852 (6%)]\tLoss: 0.243181\tAcc: 84.00\n",
      "train epoch: 190 [128/221852 (0%)]\tLoss: 0.160326\tAcc: 80.00\n",
      "train epoch: 190 [12928/221852 (6%)]\tLoss: 0.191489\tAcc: 77.00\n",
      "train epoch: 190 [25728/221852 (12%)]\tLoss: 0.155433\tAcc: 81.00\n",
      "train epoch: 190 [38528/221852 (17%)]\tLoss: 0.193101\tAcc: 81.00\n",
      "train epoch: 190 [51328/221852 (23%)]\tLoss: 0.073677\tAcc: 82.00\n",
      "train epoch: 190 [64128/221852 (29%)]\tLoss: 0.121109\tAcc: 82.00\n",
      "train epoch: 190 [76928/221852 (35%)]\tLoss: 0.107417\tAcc: 84.00\n",
      "train epoch: 190 [89728/221852 (40%)]\tLoss: 0.160799\tAcc: 82.00\n",
      "train epoch: 190 [102528/221852 (46%)]\tLoss: 0.173469\tAcc: 75.00\n",
      "train epoch: 190 [115328/221852 (52%)]\tLoss: 0.217142\tAcc: 82.00\n",
      "train epoch: 190 [128128/221852 (58%)]\tLoss: 0.794274\tAcc: 73.00\n",
      "train epoch: 190 [140928/221852 (64%)]\tLoss: 0.123092\tAcc: 84.00\n",
      "train epoch: 190 [153728/221852 (69%)]\tLoss: 0.135910\tAcc: 84.00\n",
      "train epoch: 190 [166528/221852 (75%)]\tLoss: 0.312659\tAcc: 74.00\n",
      "train epoch: 190 [179328/221852 (81%)]\tLoss: 0.160996\tAcc: 74.00\n",
      "train epoch: 190 [192128/221852 (87%)]\tLoss: 0.102627\tAcc: 80.00\n",
      "val epoch: 190 [128/221852 (0%)]\tLoss: 0.179217\tAcc: 77.00\n",
      "val epoch: 190 [12928/221852 (6%)]\tLoss: 0.237199\tAcc: 80.00\n",
      "train epoch: 191 [128/221852 (0%)]\tLoss: 0.151172\tAcc: 78.00\n",
      "train epoch: 191 [12928/221852 (6%)]\tLoss: 0.203253\tAcc: 75.00\n",
      "train epoch: 191 [25728/221852 (12%)]\tLoss: 0.186295\tAcc: 77.00\n",
      "train epoch: 191 [38528/221852 (17%)]\tLoss: 0.149253\tAcc: 79.00\n",
      "train epoch: 191 [51328/221852 (23%)]\tLoss: 0.183764\tAcc: 83.00\n",
      "train epoch: 191 [64128/221852 (29%)]\tLoss: 0.168244\tAcc: 76.00\n",
      "train epoch: 191 [76928/221852 (35%)]\tLoss: 0.189570\tAcc: 79.00\n",
      "train epoch: 191 [89728/221852 (40%)]\tLoss: 0.196406\tAcc: 73.00\n",
      "train epoch: 191 [102528/221852 (46%)]\tLoss: 0.192708\tAcc: 76.00\n",
      "train epoch: 191 [115328/221852 (52%)]\tLoss: 0.153650\tAcc: 77.00\n",
      "train epoch: 191 [128128/221852 (58%)]\tLoss: 0.190479\tAcc: 78.00\n",
      "train epoch: 191 [140928/221852 (64%)]\tLoss: 0.176592\tAcc: 82.00\n",
      "train epoch: 191 [153728/221852 (69%)]\tLoss: 0.162654\tAcc: 87.00\n",
      "train epoch: 191 [166528/221852 (75%)]\tLoss: 0.171918\tAcc: 80.00\n",
      "train epoch: 191 [179328/221852 (81%)]\tLoss: 0.093178\tAcc: 84.00\n",
      "train epoch: 191 [192128/221852 (87%)]\tLoss: 0.136942\tAcc: 81.00\n",
      "val epoch: 191 [128/221852 (0%)]\tLoss: 0.158376\tAcc: 81.00\n",
      "val epoch: 191 [12928/221852 (6%)]\tLoss: 0.128420\tAcc: 81.00\n",
      "train epoch: 192 [128/221852 (0%)]\tLoss: 0.164236\tAcc: 84.00\n",
      "train epoch: 192 [12928/221852 (6%)]\tLoss: 0.227581\tAcc: 77.00\n",
      "train epoch: 192 [25728/221852 (12%)]\tLoss: 0.144920\tAcc: 81.00\n",
      "train epoch: 192 [38528/221852 (17%)]\tLoss: 0.168915\tAcc: 77.00\n",
      "train epoch: 192 [51328/221852 (23%)]\tLoss: 0.209007\tAcc: 80.00\n",
      "train epoch: 192 [64128/221852 (29%)]\tLoss: 0.161963\tAcc: 81.00\n",
      "train epoch: 192 [76928/221852 (35%)]\tLoss: 0.196293\tAcc: 81.00\n",
      "train epoch: 192 [89728/221852 (40%)]\tLoss: 0.106352\tAcc: 79.00\n",
      "train epoch: 192 [102528/221852 (46%)]\tLoss: 0.164730\tAcc: 78.00\n",
      "train epoch: 192 [115328/221852 (52%)]\tLoss: 0.160571\tAcc: 74.00\n",
      "train epoch: 192 [128128/221852 (58%)]\tLoss: 0.154164\tAcc: 82.00\n",
      "train epoch: 192 [140928/221852 (64%)]\tLoss: 0.126124\tAcc: 77.00\n",
      "train epoch: 192 [153728/221852 (69%)]\tLoss: 0.151998\tAcc: 80.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 192 [166528/221852 (75%)]\tLoss: 0.173070\tAcc: 73.00\n",
      "train epoch: 192 [179328/221852 (81%)]\tLoss: 0.135935\tAcc: 85.00\n",
      "train epoch: 192 [192128/221852 (87%)]\tLoss: 0.102379\tAcc: 83.00\n",
      "val epoch: 192 [128/221852 (0%)]\tLoss: 0.103585\tAcc: 85.00\n",
      "val epoch: 192 [12928/221852 (6%)]\tLoss: 0.113008\tAcc: 83.00\n",
      "train epoch: 193 [128/221852 (0%)]\tLoss: 0.193645\tAcc: 79.00\n",
      "train epoch: 193 [12928/221852 (6%)]\tLoss: 0.099976\tAcc: 87.00\n",
      "train epoch: 193 [25728/221852 (12%)]\tLoss: 0.140869\tAcc: 77.00\n",
      "train epoch: 193 [38528/221852 (17%)]\tLoss: 0.669576\tAcc: 80.00\n",
      "train epoch: 193 [51328/221852 (23%)]\tLoss: 0.147239\tAcc: 84.00\n",
      "train epoch: 193 [64128/221852 (29%)]\tLoss: 0.181996\tAcc: 77.00\n",
      "train epoch: 193 [76928/221852 (35%)]\tLoss: 0.169230\tAcc: 80.00\n",
      "train epoch: 193 [89728/221852 (40%)]\tLoss: 0.147712\tAcc: 81.00\n",
      "train epoch: 193 [102528/221852 (46%)]\tLoss: 0.237346\tAcc: 72.00\n",
      "train epoch: 193 [115328/221852 (52%)]\tLoss: 0.154970\tAcc: 84.00\n",
      "train epoch: 193 [128128/221852 (58%)]\tLoss: 0.195047\tAcc: 84.00\n",
      "train epoch: 193 [140928/221852 (64%)]\tLoss: 0.211283\tAcc: 78.00\n",
      "train epoch: 193 [153728/221852 (69%)]\tLoss: 0.195356\tAcc: 78.00\n",
      "train epoch: 193 [166528/221852 (75%)]\tLoss: 0.180816\tAcc: 81.00\n",
      "train epoch: 193 [179328/221852 (81%)]\tLoss: 0.178053\tAcc: 80.00\n",
      "train epoch: 193 [192128/221852 (87%)]\tLoss: 0.171423\tAcc: 76.00\n",
      "val epoch: 193 [128/221852 (0%)]\tLoss: 0.153900\tAcc: 81.00\n",
      "val epoch: 193 [12928/221852 (6%)]\tLoss: 0.232123\tAcc: 74.00\n",
      "train epoch: 194 [128/221852 (0%)]\tLoss: 0.254346\tAcc: 80.00\n",
      "train epoch: 194 [12928/221852 (6%)]\tLoss: 0.160172\tAcc: 80.00\n",
      "train epoch: 194 [25728/221852 (12%)]\tLoss: 0.141902\tAcc: 80.00\n",
      "train epoch: 194 [38528/221852 (17%)]\tLoss: 0.144526\tAcc: 84.00\n",
      "train epoch: 194 [51328/221852 (23%)]\tLoss: 0.189370\tAcc: 80.00\n",
      "train epoch: 194 [64128/221852 (29%)]\tLoss: 0.153893\tAcc: 80.00\n",
      "train epoch: 194 [76928/221852 (35%)]\tLoss: 0.233712\tAcc: 78.00\n",
      "train epoch: 194 [89728/221852 (40%)]\tLoss: 0.078214\tAcc: 85.00\n",
      "train epoch: 194 [102528/221852 (46%)]\tLoss: 0.162034\tAcc: 85.00\n",
      "train epoch: 194 [115328/221852 (52%)]\tLoss: 0.144206\tAcc: 81.00\n",
      "train epoch: 194 [128128/221852 (58%)]\tLoss: 0.195801\tAcc: 80.00\n",
      "train epoch: 194 [140928/221852 (64%)]\tLoss: 0.088495\tAcc: 79.00\n",
      "train epoch: 194 [153728/221852 (69%)]\tLoss: 0.141329\tAcc: 77.00\n",
      "train epoch: 194 [166528/221852 (75%)]\tLoss: 0.183851\tAcc: 83.00\n",
      "train epoch: 194 [179328/221852 (81%)]\tLoss: 0.176483\tAcc: 80.00\n",
      "train epoch: 194 [192128/221852 (87%)]\tLoss: 0.263193\tAcc: 77.00\n",
      "val epoch: 194 [128/221852 (0%)]\tLoss: 0.212263\tAcc: 74.00\n",
      "val epoch: 194 [12928/221852 (6%)]\tLoss: 0.190690\tAcc: 84.00\n",
      "train epoch: 195 [128/221852 (0%)]\tLoss: 0.241176\tAcc: 80.00\n",
      "train epoch: 195 [12928/221852 (6%)]\tLoss: 0.164740\tAcc: 80.00\n",
      "train epoch: 195 [25728/221852 (12%)]\tLoss: 0.138367\tAcc: 80.00\n",
      "train epoch: 195 [38528/221852 (17%)]\tLoss: 0.190958\tAcc: 80.00\n",
      "train epoch: 195 [51328/221852 (23%)]\tLoss: 0.191312\tAcc: 81.00\n",
      "train epoch: 195 [64128/221852 (29%)]\tLoss: 0.795062\tAcc: 80.00\n",
      "train epoch: 195 [76928/221852 (35%)]\tLoss: 0.172732\tAcc: 79.00\n",
      "train epoch: 195 [89728/221852 (40%)]\tLoss: 0.185109\tAcc: 83.00\n",
      "train epoch: 195 [102528/221852 (46%)]\tLoss: 0.219669\tAcc: 71.00\n",
      "train epoch: 195 [115328/221852 (52%)]\tLoss: 0.097868\tAcc: 91.00\n",
      "train epoch: 195 [128128/221852 (58%)]\tLoss: 0.141376\tAcc: 85.00\n",
      "train epoch: 195 [140928/221852 (64%)]\tLoss: 0.108968\tAcc: 84.00\n",
      "train epoch: 195 [153728/221852 (69%)]\tLoss: 0.248289\tAcc: 74.00\n",
      "train epoch: 195 [166528/221852 (75%)]\tLoss: 0.197138\tAcc: 79.00\n",
      "train epoch: 195 [179328/221852 (81%)]\tLoss: 0.178099\tAcc: 80.00\n",
      "train epoch: 195 [192128/221852 (87%)]\tLoss: 0.119824\tAcc: 87.00\n",
      "val epoch: 195 [128/221852 (0%)]\tLoss: 0.151596\tAcc: 82.00\n",
      "val epoch: 195 [12928/221852 (6%)]\tLoss: 0.245295\tAcc: 80.00\n",
      "train epoch: 196 [128/221852 (0%)]\tLoss: 0.108624\tAcc: 81.00\n",
      "train epoch: 196 [12928/221852 (6%)]\tLoss: 0.103781\tAcc: 79.00\n",
      "train epoch: 196 [25728/221852 (12%)]\tLoss: 0.255600\tAcc: 80.00\n",
      "train epoch: 196 [38528/221852 (17%)]\tLoss: 0.116636\tAcc: 89.00\n",
      "train epoch: 196 [51328/221852 (23%)]\tLoss: 0.143345\tAcc: 77.00\n",
      "train epoch: 196 [64128/221852 (29%)]\tLoss: 0.129605\tAcc: 84.00\n",
      "train epoch: 196 [76928/221852 (35%)]\tLoss: 0.200601\tAcc: 82.00\n",
      "train epoch: 196 [89728/221852 (40%)]\tLoss: 0.199193\tAcc: 77.00\n",
      "train epoch: 196 [102528/221852 (46%)]\tLoss: 0.082246\tAcc: 81.00\n",
      "train epoch: 196 [115328/221852 (52%)]\tLoss: 0.208210\tAcc: 73.00\n",
      "train epoch: 196 [128128/221852 (58%)]\tLoss: 0.119838\tAcc: 79.00\n",
      "train epoch: 196 [140928/221852 (64%)]\tLoss: 0.094009\tAcc: 84.00\n",
      "train epoch: 196 [153728/221852 (69%)]\tLoss: 0.202604\tAcc: 82.00\n",
      "train epoch: 196 [166528/221852 (75%)]\tLoss: 0.131969\tAcc: 80.00\n",
      "train epoch: 196 [179328/221852 (81%)]\tLoss: 0.190205\tAcc: 83.00\n",
      "train epoch: 196 [192128/221852 (87%)]\tLoss: 0.236847\tAcc: 76.00\n",
      "val epoch: 196 [128/221852 (0%)]\tLoss: 0.186302\tAcc: 85.00\n",
      "val epoch: 196 [12928/221852 (6%)]\tLoss: 0.106690\tAcc: 80.00\n",
      "train epoch: 197 [128/221852 (0%)]\tLoss: 0.169031\tAcc: 80.00\n",
      "train epoch: 197 [12928/221852 (6%)]\tLoss: 0.166862\tAcc: 85.00\n",
      "train epoch: 197 [25728/221852 (12%)]\tLoss: 0.092930\tAcc: 87.00\n",
      "train epoch: 197 [38528/221852 (17%)]\tLoss: 0.183429\tAcc: 85.00\n",
      "train epoch: 197 [51328/221852 (23%)]\tLoss: 0.113984\tAcc: 80.00\n",
      "train epoch: 197 [64128/221852 (29%)]\tLoss: 0.139807\tAcc: 79.00\n",
      "train epoch: 197 [76928/221852 (35%)]\tLoss: 0.165255\tAcc: 79.00\n",
      "train epoch: 197 [89728/221852 (40%)]\tLoss: 0.136069\tAcc: 83.00\n",
      "train epoch: 197 [102528/221852 (46%)]\tLoss: 0.146444\tAcc: 77.00\n",
      "train epoch: 197 [115328/221852 (52%)]\tLoss: 0.160059\tAcc: 78.00\n",
      "train epoch: 197 [128128/221852 (58%)]\tLoss: 0.149806\tAcc: 76.00\n",
      "train epoch: 197 [140928/221852 (64%)]\tLoss: 0.177254\tAcc: 84.00\n",
      "train epoch: 197 [153728/221852 (69%)]\tLoss: 0.295125\tAcc: 80.00\n",
      "train epoch: 197 [166528/221852 (75%)]\tLoss: 0.119184\tAcc: 88.00\n",
      "train epoch: 197 [179328/221852 (81%)]\tLoss: 0.202942\tAcc: 80.00\n",
      "train epoch: 197 [192128/221852 (87%)]\tLoss: 0.196316\tAcc: 81.00\n",
      "val epoch: 197 [128/221852 (0%)]\tLoss: 0.112878\tAcc: 80.00\n",
      "val epoch: 197 [12928/221852 (6%)]\tLoss: 0.153011\tAcc: 85.00\n",
      "train epoch: 198 [128/221852 (0%)]\tLoss: 0.178862\tAcc: 80.00\n",
      "train epoch: 198 [12928/221852 (6%)]\tLoss: 0.161486\tAcc: 79.00\n",
      "train epoch: 198 [25728/221852 (12%)]\tLoss: 0.187485\tAcc: 80.00\n",
      "train epoch: 198 [38528/221852 (17%)]\tLoss: 0.195362\tAcc: 70.00\n",
      "train epoch: 198 [51328/221852 (23%)]\tLoss: 0.127545\tAcc: 86.00\n",
      "train epoch: 198 [64128/221852 (29%)]\tLoss: 0.201125\tAcc: 77.00\n",
      "train epoch: 198 [76928/221852 (35%)]\tLoss: 0.262494\tAcc: 80.00\n",
      "train epoch: 198 [89728/221852 (40%)]\tLoss: 0.265015\tAcc: 75.00\n",
      "train epoch: 198 [102528/221852 (46%)]\tLoss: 0.179047\tAcc: 70.00\n",
      "train epoch: 198 [115328/221852 (52%)]\tLoss: 0.226226\tAcc: 74.00\n",
      "train epoch: 198 [128128/221852 (58%)]\tLoss: 0.174515\tAcc: 81.00\n",
      "train epoch: 198 [140928/221852 (64%)]\tLoss: 0.103577\tAcc: 85.00\n",
      "train epoch: 198 [153728/221852 (69%)]\tLoss: 0.300879\tAcc: 77.00\n",
      "train epoch: 198 [166528/221852 (75%)]\tLoss: 0.184951\tAcc: 77.00\n",
      "train epoch: 198 [179328/221852 (81%)]\tLoss: 0.220610\tAcc: 76.00\n",
      "train epoch: 198 [192128/221852 (87%)]\tLoss: 0.117478\tAcc: 88.00\n",
      "val epoch: 198 [128/221852 (0%)]\tLoss: 0.177977\tAcc: 81.00\n",
      "val epoch: 198 [12928/221852 (6%)]\tLoss: 0.138351\tAcc: 78.00\n",
      "train epoch: 199 [128/221852 (0%)]\tLoss: 0.195983\tAcc: 80.00\n",
      "train epoch: 199 [12928/221852 (6%)]\tLoss: 0.167681\tAcc: 82.00\n",
      "train epoch: 199 [25728/221852 (12%)]\tLoss: 0.114201\tAcc: 79.00\n",
      "train epoch: 199 [38528/221852 (17%)]\tLoss: 0.159655\tAcc: 72.00\n",
      "train epoch: 199 [51328/221852 (23%)]\tLoss: 0.305893\tAcc: 77.00\n",
      "train epoch: 199 [64128/221852 (29%)]\tLoss: 0.151849\tAcc: 83.00\n",
      "train epoch: 199 [76928/221852 (35%)]\tLoss: 0.199541\tAcc: 83.00\n",
      "train epoch: 199 [89728/221852 (40%)]\tLoss: 0.189019\tAcc: 74.00\n",
      "train epoch: 199 [102528/221852 (46%)]\tLoss: 0.119150\tAcc: 84.00\n",
      "train epoch: 199 [115328/221852 (52%)]\tLoss: 0.175999\tAcc: 82.00\n",
      "train epoch: 199 [128128/221852 (58%)]\tLoss: 0.111904\tAcc: 83.00\n",
      "train epoch: 199 [140928/221852 (64%)]\tLoss: 0.121480\tAcc: 80.00\n",
      "train epoch: 199 [153728/221852 (69%)]\tLoss: 0.172172\tAcc: 84.00\n",
      "train epoch: 199 [166528/221852 (75%)]\tLoss: 0.167571\tAcc: 83.00\n",
      "train epoch: 199 [179328/221852 (81%)]\tLoss: 0.088787\tAcc: 84.00\n",
      "train epoch: 199 [192128/221852 (87%)]\tLoss: 0.185722\tAcc: 79.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 199 [128/221852 (0%)]\tLoss: 0.149262\tAcc: 83.00\n",
      "val epoch: 199 [12928/221852 (6%)]\tLoss: 0.162521\tAcc: 85.00\n",
      "saving\n",
      "train epoch: 0 [128/221852 (0%)]\tLoss: 0.696881\tAcc: 54.00\n",
      "train epoch: 0 [12928/221852 (6%)]\tLoss: 0.693931\tAcc: 57.00\n",
      "train epoch: 0 [25728/221852 (12%)]\tLoss: 0.692931\tAcc: 48.00\n",
      "train epoch: 0 [38528/221852 (17%)]\tLoss: 0.693274\tAcc: 52.00\n",
      "train epoch: 0 [51328/221852 (23%)]\tLoss: 0.691502\tAcc: 48.00\n",
      "train epoch: 0 [64128/221852 (29%)]\tLoss: 0.690698\tAcc: 54.00\n",
      "train epoch: 0 [76928/221852 (35%)]\tLoss: 0.586298\tAcc: 53.00\n",
      "train epoch: 0 [89728/221852 (40%)]\tLoss: 0.572171\tAcc: 45.00\n",
      "train epoch: 0 [102528/221852 (46%)]\tLoss: 0.562516\tAcc: 52.00\n",
      "train epoch: 0 [115328/221852 (52%)]\tLoss: 0.606899\tAcc: 51.00\n",
      "train epoch: 0 [128128/221852 (58%)]\tLoss: 0.973519\tAcc: 54.00\n",
      "train epoch: 0 [140928/221852 (64%)]\tLoss: 0.504532\tAcc: 52.00\n",
      "train epoch: 0 [153728/221852 (69%)]\tLoss: 0.628561\tAcc: 48.00\n",
      "train epoch: 0 [166528/221852 (75%)]\tLoss: 0.502565\tAcc: 50.00\n",
      "train epoch: 0 [179328/221852 (81%)]\tLoss: 0.575406\tAcc: 47.00\n",
      "train epoch: 0 [192128/221852 (87%)]\tLoss: 0.483011\tAcc: 46.00\n",
      "val epoch: 0 [128/221852 (0%)]\tLoss: 0.553949\tAcc: 51.00\n",
      "val epoch: 0 [12928/221852 (6%)]\tLoss: 0.438860\tAcc: 62.00\n",
      "train epoch: 1 [128/221852 (0%)]\tLoss: 0.487511\tAcc: 52.00\n",
      "train epoch: 1 [12928/221852 (6%)]\tLoss: 0.425960\tAcc: 48.00\n",
      "train epoch: 1 [25728/221852 (12%)]\tLoss: 0.424009\tAcc: 55.00\n",
      "train epoch: 1 [38528/221852 (17%)]\tLoss: 0.509781\tAcc: 50.00\n",
      "train epoch: 1 [51328/221852 (23%)]\tLoss: 0.414416\tAcc: 56.00\n",
      "train epoch: 1 [64128/221852 (29%)]\tLoss: 0.427500\tAcc: 62.00\n",
      "train epoch: 1 [76928/221852 (35%)]\tLoss: 0.376834\tAcc: 59.00\n",
      "train epoch: 1 [89728/221852 (40%)]\tLoss: 0.391013\tAcc: 61.00\n",
      "train epoch: 1 [102528/221852 (46%)]\tLoss: 0.411610\tAcc: 60.00\n",
      "train epoch: 1 [115328/221852 (52%)]\tLoss: 0.417262\tAcc: 58.00\n",
      "train epoch: 1 [128128/221852 (58%)]\tLoss: 0.366272\tAcc: 53.00\n",
      "train epoch: 1 [140928/221852 (64%)]\tLoss: 0.401956\tAcc: 57.00\n",
      "train epoch: 1 [153728/221852 (69%)]\tLoss: 0.330401\tAcc: 55.00\n",
      "train epoch: 1 [166528/221852 (75%)]\tLoss: 0.343554\tAcc: 58.00\n",
      "train epoch: 1 [179328/221852 (81%)]\tLoss: 0.453163\tAcc: 60.00\n",
      "train epoch: 1 [192128/221852 (87%)]\tLoss: 0.445815\tAcc: 59.00\n",
      "val epoch: 1 [128/221852 (0%)]\tLoss: 0.386797\tAcc: 50.00\n",
      "val epoch: 1 [12928/221852 (6%)]\tLoss: 0.340017\tAcc: 55.00\n",
      "train epoch: 2 [128/221852 (0%)]\tLoss: 0.368066\tAcc: 59.00\n",
      "train epoch: 2 [12928/221852 (6%)]\tLoss: 0.395588\tAcc: 55.00\n",
      "train epoch: 2 [25728/221852 (12%)]\tLoss: 0.389903\tAcc: 55.00\n",
      "train epoch: 2 [38528/221852 (17%)]\tLoss: 0.350635\tAcc: 53.00\n",
      "train epoch: 2 [51328/221852 (23%)]\tLoss: 0.602478\tAcc: 57.00\n",
      "train epoch: 2 [64128/221852 (29%)]\tLoss: 0.358859\tAcc: 62.00\n",
      "train epoch: 2 [76928/221852 (35%)]\tLoss: 0.378630\tAcc: 63.00\n",
      "train epoch: 2 [89728/221852 (40%)]\tLoss: 0.439620\tAcc: 65.00\n",
      "train epoch: 2 [102528/221852 (46%)]\tLoss: 0.425346\tAcc: 61.00\n",
      "train epoch: 2 [115328/221852 (52%)]\tLoss: 0.460935\tAcc: 55.00\n",
      "train epoch: 2 [128128/221852 (58%)]\tLoss: 0.350151\tAcc: 57.00\n",
      "train epoch: 2 [140928/221852 (64%)]\tLoss: 0.364289\tAcc: 57.00\n",
      "train epoch: 2 [153728/221852 (69%)]\tLoss: 0.374886\tAcc: 70.00\n",
      "train epoch: 2 [166528/221852 (75%)]\tLoss: 0.417715\tAcc: 57.00\n",
      "train epoch: 2 [179328/221852 (81%)]\tLoss: 0.308458\tAcc: 60.00\n",
      "train epoch: 2 [192128/221852 (87%)]\tLoss: 0.495423\tAcc: 59.00\n",
      "val epoch: 2 [128/221852 (0%)]\tLoss: 0.397194\tAcc: 66.00\n",
      "val epoch: 2 [12928/221852 (6%)]\tLoss: 0.306373\tAcc: 62.00\n",
      "train epoch: 3 [128/221852 (0%)]\tLoss: 0.417398\tAcc: 62.00\n",
      "train epoch: 3 [12928/221852 (6%)]\tLoss: 0.387793\tAcc: 58.00\n",
      "train epoch: 3 [25728/221852 (12%)]\tLoss: 0.429706\tAcc: 58.00\n",
      "train epoch: 3 [38528/221852 (17%)]\tLoss: 0.368212\tAcc: 59.00\n",
      "train epoch: 3 [51328/221852 (23%)]\tLoss: 0.422374\tAcc: 56.00\n",
      "train epoch: 3 [64128/221852 (29%)]\tLoss: 0.320642\tAcc: 69.00\n",
      "train epoch: 3 [76928/221852 (35%)]\tLoss: 0.331091\tAcc: 62.00\n",
      "train epoch: 3 [89728/221852 (40%)]\tLoss: 0.298719\tAcc: 57.00\n",
      "train epoch: 3 [102528/221852 (46%)]\tLoss: 0.300869\tAcc: 63.00\n",
      "train epoch: 3 [115328/221852 (52%)]\tLoss: 0.309676\tAcc: 63.00\n",
      "train epoch: 3 [128128/221852 (58%)]\tLoss: 0.360792\tAcc: 61.00\n",
      "train epoch: 3 [140928/221852 (64%)]\tLoss: 0.358071\tAcc: 59.00\n",
      "train epoch: 3 [153728/221852 (69%)]\tLoss: 0.347293\tAcc: 53.00\n",
      "train epoch: 3 [166528/221852 (75%)]\tLoss: 0.401272\tAcc: 56.00\n",
      "train epoch: 3 [179328/221852 (81%)]\tLoss: 0.552028\tAcc: 55.00\n",
      "train epoch: 3 [192128/221852 (87%)]\tLoss: 0.361504\tAcc: 67.00\n",
      "val epoch: 3 [128/221852 (0%)]\tLoss: 0.304644\tAcc: 62.00\n",
      "val epoch: 3 [12928/221852 (6%)]\tLoss: 0.371631\tAcc: 55.00\n",
      "train epoch: 4 [128/221852 (0%)]\tLoss: 0.426729\tAcc: 66.00\n",
      "train epoch: 4 [12928/221852 (6%)]\tLoss: 0.307690\tAcc: 62.00\n",
      "train epoch: 4 [25728/221852 (12%)]\tLoss: 0.387823\tAcc: 54.00\n",
      "train epoch: 4 [38528/221852 (17%)]\tLoss: 0.400823\tAcc: 55.00\n",
      "train epoch: 4 [51328/221852 (23%)]\tLoss: 0.414390\tAcc: 62.00\n",
      "train epoch: 4 [64128/221852 (29%)]\tLoss: 0.398706\tAcc: 58.00\n",
      "train epoch: 4 [76928/221852 (35%)]\tLoss: 0.292059\tAcc: 59.00\n",
      "train epoch: 4 [89728/221852 (40%)]\tLoss: 0.374422\tAcc: 52.00\n",
      "train epoch: 4 [102528/221852 (46%)]\tLoss: 0.406177\tAcc: 63.00\n",
      "train epoch: 4 [115328/221852 (52%)]\tLoss: 0.428975\tAcc: 57.00\n",
      "train epoch: 4 [128128/221852 (58%)]\tLoss: 0.437408\tAcc: 63.00\n",
      "train epoch: 4 [140928/221852 (64%)]\tLoss: 0.428491\tAcc: 55.00\n",
      "train epoch: 4 [153728/221852 (69%)]\tLoss: 0.400881\tAcc: 60.00\n",
      "train epoch: 4 [166528/221852 (75%)]\tLoss: 0.364606\tAcc: 57.00\n",
      "train epoch: 4 [179328/221852 (81%)]\tLoss: 0.378047\tAcc: 55.00\n",
      "train epoch: 4 [192128/221852 (87%)]\tLoss: 0.375084\tAcc: 60.00\n",
      "val epoch: 4 [128/221852 (0%)]\tLoss: 0.404635\tAcc: 61.00\n",
      "val epoch: 4 [12928/221852 (6%)]\tLoss: 0.337986\tAcc: 62.00\n",
      "train epoch: 5 [128/221852 (0%)]\tLoss: 0.371677\tAcc: 61.00\n",
      "train epoch: 5 [12928/221852 (6%)]\tLoss: 0.418832\tAcc: 65.00\n",
      "train epoch: 5 [25728/221852 (12%)]\tLoss: 0.412374\tAcc: 62.00\n",
      "train epoch: 5 [38528/221852 (17%)]\tLoss: 0.269823\tAcc: 67.00\n",
      "train epoch: 5 [51328/221852 (23%)]\tLoss: 0.307531\tAcc: 66.00\n",
      "train epoch: 5 [64128/221852 (29%)]\tLoss: 0.323037\tAcc: 68.00\n",
      "train epoch: 5 [76928/221852 (35%)]\tLoss: 0.373739\tAcc: 65.00\n",
      "train epoch: 5 [89728/221852 (40%)]\tLoss: 0.292524\tAcc: 66.00\n",
      "train epoch: 5 [102528/221852 (46%)]\tLoss: 0.420973\tAcc: 62.00\n",
      "train epoch: 5 [115328/221852 (52%)]\tLoss: 0.236490\tAcc: 64.00\n",
      "train epoch: 5 [128128/221852 (58%)]\tLoss: 0.370523\tAcc: 67.00\n",
      "train epoch: 5 [140928/221852 (64%)]\tLoss: 0.389771\tAcc: 62.00\n",
      "train epoch: 5 [153728/221852 (69%)]\tLoss: 0.296009\tAcc: 70.00\n",
      "train epoch: 5 [166528/221852 (75%)]\tLoss: 0.368441\tAcc: 62.00\n",
      "train epoch: 5 [179328/221852 (81%)]\tLoss: 0.396067\tAcc: 59.00\n",
      "train epoch: 5 [192128/221852 (87%)]\tLoss: 0.378589\tAcc: 65.00\n",
      "val epoch: 5 [128/221852 (0%)]\tLoss: 0.274137\tAcc: 60.00\n",
      "val epoch: 5 [12928/221852 (6%)]\tLoss: 0.305441\tAcc: 66.00\n",
      "train epoch: 6 [128/221852 (0%)]\tLoss: 0.335478\tAcc: 63.00\n",
      "train epoch: 6 [12928/221852 (6%)]\tLoss: 0.358388\tAcc: 69.00\n",
      "train epoch: 6 [25728/221852 (12%)]\tLoss: 0.560821\tAcc: 64.00\n",
      "train epoch: 6 [38528/221852 (17%)]\tLoss: 0.401679\tAcc: 63.00\n",
      "train epoch: 6 [51328/221852 (23%)]\tLoss: 0.412098\tAcc: 64.00\n",
      "train epoch: 6 [64128/221852 (29%)]\tLoss: 0.345736\tAcc: 61.00\n",
      "train epoch: 6 [76928/221852 (35%)]\tLoss: 0.333940\tAcc: 63.00\n",
      "train epoch: 6 [89728/221852 (40%)]\tLoss: 0.379033\tAcc: 59.00\n",
      "train epoch: 6 [102528/221852 (46%)]\tLoss: 0.416446\tAcc: 58.00\n",
      "train epoch: 6 [115328/221852 (52%)]\tLoss: 0.396949\tAcc: 57.00\n",
      "train epoch: 6 [128128/221852 (58%)]\tLoss: 0.472033\tAcc: 68.00\n",
      "train epoch: 6 [140928/221852 (64%)]\tLoss: 0.307360\tAcc: 62.00\n",
      "train epoch: 6 [153728/221852 (69%)]\tLoss: 0.401813\tAcc: 64.00\n",
      "train epoch: 6 [166528/221852 (75%)]\tLoss: 0.373780\tAcc: 62.00\n",
      "train epoch: 6 [179328/221852 (81%)]\tLoss: 0.374955\tAcc: 62.00\n",
      "train epoch: 6 [192128/221852 (87%)]\tLoss: 0.414809\tAcc: 55.00\n",
      "val epoch: 6 [128/221852 (0%)]\tLoss: 0.290745\tAcc: 60.00\n",
      "val epoch: 6 [12928/221852 (6%)]\tLoss: 0.374640\tAcc: 57.00\n",
      "train epoch: 7 [128/221852 (0%)]\tLoss: 0.296999\tAcc: 61.00\n",
      "train epoch: 7 [12928/221852 (6%)]\tLoss: 0.368144\tAcc: 63.00\n",
      "train epoch: 7 [25728/221852 (12%)]\tLoss: 0.340620\tAcc: 64.00\n",
      "train epoch: 7 [38528/221852 (17%)]\tLoss: 0.302742\tAcc: 66.00\n",
      "train epoch: 7 [51328/221852 (23%)]\tLoss: 0.332522\tAcc: 70.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 7 [64128/221852 (29%)]\tLoss: 0.328553\tAcc: 62.00\n",
      "train epoch: 7 [76928/221852 (35%)]\tLoss: 0.433792\tAcc: 55.00\n",
      "train epoch: 7 [89728/221852 (40%)]\tLoss: 0.338162\tAcc: 63.00\n",
      "train epoch: 7 [102528/221852 (46%)]\tLoss: 0.374013\tAcc: 60.00\n",
      "train epoch: 7 [115328/221852 (52%)]\tLoss: 0.363511\tAcc: 62.00\n",
      "train epoch: 7 [128128/221852 (58%)]\tLoss: 0.457150\tAcc: 66.00\n",
      "train epoch: 7 [140928/221852 (64%)]\tLoss: 0.284307\tAcc: 65.00\n",
      "train epoch: 7 [153728/221852 (69%)]\tLoss: 0.368355\tAcc: 58.00\n",
      "train epoch: 7 [166528/221852 (75%)]\tLoss: 0.337087\tAcc: 70.00\n",
      "train epoch: 7 [179328/221852 (81%)]\tLoss: 0.301585\tAcc: 65.00\n",
      "train epoch: 7 [192128/221852 (87%)]\tLoss: 0.298784\tAcc: 66.00\n",
      "val epoch: 7 [128/221852 (0%)]\tLoss: 0.383249\tAcc: 67.00\n",
      "val epoch: 7 [12928/221852 (6%)]\tLoss: 0.388391\tAcc: 61.00\n",
      "train epoch: 8 [128/221852 (0%)]\tLoss: 0.287812\tAcc: 71.00\n",
      "train epoch: 8 [12928/221852 (6%)]\tLoss: 0.350305\tAcc: 59.00\n",
      "train epoch: 8 [25728/221852 (12%)]\tLoss: 0.382319\tAcc: 61.00\n",
      "train epoch: 8 [38528/221852 (17%)]\tLoss: 0.456138\tAcc: 59.00\n",
      "train epoch: 8 [51328/221852 (23%)]\tLoss: 0.267773\tAcc: 62.00\n",
      "train epoch: 8 [64128/221852 (29%)]\tLoss: 0.400634\tAcc: 60.00\n",
      "train epoch: 8 [76928/221852 (35%)]\tLoss: 0.348643\tAcc: 62.00\n",
      "train epoch: 8 [89728/221852 (40%)]\tLoss: 0.372042\tAcc: 63.00\n",
      "train epoch: 8 [102528/221852 (46%)]\tLoss: 0.277951\tAcc: 62.00\n",
      "train epoch: 8 [115328/221852 (52%)]\tLoss: 0.257101\tAcc: 64.00\n",
      "train epoch: 8 [128128/221852 (58%)]\tLoss: 0.306187\tAcc: 59.00\n",
      "train epoch: 8 [140928/221852 (64%)]\tLoss: 0.297273\tAcc: 64.00\n",
      "train epoch: 8 [153728/221852 (69%)]\tLoss: 0.428780\tAcc: 65.00\n",
      "train epoch: 8 [166528/221852 (75%)]\tLoss: 0.231931\tAcc: 71.00\n",
      "train epoch: 8 [179328/221852 (81%)]\tLoss: 0.343866\tAcc: 62.00\n",
      "train epoch: 8 [192128/221852 (87%)]\tLoss: 0.349771\tAcc: 68.00\n",
      "val epoch: 8 [128/221852 (0%)]\tLoss: 0.299973\tAcc: 65.00\n",
      "val epoch: 8 [12928/221852 (6%)]\tLoss: 0.283446\tAcc: 67.00\n",
      "train epoch: 9 [128/221852 (0%)]\tLoss: 0.259042\tAcc: 57.00\n",
      "train epoch: 9 [12928/221852 (6%)]\tLoss: 0.254373\tAcc: 67.00\n",
      "train epoch: 9 [25728/221852 (12%)]\tLoss: 0.273392\tAcc: 66.00\n",
      "train epoch: 9 [38528/221852 (17%)]\tLoss: 0.341835\tAcc: 63.00\n",
      "train epoch: 9 [51328/221852 (23%)]\tLoss: 0.256337\tAcc: 67.00\n",
      "train epoch: 9 [64128/221852 (29%)]\tLoss: 0.411421\tAcc: 62.00\n",
      "train epoch: 9 [76928/221852 (35%)]\tLoss: 0.310449\tAcc: 66.00\n",
      "train epoch: 9 [89728/221852 (40%)]\tLoss: 0.283831\tAcc: 67.00\n",
      "train epoch: 9 [102528/221852 (46%)]\tLoss: 0.241272\tAcc: 62.00\n",
      "train epoch: 9 [115328/221852 (52%)]\tLoss: 0.221836\tAcc: 66.00\n",
      "train epoch: 9 [128128/221852 (58%)]\tLoss: 0.334194\tAcc: 62.00\n",
      "train epoch: 9 [140928/221852 (64%)]\tLoss: 0.314793\tAcc: 66.00\n",
      "train epoch: 9 [153728/221852 (69%)]\tLoss: 0.312156\tAcc: 62.00\n",
      "train epoch: 9 [166528/221852 (75%)]\tLoss: 0.339813\tAcc: 67.00\n",
      "train epoch: 9 [179328/221852 (81%)]\tLoss: 0.279648\tAcc: 64.00\n",
      "train epoch: 9 [192128/221852 (87%)]\tLoss: 0.313871\tAcc: 64.00\n",
      "val epoch: 9 [128/221852 (0%)]\tLoss: 0.431884\tAcc: 62.00\n",
      "val epoch: 9 [12928/221852 (6%)]\tLoss: 0.303683\tAcc: 58.00\n",
      "train epoch: 10 [128/221852 (0%)]\tLoss: 0.308462\tAcc: 59.00\n",
      "train epoch: 10 [12928/221852 (6%)]\tLoss: 0.341205\tAcc: 72.00\n",
      "train epoch: 10 [25728/221852 (12%)]\tLoss: 0.342886\tAcc: 62.00\n",
      "train epoch: 10 [38528/221852 (17%)]\tLoss: 0.324162\tAcc: 67.00\n",
      "train epoch: 10 [51328/221852 (23%)]\tLoss: 0.284979\tAcc: 70.00\n",
      "train epoch: 10 [64128/221852 (29%)]\tLoss: 0.351741\tAcc: 62.00\n",
      "train epoch: 10 [76928/221852 (35%)]\tLoss: 0.234322\tAcc: 64.00\n",
      "train epoch: 10 [89728/221852 (40%)]\tLoss: 0.476693\tAcc: 45.00\n",
      "train epoch: 10 [102528/221852 (46%)]\tLoss: 0.376669\tAcc: 58.00\n",
      "train epoch: 10 [115328/221852 (52%)]\tLoss: 0.269204\tAcc: 63.00\n",
      "train epoch: 10 [128128/221852 (58%)]\tLoss: 0.311446\tAcc: 58.00\n",
      "train epoch: 10 [140928/221852 (64%)]\tLoss: 0.371746\tAcc: 61.00\n",
      "train epoch: 10 [153728/221852 (69%)]\tLoss: 0.386841\tAcc: 62.00\n",
      "train epoch: 10 [166528/221852 (75%)]\tLoss: 0.385301\tAcc: 53.00\n",
      "train epoch: 10 [179328/221852 (81%)]\tLoss: 0.343910\tAcc: 61.00\n",
      "train epoch: 10 [192128/221852 (87%)]\tLoss: 0.455807\tAcc: 72.00\n",
      "val epoch: 10 [128/221852 (0%)]\tLoss: 0.265144\tAcc: 61.00\n",
      "val epoch: 10 [12928/221852 (6%)]\tLoss: 0.378841\tAcc: 57.00\n",
      "train epoch: 11 [128/221852 (0%)]\tLoss: 0.322320\tAcc: 58.00\n",
      "train epoch: 11 [12928/221852 (6%)]\tLoss: 0.380447\tAcc: 63.00\n",
      "train epoch: 11 [25728/221852 (12%)]\tLoss: 0.328653\tAcc: 66.00\n",
      "train epoch: 11 [38528/221852 (17%)]\tLoss: 0.280487\tAcc: 64.00\n",
      "train epoch: 11 [51328/221852 (23%)]\tLoss: 0.311630\tAcc: 69.00\n",
      "train epoch: 11 [64128/221852 (29%)]\tLoss: 0.263519\tAcc: 66.00\n",
      "train epoch: 11 [76928/221852 (35%)]\tLoss: 0.384923\tAcc: 65.00\n",
      "train epoch: 11 [89728/221852 (40%)]\tLoss: 0.335506\tAcc: 67.00\n",
      "train epoch: 11 [102528/221852 (46%)]\tLoss: 0.296527\tAcc: 75.00\n",
      "train epoch: 11 [115328/221852 (52%)]\tLoss: 0.614856\tAcc: 63.00\n",
      "train epoch: 11 [128128/221852 (58%)]\tLoss: 0.284192\tAcc: 66.00\n",
      "train epoch: 11 [140928/221852 (64%)]\tLoss: 0.272629\tAcc: 66.00\n",
      "train epoch: 11 [153728/221852 (69%)]\tLoss: 0.493488\tAcc: 70.00\n",
      "train epoch: 11 [166528/221852 (75%)]\tLoss: 0.261395\tAcc: 63.00\n",
      "train epoch: 11 [179328/221852 (81%)]\tLoss: 0.287285\tAcc: 59.00\n",
      "train epoch: 11 [192128/221852 (87%)]\tLoss: 0.272533\tAcc: 59.00\n",
      "val epoch: 11 [128/221852 (0%)]\tLoss: 0.305641\tAcc: 62.00\n",
      "val epoch: 11 [12928/221852 (6%)]\tLoss: 0.333898\tAcc: 59.00\n",
      "train epoch: 12 [128/221852 (0%)]\tLoss: 0.352057\tAcc: 63.00\n",
      "train epoch: 12 [12928/221852 (6%)]\tLoss: 0.275005\tAcc: 71.00\n",
      "train epoch: 12 [25728/221852 (12%)]\tLoss: 0.268765\tAcc: 64.00\n",
      "train epoch: 12 [38528/221852 (17%)]\tLoss: 0.258908\tAcc: 64.00\n",
      "train epoch: 12 [51328/221852 (23%)]\tLoss: 0.235830\tAcc: 70.00\n",
      "train epoch: 12 [64128/221852 (29%)]\tLoss: 0.307152\tAcc: 63.00\n",
      "train epoch: 12 [76928/221852 (35%)]\tLoss: 0.417843\tAcc: 60.00\n",
      "train epoch: 12 [89728/221852 (40%)]\tLoss: 0.254491\tAcc: 70.00\n",
      "train epoch: 12 [102528/221852 (46%)]\tLoss: 0.376512\tAcc: 60.00\n",
      "train epoch: 12 [115328/221852 (52%)]\tLoss: 0.308166\tAcc: 62.00\n",
      "train epoch: 12 [128128/221852 (58%)]\tLoss: 0.352220\tAcc: 62.00\n",
      "train epoch: 12 [140928/221852 (64%)]\tLoss: 0.291585\tAcc: 66.00\n",
      "train epoch: 12 [153728/221852 (69%)]\tLoss: 0.262542\tAcc: 64.00\n",
      "train epoch: 12 [166528/221852 (75%)]\tLoss: 1.027289\tAcc: 69.00\n",
      "train epoch: 12 [179328/221852 (81%)]\tLoss: 0.287560\tAcc: 66.00\n",
      "train epoch: 12 [192128/221852 (87%)]\tLoss: 0.272452\tAcc: 66.00\n",
      "val epoch: 12 [128/221852 (0%)]\tLoss: 0.273607\tAcc: 60.00\n",
      "val epoch: 12 [12928/221852 (6%)]\tLoss: 0.293441\tAcc: 65.00\n",
      "train epoch: 13 [128/221852 (0%)]\tLoss: 0.244153\tAcc: 69.00\n",
      "train epoch: 13 [12928/221852 (6%)]\tLoss: 0.264758\tAcc: 66.00\n",
      "train epoch: 13 [25728/221852 (12%)]\tLoss: 0.336656\tAcc: 64.00\n",
      "train epoch: 13 [38528/221852 (17%)]\tLoss: 0.251916\tAcc: 62.00\n",
      "train epoch: 13 [51328/221852 (23%)]\tLoss: 0.349304\tAcc: 59.00\n",
      "train epoch: 13 [64128/221852 (29%)]\tLoss: 0.269183\tAcc: 67.00\n",
      "train epoch: 13 [76928/221852 (35%)]\tLoss: 0.338824\tAcc: 66.00\n",
      "train epoch: 13 [89728/221852 (40%)]\tLoss: 0.232438\tAcc: 66.00\n",
      "train epoch: 13 [102528/221852 (46%)]\tLoss: 0.304662\tAcc: 65.00\n",
      "train epoch: 13 [115328/221852 (52%)]\tLoss: 0.268982\tAcc: 73.00\n",
      "train epoch: 13 [128128/221852 (58%)]\tLoss: 0.427480\tAcc: 63.00\n",
      "train epoch: 13 [140928/221852 (64%)]\tLoss: 0.291307\tAcc: 56.00\n",
      "train epoch: 13 [153728/221852 (69%)]\tLoss: 0.191188\tAcc: 68.00\n",
      "train epoch: 13 [166528/221852 (75%)]\tLoss: 0.344349\tAcc: 62.00\n",
      "train epoch: 13 [179328/221852 (81%)]\tLoss: 0.331115\tAcc: 59.00\n",
      "train epoch: 13 [192128/221852 (87%)]\tLoss: 0.259970\tAcc: 67.00\n",
      "val epoch: 13 [128/221852 (0%)]\tLoss: 0.415092\tAcc: 63.00\n",
      "val epoch: 13 [12928/221852 (6%)]\tLoss: 0.274151\tAcc: 58.00\n",
      "train epoch: 14 [128/221852 (0%)]\tLoss: 0.312290\tAcc: 69.00\n",
      "train epoch: 14 [12928/221852 (6%)]\tLoss: 0.385798\tAcc: 68.00\n",
      "train epoch: 14 [25728/221852 (12%)]\tLoss: 0.232720\tAcc: 69.00\n",
      "train epoch: 14 [38528/221852 (17%)]\tLoss: 0.258881\tAcc: 71.00\n",
      "train epoch: 14 [51328/221852 (23%)]\tLoss: 0.299539\tAcc: 65.00\n",
      "train epoch: 14 [64128/221852 (29%)]\tLoss: 0.421166\tAcc: 62.00\n",
      "train epoch: 14 [76928/221852 (35%)]\tLoss: 0.294752\tAcc: 63.00\n",
      "train epoch: 14 [89728/221852 (40%)]\tLoss: 0.306513\tAcc: 62.00\n",
      "train epoch: 14 [102528/221852 (46%)]\tLoss: 0.283804\tAcc: 64.00\n",
      "train epoch: 14 [115328/221852 (52%)]\tLoss: 0.254282\tAcc: 65.00\n",
      "train epoch: 14 [128128/221852 (58%)]\tLoss: 0.313083\tAcc: 62.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 14 [140928/221852 (64%)]\tLoss: 0.306547\tAcc: 62.00\n",
      "train epoch: 14 [153728/221852 (69%)]\tLoss: 0.374383\tAcc: 64.00\n",
      "train epoch: 14 [166528/221852 (75%)]\tLoss: 0.292796\tAcc: 67.00\n",
      "train epoch: 14 [179328/221852 (81%)]\tLoss: 0.304316\tAcc: 67.00\n",
      "train epoch: 14 [192128/221852 (87%)]\tLoss: 0.396476\tAcc: 63.00\n",
      "val epoch: 14 [128/221852 (0%)]\tLoss: 0.197286\tAcc: 60.00\n",
      "val epoch: 14 [12928/221852 (6%)]\tLoss: 0.304157\tAcc: 65.00\n",
      "train epoch: 15 [128/221852 (0%)]\tLoss: 0.263151\tAcc: 72.00\n",
      "train epoch: 15 [12928/221852 (6%)]\tLoss: 0.363435\tAcc: 66.00\n",
      "train epoch: 15 [25728/221852 (12%)]\tLoss: 0.230341\tAcc: 66.00\n",
      "train epoch: 15 [38528/221852 (17%)]\tLoss: 0.316881\tAcc: 69.00\n",
      "train epoch: 15 [51328/221852 (23%)]\tLoss: 0.693641\tAcc: 69.00\n",
      "train epoch: 15 [64128/221852 (29%)]\tLoss: 0.342710\tAcc: 64.00\n",
      "train epoch: 15 [76928/221852 (35%)]\tLoss: 0.346490\tAcc: 61.00\n",
      "train epoch: 15 [89728/221852 (40%)]\tLoss: 0.287156\tAcc: 62.00\n",
      "train epoch: 15 [102528/221852 (46%)]\tLoss: 0.215532\tAcc: 59.00\n",
      "train epoch: 15 [115328/221852 (52%)]\tLoss: 0.301378\tAcc: 67.00\n",
      "train epoch: 15 [128128/221852 (58%)]\tLoss: 0.307078\tAcc: 68.00\n",
      "train epoch: 15 [140928/221852 (64%)]\tLoss: 0.234131\tAcc: 67.00\n",
      "train epoch: 15 [153728/221852 (69%)]\tLoss: 0.246174\tAcc: 59.00\n",
      "train epoch: 15 [166528/221852 (75%)]\tLoss: 0.310341\tAcc: 64.00\n",
      "train epoch: 15 [179328/221852 (81%)]\tLoss: 0.291570\tAcc: 70.00\n",
      "train epoch: 15 [192128/221852 (87%)]\tLoss: 0.207331\tAcc: 60.00\n",
      "val epoch: 15 [128/221852 (0%)]\tLoss: 0.294195\tAcc: 69.00\n",
      "val epoch: 15 [12928/221852 (6%)]\tLoss: 0.268276\tAcc: 71.00\n",
      "train epoch: 16 [128/221852 (0%)]\tLoss: 0.292203\tAcc: 70.00\n",
      "train epoch: 16 [12928/221852 (6%)]\tLoss: 0.344185\tAcc: 66.00\n",
      "train epoch: 16 [25728/221852 (12%)]\tLoss: 0.255202\tAcc: 68.00\n",
      "train epoch: 16 [38528/221852 (17%)]\tLoss: 0.286140\tAcc: 62.00\n",
      "train epoch: 16 [51328/221852 (23%)]\tLoss: 0.312295\tAcc: 66.00\n",
      "train epoch: 16 [64128/221852 (29%)]\tLoss: 0.249227\tAcc: 72.00\n",
      "train epoch: 16 [76928/221852 (35%)]\tLoss: 0.240918\tAcc: 71.00\n",
      "train epoch: 16 [89728/221852 (40%)]\tLoss: 0.242738\tAcc: 70.00\n",
      "train epoch: 16 [102528/221852 (46%)]\tLoss: 0.138703\tAcc: 74.00\n",
      "train epoch: 16 [115328/221852 (52%)]\tLoss: 0.289377\tAcc: 60.00\n",
      "train epoch: 16 [128128/221852 (58%)]\tLoss: 0.237536\tAcc: 65.00\n",
      "train epoch: 16 [140928/221852 (64%)]\tLoss: 0.292996\tAcc: 66.00\n",
      "train epoch: 16 [153728/221852 (69%)]\tLoss: 0.290637\tAcc: 70.00\n",
      "train epoch: 16 [166528/221852 (75%)]\tLoss: 0.324732\tAcc: 67.00\n",
      "train epoch: 16 [179328/221852 (81%)]\tLoss: 0.318314\tAcc: 66.00\n",
      "train epoch: 16 [192128/221852 (87%)]\tLoss: 0.236180\tAcc: 66.00\n",
      "val epoch: 16 [128/221852 (0%)]\tLoss: 0.385937\tAcc: 59.00\n",
      "val epoch: 16 [12928/221852 (6%)]\tLoss: 0.280549\tAcc: 70.00\n",
      "train epoch: 17 [128/221852 (0%)]\tLoss: 0.261053\tAcc: 62.00\n",
      "train epoch: 17 [12928/221852 (6%)]\tLoss: 0.342561\tAcc: 60.00\n",
      "train epoch: 17 [25728/221852 (12%)]\tLoss: 0.263259\tAcc: 70.00\n",
      "train epoch: 17 [38528/221852 (17%)]\tLoss: 0.421650\tAcc: 66.00\n",
      "train epoch: 17 [51328/221852 (23%)]\tLoss: 0.299803\tAcc: 66.00\n",
      "train epoch: 17 [64128/221852 (29%)]\tLoss: 0.316625\tAcc: 62.00\n",
      "train epoch: 17 [76928/221852 (35%)]\tLoss: 0.286086\tAcc: 70.00\n",
      "train epoch: 17 [89728/221852 (40%)]\tLoss: 0.279030\tAcc: 59.00\n",
      "train epoch: 17 [102528/221852 (46%)]\tLoss: 0.196167\tAcc: 65.00\n",
      "train epoch: 17 [115328/221852 (52%)]\tLoss: 0.248064\tAcc: 60.00\n",
      "train epoch: 17 [128128/221852 (58%)]\tLoss: 0.277078\tAcc: 66.00\n",
      "train epoch: 17 [140928/221852 (64%)]\tLoss: 0.280016\tAcc: 67.00\n",
      "train epoch: 17 [153728/221852 (69%)]\tLoss: 0.335144\tAcc: 70.00\n",
      "train epoch: 17 [166528/221852 (75%)]\tLoss: 0.325287\tAcc: 62.00\n",
      "train epoch: 17 [179328/221852 (81%)]\tLoss: 0.207289\tAcc: 65.00\n",
      "train epoch: 17 [192128/221852 (87%)]\tLoss: 0.356111\tAcc: 65.00\n",
      "val epoch: 17 [128/221852 (0%)]\tLoss: 0.272368\tAcc: 62.00\n",
      "val epoch: 17 [12928/221852 (6%)]\tLoss: 0.370181\tAcc: 59.00\n",
      "train epoch: 18 [128/221852 (0%)]\tLoss: 0.319565\tAcc: 63.00\n",
      "train epoch: 18 [12928/221852 (6%)]\tLoss: 0.340413\tAcc: 67.00\n",
      "train epoch: 18 [25728/221852 (12%)]\tLoss: 0.191868\tAcc: 73.00\n",
      "train epoch: 18 [38528/221852 (17%)]\tLoss: 0.188576\tAcc: 64.00\n",
      "train epoch: 18 [51328/221852 (23%)]\tLoss: 0.337326\tAcc: 62.00\n",
      "train epoch: 18 [64128/221852 (29%)]\tLoss: 0.303889\tAcc: 67.00\n",
      "train epoch: 18 [76928/221852 (35%)]\tLoss: 0.310014\tAcc: 67.00\n",
      "train epoch: 18 [89728/221852 (40%)]\tLoss: 0.382694\tAcc: 64.00\n",
      "train epoch: 18 [102528/221852 (46%)]\tLoss: 0.246242\tAcc: 73.00\n",
      "train epoch: 18 [115328/221852 (52%)]\tLoss: 0.346691\tAcc: 66.00\n",
      "train epoch: 18 [128128/221852 (58%)]\tLoss: 0.288672\tAcc: 70.00\n",
      "train epoch: 18 [140928/221852 (64%)]\tLoss: 0.219773\tAcc: 63.00\n",
      "train epoch: 18 [153728/221852 (69%)]\tLoss: 0.282466\tAcc: 68.00\n",
      "train epoch: 18 [166528/221852 (75%)]\tLoss: 0.285621\tAcc: 65.00\n",
      "train epoch: 18 [179328/221852 (81%)]\tLoss: 0.338673\tAcc: 68.00\n",
      "train epoch: 18 [192128/221852 (87%)]\tLoss: 0.430986\tAcc: 63.00\n",
      "val epoch: 18 [128/221852 (0%)]\tLoss: 0.259587\tAcc: 64.00\n",
      "val epoch: 18 [12928/221852 (6%)]\tLoss: 0.312741\tAcc: 64.00\n",
      "train epoch: 19 [128/221852 (0%)]\tLoss: 0.334604\tAcc: 62.00\n",
      "train epoch: 19 [12928/221852 (6%)]\tLoss: 0.265256\tAcc: 62.00\n",
      "train epoch: 19 [25728/221852 (12%)]\tLoss: 0.219295\tAcc: 75.00\n",
      "train epoch: 19 [38528/221852 (17%)]\tLoss: 0.272572\tAcc: 66.00\n",
      "train epoch: 19 [51328/221852 (23%)]\tLoss: 0.230577\tAcc: 69.00\n",
      "train epoch: 19 [64128/221852 (29%)]\tLoss: 0.271888\tAcc: 70.00\n",
      "train epoch: 19 [76928/221852 (35%)]\tLoss: 0.225535\tAcc: 73.00\n",
      "train epoch: 19 [89728/221852 (40%)]\tLoss: 0.274115\tAcc: 66.00\n",
      "train epoch: 19 [102528/221852 (46%)]\tLoss: 0.297922\tAcc: 66.00\n",
      "train epoch: 19 [115328/221852 (52%)]\tLoss: 0.237591\tAcc: 71.00\n",
      "train epoch: 19 [128128/221852 (58%)]\tLoss: 0.248427\tAcc: 65.00\n",
      "train epoch: 19 [140928/221852 (64%)]\tLoss: 0.178294\tAcc: 75.00\n",
      "train epoch: 19 [153728/221852 (69%)]\tLoss: 0.367101\tAcc: 59.00\n",
      "train epoch: 19 [166528/221852 (75%)]\tLoss: 0.331882\tAcc: 65.00\n",
      "train epoch: 19 [179328/221852 (81%)]\tLoss: 0.216799\tAcc: 75.00\n",
      "train epoch: 19 [192128/221852 (87%)]\tLoss: 0.396904\tAcc: 51.00\n",
      "val epoch: 19 [128/221852 (0%)]\tLoss: 0.455578\tAcc: 59.00\n",
      "val epoch: 19 [12928/221852 (6%)]\tLoss: 0.317449\tAcc: 62.00\n",
      "train epoch: 20 [128/221852 (0%)]\tLoss: 0.301278\tAcc: 62.00\n",
      "train epoch: 20 [12928/221852 (6%)]\tLoss: 0.326183\tAcc: 61.00\n",
      "train epoch: 20 [25728/221852 (12%)]\tLoss: 0.387006\tAcc: 68.00\n",
      "train epoch: 20 [38528/221852 (17%)]\tLoss: 0.300706\tAcc: 61.00\n",
      "train epoch: 20 [51328/221852 (23%)]\tLoss: 0.356493\tAcc: 62.00\n",
      "train epoch: 20 [64128/221852 (29%)]\tLoss: 0.331604\tAcc: 65.00\n",
      "train epoch: 20 [76928/221852 (35%)]\tLoss: 0.333456\tAcc: 63.00\n",
      "train epoch: 20 [89728/221852 (40%)]\tLoss: 0.333836\tAcc: 55.00\n",
      "train epoch: 20 [102528/221852 (46%)]\tLoss: 0.295358\tAcc: 69.00\n",
      "train epoch: 20 [115328/221852 (52%)]\tLoss: 0.318082\tAcc: 64.00\n",
      "train epoch: 20 [128128/221852 (58%)]\tLoss: 0.291495\tAcc: 65.00\n",
      "train epoch: 20 [140928/221852 (64%)]\tLoss: 0.287874\tAcc: 66.00\n",
      "train epoch: 20 [153728/221852 (69%)]\tLoss: 0.247675\tAcc: 68.00\n",
      "train epoch: 20 [166528/221852 (75%)]\tLoss: 0.354067\tAcc: 59.00\n",
      "train epoch: 20 [179328/221852 (81%)]\tLoss: 0.379306\tAcc: 66.00\n",
      "train epoch: 20 [192128/221852 (87%)]\tLoss: 0.361352\tAcc: 66.00\n",
      "val epoch: 20 [128/221852 (0%)]\tLoss: 0.230642\tAcc: 69.00\n",
      "val epoch: 20 [12928/221852 (6%)]\tLoss: 0.300272\tAcc: 64.00\n",
      "train epoch: 21 [128/221852 (0%)]\tLoss: 0.326603\tAcc: 55.00\n",
      "train epoch: 21 [12928/221852 (6%)]\tLoss: 0.270790\tAcc: 69.00\n",
      "train epoch: 21 [25728/221852 (12%)]\tLoss: 0.391900\tAcc: 70.00\n",
      "train epoch: 21 [38528/221852 (17%)]\tLoss: 0.276652\tAcc: 67.00\n",
      "train epoch: 21 [51328/221852 (23%)]\tLoss: 0.375394\tAcc: 69.00\n",
      "train epoch: 21 [64128/221852 (29%)]\tLoss: 0.330336\tAcc: 70.00\n",
      "train epoch: 21 [76928/221852 (35%)]\tLoss: 0.298090\tAcc: 67.00\n",
      "train epoch: 21 [89728/221852 (40%)]\tLoss: 0.321068\tAcc: 64.00\n",
      "train epoch: 21 [102528/221852 (46%)]\tLoss: 0.301972\tAcc: 69.00\n",
      "train epoch: 21 [115328/221852 (52%)]\tLoss: 0.256465\tAcc: 68.00\n",
      "train epoch: 21 [128128/221852 (58%)]\tLoss: 0.237940\tAcc: 72.00\n",
      "train epoch: 21 [140928/221852 (64%)]\tLoss: 0.251253\tAcc: 54.00\n",
      "train epoch: 21 [153728/221852 (69%)]\tLoss: 0.290804\tAcc: 73.00\n",
      "train epoch: 21 [166528/221852 (75%)]\tLoss: 0.328179\tAcc: 71.00\n",
      "train epoch: 21 [179328/221852 (81%)]\tLoss: 0.246654\tAcc: 67.00\n",
      "train epoch: 21 [192128/221852 (87%)]\tLoss: 0.295334\tAcc: 73.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 21 [128/221852 (0%)]\tLoss: 0.360137\tAcc: 70.00\n",
      "val epoch: 21 [12928/221852 (6%)]\tLoss: 0.260673\tAcc: 70.00\n",
      "train epoch: 22 [128/221852 (0%)]\tLoss: 0.362017\tAcc: 58.00\n",
      "train epoch: 22 [12928/221852 (6%)]\tLoss: 0.297712\tAcc: 69.00\n",
      "train epoch: 22 [25728/221852 (12%)]\tLoss: 0.340238\tAcc: 61.00\n",
      "train epoch: 22 [38528/221852 (17%)]\tLoss: 0.372642\tAcc: 67.00\n",
      "train epoch: 22 [51328/221852 (23%)]\tLoss: 0.214601\tAcc: 70.00\n",
      "train epoch: 22 [64128/221852 (29%)]\tLoss: 0.230913\tAcc: 68.00\n",
      "train epoch: 22 [76928/221852 (35%)]\tLoss: 0.282930\tAcc: 63.00\n",
      "train epoch: 22 [89728/221852 (40%)]\tLoss: 0.242277\tAcc: 71.00\n",
      "train epoch: 22 [102528/221852 (46%)]\tLoss: 0.297775\tAcc: 65.00\n",
      "train epoch: 22 [115328/221852 (52%)]\tLoss: 0.247942\tAcc: 76.00\n",
      "train epoch: 22 [128128/221852 (58%)]\tLoss: 0.242286\tAcc: 76.00\n",
      "train epoch: 22 [140928/221852 (64%)]\tLoss: 0.273857\tAcc: 71.00\n",
      "train epoch: 22 [153728/221852 (69%)]\tLoss: 0.263464\tAcc: 70.00\n",
      "train epoch: 22 [166528/221852 (75%)]\tLoss: 0.349767\tAcc: 69.00\n",
      "train epoch: 22 [179328/221852 (81%)]\tLoss: 0.271887\tAcc: 59.00\n",
      "train epoch: 22 [192128/221852 (87%)]\tLoss: 0.333845\tAcc: 60.00\n",
      "val epoch: 22 [128/221852 (0%)]\tLoss: 0.183201\tAcc: 66.00\n",
      "val epoch: 22 [12928/221852 (6%)]\tLoss: 0.247404\tAcc: 58.00\n",
      "train epoch: 23 [128/221852 (0%)]\tLoss: 0.243147\tAcc: 61.00\n",
      "train epoch: 23 [12928/221852 (6%)]\tLoss: 0.302614\tAcc: 73.00\n",
      "train epoch: 23 [25728/221852 (12%)]\tLoss: 0.281579\tAcc: 70.00\n",
      "train epoch: 23 [38528/221852 (17%)]\tLoss: 0.218950\tAcc: 62.00\n",
      "train epoch: 23 [51328/221852 (23%)]\tLoss: 0.375741\tAcc: 68.00\n",
      "train epoch: 23 [64128/221852 (29%)]\tLoss: 0.233209\tAcc: 64.00\n",
      "train epoch: 23 [76928/221852 (35%)]\tLoss: 0.231672\tAcc: 76.00\n",
      "train epoch: 23 [89728/221852 (40%)]\tLoss: 0.302865\tAcc: 74.00\n",
      "train epoch: 23 [102528/221852 (46%)]\tLoss: 0.255583\tAcc: 78.00\n",
      "train epoch: 23 [115328/221852 (52%)]\tLoss: 0.268534\tAcc: 69.00\n",
      "train epoch: 23 [128128/221852 (58%)]\tLoss: 0.217153\tAcc: 72.00\n",
      "train epoch: 23 [140928/221852 (64%)]\tLoss: 0.253934\tAcc: 63.00\n",
      "train epoch: 23 [153728/221852 (69%)]\tLoss: 0.235178\tAcc: 76.00\n",
      "train epoch: 23 [166528/221852 (75%)]\tLoss: 0.258997\tAcc: 77.00\n",
      "train epoch: 23 [179328/221852 (81%)]\tLoss: 0.269025\tAcc: 71.00\n",
      "train epoch: 23 [192128/221852 (87%)]\tLoss: 0.281788\tAcc: 66.00\n",
      "val epoch: 23 [128/221852 (0%)]\tLoss: 0.255481\tAcc: 70.00\n",
      "val epoch: 23 [12928/221852 (6%)]\tLoss: 0.222131\tAcc: 67.00\n",
      "train epoch: 24 [128/221852 (0%)]\tLoss: 0.292302\tAcc: 59.00\n",
      "train epoch: 24 [12928/221852 (6%)]\tLoss: 0.254399\tAcc: 69.00\n",
      "train epoch: 24 [25728/221852 (12%)]\tLoss: 0.302840\tAcc: 66.00\n",
      "train epoch: 24 [38528/221852 (17%)]\tLoss: 0.263355\tAcc: 73.00\n",
      "train epoch: 24 [51328/221852 (23%)]\tLoss: 0.244015\tAcc: 72.00\n",
      "train epoch: 24 [64128/221852 (29%)]\tLoss: 0.400258\tAcc: 65.00\n",
      "train epoch: 24 [76928/221852 (35%)]\tLoss: 0.303298\tAcc: 77.00\n",
      "train epoch: 24 [89728/221852 (40%)]\tLoss: 0.154147\tAcc: 72.00\n",
      "train epoch: 24 [102528/221852 (46%)]\tLoss: 0.293351\tAcc: 63.00\n",
      "train epoch: 24 [115328/221852 (52%)]\tLoss: 0.216138\tAcc: 70.00\n",
      "train epoch: 24 [128128/221852 (58%)]\tLoss: 0.327088\tAcc: 73.00\n",
      "train epoch: 24 [140928/221852 (64%)]\tLoss: 0.250913\tAcc: 77.00\n",
      "train epoch: 24 [153728/221852 (69%)]\tLoss: 0.256352\tAcc: 73.00\n",
      "train epoch: 24 [166528/221852 (75%)]\tLoss: 0.268639\tAcc: 73.00\n",
      "train epoch: 24 [179328/221852 (81%)]\tLoss: 0.377671\tAcc: 64.00\n",
      "train epoch: 24 [192128/221852 (87%)]\tLoss: 0.326668\tAcc: 71.00\n",
      "val epoch: 24 [128/221852 (0%)]\tLoss: 0.240264\tAcc: 70.00\n",
      "val epoch: 24 [12928/221852 (6%)]\tLoss: 0.320935\tAcc: 66.00\n",
      "train epoch: 25 [128/221852 (0%)]\tLoss: 0.339971\tAcc: 73.00\n",
      "train epoch: 25 [12928/221852 (6%)]\tLoss: 0.270678\tAcc: 74.00\n",
      "train epoch: 25 [25728/221852 (12%)]\tLoss: 0.558357\tAcc: 58.00\n",
      "train epoch: 25 [38528/221852 (17%)]\tLoss: 0.298819\tAcc: 74.00\n",
      "train epoch: 25 [51328/221852 (23%)]\tLoss: 0.239349\tAcc: 78.00\n",
      "train epoch: 25 [64128/221852 (29%)]\tLoss: 0.314986\tAcc: 68.00\n",
      "train epoch: 25 [76928/221852 (35%)]\tLoss: 0.372540\tAcc: 76.00\n",
      "train epoch: 25 [89728/221852 (40%)]\tLoss: 0.262653\tAcc: 69.00\n",
      "train epoch: 25 [102528/221852 (46%)]\tLoss: 0.285419\tAcc: 70.00\n",
      "train epoch: 25 [115328/221852 (52%)]\tLoss: 0.263697\tAcc: 76.00\n",
      "train epoch: 25 [128128/221852 (58%)]\tLoss: 0.216194\tAcc: 72.00\n",
      "train epoch: 25 [140928/221852 (64%)]\tLoss: 0.161759\tAcc: 71.00\n",
      "train epoch: 25 [153728/221852 (69%)]\tLoss: 0.294320\tAcc: 76.00\n",
      "train epoch: 25 [166528/221852 (75%)]\tLoss: 0.218877\tAcc: 73.00\n",
      "train epoch: 25 [179328/221852 (81%)]\tLoss: 0.957341\tAcc: 70.00\n",
      "train epoch: 25 [192128/221852 (87%)]\tLoss: 0.365535\tAcc: 66.00\n",
      "val epoch: 25 [128/221852 (0%)]\tLoss: 0.352794\tAcc: 67.00\n",
      "val epoch: 25 [12928/221852 (6%)]\tLoss: 0.310704\tAcc: 68.00\n",
      "train epoch: 26 [128/221852 (0%)]\tLoss: 0.235979\tAcc: 80.00\n",
      "train epoch: 26 [12928/221852 (6%)]\tLoss: 0.277422\tAcc: 68.00\n",
      "train epoch: 26 [25728/221852 (12%)]\tLoss: 0.214471\tAcc: 71.00\n",
      "train epoch: 26 [38528/221852 (17%)]\tLoss: 0.231603\tAcc: 62.00\n",
      "train epoch: 26 [51328/221852 (23%)]\tLoss: 0.246516\tAcc: 70.00\n",
      "train epoch: 26 [64128/221852 (29%)]\tLoss: 0.294627\tAcc: 69.00\n",
      "train epoch: 26 [76928/221852 (35%)]\tLoss: 0.278944\tAcc: 71.00\n",
      "train epoch: 26 [89728/221852 (40%)]\tLoss: 0.291514\tAcc: 66.00\n",
      "train epoch: 26 [102528/221852 (46%)]\tLoss: 0.240528\tAcc: 75.00\n",
      "train epoch: 26 [115328/221852 (52%)]\tLoss: 0.247606\tAcc: 73.00\n",
      "train epoch: 26 [128128/221852 (58%)]\tLoss: 0.257453\tAcc: 72.00\n",
      "train epoch: 26 [140928/221852 (64%)]\tLoss: 0.193627\tAcc: 71.00\n",
      "train epoch: 26 [153728/221852 (69%)]\tLoss: 0.272581\tAcc: 72.00\n",
      "train epoch: 26 [166528/221852 (75%)]\tLoss: 0.396581\tAcc: 54.00\n",
      "train epoch: 26 [179328/221852 (81%)]\tLoss: 0.325965\tAcc: 59.00\n",
      "train epoch: 26 [192128/221852 (87%)]\tLoss: 0.225744\tAcc: 66.00\n",
      "val epoch: 26 [128/221852 (0%)]\tLoss: 0.316284\tAcc: 61.00\n",
      "val epoch: 26 [12928/221852 (6%)]\tLoss: 0.317669\tAcc: 65.00\n",
      "train epoch: 27 [128/221852 (0%)]\tLoss: 0.280903\tAcc: 55.00\n",
      "train epoch: 27 [12928/221852 (6%)]\tLoss: 0.261643\tAcc: 59.00\n",
      "train epoch: 27 [25728/221852 (12%)]\tLoss: 0.403990\tAcc: 57.00\n",
      "train epoch: 27 [38528/221852 (17%)]\tLoss: 0.320287\tAcc: 66.00\n",
      "train epoch: 27 [51328/221852 (23%)]\tLoss: 0.275062\tAcc: 70.00\n",
      "train epoch: 27 [64128/221852 (29%)]\tLoss: 0.320567\tAcc: 72.00\n",
      "train epoch: 27 [76928/221852 (35%)]\tLoss: 0.234174\tAcc: 70.00\n",
      "train epoch: 27 [89728/221852 (40%)]\tLoss: 0.225390\tAcc: 70.00\n",
      "train epoch: 27 [102528/221852 (46%)]\tLoss: 0.242069\tAcc: 75.00\n",
      "train epoch: 27 [115328/221852 (52%)]\tLoss: 0.342532\tAcc: 68.00\n",
      "train epoch: 27 [128128/221852 (58%)]\tLoss: 0.247249\tAcc: 72.00\n",
      "train epoch: 27 [140928/221852 (64%)]\tLoss: 0.226147\tAcc: 70.00\n",
      "train epoch: 27 [153728/221852 (69%)]\tLoss: 0.224459\tAcc: 69.00\n",
      "train epoch: 27 [166528/221852 (75%)]\tLoss: 0.220679\tAcc: 67.00\n",
      "train epoch: 27 [179328/221852 (81%)]\tLoss: 0.390282\tAcc: 68.00\n",
      "train epoch: 27 [192128/221852 (87%)]\tLoss: 0.287599\tAcc: 72.00\n",
      "val epoch: 27 [128/221852 (0%)]\tLoss: 0.283740\tAcc: 67.00\n",
      "val epoch: 27 [12928/221852 (6%)]\tLoss: 0.317241\tAcc: 61.00\n",
      "train epoch: 28 [128/221852 (0%)]\tLoss: 0.377893\tAcc: 63.00\n",
      "train epoch: 28 [12928/221852 (6%)]\tLoss: 0.364120\tAcc: 64.00\n",
      "train epoch: 28 [25728/221852 (12%)]\tLoss: 0.218201\tAcc: 75.00\n",
      "train epoch: 28 [38528/221852 (17%)]\tLoss: 0.215839\tAcc: 70.00\n",
      "train epoch: 28 [51328/221852 (23%)]\tLoss: 0.190221\tAcc: 70.00\n",
      "train epoch: 28 [64128/221852 (29%)]\tLoss: 0.219660\tAcc: 70.00\n",
      "train epoch: 28 [76928/221852 (35%)]\tLoss: 0.218400\tAcc: 72.00\n",
      "train epoch: 28 [89728/221852 (40%)]\tLoss: 0.205146\tAcc: 72.00\n",
      "train epoch: 28 [102528/221852 (46%)]\tLoss: 0.378596\tAcc: 66.00\n",
      "train epoch: 28 [115328/221852 (52%)]\tLoss: 0.243626\tAcc: 70.00\n",
      "train epoch: 28 [128128/221852 (58%)]\tLoss: 0.262956\tAcc: 60.00\n",
      "train epoch: 28 [140928/221852 (64%)]\tLoss: 0.301103\tAcc: 71.00\n",
      "train epoch: 28 [153728/221852 (69%)]\tLoss: 0.308130\tAcc: 77.00\n",
      "train epoch: 28 [166528/221852 (75%)]\tLoss: 0.185421\tAcc: 69.00\n",
      "train epoch: 28 [179328/221852 (81%)]\tLoss: 0.217045\tAcc: 73.00\n",
      "train epoch: 28 [192128/221852 (87%)]\tLoss: 0.211885\tAcc: 73.00\n",
      "val epoch: 28 [128/221852 (0%)]\tLoss: 0.190079\tAcc: 70.00\n",
      "val epoch: 28 [12928/221852 (6%)]\tLoss: 0.268281\tAcc: 62.00\n",
      "train epoch: 29 [128/221852 (0%)]\tLoss: 0.208742\tAcc: 73.00\n",
      "train epoch: 29 [12928/221852 (6%)]\tLoss: 0.253605\tAcc: 69.00\n",
      "train epoch: 29 [25728/221852 (12%)]\tLoss: 0.231427\tAcc: 67.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 29 [38528/221852 (17%)]\tLoss: 0.260887\tAcc: 67.00\n",
      "train epoch: 29 [51328/221852 (23%)]\tLoss: 0.216400\tAcc: 71.00\n",
      "train epoch: 29 [64128/221852 (29%)]\tLoss: 0.421733\tAcc: 59.00\n",
      "train epoch: 29 [76928/221852 (35%)]\tLoss: 0.322126\tAcc: 67.00\n",
      "train epoch: 29 [89728/221852 (40%)]\tLoss: 0.381799\tAcc: 58.00\n",
      "train epoch: 29 [102528/221852 (46%)]\tLoss: 0.294845\tAcc: 63.00\n",
      "train epoch: 29 [115328/221852 (52%)]\tLoss: 0.323314\tAcc: 62.00\n",
      "train epoch: 29 [128128/221852 (58%)]\tLoss: 0.208894\tAcc: 65.00\n",
      "train epoch: 29 [140928/221852 (64%)]\tLoss: 0.278923\tAcc: 62.00\n",
      "train epoch: 29 [153728/221852 (69%)]\tLoss: 0.277651\tAcc: 73.00\n",
      "train epoch: 29 [166528/221852 (75%)]\tLoss: 0.346440\tAcc: 64.00\n",
      "train epoch: 29 [179328/221852 (81%)]\tLoss: 0.271583\tAcc: 65.00\n",
      "train epoch: 29 [192128/221852 (87%)]\tLoss: 0.341742\tAcc: 69.00\n",
      "val epoch: 29 [128/221852 (0%)]\tLoss: 0.190730\tAcc: 73.00\n",
      "val epoch: 29 [12928/221852 (6%)]\tLoss: 0.267399\tAcc: 66.00\n",
      "train epoch: 30 [128/221852 (0%)]\tLoss: 0.328638\tAcc: 68.00\n",
      "train epoch: 30 [12928/221852 (6%)]\tLoss: 0.424324\tAcc: 66.00\n",
      "train epoch: 30 [25728/221852 (12%)]\tLoss: 0.275079\tAcc: 65.00\n",
      "train epoch: 30 [38528/221852 (17%)]\tLoss: 0.286594\tAcc: 70.00\n",
      "train epoch: 30 [51328/221852 (23%)]\tLoss: 0.272384\tAcc: 66.00\n",
      "train epoch: 30 [64128/221852 (29%)]\tLoss: 0.329579\tAcc: 70.00\n",
      "train epoch: 30 [76928/221852 (35%)]\tLoss: 0.289846\tAcc: 76.00\n",
      "train epoch: 30 [89728/221852 (40%)]\tLoss: 0.191834\tAcc: 77.00\n",
      "train epoch: 30 [102528/221852 (46%)]\tLoss: 0.220148\tAcc: 73.00\n",
      "train epoch: 30 [115328/221852 (52%)]\tLoss: 0.347504\tAcc: 70.00\n",
      "train epoch: 30 [128128/221852 (58%)]\tLoss: 0.519763\tAcc: 58.00\n",
      "train epoch: 30 [140928/221852 (64%)]\tLoss: 0.404025\tAcc: 65.00\n",
      "train epoch: 30 [153728/221852 (69%)]\tLoss: 0.407109\tAcc: 62.00\n",
      "train epoch: 30 [166528/221852 (75%)]\tLoss: 0.366125\tAcc: 56.00\n",
      "train epoch: 30 [179328/221852 (81%)]\tLoss: 0.390088\tAcc: 56.00\n",
      "train epoch: 30 [192128/221852 (87%)]\tLoss: 0.315831\tAcc: 64.00\n",
      "val epoch: 30 [128/221852 (0%)]\tLoss: 0.302544\tAcc: 69.00\n",
      "val epoch: 30 [12928/221852 (6%)]\tLoss: 0.256573\tAcc: 70.00\n",
      "train epoch: 31 [128/221852 (0%)]\tLoss: 0.184580\tAcc: 71.00\n",
      "train epoch: 31 [12928/221852 (6%)]\tLoss: 0.313728\tAcc: 59.00\n",
      "train epoch: 31 [25728/221852 (12%)]\tLoss: 0.228702\tAcc: 65.00\n",
      "train epoch: 31 [38528/221852 (17%)]\tLoss: 0.281198\tAcc: 69.00\n",
      "train epoch: 31 [51328/221852 (23%)]\tLoss: 0.248213\tAcc: 63.00\n",
      "train epoch: 31 [64128/221852 (29%)]\tLoss: 0.216705\tAcc: 66.00\n",
      "train epoch: 31 [76928/221852 (35%)]\tLoss: 0.227336\tAcc: 63.00\n",
      "train epoch: 31 [89728/221852 (40%)]\tLoss: 0.399839\tAcc: 63.00\n",
      "train epoch: 31 [102528/221852 (46%)]\tLoss: 0.192809\tAcc: 67.00\n",
      "train epoch: 31 [115328/221852 (52%)]\tLoss: 0.300191\tAcc: 67.00\n",
      "train epoch: 31 [128128/221852 (58%)]\tLoss: 0.272531\tAcc: 69.00\n",
      "train epoch: 31 [140928/221852 (64%)]\tLoss: 0.280802\tAcc: 70.00\n",
      "train epoch: 31 [153728/221852 (69%)]\tLoss: 0.190999\tAcc: 67.00\n",
      "train epoch: 31 [166528/221852 (75%)]\tLoss: 0.270961\tAcc: 66.00\n",
      "train epoch: 31 [179328/221852 (81%)]\tLoss: 0.257897\tAcc: 64.00\n",
      "train epoch: 31 [192128/221852 (87%)]\tLoss: 0.268082\tAcc: 75.00\n",
      "val epoch: 31 [128/221852 (0%)]\tLoss: 0.244977\tAcc: 67.00\n",
      "val epoch: 31 [12928/221852 (6%)]\tLoss: 0.324004\tAcc: 67.00\n",
      "train epoch: 32 [128/221852 (0%)]\tLoss: 0.341551\tAcc: 66.00\n",
      "train epoch: 32 [12928/221852 (6%)]\tLoss: 0.294066\tAcc: 66.00\n",
      "train epoch: 32 [25728/221852 (12%)]\tLoss: 0.314582\tAcc: 73.00\n",
      "train epoch: 32 [38528/221852 (17%)]\tLoss: 0.262580\tAcc: 65.00\n",
      "train epoch: 32 [51328/221852 (23%)]\tLoss: 0.211370\tAcc: 69.00\n",
      "train epoch: 32 [64128/221852 (29%)]\tLoss: 0.277267\tAcc: 70.00\n",
      "train epoch: 32 [76928/221852 (35%)]\tLoss: 0.247505\tAcc: 67.00\n",
      "train epoch: 32 [89728/221852 (40%)]\tLoss: 0.431994\tAcc: 60.00\n",
      "train epoch: 32 [102528/221852 (46%)]\tLoss: 0.267599\tAcc: 73.00\n",
      "train epoch: 32 [115328/221852 (52%)]\tLoss: 0.269350\tAcc: 66.00\n",
      "train epoch: 32 [128128/221852 (58%)]\tLoss: 0.297557\tAcc: 65.00\n",
      "train epoch: 32 [140928/221852 (64%)]\tLoss: 0.355022\tAcc: 69.00\n",
      "train epoch: 32 [153728/221852 (69%)]\tLoss: 0.254499\tAcc: 74.00\n",
      "train epoch: 32 [166528/221852 (75%)]\tLoss: 0.225337\tAcc: 58.00\n",
      "train epoch: 32 [179328/221852 (81%)]\tLoss: 0.243341\tAcc: 71.00\n",
      "train epoch: 32 [192128/221852 (87%)]\tLoss: 0.205637\tAcc: 71.00\n",
      "val epoch: 32 [128/221852 (0%)]\tLoss: 0.270578\tAcc: 70.00\n",
      "val epoch: 32 [12928/221852 (6%)]\tLoss: 0.180297\tAcc: 70.00\n",
      "train epoch: 33 [128/221852 (0%)]\tLoss: 0.204362\tAcc: 65.00\n",
      "train epoch: 33 [12928/221852 (6%)]\tLoss: 0.436115\tAcc: 66.00\n",
      "train epoch: 33 [25728/221852 (12%)]\tLoss: 0.283429\tAcc: 65.00\n",
      "train epoch: 33 [38528/221852 (17%)]\tLoss: 0.431722\tAcc: 68.00\n",
      "train epoch: 33 [51328/221852 (23%)]\tLoss: 0.321034\tAcc: 68.00\n",
      "train epoch: 33 [64128/221852 (29%)]\tLoss: 0.336659\tAcc: 64.00\n",
      "train epoch: 33 [76928/221852 (35%)]\tLoss: 0.309330\tAcc: 66.00\n",
      "train epoch: 33 [89728/221852 (40%)]\tLoss: 0.275498\tAcc: 62.00\n",
      "train epoch: 33 [102528/221852 (46%)]\tLoss: 0.198436\tAcc: 76.00\n",
      "train epoch: 33 [115328/221852 (52%)]\tLoss: 0.399170\tAcc: 64.00\n",
      "train epoch: 33 [128128/221852 (58%)]\tLoss: 0.264969\tAcc: 63.00\n",
      "train epoch: 33 [140928/221852 (64%)]\tLoss: 0.258253\tAcc: 73.00\n",
      "train epoch: 33 [153728/221852 (69%)]\tLoss: 0.258085\tAcc: 68.00\n",
      "train epoch: 33 [166528/221852 (75%)]\tLoss: 0.417127\tAcc: 71.00\n",
      "train epoch: 33 [179328/221852 (81%)]\tLoss: 0.185335\tAcc: 70.00\n",
      "train epoch: 33 [192128/221852 (87%)]\tLoss: 0.284418\tAcc: 68.00\n",
      "val epoch: 33 [128/221852 (0%)]\tLoss: 0.326230\tAcc: 64.00\n",
      "val epoch: 33 [12928/221852 (6%)]\tLoss: 0.463653\tAcc: 54.00\n",
      "train epoch: 34 [128/221852 (0%)]\tLoss: 0.400667\tAcc: 65.00\n",
      "train epoch: 34 [12928/221852 (6%)]\tLoss: 0.300890\tAcc: 62.00\n",
      "train epoch: 34 [25728/221852 (12%)]\tLoss: 0.288446\tAcc: 63.00\n",
      "train epoch: 34 [38528/221852 (17%)]\tLoss: 0.291585\tAcc: 73.00\n",
      "train epoch: 34 [51328/221852 (23%)]\tLoss: 0.269315\tAcc: 62.00\n",
      "train epoch: 34 [64128/221852 (29%)]\tLoss: 0.207781\tAcc: 69.00\n",
      "train epoch: 34 [76928/221852 (35%)]\tLoss: 0.295127\tAcc: 72.00\n",
      "train epoch: 34 [89728/221852 (40%)]\tLoss: 0.230092\tAcc: 70.00\n",
      "train epoch: 34 [102528/221852 (46%)]\tLoss: 0.306669\tAcc: 65.00\n",
      "train epoch: 34 [115328/221852 (52%)]\tLoss: 0.177201\tAcc: 70.00\n",
      "train epoch: 34 [128128/221852 (58%)]\tLoss: 0.202423\tAcc: 69.00\n",
      "train epoch: 34 [140928/221852 (64%)]\tLoss: 0.137263\tAcc: 73.00\n",
      "train epoch: 34 [153728/221852 (69%)]\tLoss: 0.346017\tAcc: 64.00\n",
      "train epoch: 34 [166528/221852 (75%)]\tLoss: 0.197485\tAcc: 73.00\n",
      "train epoch: 34 [179328/221852 (81%)]\tLoss: 0.177629\tAcc: 80.00\n",
      "train epoch: 34 [192128/221852 (87%)]\tLoss: 0.354026\tAcc: 61.00\n",
      "val epoch: 34 [128/221852 (0%)]\tLoss: 0.240648\tAcc: 72.00\n",
      "val epoch: 34 [12928/221852 (6%)]\tLoss: 0.247899\tAcc: 67.00\n",
      "train epoch: 35 [128/221852 (0%)]\tLoss: 0.298087\tAcc: 62.00\n",
      "train epoch: 35 [12928/221852 (6%)]\tLoss: 0.205824\tAcc: 67.00\n",
      "train epoch: 35 [25728/221852 (12%)]\tLoss: 0.230309\tAcc: 69.00\n",
      "train epoch: 35 [38528/221852 (17%)]\tLoss: 0.272058\tAcc: 73.00\n",
      "train epoch: 35 [51328/221852 (23%)]\tLoss: 0.173751\tAcc: 69.00\n",
      "train epoch: 35 [64128/221852 (29%)]\tLoss: 0.297429\tAcc: 71.00\n",
      "train epoch: 35 [76928/221852 (35%)]\tLoss: 0.184214\tAcc: 73.00\n",
      "train epoch: 35 [89728/221852 (40%)]\tLoss: 0.230231\tAcc: 74.00\n",
      "train epoch: 35 [102528/221852 (46%)]\tLoss: 0.305320\tAcc: 72.00\n",
      "train epoch: 35 [115328/221852 (52%)]\tLoss: 0.154343\tAcc: 73.00\n",
      "train epoch: 35 [128128/221852 (58%)]\tLoss: 0.249718\tAcc: 70.00\n",
      "train epoch: 35 [140928/221852 (64%)]\tLoss: 0.309100\tAcc: 62.00\n",
      "train epoch: 35 [153728/221852 (69%)]\tLoss: 0.209798\tAcc: 74.00\n",
      "train epoch: 35 [166528/221852 (75%)]\tLoss: 0.286912\tAcc: 73.00\n",
      "train epoch: 35 [179328/221852 (81%)]\tLoss: 0.234948\tAcc: 76.00\n",
      "train epoch: 35 [192128/221852 (87%)]\tLoss: 0.281044\tAcc: 70.00\n",
      "val epoch: 35 [128/221852 (0%)]\tLoss: 0.466402\tAcc: 62.00\n",
      "val epoch: 35 [12928/221852 (6%)]\tLoss: 0.489341\tAcc: 52.00\n",
      "train epoch: 36 [128/221852 (0%)]\tLoss: 0.540475\tAcc: 55.00\n",
      "train epoch: 36 [12928/221852 (6%)]\tLoss: 0.285480\tAcc: 73.00\n",
      "train epoch: 36 [25728/221852 (12%)]\tLoss: 0.250211\tAcc: 73.00\n",
      "train epoch: 36 [38528/221852 (17%)]\tLoss: 0.427060\tAcc: 55.00\n",
      "train epoch: 36 [51328/221852 (23%)]\tLoss: 0.256807\tAcc: 69.00\n",
      "train epoch: 36 [64128/221852 (29%)]\tLoss: 0.210492\tAcc: 68.00\n",
      "train epoch: 36 [76928/221852 (35%)]\tLoss: 0.225560\tAcc: 68.00\n",
      "train epoch: 36 [89728/221852 (40%)]\tLoss: 0.369564\tAcc: 66.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 36 [102528/221852 (46%)]\tLoss: 0.268779\tAcc: 66.00\n",
      "train epoch: 36 [115328/221852 (52%)]\tLoss: 0.240029\tAcc: 66.00\n",
      "train epoch: 36 [128128/221852 (58%)]\tLoss: 0.566738\tAcc: 58.00\n",
      "train epoch: 36 [140928/221852 (64%)]\tLoss: 0.303910\tAcc: 70.00\n",
      "train epoch: 36 [153728/221852 (69%)]\tLoss: 0.230981\tAcc: 65.00\n",
      "train epoch: 36 [166528/221852 (75%)]\tLoss: 0.217182\tAcc: 67.00\n",
      "train epoch: 36 [179328/221852 (81%)]\tLoss: 0.229950\tAcc: 77.00\n",
      "train epoch: 36 [192128/221852 (87%)]\tLoss: 0.239326\tAcc: 69.00\n",
      "val epoch: 36 [128/221852 (0%)]\tLoss: 0.306954\tAcc: 72.00\n",
      "val epoch: 36 [12928/221852 (6%)]\tLoss: 0.178444\tAcc: 76.00\n",
      "train epoch: 37 [128/221852 (0%)]\tLoss: 0.267922\tAcc: 72.00\n",
      "train epoch: 37 [12928/221852 (6%)]\tLoss: 0.374179\tAcc: 60.00\n",
      "train epoch: 37 [25728/221852 (12%)]\tLoss: 0.255557\tAcc: 73.00\n",
      "train epoch: 37 [38528/221852 (17%)]\tLoss: 0.214549\tAcc: 63.00\n",
      "train epoch: 37 [51328/221852 (23%)]\tLoss: 0.206339\tAcc: 77.00\n",
      "train epoch: 37 [64128/221852 (29%)]\tLoss: 0.235220\tAcc: 66.00\n",
      "train epoch: 37 [76928/221852 (35%)]\tLoss: 0.232209\tAcc: 75.00\n",
      "train epoch: 37 [89728/221852 (40%)]\tLoss: 0.270231\tAcc: 70.00\n",
      "train epoch: 37 [102528/221852 (46%)]\tLoss: 0.456709\tAcc: 59.00\n",
      "train epoch: 37 [115328/221852 (52%)]\tLoss: 0.333994\tAcc: 60.00\n",
      "train epoch: 37 [128128/221852 (58%)]\tLoss: 0.310509\tAcc: 65.00\n",
      "train epoch: 37 [140928/221852 (64%)]\tLoss: 0.340516\tAcc: 70.00\n",
      "train epoch: 37 [153728/221852 (69%)]\tLoss: 0.219816\tAcc: 71.00\n",
      "train epoch: 37 [166528/221852 (75%)]\tLoss: 0.272765\tAcc: 69.00\n",
      "train epoch: 37 [179328/221852 (81%)]\tLoss: 0.334366\tAcc: 69.00\n",
      "train epoch: 37 [192128/221852 (87%)]\tLoss: 0.276938\tAcc: 68.00\n",
      "val epoch: 37 [128/221852 (0%)]\tLoss: 0.228346\tAcc: 67.00\n",
      "val epoch: 37 [12928/221852 (6%)]\tLoss: 0.268522\tAcc: 64.00\n",
      "train epoch: 38 [128/221852 (0%)]\tLoss: 0.280664\tAcc: 77.00\n",
      "train epoch: 38 [12928/221852 (6%)]\tLoss: 0.205466\tAcc: 74.00\n",
      "train epoch: 38 [25728/221852 (12%)]\tLoss: 0.344438\tAcc: 66.00\n",
      "train epoch: 38 [38528/221852 (17%)]\tLoss: 0.252691\tAcc: 63.00\n",
      "train epoch: 38 [51328/221852 (23%)]\tLoss: 0.292908\tAcc: 55.00\n",
      "train epoch: 38 [64128/221852 (29%)]\tLoss: 0.353183\tAcc: 63.00\n",
      "train epoch: 38 [76928/221852 (35%)]\tLoss: 0.263747\tAcc: 68.00\n",
      "train epoch: 38 [89728/221852 (40%)]\tLoss: 0.289972\tAcc: 67.00\n",
      "train epoch: 38 [102528/221852 (46%)]\tLoss: 0.318323\tAcc: 68.00\n",
      "train epoch: 38 [115328/221852 (52%)]\tLoss: 0.249035\tAcc: 70.00\n",
      "train epoch: 38 [128128/221852 (58%)]\tLoss: 0.282529\tAcc: 69.00\n",
      "train epoch: 38 [140928/221852 (64%)]\tLoss: 0.333494\tAcc: 66.00\n",
      "train epoch: 38 [153728/221852 (69%)]\tLoss: 0.278636\tAcc: 73.00\n",
      "train epoch: 38 [166528/221852 (75%)]\tLoss: 0.257600\tAcc: 60.00\n",
      "train epoch: 38 [179328/221852 (81%)]\tLoss: 0.380997\tAcc: 70.00\n",
      "train epoch: 38 [192128/221852 (87%)]\tLoss: 0.305153\tAcc: 67.00\n",
      "val epoch: 38 [128/221852 (0%)]\tLoss: 0.359538\tAcc: 64.00\n",
      "val epoch: 38 [12928/221852 (6%)]\tLoss: 0.199352\tAcc: 69.00\n",
      "train epoch: 39 [128/221852 (0%)]\tLoss: 0.207616\tAcc: 75.00\n",
      "train epoch: 39 [12928/221852 (6%)]\tLoss: 0.390070\tAcc: 66.00\n",
      "train epoch: 39 [25728/221852 (12%)]\tLoss: 0.310990\tAcc: 60.00\n",
      "train epoch: 39 [38528/221852 (17%)]\tLoss: 0.568757\tAcc: 70.00\n",
      "train epoch: 39 [51328/221852 (23%)]\tLoss: 0.254074\tAcc: 62.00\n",
      "train epoch: 39 [64128/221852 (29%)]\tLoss: 0.238773\tAcc: 61.00\n",
      "train epoch: 39 [76928/221852 (35%)]\tLoss: 0.233780\tAcc: 68.00\n",
      "train epoch: 39 [89728/221852 (40%)]\tLoss: 0.221563\tAcc: 66.00\n",
      "train epoch: 39 [102528/221852 (46%)]\tLoss: 0.272530\tAcc: 63.00\n",
      "train epoch: 39 [115328/221852 (52%)]\tLoss: 0.219783\tAcc: 70.00\n",
      "train epoch: 39 [128128/221852 (58%)]\tLoss: 0.235668\tAcc: 73.00\n",
      "train epoch: 39 [140928/221852 (64%)]\tLoss: 0.300393\tAcc: 61.00\n",
      "train epoch: 39 [153728/221852 (69%)]\tLoss: 0.276330\tAcc: 78.00\n",
      "train epoch: 39 [166528/221852 (75%)]\tLoss: 0.229980\tAcc: 70.00\n",
      "train epoch: 39 [179328/221852 (81%)]\tLoss: 0.235879\tAcc: 72.00\n",
      "train epoch: 39 [192128/221852 (87%)]\tLoss: 0.253459\tAcc: 70.00\n",
      "val epoch: 39 [128/221852 (0%)]\tLoss: 0.210772\tAcc: 78.00\n",
      "val epoch: 39 [12928/221852 (6%)]\tLoss: 0.244605\tAcc: 73.00\n",
      "train epoch: 40 [128/221852 (0%)]\tLoss: 0.232684\tAcc: 70.00\n",
      "train epoch: 40 [12928/221852 (6%)]\tLoss: 0.365586\tAcc: 60.00\n",
      "train epoch: 40 [25728/221852 (12%)]\tLoss: 0.238931\tAcc: 69.00\n",
      "train epoch: 40 [38528/221852 (17%)]\tLoss: 0.231288\tAcc: 73.00\n",
      "train epoch: 40 [51328/221852 (23%)]\tLoss: 0.325041\tAcc: 72.00\n",
      "train epoch: 40 [64128/221852 (29%)]\tLoss: 0.247783\tAcc: 73.00\n",
      "train epoch: 40 [76928/221852 (35%)]\tLoss: 0.218760\tAcc: 67.00\n",
      "train epoch: 40 [89728/221852 (40%)]\tLoss: 0.261380\tAcc: 70.00\n",
      "train epoch: 40 [102528/221852 (46%)]\tLoss: 0.311269\tAcc: 67.00\n",
      "train epoch: 40 [115328/221852 (52%)]\tLoss: 0.220837\tAcc: 68.00\n",
      "train epoch: 40 [128128/221852 (58%)]\tLoss: 0.432754\tAcc: 64.00\n",
      "train epoch: 40 [140928/221852 (64%)]\tLoss: 0.241678\tAcc: 70.00\n",
      "train epoch: 40 [153728/221852 (69%)]\tLoss: 0.231519\tAcc: 71.00\n",
      "train epoch: 40 [166528/221852 (75%)]\tLoss: 0.232649\tAcc: 70.00\n",
      "train epoch: 40 [179328/221852 (81%)]\tLoss: 0.250503\tAcc: 65.00\n",
      "train epoch: 40 [192128/221852 (87%)]\tLoss: 0.541867\tAcc: 66.00\n",
      "val epoch: 40 [128/221852 (0%)]\tLoss: 0.326231\tAcc: 63.00\n",
      "val epoch: 40 [12928/221852 (6%)]\tLoss: 0.284928\tAcc: 67.00\n",
      "train epoch: 41 [128/221852 (0%)]\tLoss: 0.237018\tAcc: 73.00\n",
      "train epoch: 41 [12928/221852 (6%)]\tLoss: 0.324571\tAcc: 62.00\n",
      "train epoch: 41 [25728/221852 (12%)]\tLoss: 0.184260\tAcc: 74.00\n",
      "train epoch: 41 [38528/221852 (17%)]\tLoss: 0.265348\tAcc: 67.00\n",
      "train epoch: 41 [51328/221852 (23%)]\tLoss: 0.385664\tAcc: 69.00\n",
      "train epoch: 41 [64128/221852 (29%)]\tLoss: 0.190058\tAcc: 74.00\n",
      "train epoch: 41 [76928/221852 (35%)]\tLoss: 0.295334\tAcc: 73.00\n",
      "train epoch: 41 [89728/221852 (40%)]\tLoss: 0.203830\tAcc: 70.00\n",
      "train epoch: 41 [102528/221852 (46%)]\tLoss: 0.350138\tAcc: 71.00\n",
      "train epoch: 41 [115328/221852 (52%)]\tLoss: 0.242011\tAcc: 69.00\n",
      "train epoch: 41 [128128/221852 (58%)]\tLoss: 0.327326\tAcc: 74.00\n",
      "train epoch: 41 [140928/221852 (64%)]\tLoss: 0.331384\tAcc: 73.00\n",
      "train epoch: 41 [153728/221852 (69%)]\tLoss: 0.384104\tAcc: 66.00\n",
      "train epoch: 41 [166528/221852 (75%)]\tLoss: 0.399346\tAcc: 57.00\n",
      "train epoch: 41 [179328/221852 (81%)]\tLoss: 0.273680\tAcc: 71.00\n",
      "train epoch: 41 [192128/221852 (87%)]\tLoss: 0.181436\tAcc: 69.00\n",
      "val epoch: 41 [128/221852 (0%)]\tLoss: 0.204180\tAcc: 73.00\n",
      "val epoch: 41 [12928/221852 (6%)]\tLoss: 0.192415\tAcc: 67.00\n",
      "train epoch: 42 [128/221852 (0%)]\tLoss: 0.233369\tAcc: 63.00\n",
      "train epoch: 42 [12928/221852 (6%)]\tLoss: 0.259628\tAcc: 73.00\n",
      "train epoch: 42 [25728/221852 (12%)]\tLoss: 0.314442\tAcc: 68.00\n",
      "train epoch: 42 [38528/221852 (17%)]\tLoss: 0.229038\tAcc: 63.00\n",
      "train epoch: 42 [51328/221852 (23%)]\tLoss: 0.222864\tAcc: 69.00\n",
      "train epoch: 42 [64128/221852 (29%)]\tLoss: 0.306941\tAcc: 64.00\n",
      "train epoch: 42 [76928/221852 (35%)]\tLoss: 0.203942\tAcc: 74.00\n",
      "train epoch: 42 [89728/221852 (40%)]\tLoss: 0.332120\tAcc: 78.00\n",
      "train epoch: 42 [102528/221852 (46%)]\tLoss: 0.525081\tAcc: 59.00\n",
      "train epoch: 42 [115328/221852 (52%)]\tLoss: 0.267961\tAcc: 62.00\n",
      "train epoch: 42 [128128/221852 (58%)]\tLoss: 0.307270\tAcc: 60.00\n",
      "train epoch: 42 [140928/221852 (64%)]\tLoss: 0.145292\tAcc: 73.00\n",
      "train epoch: 42 [153728/221852 (69%)]\tLoss: 0.253539\tAcc: 70.00\n",
      "train epoch: 42 [166528/221852 (75%)]\tLoss: 0.269909\tAcc: 68.00\n",
      "train epoch: 42 [179328/221852 (81%)]\tLoss: 0.267851\tAcc: 67.00\n",
      "train epoch: 42 [192128/221852 (87%)]\tLoss: 0.403558\tAcc: 63.00\n",
      "val epoch: 42 [128/221852 (0%)]\tLoss: 0.196069\tAcc: 67.00\n",
      "val epoch: 42 [12928/221852 (6%)]\tLoss: 0.287627\tAcc: 66.00\n",
      "train epoch: 43 [128/221852 (0%)]\tLoss: 0.241466\tAcc: 68.00\n",
      "train epoch: 43 [12928/221852 (6%)]\tLoss: 0.190797\tAcc: 72.00\n",
      "train epoch: 43 [25728/221852 (12%)]\tLoss: 0.277142\tAcc: 67.00\n",
      "train epoch: 43 [38528/221852 (17%)]\tLoss: 0.252356\tAcc: 76.00\n",
      "train epoch: 43 [51328/221852 (23%)]\tLoss: 0.155556\tAcc: 73.00\n",
      "train epoch: 43 [64128/221852 (29%)]\tLoss: 0.228662\tAcc: 73.00\n",
      "train epoch: 43 [76928/221852 (35%)]\tLoss: 0.240505\tAcc: 73.00\n",
      "train epoch: 43 [89728/221852 (40%)]\tLoss: 0.238731\tAcc: 71.00\n",
      "train epoch: 43 [102528/221852 (46%)]\tLoss: 0.213481\tAcc: 70.00\n",
      "train epoch: 43 [115328/221852 (52%)]\tLoss: 0.171925\tAcc: 70.00\n",
      "train epoch: 43 [128128/221852 (58%)]\tLoss: 0.259362\tAcc: 68.00\n",
      "train epoch: 43 [140928/221852 (64%)]\tLoss: 0.185201\tAcc: 77.00\n",
      "train epoch: 43 [153728/221852 (69%)]\tLoss: 0.250982\tAcc: 73.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 43 [166528/221852 (75%)]\tLoss: 0.195558\tAcc: 69.00\n",
      "train epoch: 43 [179328/221852 (81%)]\tLoss: 0.199401\tAcc: 70.00\n",
      "train epoch: 43 [192128/221852 (87%)]\tLoss: 0.190377\tAcc: 71.00\n",
      "val epoch: 43 [128/221852 (0%)]\tLoss: 0.196982\tAcc: 66.00\n",
      "val epoch: 43 [12928/221852 (6%)]\tLoss: 0.187498\tAcc: 69.00\n",
      "train epoch: 44 [128/221852 (0%)]\tLoss: 0.245221\tAcc: 73.00\n",
      "train epoch: 44 [12928/221852 (6%)]\tLoss: 0.181222\tAcc: 76.00\n",
      "train epoch: 44 [25728/221852 (12%)]\tLoss: 0.266499\tAcc: 70.00\n",
      "train epoch: 44 [38528/221852 (17%)]\tLoss: 0.164651\tAcc: 73.00\n",
      "train epoch: 44 [51328/221852 (23%)]\tLoss: 0.181037\tAcc: 82.00\n",
      "train epoch: 44 [64128/221852 (29%)]\tLoss: 0.284968\tAcc: 67.00\n",
      "train epoch: 44 [76928/221852 (35%)]\tLoss: 0.240200\tAcc: 65.00\n",
      "train epoch: 44 [89728/221852 (40%)]\tLoss: 0.283602\tAcc: 68.00\n",
      "train epoch: 44 [102528/221852 (46%)]\tLoss: 0.208722\tAcc: 77.00\n",
      "train epoch: 44 [115328/221852 (52%)]\tLoss: 0.188324\tAcc: 73.00\n",
      "train epoch: 44 [128128/221852 (58%)]\tLoss: 0.297193\tAcc: 71.00\n",
      "train epoch: 44 [140928/221852 (64%)]\tLoss: 0.249601\tAcc: 74.00\n",
      "train epoch: 44 [153728/221852 (69%)]\tLoss: 0.340203\tAcc: 59.00\n",
      "train epoch: 44 [166528/221852 (75%)]\tLoss: 0.271755\tAcc: 68.00\n",
      "train epoch: 44 [179328/221852 (81%)]\tLoss: 0.265303\tAcc: 70.00\n",
      "train epoch: 44 [192128/221852 (87%)]\tLoss: 0.205721\tAcc: 72.00\n",
      "val epoch: 44 [128/221852 (0%)]\tLoss: 0.126111\tAcc: 77.00\n",
      "val epoch: 44 [12928/221852 (6%)]\tLoss: 0.195136\tAcc: 77.00\n",
      "train epoch: 45 [128/221852 (0%)]\tLoss: 0.185617\tAcc: 73.00\n",
      "train epoch: 45 [12928/221852 (6%)]\tLoss: 0.264247\tAcc: 77.00\n",
      "train epoch: 45 [25728/221852 (12%)]\tLoss: 0.206282\tAcc: 80.00\n",
      "train epoch: 45 [38528/221852 (17%)]\tLoss: 0.178878\tAcc: 80.00\n",
      "train epoch: 45 [51328/221852 (23%)]\tLoss: 0.234944\tAcc: 73.00\n",
      "train epoch: 45 [64128/221852 (29%)]\tLoss: 0.220089\tAcc: 79.00\n",
      "train epoch: 45 [76928/221852 (35%)]\tLoss: 0.221395\tAcc: 78.00\n",
      "train epoch: 45 [89728/221852 (40%)]\tLoss: 0.267318\tAcc: 75.00\n",
      "train epoch: 45 [102528/221852 (46%)]\tLoss: 0.236411\tAcc: 73.00\n",
      "train epoch: 45 [115328/221852 (52%)]\tLoss: 0.223357\tAcc: 70.00\n",
      "train epoch: 45 [128128/221852 (58%)]\tLoss: 0.204725\tAcc: 66.00\n",
      "train epoch: 45 [140928/221852 (64%)]\tLoss: 0.251286\tAcc: 70.00\n",
      "train epoch: 45 [153728/221852 (69%)]\tLoss: 0.214370\tAcc: 71.00\n",
      "train epoch: 45 [166528/221852 (75%)]\tLoss: 0.333300\tAcc: 73.00\n",
      "train epoch: 45 [179328/221852 (81%)]\tLoss: 0.209049\tAcc: 74.00\n",
      "train epoch: 45 [192128/221852 (87%)]\tLoss: 0.256544\tAcc: 72.00\n",
      "val epoch: 45 [128/221852 (0%)]\tLoss: 0.320289\tAcc: 60.00\n",
      "val epoch: 45 [12928/221852 (6%)]\tLoss: 0.228151\tAcc: 63.00\n",
      "train epoch: 46 [128/221852 (0%)]\tLoss: 0.251710\tAcc: 70.00\n",
      "train epoch: 46 [12928/221852 (6%)]\tLoss: 0.199337\tAcc: 73.00\n",
      "train epoch: 46 [25728/221852 (12%)]\tLoss: 0.221426\tAcc: 72.00\n",
      "train epoch: 46 [38528/221852 (17%)]\tLoss: 0.236232\tAcc: 71.00\n",
      "train epoch: 46 [51328/221852 (23%)]\tLoss: 0.166932\tAcc: 73.00\n",
      "train epoch: 46 [64128/221852 (29%)]\tLoss: 0.188059\tAcc: 76.00\n",
      "train epoch: 46 [76928/221852 (35%)]\tLoss: 0.238000\tAcc: 74.00\n",
      "train epoch: 46 [89728/221852 (40%)]\tLoss: 0.222464\tAcc: 80.00\n",
      "train epoch: 46 [102528/221852 (46%)]\tLoss: 0.422435\tAcc: 62.00\n",
      "train epoch: 46 [115328/221852 (52%)]\tLoss: 0.301649\tAcc: 70.00\n",
      "train epoch: 46 [128128/221852 (58%)]\tLoss: 0.241971\tAcc: 68.00\n",
      "train epoch: 46 [140928/221852 (64%)]\tLoss: 0.199368\tAcc: 71.00\n",
      "train epoch: 46 [153728/221852 (69%)]\tLoss: 0.189155\tAcc: 64.00\n",
      "train epoch: 46 [166528/221852 (75%)]\tLoss: 0.235008\tAcc: 71.00\n",
      "train epoch: 46 [179328/221852 (81%)]\tLoss: 0.233788\tAcc: 65.00\n",
      "train epoch: 46 [192128/221852 (87%)]\tLoss: 0.177170\tAcc: 74.00\n",
      "val epoch: 46 [128/221852 (0%)]\tLoss: 0.270948\tAcc: 71.00\n",
      "val epoch: 46 [12928/221852 (6%)]\tLoss: 0.277724\tAcc: 74.00\n",
      "train epoch: 47 [128/221852 (0%)]\tLoss: 0.325727\tAcc: 69.00\n",
      "train epoch: 47 [12928/221852 (6%)]\tLoss: 0.273291\tAcc: 66.00\n",
      "train epoch: 47 [25728/221852 (12%)]\tLoss: 0.218467\tAcc: 70.00\n",
      "train epoch: 47 [38528/221852 (17%)]\tLoss: 0.256346\tAcc: 75.00\n",
      "train epoch: 47 [51328/221852 (23%)]\tLoss: 0.244170\tAcc: 80.00\n",
      "train epoch: 47 [64128/221852 (29%)]\tLoss: 0.281114\tAcc: 72.00\n",
      "train epoch: 47 [76928/221852 (35%)]\tLoss: 0.182490\tAcc: 80.00\n",
      "train epoch: 47 [89728/221852 (40%)]\tLoss: 0.296379\tAcc: 71.00\n",
      "train epoch: 47 [102528/221852 (46%)]\tLoss: 0.249757\tAcc: 74.00\n",
      "train epoch: 47 [115328/221852 (52%)]\tLoss: 0.230736\tAcc: 78.00\n",
      "train epoch: 47 [128128/221852 (58%)]\tLoss: 0.217402\tAcc: 71.00\n",
      "train epoch: 47 [140928/221852 (64%)]\tLoss: 0.170176\tAcc: 81.00\n",
      "train epoch: 47 [153728/221852 (69%)]\tLoss: 0.206439\tAcc: 76.00\n",
      "train epoch: 47 [166528/221852 (75%)]\tLoss: 0.345094\tAcc: 70.00\n",
      "train epoch: 47 [179328/221852 (81%)]\tLoss: 0.269211\tAcc: 72.00\n",
      "train epoch: 47 [192128/221852 (87%)]\tLoss: 0.212536\tAcc: 72.00\n",
      "val epoch: 47 [128/221852 (0%)]\tLoss: 0.196104\tAcc: 68.00\n",
      "val epoch: 47 [12928/221852 (6%)]\tLoss: 0.221615\tAcc: 74.00\n",
      "train epoch: 48 [128/221852 (0%)]\tLoss: 0.217753\tAcc: 73.00\n",
      "train epoch: 48 [12928/221852 (6%)]\tLoss: 0.301213\tAcc: 70.00\n",
      "train epoch: 48 [25728/221852 (12%)]\tLoss: 0.152294\tAcc: 77.00\n",
      "train epoch: 48 [38528/221852 (17%)]\tLoss: 0.230604\tAcc: 75.00\n",
      "train epoch: 48 [51328/221852 (23%)]\tLoss: 0.251808\tAcc: 69.00\n",
      "train epoch: 48 [64128/221852 (29%)]\tLoss: 0.366485\tAcc: 70.00\n",
      "train epoch: 48 [76928/221852 (35%)]\tLoss: 0.249017\tAcc: 80.00\n",
      "train epoch: 48 [89728/221852 (40%)]\tLoss: 0.228514\tAcc: 72.00\n",
      "train epoch: 48 [102528/221852 (46%)]\tLoss: 0.198295\tAcc: 79.00\n",
      "train epoch: 48 [115328/221852 (52%)]\tLoss: 0.150419\tAcc: 78.00\n",
      "train epoch: 48 [128128/221852 (58%)]\tLoss: 0.214482\tAcc: 75.00\n",
      "train epoch: 48 [140928/221852 (64%)]\tLoss: 0.272499\tAcc: 75.00\n",
      "train epoch: 48 [153728/221852 (69%)]\tLoss: 0.326913\tAcc: 62.00\n",
      "train epoch: 48 [166528/221852 (75%)]\tLoss: 0.303122\tAcc: 74.00\n",
      "train epoch: 48 [179328/221852 (81%)]\tLoss: 0.253774\tAcc: 72.00\n",
      "train epoch: 48 [192128/221852 (87%)]\tLoss: 0.272999\tAcc: 72.00\n",
      "val epoch: 48 [128/221852 (0%)]\tLoss: 0.180658\tAcc: 79.00\n",
      "val epoch: 48 [12928/221852 (6%)]\tLoss: 0.231327\tAcc: 69.00\n",
      "train epoch: 49 [128/221852 (0%)]\tLoss: 0.209868\tAcc: 70.00\n",
      "train epoch: 49 [12928/221852 (6%)]\tLoss: 0.176990\tAcc: 74.00\n",
      "train epoch: 49 [25728/221852 (12%)]\tLoss: 0.240721\tAcc: 71.00\n",
      "train epoch: 49 [38528/221852 (17%)]\tLoss: 0.238149\tAcc: 77.00\n",
      "train epoch: 49 [51328/221852 (23%)]\tLoss: 0.213112\tAcc: 69.00\n",
      "train epoch: 49 [64128/221852 (29%)]\tLoss: 0.376027\tAcc: 69.00\n",
      "train epoch: 49 [76928/221852 (35%)]\tLoss: 0.322940\tAcc: 73.00\n",
      "train epoch: 49 [89728/221852 (40%)]\tLoss: 0.246926\tAcc: 73.00\n",
      "train epoch: 49 [102528/221852 (46%)]\tLoss: 0.209456\tAcc: 71.00\n",
      "train epoch: 49 [115328/221852 (52%)]\tLoss: 0.507751\tAcc: 66.00\n",
      "train epoch: 49 [128128/221852 (58%)]\tLoss: 0.220420\tAcc: 66.00\n",
      "train epoch: 49 [140928/221852 (64%)]\tLoss: 0.269612\tAcc: 64.00\n",
      "train epoch: 49 [153728/221852 (69%)]\tLoss: 0.196721\tAcc: 77.00\n",
      "train epoch: 49 [166528/221852 (75%)]\tLoss: 0.275409\tAcc: 60.00\n",
      "train epoch: 49 [179328/221852 (81%)]\tLoss: 0.271410\tAcc: 76.00\n",
      "train epoch: 49 [192128/221852 (87%)]\tLoss: 0.176591\tAcc: 74.00\n",
      "val epoch: 49 [128/221852 (0%)]\tLoss: 0.231068\tAcc: 75.00\n",
      "val epoch: 49 [12928/221852 (6%)]\tLoss: 0.298244\tAcc: 69.00\n",
      "train epoch: 50 [128/221852 (0%)]\tLoss: 0.260159\tAcc: 75.00\n",
      "train epoch: 50 [12928/221852 (6%)]\tLoss: 0.245238\tAcc: 74.00\n",
      "train epoch: 50 [25728/221852 (12%)]\tLoss: 0.208408\tAcc: 75.00\n",
      "train epoch: 50 [38528/221852 (17%)]\tLoss: 0.264264\tAcc: 75.00\n",
      "train epoch: 50 [51328/221852 (23%)]\tLoss: 0.147588\tAcc: 80.00\n",
      "train epoch: 50 [64128/221852 (29%)]\tLoss: 0.342521\tAcc: 68.00\n",
      "train epoch: 50 [76928/221852 (35%)]\tLoss: 0.208884\tAcc: 68.00\n",
      "train epoch: 50 [89728/221852 (40%)]\tLoss: 0.169632\tAcc: 73.00\n",
      "train epoch: 50 [102528/221852 (46%)]\tLoss: 0.182206\tAcc: 77.00\n",
      "train epoch: 50 [115328/221852 (52%)]\tLoss: 0.311669\tAcc: 66.00\n",
      "train epoch: 50 [128128/221852 (58%)]\tLoss: 0.325858\tAcc: 69.00\n",
      "train epoch: 50 [140928/221852 (64%)]\tLoss: 0.230615\tAcc: 76.00\n",
      "train epoch: 50 [153728/221852 (69%)]\tLoss: 0.292747\tAcc: 66.00\n",
      "train epoch: 50 [166528/221852 (75%)]\tLoss: 0.263603\tAcc: 77.00\n",
      "train epoch: 50 [179328/221852 (81%)]\tLoss: 0.278875\tAcc: 70.00\n",
      "train epoch: 50 [192128/221852 (87%)]\tLoss: 0.168978\tAcc: 80.00\n",
      "val epoch: 50 [128/221852 (0%)]\tLoss: 0.308996\tAcc: 71.00\n",
      "val epoch: 50 [12928/221852 (6%)]\tLoss: 0.207895\tAcc: 78.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 51 [128/221852 (0%)]\tLoss: 0.210181\tAcc: 73.00\n",
      "train epoch: 51 [12928/221852 (6%)]\tLoss: 0.305510\tAcc: 67.00\n",
      "train epoch: 51 [25728/221852 (12%)]\tLoss: 0.175322\tAcc: 78.00\n",
      "train epoch: 51 [38528/221852 (17%)]\tLoss: 0.187981\tAcc: 76.00\n",
      "train epoch: 51 [51328/221852 (23%)]\tLoss: 0.209109\tAcc: 71.00\n",
      "train epoch: 51 [64128/221852 (29%)]\tLoss: 0.241266\tAcc: 76.00\n",
      "train epoch: 51 [76928/221852 (35%)]\tLoss: 0.205138\tAcc: 76.00\n",
      "train epoch: 51 [89728/221852 (40%)]\tLoss: 0.180555\tAcc: 73.00\n",
      "train epoch: 51 [102528/221852 (46%)]\tLoss: 0.185135\tAcc: 78.00\n",
      "train epoch: 51 [115328/221852 (52%)]\tLoss: 0.211031\tAcc: 73.00\n",
      "train epoch: 51 [128128/221852 (58%)]\tLoss: 0.186320\tAcc: 78.00\n",
      "train epoch: 51 [140928/221852 (64%)]\tLoss: 0.266748\tAcc: 75.00\n",
      "train epoch: 51 [153728/221852 (69%)]\tLoss: 0.364983\tAcc: 69.00\n",
      "train epoch: 51 [166528/221852 (75%)]\tLoss: 0.170360\tAcc: 77.00\n",
      "train epoch: 51 [179328/221852 (81%)]\tLoss: 0.137025\tAcc: 81.00\n",
      "train epoch: 51 [192128/221852 (87%)]\tLoss: 0.211834\tAcc: 75.00\n",
      "val epoch: 51 [128/221852 (0%)]\tLoss: 0.249108\tAcc: 75.00\n",
      "val epoch: 51 [12928/221852 (6%)]\tLoss: 0.193819\tAcc: 81.00\n",
      "train epoch: 52 [128/221852 (0%)]\tLoss: 0.171622\tAcc: 81.00\n",
      "train epoch: 52 [12928/221852 (6%)]\tLoss: 0.147244\tAcc: 84.00\n",
      "train epoch: 52 [25728/221852 (12%)]\tLoss: 0.273508\tAcc: 73.00\n",
      "train epoch: 52 [38528/221852 (17%)]\tLoss: 0.181824\tAcc: 73.00\n",
      "train epoch: 52 [51328/221852 (23%)]\tLoss: 0.209001\tAcc: 76.00\n",
      "train epoch: 52 [64128/221852 (29%)]\tLoss: 0.201988\tAcc: 74.00\n",
      "train epoch: 52 [76928/221852 (35%)]\tLoss: 0.162365\tAcc: 80.00\n",
      "train epoch: 52 [89728/221852 (40%)]\tLoss: 0.247743\tAcc: 66.00\n",
      "train epoch: 52 [102528/221852 (46%)]\tLoss: 0.221202\tAcc: 77.00\n",
      "train epoch: 52 [115328/221852 (52%)]\tLoss: 0.200120\tAcc: 73.00\n",
      "train epoch: 52 [128128/221852 (58%)]\tLoss: 0.167245\tAcc: 74.00\n",
      "train epoch: 52 [140928/221852 (64%)]\tLoss: 0.238439\tAcc: 78.00\n",
      "train epoch: 52 [153728/221852 (69%)]\tLoss: 0.225358\tAcc: 77.00\n",
      "train epoch: 52 [166528/221852 (75%)]\tLoss: 0.223565\tAcc: 73.00\n",
      "train epoch: 52 [179328/221852 (81%)]\tLoss: 0.288234\tAcc: 73.00\n",
      "train epoch: 52 [192128/221852 (87%)]\tLoss: 0.139224\tAcc: 80.00\n",
      "val epoch: 52 [128/221852 (0%)]\tLoss: 0.233468\tAcc: 77.00\n",
      "val epoch: 52 [12928/221852 (6%)]\tLoss: 0.245740\tAcc: 76.00\n",
      "train epoch: 53 [128/221852 (0%)]\tLoss: 0.272886\tAcc: 72.00\n",
      "train epoch: 53 [12928/221852 (6%)]\tLoss: 0.237049\tAcc: 77.00\n",
      "train epoch: 53 [25728/221852 (12%)]\tLoss: 0.303130\tAcc: 78.00\n",
      "train epoch: 53 [38528/221852 (17%)]\tLoss: 0.175960\tAcc: 77.00\n",
      "train epoch: 53 [51328/221852 (23%)]\tLoss: 0.185089\tAcc: 77.00\n",
      "train epoch: 53 [64128/221852 (29%)]\tLoss: 0.197085\tAcc: 77.00\n",
      "train epoch: 53 [76928/221852 (35%)]\tLoss: 0.267908\tAcc: 83.00\n",
      "train epoch: 53 [89728/221852 (40%)]\tLoss: 0.163241\tAcc: 78.00\n",
      "train epoch: 53 [102528/221852 (46%)]\tLoss: 0.173752\tAcc: 81.00\n",
      "train epoch: 53 [115328/221852 (52%)]\tLoss: 0.267762\tAcc: 70.00\n",
      "train epoch: 53 [128128/221852 (58%)]\tLoss: 0.224281\tAcc: 69.00\n",
      "train epoch: 53 [140928/221852 (64%)]\tLoss: 0.213875\tAcc: 65.00\n",
      "train epoch: 53 [153728/221852 (69%)]\tLoss: 0.194835\tAcc: 67.00\n",
      "train epoch: 53 [166528/221852 (75%)]\tLoss: 0.138281\tAcc: 84.00\n",
      "train epoch: 53 [179328/221852 (81%)]\tLoss: 0.203069\tAcc: 76.00\n",
      "train epoch: 53 [192128/221852 (87%)]\tLoss: 0.200136\tAcc: 83.00\n",
      "val epoch: 53 [128/221852 (0%)]\tLoss: 0.228367\tAcc: 79.00\n",
      "val epoch: 53 [12928/221852 (6%)]\tLoss: 0.224409\tAcc: 76.00\n",
      "train epoch: 54 [128/221852 (0%)]\tLoss: 0.199522\tAcc: 74.00\n",
      "train epoch: 54 [12928/221852 (6%)]\tLoss: 0.176682\tAcc: 80.00\n",
      "train epoch: 54 [25728/221852 (12%)]\tLoss: 0.246963\tAcc: 73.00\n",
      "train epoch: 54 [38528/221852 (17%)]\tLoss: 0.360376\tAcc: 75.00\n",
      "train epoch: 54 [51328/221852 (23%)]\tLoss: 0.191648\tAcc: 64.00\n",
      "train epoch: 54 [64128/221852 (29%)]\tLoss: 0.183706\tAcc: 72.00\n",
      "train epoch: 54 [76928/221852 (35%)]\tLoss: 0.253129\tAcc: 71.00\n",
      "train epoch: 54 [89728/221852 (40%)]\tLoss: 0.187594\tAcc: 78.00\n",
      "train epoch: 54 [102528/221852 (46%)]\tLoss: 0.241040\tAcc: 78.00\n",
      "train epoch: 54 [115328/221852 (52%)]\tLoss: 0.288400\tAcc: 68.00\n",
      "train epoch: 54 [128128/221852 (58%)]\tLoss: 0.218910\tAcc: 79.00\n",
      "train epoch: 54 [140928/221852 (64%)]\tLoss: 0.226441\tAcc: 80.00\n",
      "train epoch: 54 [153728/221852 (69%)]\tLoss: 0.243888\tAcc: 80.00\n",
      "train epoch: 54 [166528/221852 (75%)]\tLoss: 0.245210\tAcc: 78.00\n",
      "train epoch: 54 [179328/221852 (81%)]\tLoss: 0.274961\tAcc: 75.00\n",
      "train epoch: 54 [192128/221852 (87%)]\tLoss: 0.205408\tAcc: 73.00\n",
      "val epoch: 54 [128/221852 (0%)]\tLoss: 0.245477\tAcc: 80.00\n",
      "val epoch: 54 [12928/221852 (6%)]\tLoss: 0.206830\tAcc: 74.00\n",
      "train epoch: 55 [128/221852 (0%)]\tLoss: 0.227533\tAcc: 73.00\n",
      "train epoch: 55 [12928/221852 (6%)]\tLoss: 0.221944\tAcc: 77.00\n",
      "train epoch: 55 [25728/221852 (12%)]\tLoss: 0.230604\tAcc: 74.00\n",
      "train epoch: 55 [38528/221852 (17%)]\tLoss: 0.240769\tAcc: 74.00\n",
      "train epoch: 55 [51328/221852 (23%)]\tLoss: 0.207848\tAcc: 67.00\n",
      "train epoch: 55 [64128/221852 (29%)]\tLoss: 0.212672\tAcc: 77.00\n",
      "train epoch: 55 [76928/221852 (35%)]\tLoss: 0.175481\tAcc: 70.00\n",
      "train epoch: 55 [89728/221852 (40%)]\tLoss: 0.181129\tAcc: 78.00\n",
      "train epoch: 55 [102528/221852 (46%)]\tLoss: 0.194497\tAcc: 76.00\n",
      "train epoch: 55 [115328/221852 (52%)]\tLoss: 0.183602\tAcc: 77.00\n",
      "train epoch: 55 [128128/221852 (58%)]\tLoss: 0.268014\tAcc: 74.00\n",
      "train epoch: 55 [140928/221852 (64%)]\tLoss: 0.166108\tAcc: 78.00\n",
      "train epoch: 55 [153728/221852 (69%)]\tLoss: 0.162262\tAcc: 84.00\n",
      "train epoch: 55 [166528/221852 (75%)]\tLoss: 0.103189\tAcc: 80.00\n",
      "train epoch: 55 [179328/221852 (81%)]\tLoss: 0.191916\tAcc: 77.00\n",
      "train epoch: 55 [192128/221852 (87%)]\tLoss: 0.297162\tAcc: 78.00\n",
      "val epoch: 55 [128/221852 (0%)]\tLoss: 0.293660\tAcc: 69.00\n",
      "val epoch: 55 [12928/221852 (6%)]\tLoss: 0.141375\tAcc: 77.00\n",
      "train epoch: 56 [128/221852 (0%)]\tLoss: 0.279107\tAcc: 74.00\n",
      "train epoch: 56 [12928/221852 (6%)]\tLoss: 0.224488\tAcc: 81.00\n",
      "train epoch: 56 [25728/221852 (12%)]\tLoss: 0.209910\tAcc: 74.00\n",
      "train epoch: 56 [38528/221852 (17%)]\tLoss: 0.191179\tAcc: 80.00\n",
      "train epoch: 56 [51328/221852 (23%)]\tLoss: 0.349696\tAcc: 74.00\n",
      "train epoch: 56 [64128/221852 (29%)]\tLoss: 0.220336\tAcc: 77.00\n",
      "train epoch: 56 [76928/221852 (35%)]\tLoss: 0.194010\tAcc: 73.00\n",
      "train epoch: 56 [89728/221852 (40%)]\tLoss: 0.222922\tAcc: 80.00\n",
      "train epoch: 56 [102528/221852 (46%)]\tLoss: 0.292644\tAcc: 72.00\n",
      "train epoch: 56 [115328/221852 (52%)]\tLoss: 0.348771\tAcc: 76.00\n",
      "train epoch: 56 [128128/221852 (58%)]\tLoss: 0.169117\tAcc: 79.00\n",
      "train epoch: 56 [140928/221852 (64%)]\tLoss: 0.329574\tAcc: 78.00\n",
      "train epoch: 56 [153728/221852 (69%)]\tLoss: 0.192476\tAcc: 79.00\n",
      "train epoch: 56 [166528/221852 (75%)]\tLoss: 0.169723\tAcc: 74.00\n",
      "train epoch: 56 [179328/221852 (81%)]\tLoss: 0.122674\tAcc: 74.00\n",
      "train epoch: 56 [192128/221852 (87%)]\tLoss: 0.107803\tAcc: 82.00\n",
      "val epoch: 56 [128/221852 (0%)]\tLoss: 0.252734\tAcc: 76.00\n",
      "val epoch: 56 [12928/221852 (6%)]\tLoss: 0.163138\tAcc: 76.00\n",
      "train epoch: 57 [128/221852 (0%)]\tLoss: 0.160150\tAcc: 77.00\n",
      "train epoch: 57 [12928/221852 (6%)]\tLoss: 0.161050\tAcc: 77.00\n",
      "train epoch: 57 [25728/221852 (12%)]\tLoss: 0.241331\tAcc: 75.00\n",
      "train epoch: 57 [38528/221852 (17%)]\tLoss: 0.300291\tAcc: 78.00\n",
      "train epoch: 57 [51328/221852 (23%)]\tLoss: 0.185079\tAcc: 76.00\n",
      "train epoch: 57 [64128/221852 (29%)]\tLoss: 0.170954\tAcc: 76.00\n",
      "train epoch: 57 [76928/221852 (35%)]\tLoss: 0.204197\tAcc: 77.00\n",
      "train epoch: 57 [89728/221852 (40%)]\tLoss: 0.224361\tAcc: 73.00\n",
      "train epoch: 57 [102528/221852 (46%)]\tLoss: 0.193742\tAcc: 81.00\n",
      "train epoch: 57 [115328/221852 (52%)]\tLoss: 0.182537\tAcc: 77.00\n",
      "train epoch: 57 [128128/221852 (58%)]\tLoss: 0.288373\tAcc: 68.00\n",
      "train epoch: 57 [140928/221852 (64%)]\tLoss: 0.233012\tAcc: 74.00\n",
      "train epoch: 57 [153728/221852 (69%)]\tLoss: 0.151342\tAcc: 77.00\n",
      "train epoch: 57 [166528/221852 (75%)]\tLoss: 0.232517\tAcc: 76.00\n",
      "train epoch: 57 [179328/221852 (81%)]\tLoss: 0.270962\tAcc: 72.00\n",
      "train epoch: 57 [192128/221852 (87%)]\tLoss: 0.158157\tAcc: 86.00\n",
      "val epoch: 57 [128/221852 (0%)]\tLoss: 0.188355\tAcc: 84.00\n",
      "val epoch: 57 [12928/221852 (6%)]\tLoss: 0.195479\tAcc: 80.00\n",
      "train epoch: 58 [128/221852 (0%)]\tLoss: 0.254541\tAcc: 75.00\n",
      "train epoch: 58 [12928/221852 (6%)]\tLoss: 0.237451\tAcc: 80.00\n",
      "train epoch: 58 [25728/221852 (12%)]\tLoss: 0.207639\tAcc: 74.00\n",
      "train epoch: 58 [38528/221852 (17%)]\tLoss: 0.257010\tAcc: 73.00\n",
      "train epoch: 58 [51328/221852 (23%)]\tLoss: 0.172208\tAcc: 78.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 58 [64128/221852 (29%)]\tLoss: 0.154704\tAcc: 73.00\n",
      "train epoch: 58 [76928/221852 (35%)]\tLoss: 0.182049\tAcc: 74.00\n",
      "train epoch: 58 [89728/221852 (40%)]\tLoss: 0.193140\tAcc: 81.00\n",
      "train epoch: 58 [102528/221852 (46%)]\tLoss: 0.171634\tAcc: 78.00\n",
      "train epoch: 58 [115328/221852 (52%)]\tLoss: 0.187051\tAcc: 76.00\n",
      "train epoch: 58 [128128/221852 (58%)]\tLoss: 0.181376\tAcc: 78.00\n",
      "train epoch: 58 [140928/221852 (64%)]\tLoss: 0.376943\tAcc: 83.00\n",
      "train epoch: 58 [153728/221852 (69%)]\tLoss: 0.241220\tAcc: 72.00\n",
      "train epoch: 58 [166528/221852 (75%)]\tLoss: 0.203297\tAcc: 76.00\n",
      "train epoch: 58 [179328/221852 (81%)]\tLoss: 0.172081\tAcc: 80.00\n",
      "train epoch: 58 [192128/221852 (87%)]\tLoss: 0.190092\tAcc: 77.00\n",
      "val epoch: 58 [128/221852 (0%)]\tLoss: 0.207249\tAcc: 79.00\n",
      "val epoch: 58 [12928/221852 (6%)]\tLoss: 0.236581\tAcc: 77.00\n",
      "train epoch: 59 [128/221852 (0%)]\tLoss: 0.223993\tAcc: 74.00\n",
      "train epoch: 59 [12928/221852 (6%)]\tLoss: 0.244464\tAcc: 80.00\n",
      "train epoch: 59 [25728/221852 (12%)]\tLoss: 0.250120\tAcc: 66.00\n",
      "train epoch: 59 [38528/221852 (17%)]\tLoss: 0.220593\tAcc: 76.00\n",
      "train epoch: 59 [51328/221852 (23%)]\tLoss: 0.190396\tAcc: 76.00\n",
      "train epoch: 59 [64128/221852 (29%)]\tLoss: 0.180473\tAcc: 78.00\n",
      "train epoch: 59 [76928/221852 (35%)]\tLoss: 0.215635\tAcc: 77.00\n",
      "train epoch: 59 [89728/221852 (40%)]\tLoss: 0.269408\tAcc: 77.00\n",
      "train epoch: 59 [102528/221852 (46%)]\tLoss: 0.244568\tAcc: 77.00\n",
      "train epoch: 59 [115328/221852 (52%)]\tLoss: 0.222203\tAcc: 84.00\n",
      "train epoch: 59 [128128/221852 (58%)]\tLoss: 0.329798\tAcc: 74.00\n",
      "train epoch: 59 [140928/221852 (64%)]\tLoss: 0.185136\tAcc: 85.00\n",
      "train epoch: 59 [153728/221852 (69%)]\tLoss: 0.192751\tAcc: 74.00\n",
      "train epoch: 59 [166528/221852 (75%)]\tLoss: 0.234182\tAcc: 81.00\n",
      "train epoch: 59 [179328/221852 (81%)]\tLoss: 0.237546\tAcc: 79.00\n",
      "train epoch: 59 [192128/221852 (87%)]\tLoss: 0.778472\tAcc: 77.00\n",
      "val epoch: 59 [128/221852 (0%)]\tLoss: 0.371544\tAcc: 63.00\n",
      "val epoch: 59 [12928/221852 (6%)]\tLoss: 0.226677\tAcc: 76.00\n",
      "train epoch: 60 [128/221852 (0%)]\tLoss: 0.230871\tAcc: 77.00\n",
      "train epoch: 60 [12928/221852 (6%)]\tLoss: 0.184359\tAcc: 80.00\n",
      "train epoch: 60 [25728/221852 (12%)]\tLoss: 0.198441\tAcc: 76.00\n",
      "train epoch: 60 [38528/221852 (17%)]\tLoss: 0.151777\tAcc: 84.00\n",
      "train epoch: 60 [51328/221852 (23%)]\tLoss: 0.233963\tAcc: 70.00\n",
      "train epoch: 60 [64128/221852 (29%)]\tLoss: 0.166209\tAcc: 83.00\n",
      "train epoch: 60 [76928/221852 (35%)]\tLoss: 0.168662\tAcc: 77.00\n",
      "train epoch: 60 [89728/221852 (40%)]\tLoss: 0.220011\tAcc: 77.00\n",
      "train epoch: 60 [102528/221852 (46%)]\tLoss: 0.170097\tAcc: 79.00\n",
      "train epoch: 60 [115328/221852 (52%)]\tLoss: 0.264950\tAcc: 67.00\n",
      "train epoch: 60 [128128/221852 (58%)]\tLoss: 0.227684\tAcc: 79.00\n",
      "train epoch: 60 [140928/221852 (64%)]\tLoss: 0.216503\tAcc: 75.00\n",
      "train epoch: 60 [153728/221852 (69%)]\tLoss: 0.229747\tAcc: 74.00\n",
      "train epoch: 60 [166528/221852 (75%)]\tLoss: 0.128623\tAcc: 84.00\n",
      "train epoch: 60 [179328/221852 (81%)]\tLoss: 0.216956\tAcc: 74.00\n",
      "train epoch: 60 [192128/221852 (87%)]\tLoss: 0.227974\tAcc: 79.00\n",
      "val epoch: 60 [128/221852 (0%)]\tLoss: 0.123792\tAcc: 77.00\n",
      "val epoch: 60 [12928/221852 (6%)]\tLoss: 0.176599\tAcc: 82.00\n",
      "train epoch: 61 [128/221852 (0%)]\tLoss: 0.177470\tAcc: 84.00\n",
      "train epoch: 61 [12928/221852 (6%)]\tLoss: 0.201536\tAcc: 79.00\n",
      "train epoch: 61 [25728/221852 (12%)]\tLoss: 0.153794\tAcc: 79.00\n",
      "train epoch: 61 [38528/221852 (17%)]\tLoss: 0.238605\tAcc: 73.00\n",
      "train epoch: 61 [51328/221852 (23%)]\tLoss: 0.180005\tAcc: 79.00\n",
      "train epoch: 61 [64128/221852 (29%)]\tLoss: 0.228492\tAcc: 73.00\n",
      "train epoch: 61 [76928/221852 (35%)]\tLoss: 0.135591\tAcc: 76.00\n",
      "train epoch: 61 [89728/221852 (40%)]\tLoss: 0.173114\tAcc: 79.00\n",
      "train epoch: 61 [102528/221852 (46%)]\tLoss: 0.246089\tAcc: 73.00\n",
      "train epoch: 61 [115328/221852 (52%)]\tLoss: 0.233068\tAcc: 80.00\n",
      "train epoch: 61 [128128/221852 (58%)]\tLoss: 0.150911\tAcc: 77.00\n",
      "train epoch: 61 [140928/221852 (64%)]\tLoss: 0.195748\tAcc: 77.00\n",
      "train epoch: 61 [153728/221852 (69%)]\tLoss: 0.293149\tAcc: 77.00\n",
      "train epoch: 61 [166528/221852 (75%)]\tLoss: 0.242742\tAcc: 82.00\n",
      "train epoch: 61 [179328/221852 (81%)]\tLoss: 0.238542\tAcc: 80.00\n",
      "train epoch: 61 [192128/221852 (87%)]\tLoss: 0.248411\tAcc: 77.00\n",
      "val epoch: 61 [128/221852 (0%)]\tLoss: 0.267402\tAcc: 73.00\n",
      "val epoch: 61 [12928/221852 (6%)]\tLoss: 0.184290\tAcc: 85.00\n",
      "train epoch: 62 [128/221852 (0%)]\tLoss: 0.258539\tAcc: 79.00\n",
      "train epoch: 62 [12928/221852 (6%)]\tLoss: 0.211986\tAcc: 78.00\n",
      "train epoch: 62 [25728/221852 (12%)]\tLoss: 0.199935\tAcc: 73.00\n",
      "train epoch: 62 [38528/221852 (17%)]\tLoss: 0.191532\tAcc: 77.00\n",
      "train epoch: 62 [51328/221852 (23%)]\tLoss: 0.288330\tAcc: 75.00\n",
      "train epoch: 62 [64128/221852 (29%)]\tLoss: 0.223241\tAcc: 78.00\n",
      "train epoch: 62 [76928/221852 (35%)]\tLoss: 0.117533\tAcc: 84.00\n",
      "train epoch: 62 [89728/221852 (40%)]\tLoss: 0.168840\tAcc: 79.00\n",
      "train epoch: 62 [102528/221852 (46%)]\tLoss: 0.170757\tAcc: 81.00\n",
      "train epoch: 62 [115328/221852 (52%)]\tLoss: 0.134142\tAcc: 83.00\n",
      "train epoch: 62 [128128/221852 (58%)]\tLoss: 0.137722\tAcc: 79.00\n",
      "train epoch: 62 [140928/221852 (64%)]\tLoss: 0.226491\tAcc: 75.00\n",
      "train epoch: 62 [153728/221852 (69%)]\tLoss: 0.110739\tAcc: 84.00\n",
      "train epoch: 62 [166528/221852 (75%)]\tLoss: 0.196104\tAcc: 79.00\n",
      "train epoch: 62 [179328/221852 (81%)]\tLoss: 0.170250\tAcc: 78.00\n",
      "train epoch: 62 [192128/221852 (87%)]\tLoss: 0.231894\tAcc: 77.00\n",
      "val epoch: 62 [128/221852 (0%)]\tLoss: 0.148460\tAcc: 77.00\n",
      "val epoch: 62 [12928/221852 (6%)]\tLoss: 0.175391\tAcc: 77.00\n",
      "train epoch: 63 [128/221852 (0%)]\tLoss: 0.168144\tAcc: 77.00\n",
      "train epoch: 63 [12928/221852 (6%)]\tLoss: 0.205077\tAcc: 74.00\n",
      "train epoch: 63 [25728/221852 (12%)]\tLoss: 0.187704\tAcc: 77.00\n",
      "train epoch: 63 [38528/221852 (17%)]\tLoss: 0.345280\tAcc: 73.00\n",
      "train epoch: 63 [51328/221852 (23%)]\tLoss: 0.177793\tAcc: 78.00\n",
      "train epoch: 63 [64128/221852 (29%)]\tLoss: 0.206886\tAcc: 73.00\n",
      "train epoch: 63 [76928/221852 (35%)]\tLoss: 0.208699\tAcc: 76.00\n",
      "train epoch: 63 [89728/221852 (40%)]\tLoss: 0.193839\tAcc: 80.00\n",
      "train epoch: 63 [102528/221852 (46%)]\tLoss: 0.177228\tAcc: 83.00\n",
      "train epoch: 63 [115328/221852 (52%)]\tLoss: 0.256333\tAcc: 67.00\n",
      "train epoch: 63 [128128/221852 (58%)]\tLoss: 0.196521\tAcc: 77.00\n",
      "train epoch: 63 [140928/221852 (64%)]\tLoss: 0.134165\tAcc: 79.00\n",
      "train epoch: 63 [153728/221852 (69%)]\tLoss: 0.212733\tAcc: 73.00\n",
      "train epoch: 63 [166528/221852 (75%)]\tLoss: 0.266579\tAcc: 74.00\n",
      "train epoch: 63 [179328/221852 (81%)]\tLoss: 0.189907\tAcc: 81.00\n",
      "train epoch: 63 [192128/221852 (87%)]\tLoss: 0.196003\tAcc: 75.00\n",
      "val epoch: 63 [128/221852 (0%)]\tLoss: 0.209541\tAcc: 78.00\n",
      "val epoch: 63 [12928/221852 (6%)]\tLoss: 0.236011\tAcc: 71.00\n",
      "train epoch: 64 [128/221852 (0%)]\tLoss: 0.166120\tAcc: 80.00\n",
      "train epoch: 64 [12928/221852 (6%)]\tLoss: 0.221874\tAcc: 73.00\n",
      "train epoch: 64 [25728/221852 (12%)]\tLoss: 0.163607\tAcc: 84.00\n",
      "train epoch: 64 [38528/221852 (17%)]\tLoss: 0.219154\tAcc: 77.00\n",
      "train epoch: 64 [51328/221852 (23%)]\tLoss: 0.238128\tAcc: 82.00\n",
      "train epoch: 64 [64128/221852 (29%)]\tLoss: 0.303435\tAcc: 77.00\n",
      "train epoch: 64 [76928/221852 (35%)]\tLoss: 0.211096\tAcc: 72.00\n",
      "train epoch: 64 [89728/221852 (40%)]\tLoss: 0.230352\tAcc: 79.00\n",
      "train epoch: 64 [102528/221852 (46%)]\tLoss: 0.247698\tAcc: 72.00\n",
      "train epoch: 64 [115328/221852 (52%)]\tLoss: 0.240929\tAcc: 77.00\n",
      "train epoch: 64 [128128/221852 (58%)]\tLoss: 0.128377\tAcc: 79.00\n",
      "train epoch: 64 [140928/221852 (64%)]\tLoss: 0.234694\tAcc: 73.00\n",
      "train epoch: 64 [153728/221852 (69%)]\tLoss: 0.140385\tAcc: 77.00\n",
      "train epoch: 64 [166528/221852 (75%)]\tLoss: 0.194378\tAcc: 80.00\n",
      "train epoch: 64 [179328/221852 (81%)]\tLoss: 0.258658\tAcc: 80.00\n",
      "train epoch: 64 [192128/221852 (87%)]\tLoss: 0.277433\tAcc: 69.00\n",
      "val epoch: 64 [128/221852 (0%)]\tLoss: 0.170516\tAcc: 75.00\n",
      "val epoch: 64 [12928/221852 (6%)]\tLoss: 0.203035\tAcc: 78.00\n",
      "train epoch: 65 [128/221852 (0%)]\tLoss: 0.181486\tAcc: 79.00\n",
      "train epoch: 65 [12928/221852 (6%)]\tLoss: 0.229661\tAcc: 76.00\n",
      "train epoch: 65 [25728/221852 (12%)]\tLoss: 0.233610\tAcc: 75.00\n",
      "train epoch: 65 [38528/221852 (17%)]\tLoss: 0.121371\tAcc: 85.00\n",
      "train epoch: 65 [51328/221852 (23%)]\tLoss: 0.264892\tAcc: 73.00\n",
      "train epoch: 65 [64128/221852 (29%)]\tLoss: 0.141313\tAcc: 81.00\n",
      "train epoch: 65 [76928/221852 (35%)]\tLoss: 0.229010\tAcc: 83.00\n",
      "train epoch: 65 [89728/221852 (40%)]\tLoss: 0.170362\tAcc: 82.00\n",
      "train epoch: 65 [102528/221852 (46%)]\tLoss: 0.243840\tAcc: 83.00\n",
      "train epoch: 65 [115328/221852 (52%)]\tLoss: 0.280760\tAcc: 81.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 65 [128128/221852 (58%)]\tLoss: 0.200164\tAcc: 78.00\n",
      "train epoch: 65 [140928/221852 (64%)]\tLoss: 0.164607\tAcc: 80.00\n",
      "train epoch: 65 [153728/221852 (69%)]\tLoss: 0.287271\tAcc: 73.00\n",
      "train epoch: 65 [166528/221852 (75%)]\tLoss: 0.293360\tAcc: 70.00\n",
      "train epoch: 65 [179328/221852 (81%)]\tLoss: 0.144434\tAcc: 86.00\n",
      "train epoch: 65 [192128/221852 (87%)]\tLoss: 0.198911\tAcc: 80.00\n",
      "val epoch: 65 [128/221852 (0%)]\tLoss: 0.310332\tAcc: 78.00\n",
      "val epoch: 65 [12928/221852 (6%)]\tLoss: 0.225393\tAcc: 75.00\n",
      "train epoch: 66 [128/221852 (0%)]\tLoss: 0.231806\tAcc: 82.00\n",
      "train epoch: 66 [12928/221852 (6%)]\tLoss: 0.251957\tAcc: 78.00\n",
      "train epoch: 66 [25728/221852 (12%)]\tLoss: 0.353772\tAcc: 68.00\n",
      "train epoch: 66 [38528/221852 (17%)]\tLoss: 0.138227\tAcc: 78.00\n",
      "train epoch: 66 [51328/221852 (23%)]\tLoss: 0.267867\tAcc: 74.00\n",
      "train epoch: 66 [64128/221852 (29%)]\tLoss: 0.200166\tAcc: 77.00\n",
      "train epoch: 66 [76928/221852 (35%)]\tLoss: 0.219001\tAcc: 80.00\n",
      "train epoch: 66 [89728/221852 (40%)]\tLoss: 0.174885\tAcc: 75.00\n",
      "train epoch: 66 [102528/221852 (46%)]\tLoss: 0.114289\tAcc: 84.00\n",
      "train epoch: 66 [115328/221852 (52%)]\tLoss: 0.265192\tAcc: 72.00\n",
      "train epoch: 66 [128128/221852 (58%)]\tLoss: 0.179186\tAcc: 81.00\n",
      "train epoch: 66 [140928/221852 (64%)]\tLoss: 0.212182\tAcc: 75.00\n",
      "train epoch: 66 [153728/221852 (69%)]\tLoss: 0.285822\tAcc: 69.00\n",
      "train epoch: 66 [166528/221852 (75%)]\tLoss: 0.147050\tAcc: 79.00\n",
      "train epoch: 66 [179328/221852 (81%)]\tLoss: 0.267605\tAcc: 74.00\n",
      "train epoch: 66 [192128/221852 (87%)]\tLoss: 0.297895\tAcc: 74.00\n",
      "val epoch: 66 [128/221852 (0%)]\tLoss: 0.247316\tAcc: 79.00\n",
      "val epoch: 66 [12928/221852 (6%)]\tLoss: 0.300814\tAcc: 79.00\n",
      "train epoch: 67 [128/221852 (0%)]\tLoss: 0.316724\tAcc: 72.00\n",
      "train epoch: 67 [12928/221852 (6%)]\tLoss: 0.210003\tAcc: 78.00\n",
      "train epoch: 67 [25728/221852 (12%)]\tLoss: 0.247223\tAcc: 77.00\n",
      "train epoch: 67 [38528/221852 (17%)]\tLoss: 0.161980\tAcc: 77.00\n",
      "train epoch: 67 [51328/221852 (23%)]\tLoss: 0.255424\tAcc: 75.00\n",
      "train epoch: 67 [64128/221852 (29%)]\tLoss: 0.158245\tAcc: 82.00\n",
      "train epoch: 67 [76928/221852 (35%)]\tLoss: 0.176398\tAcc: 78.00\n",
      "train epoch: 67 [89728/221852 (40%)]\tLoss: 0.253622\tAcc: 80.00\n",
      "train epoch: 67 [102528/221852 (46%)]\tLoss: 0.224012\tAcc: 74.00\n",
      "train epoch: 67 [115328/221852 (52%)]\tLoss: 0.226476\tAcc: 80.00\n",
      "train epoch: 67 [128128/221852 (58%)]\tLoss: 0.169490\tAcc: 85.00\n",
      "train epoch: 67 [140928/221852 (64%)]\tLoss: 0.175859\tAcc: 81.00\n",
      "train epoch: 67 [153728/221852 (69%)]\tLoss: 0.219123\tAcc: 80.00\n",
      "train epoch: 67 [166528/221852 (75%)]\tLoss: 0.216176\tAcc: 79.00\n",
      "train epoch: 67 [179328/221852 (81%)]\tLoss: 0.198081\tAcc: 77.00\n",
      "train epoch: 67 [192128/221852 (87%)]\tLoss: 0.216225\tAcc: 79.00\n",
      "val epoch: 67 [128/221852 (0%)]\tLoss: 0.187085\tAcc: 82.00\n",
      "val epoch: 67 [12928/221852 (6%)]\tLoss: 0.151154\tAcc: 84.00\n",
      "train epoch: 68 [128/221852 (0%)]\tLoss: 0.209564\tAcc: 82.00\n",
      "train epoch: 68 [12928/221852 (6%)]\tLoss: 0.262672\tAcc: 71.00\n",
      "train epoch: 68 [25728/221852 (12%)]\tLoss: 0.239879\tAcc: 78.00\n",
      "train epoch: 68 [38528/221852 (17%)]\tLoss: 0.212474\tAcc: 73.00\n",
      "train epoch: 68 [51328/221852 (23%)]\tLoss: 0.343017\tAcc: 70.00\n",
      "train epoch: 68 [64128/221852 (29%)]\tLoss: 0.135566\tAcc: 74.00\n",
      "train epoch: 68 [76928/221852 (35%)]\tLoss: 0.158017\tAcc: 80.00\n",
      "train epoch: 68 [89728/221852 (40%)]\tLoss: 0.202953\tAcc: 76.00\n",
      "train epoch: 68 [102528/221852 (46%)]\tLoss: 0.204982\tAcc: 79.00\n",
      "train epoch: 68 [115328/221852 (52%)]\tLoss: 0.196189\tAcc: 82.00\n",
      "train epoch: 68 [128128/221852 (58%)]\tLoss: 0.159160\tAcc: 81.00\n",
      "train epoch: 68 [140928/221852 (64%)]\tLoss: 0.237092\tAcc: 76.00\n",
      "train epoch: 68 [153728/221852 (69%)]\tLoss: 0.135218\tAcc: 83.00\n",
      "train epoch: 68 [166528/221852 (75%)]\tLoss: 0.270083\tAcc: 74.00\n",
      "train epoch: 68 [179328/221852 (81%)]\tLoss: 0.239919\tAcc: 80.00\n",
      "train epoch: 68 [192128/221852 (87%)]\tLoss: 0.091348\tAcc: 77.00\n",
      "val epoch: 68 [128/221852 (0%)]\tLoss: 0.087636\tAcc: 86.00\n",
      "val epoch: 68 [12928/221852 (6%)]\tLoss: 0.127877\tAcc: 80.00\n",
      "train epoch: 69 [128/221852 (0%)]\tLoss: 0.166568\tAcc: 83.00\n",
      "train epoch: 69 [12928/221852 (6%)]\tLoss: 0.177460\tAcc: 80.00\n",
      "train epoch: 69 [25728/221852 (12%)]\tLoss: 0.243254\tAcc: 79.00\n",
      "train epoch: 69 [38528/221852 (17%)]\tLoss: 0.236322\tAcc: 73.00\n",
      "train epoch: 69 [51328/221852 (23%)]\tLoss: 0.235613\tAcc: 82.00\n",
      "train epoch: 69 [64128/221852 (29%)]\tLoss: 0.192047\tAcc: 79.00\n",
      "train epoch: 69 [76928/221852 (35%)]\tLoss: 0.182743\tAcc: 70.00\n",
      "train epoch: 69 [89728/221852 (40%)]\tLoss: 0.205500\tAcc: 82.00\n",
      "train epoch: 69 [102528/221852 (46%)]\tLoss: 0.230675\tAcc: 78.00\n",
      "train epoch: 69 [115328/221852 (52%)]\tLoss: 0.300961\tAcc: 74.00\n",
      "train epoch: 69 [128128/221852 (58%)]\tLoss: 0.244014\tAcc: 78.00\n",
      "train epoch: 69 [140928/221852 (64%)]\tLoss: 0.233948\tAcc: 78.00\n",
      "train epoch: 69 [153728/221852 (69%)]\tLoss: 0.189242\tAcc: 85.00\n",
      "train epoch: 69 [166528/221852 (75%)]\tLoss: 0.243733\tAcc: 74.00\n",
      "train epoch: 69 [179328/221852 (81%)]\tLoss: 0.196769\tAcc: 80.00\n",
      "train epoch: 69 [192128/221852 (87%)]\tLoss: 0.221516\tAcc: 74.00\n",
      "val epoch: 69 [128/221852 (0%)]\tLoss: 0.321373\tAcc: 77.00\n",
      "val epoch: 69 [12928/221852 (6%)]\tLoss: 0.181177\tAcc: 81.00\n",
      "train epoch: 70 [128/221852 (0%)]\tLoss: 0.135817\tAcc: 80.00\n",
      "train epoch: 70 [12928/221852 (6%)]\tLoss: 0.249366\tAcc: 72.00\n",
      "train epoch: 70 [25728/221852 (12%)]\tLoss: 0.229245\tAcc: 73.00\n",
      "train epoch: 70 [38528/221852 (17%)]\tLoss: 0.255164\tAcc: 78.00\n",
      "train epoch: 70 [51328/221852 (23%)]\tLoss: 0.102263\tAcc: 88.00\n",
      "train epoch: 70 [64128/221852 (29%)]\tLoss: 0.151877\tAcc: 83.00\n",
      "train epoch: 70 [76928/221852 (35%)]\tLoss: 0.206631\tAcc: 79.00\n",
      "train epoch: 70 [89728/221852 (40%)]\tLoss: 0.214632\tAcc: 81.00\n",
      "train epoch: 70 [102528/221852 (46%)]\tLoss: 0.135674\tAcc: 83.00\n",
      "train epoch: 70 [115328/221852 (52%)]\tLoss: 0.204844\tAcc: 82.00\n",
      "train epoch: 70 [128128/221852 (58%)]\tLoss: 0.140639\tAcc: 83.00\n",
      "train epoch: 70 [140928/221852 (64%)]\tLoss: 0.355009\tAcc: 81.00\n",
      "train epoch: 70 [153728/221852 (69%)]\tLoss: 0.212667\tAcc: 83.00\n",
      "train epoch: 70 [166528/221852 (75%)]\tLoss: 0.117715\tAcc: 83.00\n",
      "train epoch: 70 [179328/221852 (81%)]\tLoss: 0.138526\tAcc: 82.00\n",
      "train epoch: 70 [192128/221852 (87%)]\tLoss: 0.154967\tAcc: 81.00\n",
      "val epoch: 70 [128/221852 (0%)]\tLoss: 0.284121\tAcc: 82.00\n",
      "val epoch: 70 [12928/221852 (6%)]\tLoss: 0.180074\tAcc: 80.00\n",
      "train epoch: 71 [128/221852 (0%)]\tLoss: 0.221151\tAcc: 82.00\n",
      "train epoch: 71 [12928/221852 (6%)]\tLoss: 0.200879\tAcc: 83.00\n",
      "train epoch: 71 [25728/221852 (12%)]\tLoss: 0.147257\tAcc: 83.00\n",
      "train epoch: 71 [38528/221852 (17%)]\tLoss: 0.243303\tAcc: 74.00\n",
      "train epoch: 71 [51328/221852 (23%)]\tLoss: 0.211059\tAcc: 76.00\n",
      "train epoch: 71 [64128/221852 (29%)]\tLoss: 0.196301\tAcc: 84.00\n",
      "train epoch: 71 [76928/221852 (35%)]\tLoss: 0.191722\tAcc: 77.00\n",
      "train epoch: 71 [89728/221852 (40%)]\tLoss: 0.182841\tAcc: 75.00\n",
      "train epoch: 71 [102528/221852 (46%)]\tLoss: 0.168748\tAcc: 85.00\n",
      "train epoch: 71 [115328/221852 (52%)]\tLoss: 0.319544\tAcc: 77.00\n",
      "train epoch: 71 [128128/221852 (58%)]\tLoss: 0.193614\tAcc: 78.00\n",
      "train epoch: 71 [140928/221852 (64%)]\tLoss: 0.234211\tAcc: 80.00\n",
      "train epoch: 71 [153728/221852 (69%)]\tLoss: 0.159649\tAcc: 82.00\n",
      "train epoch: 71 [166528/221852 (75%)]\tLoss: 0.195203\tAcc: 78.00\n",
      "train epoch: 71 [179328/221852 (81%)]\tLoss: 0.224119\tAcc: 77.00\n",
      "train epoch: 71 [192128/221852 (87%)]\tLoss: 0.206057\tAcc: 78.00\n",
      "val epoch: 71 [128/221852 (0%)]\tLoss: 0.172256\tAcc: 80.00\n",
      "val epoch: 71 [12928/221852 (6%)]\tLoss: 0.269171\tAcc: 80.00\n",
      "train epoch: 72 [128/221852 (0%)]\tLoss: 0.202377\tAcc: 77.00\n",
      "train epoch: 72 [12928/221852 (6%)]\tLoss: 0.273554\tAcc: 73.00\n",
      "train epoch: 72 [25728/221852 (12%)]\tLoss: 0.183942\tAcc: 77.00\n",
      "train epoch: 72 [38528/221852 (17%)]\tLoss: 0.233109\tAcc: 73.00\n",
      "train epoch: 72 [51328/221852 (23%)]\tLoss: 0.239625\tAcc: 79.00\n",
      "train epoch: 72 [64128/221852 (29%)]\tLoss: 0.190673\tAcc: 80.00\n",
      "train epoch: 72 [76928/221852 (35%)]\tLoss: 0.237640\tAcc: 82.00\n",
      "train epoch: 72 [89728/221852 (40%)]\tLoss: 0.225193\tAcc: 77.00\n",
      "train epoch: 72 [102528/221852 (46%)]\tLoss: 0.167606\tAcc: 81.00\n",
      "train epoch: 72 [115328/221852 (52%)]\tLoss: 0.248066\tAcc: 81.00\n",
      "train epoch: 72 [128128/221852 (58%)]\tLoss: 0.185697\tAcc: 79.00\n",
      "train epoch: 72 [140928/221852 (64%)]\tLoss: 0.140057\tAcc: 79.00\n",
      "train epoch: 72 [153728/221852 (69%)]\tLoss: 0.222016\tAcc: 82.00\n",
      "train epoch: 72 [166528/221852 (75%)]\tLoss: 0.181887\tAcc: 77.00\n",
      "train epoch: 72 [179328/221852 (81%)]\tLoss: 0.214292\tAcc: 84.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 72 [192128/221852 (87%)]\tLoss: 0.181902\tAcc: 79.00\n",
      "val epoch: 72 [128/221852 (0%)]\tLoss: 0.183039\tAcc: 81.00\n",
      "val epoch: 72 [12928/221852 (6%)]\tLoss: 0.180878\tAcc: 79.00\n",
      "train epoch: 73 [128/221852 (0%)]\tLoss: 0.241608\tAcc: 80.00\n",
      "train epoch: 73 [12928/221852 (6%)]\tLoss: 0.110387\tAcc: 84.00\n",
      "train epoch: 73 [25728/221852 (12%)]\tLoss: 0.193671\tAcc: 86.00\n",
      "train epoch: 73 [38528/221852 (17%)]\tLoss: 0.327636\tAcc: 80.00\n",
      "train epoch: 73 [51328/221852 (23%)]\tLoss: 0.140588\tAcc: 85.00\n",
      "train epoch: 73 [64128/221852 (29%)]\tLoss: 0.160744\tAcc: 83.00\n",
      "train epoch: 73 [76928/221852 (35%)]\tLoss: 0.229104\tAcc: 70.00\n",
      "train epoch: 73 [89728/221852 (40%)]\tLoss: 0.224660\tAcc: 82.00\n",
      "train epoch: 73 [102528/221852 (46%)]\tLoss: 0.136469\tAcc: 79.00\n",
      "train epoch: 73 [115328/221852 (52%)]\tLoss: 0.179645\tAcc: 73.00\n",
      "train epoch: 73 [128128/221852 (58%)]\tLoss: 0.176205\tAcc: 85.00\n",
      "train epoch: 73 [140928/221852 (64%)]\tLoss: 0.140400\tAcc: 84.00\n",
      "train epoch: 73 [153728/221852 (69%)]\tLoss: 0.257275\tAcc: 73.00\n",
      "train epoch: 73 [166528/221852 (75%)]\tLoss: 1.412939\tAcc: 82.00\n",
      "train epoch: 73 [179328/221852 (81%)]\tLoss: 0.282745\tAcc: 75.00\n",
      "train epoch: 73 [192128/221852 (87%)]\tLoss: 0.166502\tAcc: 84.00\n",
      "val epoch: 73 [128/221852 (0%)]\tLoss: 0.118849\tAcc: 84.00\n",
      "val epoch: 73 [12928/221852 (6%)]\tLoss: 0.172714\tAcc: 86.00\n",
      "train epoch: 74 [128/221852 (0%)]\tLoss: 0.133967\tAcc: 81.00\n",
      "train epoch: 74 [12928/221852 (6%)]\tLoss: 0.237860\tAcc: 77.00\n",
      "train epoch: 74 [25728/221852 (12%)]\tLoss: 0.301189\tAcc: 82.00\n",
      "train epoch: 74 [38528/221852 (17%)]\tLoss: 0.196057\tAcc: 74.00\n",
      "train epoch: 74 [51328/221852 (23%)]\tLoss: 0.223418\tAcc: 77.00\n",
      "train epoch: 74 [64128/221852 (29%)]\tLoss: 0.278316\tAcc: 69.00\n",
      "train epoch: 74 [76928/221852 (35%)]\tLoss: 0.121661\tAcc: 80.00\n",
      "train epoch: 74 [89728/221852 (40%)]\tLoss: 0.161350\tAcc: 80.00\n",
      "train epoch: 74 [102528/221852 (46%)]\tLoss: 0.248887\tAcc: 77.00\n",
      "train epoch: 74 [115328/221852 (52%)]\tLoss: 0.180334\tAcc: 77.00\n",
      "train epoch: 74 [128128/221852 (58%)]\tLoss: 0.166968\tAcc: 80.00\n",
      "train epoch: 74 [140928/221852 (64%)]\tLoss: 0.197132\tAcc: 81.00\n",
      "train epoch: 74 [153728/221852 (69%)]\tLoss: 0.224086\tAcc: 77.00\n",
      "train epoch: 74 [166528/221852 (75%)]\tLoss: 0.142102\tAcc: 84.00\n",
      "train epoch: 74 [179328/221852 (81%)]\tLoss: 0.228005\tAcc: 78.00\n",
      "train epoch: 74 [192128/221852 (87%)]\tLoss: 0.170825\tAcc: 81.00\n",
      "val epoch: 74 [128/221852 (0%)]\tLoss: 0.230632\tAcc: 77.00\n",
      "val epoch: 74 [12928/221852 (6%)]\tLoss: 0.174851\tAcc: 76.00\n",
      "train epoch: 75 [128/221852 (0%)]\tLoss: 0.272795\tAcc: 79.00\n",
      "train epoch: 75 [12928/221852 (6%)]\tLoss: 0.196564\tAcc: 79.00\n",
      "train epoch: 75 [25728/221852 (12%)]\tLoss: 0.263032\tAcc: 73.00\n",
      "train epoch: 75 [38528/221852 (17%)]\tLoss: 0.168799\tAcc: 81.00\n",
      "train epoch: 75 [51328/221852 (23%)]\tLoss: 0.208277\tAcc: 86.00\n",
      "train epoch: 75 [64128/221852 (29%)]\tLoss: 0.126763\tAcc: 88.00\n",
      "train epoch: 75 [76928/221852 (35%)]\tLoss: 0.188688\tAcc: 77.00\n",
      "train epoch: 75 [89728/221852 (40%)]\tLoss: 0.299034\tAcc: 73.00\n",
      "train epoch: 75 [102528/221852 (46%)]\tLoss: 0.210554\tAcc: 82.00\n",
      "train epoch: 75 [115328/221852 (52%)]\tLoss: 0.139729\tAcc: 80.00\n",
      "train epoch: 75 [128128/221852 (58%)]\tLoss: 0.198168\tAcc: 77.00\n",
      "train epoch: 75 [140928/221852 (64%)]\tLoss: 0.181158\tAcc: 85.00\n",
      "train epoch: 75 [153728/221852 (69%)]\tLoss: 0.240986\tAcc: 79.00\n",
      "train epoch: 75 [166528/221852 (75%)]\tLoss: 0.207513\tAcc: 77.00\n",
      "train epoch: 75 [179328/221852 (81%)]\tLoss: 0.170054\tAcc: 84.00\n",
      "train epoch: 75 [192128/221852 (87%)]\tLoss: 0.136321\tAcc: 80.00\n",
      "val epoch: 75 [128/221852 (0%)]\tLoss: 0.210172\tAcc: 77.00\n",
      "val epoch: 75 [12928/221852 (6%)]\tLoss: 0.165200\tAcc: 77.00\n",
      "train epoch: 76 [128/221852 (0%)]\tLoss: 0.160385\tAcc: 79.00\n",
      "train epoch: 76 [12928/221852 (6%)]\tLoss: 0.134059\tAcc: 80.00\n",
      "train epoch: 76 [25728/221852 (12%)]\tLoss: 0.176067\tAcc: 74.00\n",
      "train epoch: 76 [38528/221852 (17%)]\tLoss: 0.168694\tAcc: 81.00\n",
      "train epoch: 76 [51328/221852 (23%)]\tLoss: 0.215747\tAcc: 77.00\n",
      "train epoch: 76 [64128/221852 (29%)]\tLoss: 0.256896\tAcc: 81.00\n",
      "train epoch: 76 [76928/221852 (35%)]\tLoss: 0.162522\tAcc: 79.00\n",
      "train epoch: 76 [89728/221852 (40%)]\tLoss: 0.231437\tAcc: 78.00\n",
      "train epoch: 76 [102528/221852 (46%)]\tLoss: 0.248656\tAcc: 77.00\n",
      "train epoch: 76 [115328/221852 (52%)]\tLoss: 0.122179\tAcc: 87.00\n",
      "train epoch: 76 [128128/221852 (58%)]\tLoss: 0.214989\tAcc: 83.00\n",
      "train epoch: 76 [140928/221852 (64%)]\tLoss: 0.179530\tAcc: 78.00\n",
      "train epoch: 76 [153728/221852 (69%)]\tLoss: 0.121226\tAcc: 79.00\n",
      "train epoch: 76 [166528/221852 (75%)]\tLoss: 0.096766\tAcc: 85.00\n",
      "train epoch: 76 [179328/221852 (81%)]\tLoss: 0.231702\tAcc: 75.00\n",
      "train epoch: 76 [192128/221852 (87%)]\tLoss: 0.264742\tAcc: 77.00\n",
      "val epoch: 76 [128/221852 (0%)]\tLoss: 0.224900\tAcc: 76.00\n",
      "val epoch: 76 [12928/221852 (6%)]\tLoss: 0.121479\tAcc: 84.00\n",
      "train epoch: 77 [128/221852 (0%)]\tLoss: 0.096537\tAcc: 84.00\n",
      "train epoch: 77 [12928/221852 (6%)]\tLoss: 0.192024\tAcc: 80.00\n",
      "train epoch: 77 [25728/221852 (12%)]\tLoss: 0.272652\tAcc: 78.00\n",
      "train epoch: 77 [38528/221852 (17%)]\tLoss: 0.209926\tAcc: 76.00\n",
      "train epoch: 77 [51328/221852 (23%)]\tLoss: 0.239112\tAcc: 81.00\n",
      "train epoch: 77 [64128/221852 (29%)]\tLoss: 0.209185\tAcc: 77.00\n",
      "train epoch: 77 [76928/221852 (35%)]\tLoss: 0.266550\tAcc: 78.00\n",
      "train epoch: 77 [89728/221852 (40%)]\tLoss: 0.217910\tAcc: 88.00\n",
      "train epoch: 77 [102528/221852 (46%)]\tLoss: 0.217103\tAcc: 78.00\n",
      "train epoch: 77 [115328/221852 (52%)]\tLoss: 0.220540\tAcc: 78.00\n",
      "train epoch: 77 [128128/221852 (58%)]\tLoss: 0.172756\tAcc: 85.00\n",
      "train epoch: 77 [140928/221852 (64%)]\tLoss: 0.189317\tAcc: 83.00\n",
      "train epoch: 77 [153728/221852 (69%)]\tLoss: 0.207540\tAcc: 74.00\n",
      "train epoch: 77 [166528/221852 (75%)]\tLoss: 0.171959\tAcc: 83.00\n",
      "train epoch: 77 [179328/221852 (81%)]\tLoss: 0.219608\tAcc: 77.00\n",
      "train epoch: 77 [192128/221852 (87%)]\tLoss: 0.175834\tAcc: 81.00\n",
      "val epoch: 77 [128/221852 (0%)]\tLoss: 0.160977\tAcc: 82.00\n",
      "val epoch: 77 [12928/221852 (6%)]\tLoss: 0.164623\tAcc: 77.00\n",
      "train epoch: 78 [128/221852 (0%)]\tLoss: 0.128200\tAcc: 81.00\n",
      "train epoch: 78 [12928/221852 (6%)]\tLoss: 0.206847\tAcc: 79.00\n",
      "train epoch: 78 [25728/221852 (12%)]\tLoss: 0.166830\tAcc: 81.00\n",
      "train epoch: 78 [38528/221852 (17%)]\tLoss: 0.217777\tAcc: 82.00\n",
      "train epoch: 78 [51328/221852 (23%)]\tLoss: 0.182799\tAcc: 82.00\n",
      "train epoch: 78 [64128/221852 (29%)]\tLoss: 0.188035\tAcc: 77.00\n",
      "train epoch: 78 [76928/221852 (35%)]\tLoss: 0.143195\tAcc: 80.00\n",
      "train epoch: 78 [89728/221852 (40%)]\tLoss: 0.220233\tAcc: 80.00\n",
      "train epoch: 78 [102528/221852 (46%)]\tLoss: 0.232240\tAcc: 86.00\n",
      "train epoch: 78 [115328/221852 (52%)]\tLoss: 0.258988\tAcc: 83.00\n",
      "train epoch: 78 [128128/221852 (58%)]\tLoss: 0.203220\tAcc: 81.00\n",
      "train epoch: 78 [140928/221852 (64%)]\tLoss: 0.364068\tAcc: 72.00\n",
      "train epoch: 78 [153728/221852 (69%)]\tLoss: 0.194831\tAcc: 74.00\n",
      "train epoch: 78 [166528/221852 (75%)]\tLoss: 0.266191\tAcc: 84.00\n",
      "train epoch: 78 [179328/221852 (81%)]\tLoss: 0.248251\tAcc: 73.00\n",
      "train epoch: 78 [192128/221852 (87%)]\tLoss: 0.209645\tAcc: 79.00\n",
      "val epoch: 78 [128/221852 (0%)]\tLoss: 0.210987\tAcc: 80.00\n",
      "val epoch: 78 [12928/221852 (6%)]\tLoss: 0.239108\tAcc: 76.00\n",
      "train epoch: 79 [128/221852 (0%)]\tLoss: 0.146288\tAcc: 82.00\n",
      "train epoch: 79 [12928/221852 (6%)]\tLoss: 0.232248\tAcc: 77.00\n",
      "train epoch: 79 [25728/221852 (12%)]\tLoss: 0.296101\tAcc: 83.00\n",
      "train epoch: 79 [38528/221852 (17%)]\tLoss: 0.260404\tAcc: 80.00\n",
      "train epoch: 79 [51328/221852 (23%)]\tLoss: 0.144077\tAcc: 80.00\n",
      "train epoch: 79 [64128/221852 (29%)]\tLoss: 0.164528\tAcc: 84.00\n",
      "train epoch: 79 [76928/221852 (35%)]\tLoss: 0.150414\tAcc: 80.00\n",
      "train epoch: 79 [89728/221852 (40%)]\tLoss: 0.158966\tAcc: 82.00\n",
      "train epoch: 79 [102528/221852 (46%)]\tLoss: 0.227103\tAcc: 81.00\n",
      "train epoch: 79 [115328/221852 (52%)]\tLoss: 0.166133\tAcc: 80.00\n",
      "train epoch: 79 [128128/221852 (58%)]\tLoss: 0.167773\tAcc: 80.00\n",
      "train epoch: 79 [140928/221852 (64%)]\tLoss: 0.165280\tAcc: 80.00\n",
      "train epoch: 79 [153728/221852 (69%)]\tLoss: 0.135940\tAcc: 77.00\n",
      "train epoch: 79 [166528/221852 (75%)]\tLoss: 0.166992\tAcc: 83.00\n",
      "train epoch: 79 [179328/221852 (81%)]\tLoss: 0.223506\tAcc: 81.00\n",
      "train epoch: 79 [192128/221852 (87%)]\tLoss: 0.212376\tAcc: 76.00\n",
      "val epoch: 79 [128/221852 (0%)]\tLoss: 0.206536\tAcc: 78.00\n",
      "val epoch: 79 [12928/221852 (6%)]\tLoss: 0.227517\tAcc: 78.00\n",
      "train epoch: 80 [128/221852 (0%)]\tLoss: 0.193560\tAcc: 78.00\n",
      "train epoch: 80 [12928/221852 (6%)]\tLoss: 0.179361\tAcc: 79.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 80 [25728/221852 (12%)]\tLoss: 0.206258\tAcc: 80.00\n",
      "train epoch: 80 [38528/221852 (17%)]\tLoss: 0.239366\tAcc: 82.00\n",
      "train epoch: 80 [51328/221852 (23%)]\tLoss: 0.319311\tAcc: 77.00\n",
      "train epoch: 80 [64128/221852 (29%)]\tLoss: 0.152618\tAcc: 82.00\n",
      "train epoch: 80 [76928/221852 (35%)]\tLoss: 0.225546\tAcc: 79.00\n",
      "train epoch: 80 [89728/221852 (40%)]\tLoss: 0.193261\tAcc: 77.00\n",
      "train epoch: 80 [102528/221852 (46%)]\tLoss: 0.277188\tAcc: 80.00\n",
      "train epoch: 80 [115328/221852 (52%)]\tLoss: 0.165887\tAcc: 77.00\n",
      "train epoch: 80 [128128/221852 (58%)]\tLoss: 0.138273\tAcc: 72.00\n",
      "train epoch: 80 [140928/221852 (64%)]\tLoss: 0.243398\tAcc: 77.00\n",
      "train epoch: 80 [153728/221852 (69%)]\tLoss: 0.235693\tAcc: 83.00\n",
      "train epoch: 80 [166528/221852 (75%)]\tLoss: 0.226712\tAcc: 87.00\n",
      "train epoch: 80 [179328/221852 (81%)]\tLoss: 0.145018\tAcc: 80.00\n",
      "train epoch: 80 [192128/221852 (87%)]\tLoss: 0.159648\tAcc: 77.00\n",
      "val epoch: 80 [128/221852 (0%)]\tLoss: 0.202731\tAcc: 78.00\n",
      "val epoch: 80 [12928/221852 (6%)]\tLoss: 0.177303\tAcc: 78.00\n",
      "train epoch: 81 [128/221852 (0%)]\tLoss: 0.158283\tAcc: 79.00\n",
      "train epoch: 81 [12928/221852 (6%)]\tLoss: 0.196248\tAcc: 80.00\n",
      "train epoch: 81 [25728/221852 (12%)]\tLoss: 0.204007\tAcc: 84.00\n",
      "train epoch: 81 [38528/221852 (17%)]\tLoss: 0.178336\tAcc: 80.00\n",
      "train epoch: 81 [51328/221852 (23%)]\tLoss: 0.269244\tAcc: 79.00\n",
      "train epoch: 81 [64128/221852 (29%)]\tLoss: 0.200551\tAcc: 78.00\n",
      "train epoch: 81 [76928/221852 (35%)]\tLoss: 0.219381\tAcc: 83.00\n",
      "train epoch: 81 [89728/221852 (40%)]\tLoss: 0.164898\tAcc: 87.00\n",
      "train epoch: 81 [102528/221852 (46%)]\tLoss: 0.178700\tAcc: 84.00\n",
      "train epoch: 81 [115328/221852 (52%)]\tLoss: 0.143769\tAcc: 84.00\n",
      "train epoch: 81 [128128/221852 (58%)]\tLoss: 0.312126\tAcc: 77.00\n",
      "train epoch: 81 [140928/221852 (64%)]\tLoss: 0.276669\tAcc: 80.00\n",
      "train epoch: 81 [153728/221852 (69%)]\tLoss: 0.144023\tAcc: 83.00\n",
      "train epoch: 81 [166528/221852 (75%)]\tLoss: 0.181965\tAcc: 84.00\n",
      "train epoch: 81 [179328/221852 (81%)]\tLoss: 0.319839\tAcc: 75.00\n",
      "train epoch: 81 [192128/221852 (87%)]\tLoss: 0.143707\tAcc: 83.00\n",
      "val epoch: 81 [128/221852 (0%)]\tLoss: 0.212749\tAcc: 79.00\n",
      "val epoch: 81 [12928/221852 (6%)]\tLoss: 0.108405\tAcc: 90.00\n",
      "train epoch: 82 [128/221852 (0%)]\tLoss: 0.162472\tAcc: 85.00\n",
      "train epoch: 82 [12928/221852 (6%)]\tLoss: 0.170072\tAcc: 81.00\n",
      "train epoch: 82 [25728/221852 (12%)]\tLoss: 0.309210\tAcc: 77.00\n",
      "train epoch: 82 [38528/221852 (17%)]\tLoss: 0.272201\tAcc: 76.00\n",
      "train epoch: 82 [51328/221852 (23%)]\tLoss: 0.252622\tAcc: 81.00\n",
      "train epoch: 82 [64128/221852 (29%)]\tLoss: 0.164187\tAcc: 85.00\n",
      "train epoch: 82 [76928/221852 (35%)]\tLoss: 0.184210\tAcc: 73.00\n",
      "train epoch: 82 [89728/221852 (40%)]\tLoss: 0.116301\tAcc: 81.00\n",
      "train epoch: 82 [102528/221852 (46%)]\tLoss: 0.225448\tAcc: 73.00\n",
      "train epoch: 82 [115328/221852 (52%)]\tLoss: 0.185668\tAcc: 77.00\n",
      "train epoch: 82 [128128/221852 (58%)]\tLoss: 0.185496\tAcc: 80.00\n",
      "train epoch: 82 [140928/221852 (64%)]\tLoss: 0.161211\tAcc: 81.00\n",
      "train epoch: 82 [153728/221852 (69%)]\tLoss: 0.195294\tAcc: 84.00\n",
      "train epoch: 82 [166528/221852 (75%)]\tLoss: 0.141944\tAcc: 82.00\n",
      "train epoch: 82 [179328/221852 (81%)]\tLoss: 0.160883\tAcc: 77.00\n",
      "train epoch: 82 [192128/221852 (87%)]\tLoss: 0.287500\tAcc: 74.00\n",
      "val epoch: 82 [128/221852 (0%)]\tLoss: 0.211340\tAcc: 82.00\n",
      "val epoch: 82 [12928/221852 (6%)]\tLoss: 0.172666\tAcc: 81.00\n",
      "train epoch: 83 [128/221852 (0%)]\tLoss: 0.200141\tAcc: 77.00\n",
      "train epoch: 83 [12928/221852 (6%)]\tLoss: 0.156597\tAcc: 77.00\n",
      "train epoch: 83 [25728/221852 (12%)]\tLoss: 0.184437\tAcc: 78.00\n",
      "train epoch: 83 [38528/221852 (17%)]\tLoss: 0.265367\tAcc: 77.00\n",
      "train epoch: 83 [51328/221852 (23%)]\tLoss: 0.189228\tAcc: 79.00\n",
      "train epoch: 83 [64128/221852 (29%)]\tLoss: 0.221059\tAcc: 82.00\n",
      "train epoch: 83 [76928/221852 (35%)]\tLoss: 0.221482\tAcc: 73.00\n",
      "train epoch: 83 [89728/221852 (40%)]\tLoss: 0.221304\tAcc: 80.00\n",
      "train epoch: 83 [102528/221852 (46%)]\tLoss: 0.147454\tAcc: 77.00\n",
      "train epoch: 83 [115328/221852 (52%)]\tLoss: 0.169999\tAcc: 83.00\n",
      "train epoch: 83 [128128/221852 (58%)]\tLoss: 0.148276\tAcc: 80.00\n",
      "train epoch: 83 [140928/221852 (64%)]\tLoss: 0.309010\tAcc: 80.00\n",
      "train epoch: 83 [153728/221852 (69%)]\tLoss: 0.199947\tAcc: 78.00\n",
      "train epoch: 83 [166528/221852 (75%)]\tLoss: 0.151422\tAcc: 81.00\n",
      "train epoch: 83 [179328/221852 (81%)]\tLoss: 0.183844\tAcc: 80.00\n",
      "train epoch: 83 [192128/221852 (87%)]\tLoss: 0.182176\tAcc: 84.00\n",
      "val epoch: 83 [128/221852 (0%)]\tLoss: 0.270518\tAcc: 75.00\n",
      "val epoch: 83 [12928/221852 (6%)]\tLoss: 0.139413\tAcc: 84.00\n",
      "train epoch: 84 [128/221852 (0%)]\tLoss: 0.158666\tAcc: 84.00\n",
      "train epoch: 84 [12928/221852 (6%)]\tLoss: 0.189069\tAcc: 80.00\n",
      "train epoch: 84 [25728/221852 (12%)]\tLoss: 0.576466\tAcc: 85.00\n",
      "train epoch: 84 [38528/221852 (17%)]\tLoss: 0.146919\tAcc: 86.00\n",
      "train epoch: 84 [51328/221852 (23%)]\tLoss: 0.183778\tAcc: 80.00\n",
      "train epoch: 84 [64128/221852 (29%)]\tLoss: 0.167261\tAcc: 82.00\n",
      "train epoch: 84 [76928/221852 (35%)]\tLoss: 0.209347\tAcc: 80.00\n",
      "train epoch: 84 [89728/221852 (40%)]\tLoss: 0.323102\tAcc: 81.00\n",
      "train epoch: 84 [102528/221852 (46%)]\tLoss: 0.251206\tAcc: 80.00\n",
      "train epoch: 84 [115328/221852 (52%)]\tLoss: 0.254420\tAcc: 81.00\n",
      "train epoch: 84 [128128/221852 (58%)]\tLoss: 0.120150\tAcc: 88.00\n",
      "train epoch: 84 [140928/221852 (64%)]\tLoss: 0.157420\tAcc: 87.00\n",
      "train epoch: 84 [153728/221852 (69%)]\tLoss: 0.171360\tAcc: 81.00\n",
      "train epoch: 84 [166528/221852 (75%)]\tLoss: 0.136014\tAcc: 84.00\n",
      "train epoch: 84 [179328/221852 (81%)]\tLoss: 0.130898\tAcc: 81.00\n",
      "train epoch: 84 [192128/221852 (87%)]\tLoss: 0.176236\tAcc: 85.00\n",
      "val epoch: 84 [128/221852 (0%)]\tLoss: 0.139288\tAcc: 84.00\n",
      "val epoch: 84 [12928/221852 (6%)]\tLoss: 0.194452\tAcc: 77.00\n",
      "train epoch: 85 [128/221852 (0%)]\tLoss: 0.167942\tAcc: 85.00\n",
      "train epoch: 85 [12928/221852 (6%)]\tLoss: 0.177340\tAcc: 82.00\n",
      "train epoch: 85 [25728/221852 (12%)]\tLoss: 0.229768\tAcc: 88.00\n",
      "train epoch: 85 [38528/221852 (17%)]\tLoss: 0.249370\tAcc: 77.00\n",
      "train epoch: 85 [51328/221852 (23%)]\tLoss: 0.195470\tAcc: 81.00\n",
      "train epoch: 85 [64128/221852 (29%)]\tLoss: 0.192485\tAcc: 84.00\n",
      "train epoch: 85 [76928/221852 (35%)]\tLoss: 0.209725\tAcc: 80.00\n",
      "train epoch: 85 [89728/221852 (40%)]\tLoss: 0.202897\tAcc: 76.00\n",
      "train epoch: 85 [102528/221852 (46%)]\tLoss: 0.112817\tAcc: 84.00\n",
      "train epoch: 85 [115328/221852 (52%)]\tLoss: 0.260108\tAcc: 77.00\n",
      "train epoch: 85 [128128/221852 (58%)]\tLoss: 0.202195\tAcc: 77.00\n",
      "train epoch: 85 [140928/221852 (64%)]\tLoss: 0.186441\tAcc: 84.00\n",
      "train epoch: 85 [153728/221852 (69%)]\tLoss: 0.153817\tAcc: 84.00\n",
      "train epoch: 85 [166528/221852 (75%)]\tLoss: 0.150917\tAcc: 83.00\n",
      "train epoch: 85 [179328/221852 (81%)]\tLoss: 0.205862\tAcc: 74.00\n",
      "train epoch: 85 [192128/221852 (87%)]\tLoss: 0.280771\tAcc: 78.00\n",
      "val epoch: 85 [128/221852 (0%)]\tLoss: 0.179364\tAcc: 80.00\n",
      "val epoch: 85 [12928/221852 (6%)]\tLoss: 0.243913\tAcc: 79.00\n",
      "train epoch: 86 [128/221852 (0%)]\tLoss: 0.200493\tAcc: 75.00\n",
      "train epoch: 86 [12928/221852 (6%)]\tLoss: 0.168828\tAcc: 78.00\n",
      "train epoch: 86 [25728/221852 (12%)]\tLoss: 0.218883\tAcc: 79.00\n",
      "train epoch: 86 [38528/221852 (17%)]\tLoss: 0.277827\tAcc: 79.00\n",
      "train epoch: 86 [51328/221852 (23%)]\tLoss: 0.236855\tAcc: 79.00\n",
      "train epoch: 86 [64128/221852 (29%)]\tLoss: 0.103299\tAcc: 87.00\n",
      "train epoch: 86 [76928/221852 (35%)]\tLoss: 0.199783\tAcc: 79.00\n",
      "train epoch: 86 [89728/221852 (40%)]\tLoss: 0.139769\tAcc: 88.00\n",
      "train epoch: 86 [102528/221852 (46%)]\tLoss: 0.211815\tAcc: 79.00\n",
      "train epoch: 86 [115328/221852 (52%)]\tLoss: 0.187751\tAcc: 84.00\n",
      "train epoch: 86 [128128/221852 (58%)]\tLoss: 0.223334\tAcc: 77.00\n",
      "train epoch: 86 [140928/221852 (64%)]\tLoss: 0.117936\tAcc: 85.00\n",
      "train epoch: 86 [153728/221852 (69%)]\tLoss: 0.270023\tAcc: 75.00\n",
      "train epoch: 86 [166528/221852 (75%)]\tLoss: 0.327006\tAcc: 75.00\n",
      "train epoch: 86 [179328/221852 (81%)]\tLoss: 0.159068\tAcc: 86.00\n",
      "train epoch: 86 [192128/221852 (87%)]\tLoss: 0.095872\tAcc: 84.00\n",
      "val epoch: 86 [128/221852 (0%)]\tLoss: 0.196754\tAcc: 75.00\n",
      "val epoch: 86 [12928/221852 (6%)]\tLoss: 0.124566\tAcc: 85.00\n",
      "train epoch: 87 [128/221852 (0%)]\tLoss: 0.215319\tAcc: 80.00\n",
      "train epoch: 87 [12928/221852 (6%)]\tLoss: 0.187899\tAcc: 80.00\n",
      "train epoch: 87 [25728/221852 (12%)]\tLoss: 0.174976\tAcc: 85.00\n",
      "train epoch: 87 [38528/221852 (17%)]\tLoss: 0.091124\tAcc: 89.00\n",
      "train epoch: 87 [51328/221852 (23%)]\tLoss: 0.182426\tAcc: 82.00\n",
      "train epoch: 87 [64128/221852 (29%)]\tLoss: 0.204112\tAcc: 81.00\n",
      "train epoch: 87 [76928/221852 (35%)]\tLoss: 0.185881\tAcc: 84.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 87 [89728/221852 (40%)]\tLoss: 0.233330\tAcc: 75.00\n",
      "train epoch: 87 [102528/221852 (46%)]\tLoss: 0.248909\tAcc: 86.00\n",
      "train epoch: 87 [115328/221852 (52%)]\tLoss: 0.255035\tAcc: 73.00\n",
      "train epoch: 87 [128128/221852 (58%)]\tLoss: 0.217342\tAcc: 82.00\n",
      "train epoch: 87 [140928/221852 (64%)]\tLoss: 0.122437\tAcc: 84.00\n",
      "train epoch: 87 [153728/221852 (69%)]\tLoss: 0.170462\tAcc: 87.00\n",
      "train epoch: 87 [166528/221852 (75%)]\tLoss: 0.267044\tAcc: 74.00\n",
      "train epoch: 87 [179328/221852 (81%)]\tLoss: 0.188039\tAcc: 83.00\n",
      "train epoch: 87 [192128/221852 (87%)]\tLoss: 0.272846\tAcc: 80.00\n",
      "val epoch: 87 [128/221852 (0%)]\tLoss: 0.233750\tAcc: 78.00\n",
      "val epoch: 87 [12928/221852 (6%)]\tLoss: 0.295681\tAcc: 77.00\n",
      "train epoch: 88 [128/221852 (0%)]\tLoss: 0.308060\tAcc: 81.00\n",
      "train epoch: 88 [12928/221852 (6%)]\tLoss: 0.182089\tAcc: 80.00\n",
      "train epoch: 88 [25728/221852 (12%)]\tLoss: 0.216518\tAcc: 72.00\n",
      "train epoch: 88 [38528/221852 (17%)]\tLoss: 0.192693\tAcc: 85.00\n",
      "train epoch: 88 [51328/221852 (23%)]\tLoss: 0.215345\tAcc: 82.00\n",
      "train epoch: 88 [64128/221852 (29%)]\tLoss: 0.190113\tAcc: 82.00\n",
      "train epoch: 88 [76928/221852 (35%)]\tLoss: 0.190386\tAcc: 71.00\n",
      "train epoch: 88 [89728/221852 (40%)]\tLoss: 0.108664\tAcc: 84.00\n",
      "train epoch: 88 [102528/221852 (46%)]\tLoss: 0.248620\tAcc: 80.00\n",
      "train epoch: 88 [115328/221852 (52%)]\tLoss: 0.176176\tAcc: 77.00\n",
      "train epoch: 88 [128128/221852 (58%)]\tLoss: 0.228369\tAcc: 78.00\n",
      "train epoch: 88 [140928/221852 (64%)]\tLoss: 0.096520\tAcc: 79.00\n",
      "train epoch: 88 [153728/221852 (69%)]\tLoss: 0.210032\tAcc: 79.00\n",
      "train epoch: 88 [166528/221852 (75%)]\tLoss: 0.228601\tAcc: 73.00\n",
      "train epoch: 88 [179328/221852 (81%)]\tLoss: 0.131022\tAcc: 86.00\n",
      "train epoch: 88 [192128/221852 (87%)]\tLoss: 0.181063\tAcc: 82.00\n",
      "val epoch: 88 [128/221852 (0%)]\tLoss: 0.188481\tAcc: 82.00\n",
      "val epoch: 88 [12928/221852 (6%)]\tLoss: 0.165633\tAcc: 84.00\n",
      "train epoch: 89 [128/221852 (0%)]\tLoss: 0.137002\tAcc: 81.00\n",
      "train epoch: 89 [12928/221852 (6%)]\tLoss: 0.205723\tAcc: 75.00\n",
      "train epoch: 89 [25728/221852 (12%)]\tLoss: 0.159879\tAcc: 78.00\n",
      "train epoch: 89 [38528/221852 (17%)]\tLoss: 0.195332\tAcc: 79.00\n",
      "train epoch: 89 [51328/221852 (23%)]\tLoss: 0.279477\tAcc: 79.00\n",
      "train epoch: 89 [64128/221852 (29%)]\tLoss: 0.226341\tAcc: 82.00\n",
      "train epoch: 89 [76928/221852 (35%)]\tLoss: 0.266882\tAcc: 77.00\n",
      "train epoch: 89 [89728/221852 (40%)]\tLoss: 0.225688\tAcc: 75.00\n",
      "train epoch: 89 [102528/221852 (46%)]\tLoss: 0.201467\tAcc: 84.00\n",
      "train epoch: 89 [115328/221852 (52%)]\tLoss: 0.179958\tAcc: 80.00\n",
      "train epoch: 89 [128128/221852 (58%)]\tLoss: 0.128298\tAcc: 86.00\n",
      "train epoch: 89 [140928/221852 (64%)]\tLoss: 0.259672\tAcc: 82.00\n",
      "train epoch: 89 [153728/221852 (69%)]\tLoss: 0.185067\tAcc: 81.00\n",
      "train epoch: 89 [166528/221852 (75%)]\tLoss: 0.251448\tAcc: 78.00\n",
      "train epoch: 89 [179328/221852 (81%)]\tLoss: 0.201772\tAcc: 85.00\n",
      "train epoch: 89 [192128/221852 (87%)]\tLoss: 0.211910\tAcc: 82.00\n",
      "val epoch: 89 [128/221852 (0%)]\tLoss: 0.191636\tAcc: 79.00\n",
      "val epoch: 89 [12928/221852 (6%)]\tLoss: 0.236950\tAcc: 75.00\n",
      "train epoch: 90 [128/221852 (0%)]\tLoss: 0.191892\tAcc: 80.00\n",
      "train epoch: 90 [12928/221852 (6%)]\tLoss: 0.200720\tAcc: 86.00\n",
      "train epoch: 90 [25728/221852 (12%)]\tLoss: 0.211414\tAcc: 80.00\n",
      "train epoch: 90 [38528/221852 (17%)]\tLoss: 0.208851\tAcc: 79.00\n",
      "train epoch: 90 [51328/221852 (23%)]\tLoss: 0.208172\tAcc: 80.00\n",
      "train epoch: 90 [64128/221852 (29%)]\tLoss: 0.206904\tAcc: 81.00\n",
      "train epoch: 90 [76928/221852 (35%)]\tLoss: 0.168802\tAcc: 82.00\n",
      "train epoch: 90 [89728/221852 (40%)]\tLoss: 0.235392\tAcc: 82.00\n",
      "train epoch: 90 [102528/221852 (46%)]\tLoss: 0.192318\tAcc: 76.00\n",
      "train epoch: 90 [115328/221852 (52%)]\tLoss: 0.256572\tAcc: 82.00\n",
      "train epoch: 90 [128128/221852 (58%)]\tLoss: 0.179785\tAcc: 81.00\n",
      "train epoch: 90 [140928/221852 (64%)]\tLoss: 0.209288\tAcc: 76.00\n",
      "train epoch: 90 [153728/221852 (69%)]\tLoss: 0.236157\tAcc: 76.00\n",
      "train epoch: 90 [166528/221852 (75%)]\tLoss: 0.243808\tAcc: 82.00\n",
      "train epoch: 90 [179328/221852 (81%)]\tLoss: 0.283779\tAcc: 74.00\n",
      "train epoch: 90 [192128/221852 (87%)]\tLoss: 0.138887\tAcc: 77.00\n",
      "val epoch: 90 [128/221852 (0%)]\tLoss: 0.167828\tAcc: 76.00\n",
      "val epoch: 90 [12928/221852 (6%)]\tLoss: 0.213870\tAcc: 78.00\n",
      "train epoch: 91 [128/221852 (0%)]\tLoss: 0.202065\tAcc: 83.00\n",
      "train epoch: 91 [12928/221852 (6%)]\tLoss: 0.252617\tAcc: 81.00\n",
      "train epoch: 91 [25728/221852 (12%)]\tLoss: 0.168479\tAcc: 84.00\n",
      "train epoch: 91 [38528/221852 (17%)]\tLoss: 0.326089\tAcc: 75.00\n",
      "train epoch: 91 [51328/221852 (23%)]\tLoss: 0.247896\tAcc: 84.00\n",
      "train epoch: 91 [64128/221852 (29%)]\tLoss: 0.162094\tAcc: 79.00\n",
      "train epoch: 91 [76928/221852 (35%)]\tLoss: 0.258815\tAcc: 75.00\n",
      "train epoch: 91 [89728/221852 (40%)]\tLoss: 0.147204\tAcc: 82.00\n",
      "train epoch: 91 [102528/221852 (46%)]\tLoss: 0.165720\tAcc: 81.00\n",
      "train epoch: 91 [115328/221852 (52%)]\tLoss: 0.200033\tAcc: 87.00\n",
      "train epoch: 91 [128128/221852 (58%)]\tLoss: 0.238424\tAcc: 77.00\n",
      "train epoch: 91 [140928/221852 (64%)]\tLoss: 0.116896\tAcc: 81.00\n",
      "train epoch: 91 [153728/221852 (69%)]\tLoss: 0.222775\tAcc: 84.00\n",
      "train epoch: 91 [166528/221852 (75%)]\tLoss: 0.163231\tAcc: 80.00\n",
      "train epoch: 91 [179328/221852 (81%)]\tLoss: 0.265421\tAcc: 82.00\n",
      "train epoch: 91 [192128/221852 (87%)]\tLoss: 0.214385\tAcc: 80.00\n",
      "val epoch: 91 [128/221852 (0%)]\tLoss: 0.111787\tAcc: 84.00\n",
      "val epoch: 91 [12928/221852 (6%)]\tLoss: 0.137316\tAcc: 80.00\n",
      "train epoch: 92 [128/221852 (0%)]\tLoss: 0.149185\tAcc: 78.00\n",
      "train epoch: 92 [12928/221852 (6%)]\tLoss: 0.129438\tAcc: 85.00\n",
      "train epoch: 92 [25728/221852 (12%)]\tLoss: 0.168876\tAcc: 82.00\n",
      "train epoch: 92 [38528/221852 (17%)]\tLoss: 0.230592\tAcc: 78.00\n",
      "train epoch: 92 [51328/221852 (23%)]\tLoss: 0.157350\tAcc: 83.00\n",
      "train epoch: 92 [64128/221852 (29%)]\tLoss: 0.246285\tAcc: 82.00\n",
      "train epoch: 92 [76928/221852 (35%)]\tLoss: 0.256905\tAcc: 79.00\n",
      "train epoch: 92 [89728/221852 (40%)]\tLoss: 0.153653\tAcc: 79.00\n",
      "train epoch: 92 [102528/221852 (46%)]\tLoss: 0.162276\tAcc: 85.00\n",
      "train epoch: 92 [115328/221852 (52%)]\tLoss: 0.199233\tAcc: 79.00\n",
      "train epoch: 92 [128128/221852 (58%)]\tLoss: 0.161842\tAcc: 84.00\n",
      "train epoch: 92 [140928/221852 (64%)]\tLoss: 0.165582\tAcc: 88.00\n",
      "train epoch: 92 [153728/221852 (69%)]\tLoss: 0.248220\tAcc: 81.00\n",
      "train epoch: 92 [166528/221852 (75%)]\tLoss: 0.201709\tAcc: 82.00\n",
      "train epoch: 92 [179328/221852 (81%)]\tLoss: 0.147876\tAcc: 86.00\n",
      "train epoch: 92 [192128/221852 (87%)]\tLoss: 0.184867\tAcc: 81.00\n",
      "val epoch: 92 [128/221852 (0%)]\tLoss: 0.469598\tAcc: 89.00\n",
      "val epoch: 92 [12928/221852 (6%)]\tLoss: 0.434286\tAcc: 83.00\n",
      "train epoch: 93 [128/221852 (0%)]\tLoss: 0.454292\tAcc: 82.00\n",
      "train epoch: 93 [12928/221852 (6%)]\tLoss: 0.239100\tAcc: 84.00\n",
      "train epoch: 93 [25728/221852 (12%)]\tLoss: 0.263621\tAcc: 83.00\n",
      "train epoch: 93 [38528/221852 (17%)]\tLoss: 0.176356\tAcc: 88.00\n",
      "train epoch: 93 [51328/221852 (23%)]\tLoss: 0.173112\tAcc: 85.00\n",
      "train epoch: 93 [64128/221852 (29%)]\tLoss: 0.223450\tAcc: 82.00\n",
      "train epoch: 93 [76928/221852 (35%)]\tLoss: 0.267654\tAcc: 77.00\n",
      "train epoch: 93 [89728/221852 (40%)]\tLoss: 0.205564\tAcc: 80.00\n",
      "train epoch: 93 [102528/221852 (46%)]\tLoss: 0.142640\tAcc: 84.00\n",
      "train epoch: 93 [115328/221852 (52%)]\tLoss: 0.235970\tAcc: 84.00\n",
      "train epoch: 93 [128128/221852 (58%)]\tLoss: 0.159045\tAcc: 82.00\n",
      "train epoch: 93 [140928/221852 (64%)]\tLoss: 0.250416\tAcc: 83.00\n",
      "train epoch: 93 [153728/221852 (69%)]\tLoss: 0.128922\tAcc: 79.00\n",
      "train epoch: 93 [166528/221852 (75%)]\tLoss: 0.253647\tAcc: 79.00\n",
      "train epoch: 93 [179328/221852 (81%)]\tLoss: 0.264371\tAcc: 80.00\n",
      "train epoch: 93 [192128/221852 (87%)]\tLoss: 0.158131\tAcc: 80.00\n",
      "val epoch: 93 [128/221852 (0%)]\tLoss: 0.151802\tAcc: 85.00\n",
      "val epoch: 93 [12928/221852 (6%)]\tLoss: 0.276483\tAcc: 77.00\n",
      "train epoch: 94 [128/221852 (0%)]\tLoss: 0.161199\tAcc: 84.00\n",
      "train epoch: 94 [12928/221852 (6%)]\tLoss: 0.194122\tAcc: 88.00\n",
      "train epoch: 94 [25728/221852 (12%)]\tLoss: 0.223136\tAcc: 74.00\n",
      "train epoch: 94 [38528/221852 (17%)]\tLoss: 0.311639\tAcc: 79.00\n",
      "train epoch: 94 [51328/221852 (23%)]\tLoss: 0.111921\tAcc: 84.00\n",
      "train epoch: 94 [64128/221852 (29%)]\tLoss: 0.207399\tAcc: 80.00\n",
      "train epoch: 94 [76928/221852 (35%)]\tLoss: 0.169234\tAcc: 79.00\n",
      "train epoch: 94 [89728/221852 (40%)]\tLoss: 0.149738\tAcc: 94.00\n",
      "train epoch: 94 [102528/221852 (46%)]\tLoss: 0.219835\tAcc: 81.00\n",
      "train epoch: 94 [115328/221852 (52%)]\tLoss: 0.331886\tAcc: 74.00\n",
      "train epoch: 94 [128128/221852 (58%)]\tLoss: 0.188589\tAcc: 85.00\n",
      "train epoch: 94 [140928/221852 (64%)]\tLoss: 0.191127\tAcc: 83.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 94 [153728/221852 (69%)]\tLoss: 0.136181\tAcc: 84.00\n",
      "train epoch: 94 [166528/221852 (75%)]\tLoss: 0.266294\tAcc: 75.00\n",
      "train epoch: 94 [179328/221852 (81%)]\tLoss: 0.223461\tAcc: 72.00\n",
      "train epoch: 94 [192128/221852 (87%)]\tLoss: 0.335574\tAcc: 78.00\n",
      "val epoch: 94 [128/221852 (0%)]\tLoss: 0.169759\tAcc: 79.00\n",
      "val epoch: 94 [12928/221852 (6%)]\tLoss: 0.230061\tAcc: 86.00\n",
      "train epoch: 95 [128/221852 (0%)]\tLoss: 0.149862\tAcc: 88.00\n",
      "train epoch: 95 [12928/221852 (6%)]\tLoss: 0.195809\tAcc: 84.00\n",
      "train epoch: 95 [25728/221852 (12%)]\tLoss: 0.137552\tAcc: 88.00\n",
      "train epoch: 95 [38528/221852 (17%)]\tLoss: 0.214503\tAcc: 77.00\n",
      "train epoch: 95 [51328/221852 (23%)]\tLoss: 0.152562\tAcc: 84.00\n",
      "train epoch: 95 [64128/221852 (29%)]\tLoss: 0.149031\tAcc: 80.00\n",
      "train epoch: 95 [76928/221852 (35%)]\tLoss: 0.196904\tAcc: 77.00\n",
      "train epoch: 95 [89728/221852 (40%)]\tLoss: 0.200001\tAcc: 88.00\n",
      "train epoch: 95 [102528/221852 (46%)]\tLoss: 0.238423\tAcc: 83.00\n",
      "train epoch: 95 [115328/221852 (52%)]\tLoss: 0.144832\tAcc: 81.00\n",
      "train epoch: 95 [128128/221852 (58%)]\tLoss: 0.164256\tAcc: 84.00\n",
      "train epoch: 95 [140928/221852 (64%)]\tLoss: 0.277059\tAcc: 80.00\n",
      "train epoch: 95 [153728/221852 (69%)]\tLoss: 0.242159\tAcc: 79.00\n",
      "train epoch: 95 [166528/221852 (75%)]\tLoss: 0.159794\tAcc: 77.00\n",
      "train epoch: 95 [179328/221852 (81%)]\tLoss: 0.213946\tAcc: 80.00\n",
      "train epoch: 95 [192128/221852 (87%)]\tLoss: 0.211574\tAcc: 83.00\n",
      "val epoch: 95 [128/221852 (0%)]\tLoss: 0.143154\tAcc: 83.00\n",
      "val epoch: 95 [12928/221852 (6%)]\tLoss: 0.130558\tAcc: 81.00\n",
      "train epoch: 96 [128/221852 (0%)]\tLoss: 0.169806\tAcc: 81.00\n",
      "train epoch: 96 [12928/221852 (6%)]\tLoss: 0.115689\tAcc: 88.00\n",
      "train epoch: 96 [25728/221852 (12%)]\tLoss: 0.232507\tAcc: 79.00\n",
      "train epoch: 96 [38528/221852 (17%)]\tLoss: 0.235820\tAcc: 77.00\n",
      "train epoch: 96 [51328/221852 (23%)]\tLoss: 0.225740\tAcc: 77.00\n",
      "train epoch: 96 [64128/221852 (29%)]\tLoss: 0.118415\tAcc: 82.00\n",
      "train epoch: 96 [76928/221852 (35%)]\tLoss: 0.174642\tAcc: 89.00\n",
      "train epoch: 96 [89728/221852 (40%)]\tLoss: 0.163065\tAcc: 83.00\n",
      "train epoch: 96 [102528/221852 (46%)]\tLoss: 0.210896\tAcc: 78.00\n",
      "train epoch: 96 [115328/221852 (52%)]\tLoss: 0.149736\tAcc: 74.00\n",
      "train epoch: 96 [128128/221852 (58%)]\tLoss: 0.162390\tAcc: 88.00\n",
      "train epoch: 96 [140928/221852 (64%)]\tLoss: 0.274745\tAcc: 76.00\n",
      "train epoch: 96 [153728/221852 (69%)]\tLoss: 0.122340\tAcc: 80.00\n",
      "train epoch: 96 [166528/221852 (75%)]\tLoss: 0.242695\tAcc: 81.00\n",
      "train epoch: 96 [179328/221852 (81%)]\tLoss: 0.100775\tAcc: 84.00\n",
      "train epoch: 96 [192128/221852 (87%)]\tLoss: 0.191984\tAcc: 83.00\n",
      "val epoch: 96 [128/221852 (0%)]\tLoss: 0.192574\tAcc: 88.00\n",
      "val epoch: 96 [12928/221852 (6%)]\tLoss: 0.232880\tAcc: 81.00\n",
      "train epoch: 97 [128/221852 (0%)]\tLoss: 0.210886\tAcc: 84.00\n",
      "train epoch: 97 [12928/221852 (6%)]\tLoss: 0.161253\tAcc: 83.00\n",
      "train epoch: 97 [25728/221852 (12%)]\tLoss: 0.171101\tAcc: 81.00\n",
      "train epoch: 97 [38528/221852 (17%)]\tLoss: 0.183965\tAcc: 83.00\n",
      "train epoch: 97 [51328/221852 (23%)]\tLoss: 0.169769\tAcc: 84.00\n",
      "train epoch: 97 [64128/221852 (29%)]\tLoss: 0.218964\tAcc: 76.00\n",
      "train epoch: 97 [76928/221852 (35%)]\tLoss: 0.155887\tAcc: 84.00\n",
      "train epoch: 97 [89728/221852 (40%)]\tLoss: 0.127838\tAcc: 80.00\n",
      "train epoch: 97 [102528/221852 (46%)]\tLoss: 0.151182\tAcc: 83.00\n",
      "train epoch: 97 [115328/221852 (52%)]\tLoss: 0.199651\tAcc: 77.00\n",
      "train epoch: 97 [128128/221852 (58%)]\tLoss: 0.150395\tAcc: 82.00\n",
      "train epoch: 97 [140928/221852 (64%)]\tLoss: 0.185548\tAcc: 82.00\n",
      "train epoch: 97 [153728/221852 (69%)]\tLoss: 0.201463\tAcc: 83.00\n",
      "train epoch: 97 [166528/221852 (75%)]\tLoss: 0.188869\tAcc: 76.00\n",
      "train epoch: 97 [179328/221852 (81%)]\tLoss: 0.259444\tAcc: 72.00\n",
      "train epoch: 97 [192128/221852 (87%)]\tLoss: 0.214394\tAcc: 81.00\n",
      "val epoch: 97 [128/221852 (0%)]\tLoss: 0.145346\tAcc: 84.00\n",
      "val epoch: 97 [12928/221852 (6%)]\tLoss: 0.188457\tAcc: 82.00\n",
      "train epoch: 98 [128/221852 (0%)]\tLoss: 0.216873\tAcc: 77.00\n",
      "train epoch: 98 [12928/221852 (6%)]\tLoss: 0.177519\tAcc: 81.00\n",
      "train epoch: 98 [25728/221852 (12%)]\tLoss: 0.172031\tAcc: 82.00\n",
      "train epoch: 98 [38528/221852 (17%)]\tLoss: 0.294654\tAcc: 84.00\n",
      "train epoch: 98 [51328/221852 (23%)]\tLoss: 0.178698\tAcc: 84.00\n",
      "train epoch: 98 [64128/221852 (29%)]\tLoss: 0.192638\tAcc: 81.00\n",
      "train epoch: 98 [76928/221852 (35%)]\tLoss: 0.179988\tAcc: 80.00\n",
      "train epoch: 98 [89728/221852 (40%)]\tLoss: 0.200116\tAcc: 82.00\n",
      "train epoch: 98 [102528/221852 (46%)]\tLoss: 0.163236\tAcc: 87.00\n",
      "train epoch: 98 [115328/221852 (52%)]\tLoss: 0.112391\tAcc: 88.00\n",
      "train epoch: 98 [128128/221852 (58%)]\tLoss: 0.182072\tAcc: 73.00\n",
      "train epoch: 98 [140928/221852 (64%)]\tLoss: 0.250183\tAcc: 77.00\n",
      "train epoch: 98 [153728/221852 (69%)]\tLoss: 0.181277\tAcc: 82.00\n",
      "train epoch: 98 [166528/221852 (75%)]\tLoss: 0.146566\tAcc: 80.00\n",
      "train epoch: 98 [179328/221852 (81%)]\tLoss: 0.136363\tAcc: 84.00\n",
      "train epoch: 98 [192128/221852 (87%)]\tLoss: 0.267288\tAcc: 77.00\n",
      "val epoch: 98 [128/221852 (0%)]\tLoss: 0.210509\tAcc: 80.00\n",
      "val epoch: 98 [12928/221852 (6%)]\tLoss: 0.198843\tAcc: 82.00\n",
      "train epoch: 99 [128/221852 (0%)]\tLoss: 0.230042\tAcc: 77.00\n",
      "train epoch: 99 [12928/221852 (6%)]\tLoss: 0.160274\tAcc: 80.00\n",
      "train epoch: 99 [25728/221852 (12%)]\tLoss: 0.144342\tAcc: 87.00\n",
      "train epoch: 99 [38528/221852 (17%)]\tLoss: 0.157787\tAcc: 81.00\n",
      "train epoch: 99 [51328/221852 (23%)]\tLoss: 0.241760\tAcc: 84.00\n",
      "train epoch: 99 [64128/221852 (29%)]\tLoss: 0.131603\tAcc: 74.00\n",
      "train epoch: 99 [76928/221852 (35%)]\tLoss: 0.170943\tAcc: 84.00\n",
      "train epoch: 99 [89728/221852 (40%)]\tLoss: 0.199051\tAcc: 83.00\n",
      "train epoch: 99 [102528/221852 (46%)]\tLoss: 0.158209\tAcc: 83.00\n",
      "train epoch: 99 [115328/221852 (52%)]\tLoss: 0.063956\tAcc: 85.00\n",
      "train epoch: 99 [128128/221852 (58%)]\tLoss: 0.174548\tAcc: 82.00\n",
      "train epoch: 99 [140928/221852 (64%)]\tLoss: 0.224945\tAcc: 80.00\n",
      "train epoch: 99 [153728/221852 (69%)]\tLoss: 0.257047\tAcc: 77.00\n",
      "train epoch: 99 [166528/221852 (75%)]\tLoss: 0.261020\tAcc: 80.00\n",
      "train epoch: 99 [179328/221852 (81%)]\tLoss: 0.113143\tAcc: 90.00\n",
      "train epoch: 99 [192128/221852 (87%)]\tLoss: 0.296133\tAcc: 80.00\n",
      "val epoch: 99 [128/221852 (0%)]\tLoss: 0.173231\tAcc: 81.00\n",
      "val epoch: 99 [12928/221852 (6%)]\tLoss: 0.221907\tAcc: 80.00\n",
      "train epoch: 100 [128/221852 (0%)]\tLoss: 0.150963\tAcc: 84.00\n",
      "train epoch: 100 [12928/221852 (6%)]\tLoss: 0.184060\tAcc: 83.00\n",
      "train epoch: 100 [25728/221852 (12%)]\tLoss: 0.190805\tAcc: 85.00\n",
      "train epoch: 100 [38528/221852 (17%)]\tLoss: 0.166085\tAcc: 84.00\n",
      "train epoch: 100 [51328/221852 (23%)]\tLoss: 0.148892\tAcc: 81.00\n",
      "train epoch: 100 [64128/221852 (29%)]\tLoss: 0.104696\tAcc: 81.00\n",
      "train epoch: 100 [76928/221852 (35%)]\tLoss: 0.270473\tAcc: 80.00\n",
      "train epoch: 100 [89728/221852 (40%)]\tLoss: 0.124345\tAcc: 84.00\n",
      "train epoch: 100 [102528/221852 (46%)]\tLoss: 0.243075\tAcc: 74.00\n",
      "train epoch: 100 [115328/221852 (52%)]\tLoss: 0.152038\tAcc: 85.00\n",
      "train epoch: 100 [128128/221852 (58%)]\tLoss: 0.156643\tAcc: 82.00\n",
      "train epoch: 100 [140928/221852 (64%)]\tLoss: 0.230400\tAcc: 80.00\n",
      "train epoch: 100 [153728/221852 (69%)]\tLoss: 0.112431\tAcc: 83.00\n",
      "train epoch: 100 [166528/221852 (75%)]\tLoss: 0.187959\tAcc: 82.00\n",
      "train epoch: 100 [179328/221852 (81%)]\tLoss: 0.067806\tAcc: 89.00\n",
      "train epoch: 100 [192128/221852 (87%)]\tLoss: 0.158026\tAcc: 83.00\n",
      "val epoch: 100 [128/221852 (0%)]\tLoss: 0.291008\tAcc: 80.00\n",
      "val epoch: 100 [12928/221852 (6%)]\tLoss: 0.238985\tAcc: 87.00\n",
      "train epoch: 101 [128/221852 (0%)]\tLoss: 0.241305\tAcc: 80.00\n",
      "train epoch: 101 [12928/221852 (6%)]\tLoss: 0.159825\tAcc: 80.00\n",
      "train epoch: 101 [25728/221852 (12%)]\tLoss: 0.176739\tAcc: 80.00\n",
      "train epoch: 101 [38528/221852 (17%)]\tLoss: 0.202552\tAcc: 83.00\n",
      "train epoch: 101 [51328/221852 (23%)]\tLoss: 0.133601\tAcc: 81.00\n",
      "train epoch: 101 [64128/221852 (29%)]\tLoss: 0.215667\tAcc: 79.00\n",
      "train epoch: 101 [76928/221852 (35%)]\tLoss: 0.178187\tAcc: 84.00\n",
      "train epoch: 101 [89728/221852 (40%)]\tLoss: 0.246639\tAcc: 84.00\n",
      "train epoch: 101 [102528/221852 (46%)]\tLoss: 0.188383\tAcc: 77.00\n",
      "train epoch: 101 [115328/221852 (52%)]\tLoss: 0.161266\tAcc: 84.00\n",
      "train epoch: 101 [128128/221852 (58%)]\tLoss: 0.218629\tAcc: 85.00\n",
      "train epoch: 101 [140928/221852 (64%)]\tLoss: 0.220900\tAcc: 82.00\n",
      "train epoch: 101 [153728/221852 (69%)]\tLoss: 0.120937\tAcc: 81.00\n",
      "train epoch: 101 [166528/221852 (75%)]\tLoss: 0.204037\tAcc: 75.00\n",
      "train epoch: 101 [179328/221852 (81%)]\tLoss: 0.132461\tAcc: 85.00\n",
      "train epoch: 101 [192128/221852 (87%)]\tLoss: 0.157158\tAcc: 84.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 101 [128/221852 (0%)]\tLoss: 0.131488\tAcc: 80.00\n",
      "val epoch: 101 [12928/221852 (6%)]\tLoss: 0.175112\tAcc: 80.00\n",
      "train epoch: 102 [128/221852 (0%)]\tLoss: 0.166011\tAcc: 80.00\n",
      "train epoch: 102 [12928/221852 (6%)]\tLoss: 0.231688\tAcc: 79.00\n",
      "train epoch: 102 [25728/221852 (12%)]\tLoss: 0.322215\tAcc: 77.00\n",
      "train epoch: 102 [38528/221852 (17%)]\tLoss: 0.273436\tAcc: 76.00\n",
      "train epoch: 102 [51328/221852 (23%)]\tLoss: 0.132954\tAcc: 90.00\n",
      "train epoch: 102 [64128/221852 (29%)]\tLoss: 0.220593\tAcc: 80.00\n",
      "train epoch: 102 [76928/221852 (35%)]\tLoss: 0.207084\tAcc: 84.00\n",
      "train epoch: 102 [89728/221852 (40%)]\tLoss: 0.160119\tAcc: 81.00\n",
      "train epoch: 102 [102528/221852 (46%)]\tLoss: 0.163643\tAcc: 84.00\n",
      "train epoch: 102 [115328/221852 (52%)]\tLoss: 0.253687\tAcc: 80.00\n",
      "train epoch: 102 [128128/221852 (58%)]\tLoss: 0.188975\tAcc: 80.00\n",
      "train epoch: 102 [140928/221852 (64%)]\tLoss: 0.263075\tAcc: 74.00\n",
      "train epoch: 102 [153728/221852 (69%)]\tLoss: 0.242110\tAcc: 80.00\n",
      "train epoch: 102 [166528/221852 (75%)]\tLoss: 0.201209\tAcc: 78.00\n",
      "train epoch: 102 [179328/221852 (81%)]\tLoss: 0.142601\tAcc: 81.00\n",
      "train epoch: 102 [192128/221852 (87%)]\tLoss: 0.228912\tAcc: 84.00\n",
      "val epoch: 102 [128/221852 (0%)]\tLoss: 0.219234\tAcc: 78.00\n",
      "val epoch: 102 [12928/221852 (6%)]\tLoss: 0.209144\tAcc: 81.00\n",
      "train epoch: 103 [128/221852 (0%)]\tLoss: 0.300283\tAcc: 73.00\n",
      "train epoch: 103 [12928/221852 (6%)]\tLoss: 0.151152\tAcc: 85.00\n",
      "train epoch: 103 [25728/221852 (12%)]\tLoss: 0.186635\tAcc: 80.00\n",
      "train epoch: 103 [38528/221852 (17%)]\tLoss: 0.178639\tAcc: 83.00\n",
      "train epoch: 103 [51328/221852 (23%)]\tLoss: 0.203113\tAcc: 80.00\n",
      "train epoch: 103 [64128/221852 (29%)]\tLoss: 0.319383\tAcc: 74.00\n",
      "train epoch: 103 [76928/221852 (35%)]\tLoss: 0.174635\tAcc: 77.00\n",
      "train epoch: 103 [89728/221852 (40%)]\tLoss: 0.137108\tAcc: 79.00\n",
      "train epoch: 103 [102528/221852 (46%)]\tLoss: 0.152548\tAcc: 82.00\n",
      "train epoch: 103 [115328/221852 (52%)]\tLoss: 0.157032\tAcc: 83.00\n",
      "train epoch: 103 [128128/221852 (58%)]\tLoss: 0.176041\tAcc: 84.00\n",
      "train epoch: 103 [140928/221852 (64%)]\tLoss: 0.244150\tAcc: 86.00\n",
      "train epoch: 103 [153728/221852 (69%)]\tLoss: 0.264791\tAcc: 74.00\n",
      "train epoch: 103 [166528/221852 (75%)]\tLoss: 0.102209\tAcc: 83.00\n",
      "train epoch: 103 [179328/221852 (81%)]\tLoss: 0.187056\tAcc: 82.00\n",
      "train epoch: 103 [192128/221852 (87%)]\tLoss: 0.165300\tAcc: 77.00\n",
      "val epoch: 103 [128/221852 (0%)]\tLoss: 0.159998\tAcc: 77.00\n",
      "val epoch: 103 [12928/221852 (6%)]\tLoss: 0.167516\tAcc: 77.00\n",
      "train epoch: 104 [128/221852 (0%)]\tLoss: 0.172589\tAcc: 77.00\n",
      "train epoch: 104 [12928/221852 (6%)]\tLoss: 0.157761\tAcc: 84.00\n",
      "train epoch: 104 [25728/221852 (12%)]\tLoss: 0.121523\tAcc: 82.00\n",
      "train epoch: 104 [38528/221852 (17%)]\tLoss: 0.286691\tAcc: 81.00\n",
      "train epoch: 104 [51328/221852 (23%)]\tLoss: 0.260052\tAcc: 77.00\n",
      "train epoch: 104 [64128/221852 (29%)]\tLoss: 0.154265\tAcc: 80.00\n",
      "train epoch: 104 [76928/221852 (35%)]\tLoss: 0.140176\tAcc: 83.00\n",
      "train epoch: 104 [89728/221852 (40%)]\tLoss: 0.171615\tAcc: 81.00\n",
      "train epoch: 104 [102528/221852 (46%)]\tLoss: 0.299706\tAcc: 77.00\n",
      "train epoch: 104 [115328/221852 (52%)]\tLoss: 0.136266\tAcc: 82.00\n",
      "train epoch: 104 [128128/221852 (58%)]\tLoss: 0.228611\tAcc: 73.00\n",
      "train epoch: 104 [140928/221852 (64%)]\tLoss: 0.236540\tAcc: 77.00\n",
      "train epoch: 104 [153728/221852 (69%)]\tLoss: 0.182889\tAcc: 80.00\n",
      "train epoch: 104 [166528/221852 (75%)]\tLoss: 0.182868\tAcc: 78.00\n",
      "train epoch: 104 [179328/221852 (81%)]\tLoss: 0.117880\tAcc: 84.00\n",
      "train epoch: 104 [192128/221852 (87%)]\tLoss: 0.145899\tAcc: 77.00\n",
      "val epoch: 104 [128/221852 (0%)]\tLoss: 0.201065\tAcc: 75.00\n",
      "val epoch: 104 [12928/221852 (6%)]\tLoss: 0.257785\tAcc: 79.00\n",
      "train epoch: 105 [128/221852 (0%)]\tLoss: 0.234991\tAcc: 83.00\n",
      "train epoch: 105 [12928/221852 (6%)]\tLoss: 0.117570\tAcc: 85.00\n",
      "train epoch: 105 [25728/221852 (12%)]\tLoss: 0.226207\tAcc: 88.00\n",
      "train epoch: 105 [38528/221852 (17%)]\tLoss: 0.230182\tAcc: 77.00\n",
      "train epoch: 105 [51328/221852 (23%)]\tLoss: 0.096682\tAcc: 83.00\n",
      "train epoch: 105 [64128/221852 (29%)]\tLoss: 0.135912\tAcc: 86.00\n",
      "train epoch: 105 [76928/221852 (35%)]\tLoss: 0.230272\tAcc: 79.00\n",
      "train epoch: 105 [89728/221852 (40%)]\tLoss: 0.189902\tAcc: 84.00\n",
      "train epoch: 105 [102528/221852 (46%)]\tLoss: 0.164844\tAcc: 76.00\n",
      "train epoch: 105 [115328/221852 (52%)]\tLoss: 0.116767\tAcc: 81.00\n",
      "train epoch: 105 [128128/221852 (58%)]\tLoss: 0.193558\tAcc: 84.00\n",
      "train epoch: 105 [140928/221852 (64%)]\tLoss: 0.196419\tAcc: 79.00\n",
      "train epoch: 105 [153728/221852 (69%)]\tLoss: 0.190540\tAcc: 81.00\n",
      "train epoch: 105 [166528/221852 (75%)]\tLoss: 0.149727\tAcc: 83.00\n",
      "train epoch: 105 [179328/221852 (81%)]\tLoss: 0.137786\tAcc: 88.00\n",
      "train epoch: 105 [192128/221852 (87%)]\tLoss: 0.162088\tAcc: 81.00\n",
      "val epoch: 105 [128/221852 (0%)]\tLoss: 0.158174\tAcc: 87.00\n",
      "val epoch: 105 [12928/221852 (6%)]\tLoss: 0.302535\tAcc: 78.00\n",
      "train epoch: 106 [128/221852 (0%)]\tLoss: 0.234121\tAcc: 85.00\n",
      "train epoch: 106 [12928/221852 (6%)]\tLoss: 0.147313\tAcc: 88.00\n",
      "train epoch: 106 [25728/221852 (12%)]\tLoss: 0.228876\tAcc: 80.00\n",
      "train epoch: 106 [38528/221852 (17%)]\tLoss: 0.217526\tAcc: 79.00\n",
      "train epoch: 106 [51328/221852 (23%)]\tLoss: 0.204024\tAcc: 79.00\n",
      "train epoch: 106 [64128/221852 (29%)]\tLoss: 0.183128\tAcc: 83.00\n",
      "train epoch: 106 [76928/221852 (35%)]\tLoss: 0.223306\tAcc: 79.00\n",
      "train epoch: 106 [89728/221852 (40%)]\tLoss: 0.185618\tAcc: 84.00\n",
      "train epoch: 106 [102528/221852 (46%)]\tLoss: 0.282926\tAcc: 73.00\n",
      "train epoch: 106 [115328/221852 (52%)]\tLoss: 0.187873\tAcc: 82.00\n",
      "train epoch: 106 [128128/221852 (58%)]\tLoss: 0.199666\tAcc: 79.00\n",
      "train epoch: 106 [140928/221852 (64%)]\tLoss: 0.208086\tAcc: 84.00\n",
      "train epoch: 106 [153728/221852 (69%)]\tLoss: 0.123941\tAcc: 87.00\n",
      "train epoch: 106 [166528/221852 (75%)]\tLoss: 0.225310\tAcc: 82.00\n",
      "train epoch: 106 [179328/221852 (81%)]\tLoss: 0.318515\tAcc: 71.00\n",
      "train epoch: 106 [192128/221852 (87%)]\tLoss: 0.180209\tAcc: 79.00\n",
      "val epoch: 106 [128/221852 (0%)]\tLoss: 0.250679\tAcc: 82.00\n",
      "val epoch: 106 [12928/221852 (6%)]\tLoss: 0.260372\tAcc: 82.00\n",
      "train epoch: 107 [128/221852 (0%)]\tLoss: 0.206810\tAcc: 81.00\n",
      "train epoch: 107 [12928/221852 (6%)]\tLoss: 0.178921\tAcc: 77.00\n",
      "train epoch: 107 [25728/221852 (12%)]\tLoss: 0.197340\tAcc: 82.00\n",
      "train epoch: 107 [38528/221852 (17%)]\tLoss: 0.157321\tAcc: 80.00\n",
      "train epoch: 107 [51328/221852 (23%)]\tLoss: 0.252979\tAcc: 80.00\n",
      "train epoch: 107 [64128/221852 (29%)]\tLoss: 0.154454\tAcc: 88.00\n",
      "train epoch: 107 [76928/221852 (35%)]\tLoss: 0.179249\tAcc: 78.00\n",
      "train epoch: 107 [89728/221852 (40%)]\tLoss: 0.282343\tAcc: 84.00\n",
      "train epoch: 107 [102528/221852 (46%)]\tLoss: 0.196307\tAcc: 75.00\n",
      "train epoch: 107 [115328/221852 (52%)]\tLoss: 0.242627\tAcc: 80.00\n",
      "train epoch: 107 [128128/221852 (58%)]\tLoss: 0.116948\tAcc: 82.00\n",
      "train epoch: 107 [140928/221852 (64%)]\tLoss: 0.208077\tAcc: 76.00\n",
      "train epoch: 107 [153728/221852 (69%)]\tLoss: 0.132163\tAcc: 83.00\n",
      "train epoch: 107 [166528/221852 (75%)]\tLoss: 0.150510\tAcc: 82.00\n",
      "train epoch: 107 [179328/221852 (81%)]\tLoss: 0.114600\tAcc: 88.00\n",
      "train epoch: 107 [192128/221852 (87%)]\tLoss: 0.155703\tAcc: 87.00\n",
      "val epoch: 107 [128/221852 (0%)]\tLoss: 0.144684\tAcc: 86.00\n",
      "val epoch: 107 [12928/221852 (6%)]\tLoss: 0.232689\tAcc: 77.00\n",
      "train epoch: 108 [128/221852 (0%)]\tLoss: 0.209283\tAcc: 78.00\n",
      "train epoch: 108 [12928/221852 (6%)]\tLoss: 0.170644\tAcc: 84.00\n",
      "train epoch: 108 [25728/221852 (12%)]\tLoss: 0.215331\tAcc: 79.00\n",
      "train epoch: 108 [38528/221852 (17%)]\tLoss: 0.206697\tAcc: 78.00\n",
      "train epoch: 108 [51328/221852 (23%)]\tLoss: 0.153256\tAcc: 82.00\n",
      "train epoch: 108 [64128/221852 (29%)]\tLoss: 0.241840\tAcc: 82.00\n",
      "train epoch: 108 [76928/221852 (35%)]\tLoss: 0.233585\tAcc: 82.00\n",
      "train epoch: 108 [89728/221852 (40%)]\tLoss: 0.165593\tAcc: 91.00\n",
      "train epoch: 108 [102528/221852 (46%)]\tLoss: 0.181881\tAcc: 75.00\n",
      "train epoch: 108 [115328/221852 (52%)]\tLoss: 0.104746\tAcc: 80.00\n",
      "train epoch: 108 [128128/221852 (58%)]\tLoss: 0.182767\tAcc: 84.00\n",
      "train epoch: 108 [140928/221852 (64%)]\tLoss: 0.159885\tAcc: 83.00\n",
      "train epoch: 108 [153728/221852 (69%)]\tLoss: 0.121030\tAcc: 81.00\n",
      "train epoch: 108 [166528/221852 (75%)]\tLoss: 0.184416\tAcc: 78.00\n",
      "train epoch: 108 [179328/221852 (81%)]\tLoss: 0.168251\tAcc: 87.00\n",
      "train epoch: 108 [192128/221852 (87%)]\tLoss: 0.236445\tAcc: 73.00\n",
      "val epoch: 108 [128/221852 (0%)]\tLoss: 0.186724\tAcc: 83.00\n",
      "val epoch: 108 [12928/221852 (6%)]\tLoss: 0.121839\tAcc: 84.00\n",
      "train epoch: 109 [128/221852 (0%)]\tLoss: 0.248833\tAcc: 69.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 109 [12928/221852 (6%)]\tLoss: 0.209624\tAcc: 79.00\n",
      "train epoch: 109 [25728/221852 (12%)]\tLoss: 0.174547\tAcc: 77.00\n",
      "train epoch: 109 [38528/221852 (17%)]\tLoss: 0.197113\tAcc: 80.00\n",
      "train epoch: 109 [51328/221852 (23%)]\tLoss: 0.119034\tAcc: 77.00\n",
      "train epoch: 109 [64128/221852 (29%)]\tLoss: 0.177104\tAcc: 84.00\n",
      "train epoch: 109 [76928/221852 (35%)]\tLoss: 0.107653\tAcc: 82.00\n",
      "train epoch: 109 [89728/221852 (40%)]\tLoss: 0.199941\tAcc: 78.00\n",
      "train epoch: 109 [102528/221852 (46%)]\tLoss: 0.177340\tAcc: 86.00\n",
      "train epoch: 109 [115328/221852 (52%)]\tLoss: 0.217388\tAcc: 78.00\n",
      "train epoch: 109 [128128/221852 (58%)]\tLoss: 0.214069\tAcc: 77.00\n",
      "train epoch: 109 [140928/221852 (64%)]\tLoss: 0.165984\tAcc: 78.00\n",
      "train epoch: 109 [153728/221852 (69%)]\tLoss: 0.180802\tAcc: 77.00\n",
      "train epoch: 109 [166528/221852 (75%)]\tLoss: 0.141549\tAcc: 92.00\n",
      "train epoch: 109 [179328/221852 (81%)]\tLoss: 0.160936\tAcc: 81.00\n",
      "train epoch: 109 [192128/221852 (87%)]\tLoss: 0.105296\tAcc: 86.00\n",
      "val epoch: 109 [128/221852 (0%)]\tLoss: 0.261933\tAcc: 81.00\n",
      "val epoch: 109 [12928/221852 (6%)]\tLoss: 0.171310\tAcc: 83.00\n",
      "train epoch: 110 [128/221852 (0%)]\tLoss: 0.173129\tAcc: 85.00\n",
      "train epoch: 110 [12928/221852 (6%)]\tLoss: 0.306383\tAcc: 75.00\n",
      "train epoch: 110 [25728/221852 (12%)]\tLoss: 0.164944\tAcc: 75.00\n",
      "train epoch: 110 [38528/221852 (17%)]\tLoss: 0.173822\tAcc: 80.00\n",
      "train epoch: 110 [51328/221852 (23%)]\tLoss: 0.131344\tAcc: 80.00\n",
      "train epoch: 110 [64128/221852 (29%)]\tLoss: 0.166917\tAcc: 85.00\n",
      "train epoch: 110 [76928/221852 (35%)]\tLoss: 0.149962\tAcc: 77.00\n",
      "train epoch: 110 [89728/221852 (40%)]\tLoss: 0.156745\tAcc: 85.00\n",
      "train epoch: 110 [102528/221852 (46%)]\tLoss: 0.143903\tAcc: 80.00\n",
      "train epoch: 110 [115328/221852 (52%)]\tLoss: 0.137507\tAcc: 82.00\n",
      "train epoch: 110 [128128/221852 (58%)]\tLoss: 0.135002\tAcc: 89.00\n",
      "train epoch: 110 [140928/221852 (64%)]\tLoss: 0.191052\tAcc: 86.00\n",
      "train epoch: 110 [153728/221852 (69%)]\tLoss: 0.262330\tAcc: 71.00\n",
      "train epoch: 110 [166528/221852 (75%)]\tLoss: 0.322449\tAcc: 81.00\n",
      "train epoch: 110 [179328/221852 (81%)]\tLoss: 0.151060\tAcc: 86.00\n",
      "train epoch: 110 [192128/221852 (87%)]\tLoss: 0.201202\tAcc: 79.00\n",
      "val epoch: 110 [128/221852 (0%)]\tLoss: 0.155828\tAcc: 82.00\n",
      "val epoch: 110 [12928/221852 (6%)]\tLoss: 0.163244\tAcc: 81.00\n",
      "train epoch: 111 [128/221852 (0%)]\tLoss: 0.145300\tAcc: 80.00\n",
      "train epoch: 111 [12928/221852 (6%)]\tLoss: 0.345722\tAcc: 80.00\n",
      "train epoch: 111 [25728/221852 (12%)]\tLoss: 0.161668\tAcc: 84.00\n",
      "train epoch: 111 [38528/221852 (17%)]\tLoss: 0.252819\tAcc: 80.00\n",
      "train epoch: 111 [51328/221852 (23%)]\tLoss: 0.175720\tAcc: 83.00\n",
      "train epoch: 111 [64128/221852 (29%)]\tLoss: 0.188516\tAcc: 80.00\n"
     ]
    }
   ],
   "source": [
    "for hl in HL:\n",
    "    model_loop = Net(f, 1, hl)\n",
    "    model_loop.to(device)\n",
    "#     summary(model_loop, (1, f))\n",
    "    optimizer = optim.Adam(model_loop.parameters(), lr=float(LEARNING_RATE))\n",
    "    \n",
    "    layers= str(len(hl))+'hl'\n",
    "    model_dir = model_path + model_name+'_'+layers\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)    \n",
    "    metrics_path = os.path.join(model_dir, 'metrics.json')\n",
    "    \n",
    "    metrics = {\n",
    "        'model': model_dir,\n",
    "        'optimizer': optimizer.__class__.__name__,\n",
    "        'criterion': criterion.__class__.__name__,\n",
    "    #     'scheduler': scheduler.__class__.__name__,\n",
    "        'dataset_size': int(len(dataset)),\n",
    "        'train_size': int(split[0]*len(dataset)),\n",
    "        'test_size': int(split[1]*len(dataset)),\n",
    "        'n_epoch': nb_epoch,\n",
    "        'batch_size': batch_size,\n",
    "    #     'learning_rate': [],\n",
    "        'train_loss': [],\n",
    "        'val_loss': []\n",
    "    }\n",
    "    \n",
    "    train(nb_epoch, model_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "petitRT",
   "language": "python",
   "name": "petitrt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
